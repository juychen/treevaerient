{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreeVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Of Contents\n",
    "1. [Data Loading](#section_1)\n",
    "2. [Generations](#section_2)\n",
    "3. [Reconstructions](#section_3)\n",
    "4. [Tree and Representation Analysis](#section_4)\n",
    "5. [CelebA Attributes](#section_5)\n",
    "\n",
    "This is the notebook for analyzing and visualizing the trees learnt by TreeVAE. \n",
    "\n",
    "Trees can be learnt by running main.py and stored by setting the option save_model to True in the config file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_1\"></a> 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always execute this section first. This section loads the data and model and computes the NMI to ensure that the model was loaded correctly. Make sure to set the path in the second cell to the specific model that you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from models.model import TreeVAE\n",
    "import scipy\n",
    "import os\n",
    "import yaml\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score\n",
    "from pathlib import Path\n",
    "from utils.utils import reset_random_seeds, display_image\n",
    "from utils.data_utils import get_data, get_gen\n",
    "from utils.training_utils import compute_leaves, predict, move_to\n",
    "from train.validate_tree import compute_likelihood\n",
    "from models.model_smalltree import SmallTreeVAE\n",
    "from models.losses import loss_reconstruction_binary, loss_reconstruction_mse, loss_reconstruction_cov_mse_eval\n",
    "from utils.model_utils import Node, construct_tree_fromnpy, return_list_tree, construct_data_tree, construct_tree_fromnpy\n",
    "from utils.plotting_utils import plot_tree_graph, get_node_embeddings, draw_tree_with_scatter_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'data_name': 'waldvarient', 'num_clusters_data': 10, 'return_full_data': False, 'varient_path': '/home/junyi/code/treevae/data/Variant/bpdcn712_assemble_trimmed_aligned_mt_addtag_cellSNP0_WaldVariant_paperCell/'}, 'globals': {'config_name': 'waldvarient', 'eager_mode': True, 'results_dir': PosixPath('/home/junyi/code/treevae/models/experiments'), 'save_model': True, 'seed': 42, 'wandb_logging': 'disabled'}, 'parser': {}, 'run_name': 'waldvarient', 'training': {'activation': 'afdpce', 'aug_decisions_weight': 1, 'augment': False, 'augmentation_method': ['simple'], 'batch_size': 256, 'compute_ll': False, 'decay_kl': 0.001, 'decay_lr': 0.1, 'decay_stepsize': 100, 'encoder': 'mlp', 'grow': True, 'initial_depth': 1, 'inp_shape': 7318, 'input_data': 'varient', 'kl_start': 0.0, 'latent_dim': [32, 32, 32], 'lr': 0.001, 'mlp_layers': [128, 128, 128], 'num_clusters_tree': 10, 'num_epochs': 150, 'num_epochs_finetuning': 200, 'num_epochs_intermediate_fulltrain': 80, 'num_epochs_smalltree': 150, 'prune': True, 'weight_decay': 1e-05}}\n"
     ]
    }
   ],
   "source": [
    "path = 'models/experiments/'\n",
    "#ex_path = 'waldvarient/20240517-152258_398b7' # INSERT YOUR PATH HERE previous\n",
    "#ex_path = 'waldvarient/20240520-165201_0bf0e'\n",
    "#ex_path = 'waldvarient/20240521-160839_c28bd'\n",
    "#ex_path = 'waldvarient/20240521-162133_3c9cd'\n",
    "#ex_path = 'waldvarient/20240521-163048_ad4c3'\n",
    "ex_path = 'waldvarient/20240521-170839_436af'\n",
    "checkpoint_path = path+ex_path\n",
    "with open(checkpoint_path + \"/config.yaml\", 'r') as stream:\n",
    "    configs = yaml.load(stream,Loader=yaml.Loader)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'data_name': 'waldvarient',\n",
       "  'num_clusters_data': 10,\n",
       "  'return_full_data': False,\n",
       "  'varient_path': '/home/junyi/code/treevae/data/Variant/bpdcn712_assemble_trimmed_aligned_mt_addtag_cellSNP0_WaldVariant_paperCell/'},\n",
       " 'globals': {'config_name': 'waldvarient',\n",
       "  'eager_mode': True,\n",
       "  'results_dir': PosixPath('/home/junyi/code/treevae/models/experiments'),\n",
       "  'save_model': True,\n",
       "  'seed': 42,\n",
       "  'wandb_logging': 'disabled'},\n",
       " 'parser': {},\n",
       " 'run_name': 'waldvarient',\n",
       " 'training': {'activation': 'afdpce',\n",
       "  'aug_decisions_weight': 1,\n",
       "  'augment': False,\n",
       "  'augmentation_method': ['simple'],\n",
       "  'batch_size': 256,\n",
       "  'compute_ll': False,\n",
       "  'decay_kl': 0.001,\n",
       "  'decay_lr': 0.1,\n",
       "  'decay_stepsize': 100,\n",
       "  'encoder': 'mlp',\n",
       "  'grow': True,\n",
       "  'initial_depth': 1,\n",
       "  'inp_shape': 7318,\n",
       "  'input_data': 'varient',\n",
       "  'kl_start': 0.0,\n",
       "  'latent_dim': [32, 32, 32],\n",
       "  'lr': 0.001,\n",
       "  'mlp_layers': [128, 128, 128],\n",
       "  'num_clusters_tree': 10,\n",
       "  'num_epochs': 150,\n",
       "  'num_epochs_finetuning': 200,\n",
       "  'num_epochs_intermediate_fulltrain': 80,\n",
       "  'num_epochs_smalltree': 150,\n",
       "  'prune': True,\n",
       "  'weight_decay': 1e-05}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waldvarient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyi/code/treevae/utils/data_utils.py:332: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainset.dataset.targets = torch.tensor(trainset.dataset.tensors[1])\n",
      "/home/junyi/code/treevae/utils/data_utils.py:333: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainset_eval.dataset.targets = torch.tensor(trainset_eval.dataset.tensors[1])\n",
      "/home/junyi/code/treevae/utils/data_utils.py:334: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  testset.dataset.targets = torch.tensor(testset.dataset.tensors[1])\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "configs['data'].update({'return_full_data': True})\n",
    "trainset, trainset_eval, testset = get_data(configs)\n",
    "gen_train = get_gen(trainset, configs, validation=False, shuffle=False)\n",
    "gen_train_eval = get_gen(trainset_eval, configs, validation=True, shuffle=False)\n",
    "gen_test = get_gen(testset, configs, validation=True, shuffle=False)\n",
    "gen_train_eval_iter = iter(gen_train_eval)\n",
    "gen_test_iter = iter(gen_test)\n",
    "y_train = trainset_eval.dataset.targets[trainset_eval.indices].numpy()\n",
    "y_test = testset.dataset.targets[testset.indices].numpy()\n",
    "\n",
    "# Load Model\n",
    "n_d = configs['training']['num_clusters_tree']\n",
    "configs[\"input_data\"]='varient'\n",
    "model = TreeVAE(**configs['training'])\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "data_tree = np.load(checkpoint_path+'/data_tree.npy', allow_pickle=True)\n",
    "model = construct_tree_fromnpy(model, data_tree, configs)\n",
    "if not configs['globals']['eager_mode']:\n",
    "    model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f3b92154e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bottom_up.0.dense1.weight',\n",
       "              tensor([[ 0.0165,  0.0030,  0.0076,  ..., -0.0038, -0.0039, -0.0068],\n",
       "                      [-0.0101,  0.0126, -0.0130,  ...,  0.0027, -0.0046,  0.0160],\n",
       "                      [-0.0017,  0.0053,  0.0093,  ...,  0.0159, -0.0115,  0.0012],\n",
       "                      ...,\n",
       "                      [-0.0017, -0.0034, -0.0145,  ...,  0.0039,  0.0033,  0.0053],\n",
       "                      [ 0.0014,  0.0011,  0.0017,  ...,  0.0016, -0.0014,  0.0048],\n",
       "                      [-0.0179,  0.0230, -0.0201,  ..., -0.0040,  0.0162,  0.0048]])),\n",
       "             ('bottom_up.0.bn1.weight',\n",
       "              tensor([1.0067, 1.0165, 1.0048, 1.0066, 0.9911, 0.9979, 0.9866, 1.0145, 0.9851,\n",
       "                      0.9853, 0.9968, 0.9960, 0.9863, 0.9931, 0.9900, 0.9849, 0.9934, 1.0024,\n",
       "                      0.9897, 1.0057, 0.9931, 1.0015, 0.9915, 0.9944, 0.9996, 1.0046, 0.9971,\n",
       "                      1.0157, 1.0005, 1.0058, 1.0024, 0.9927, 0.9953, 0.9843, 0.9904, 1.0094,\n",
       "                      1.0042, 0.9869, 0.9895, 1.0051, 1.0029, 1.0040, 0.9951, 1.0117, 0.9996,\n",
       "                      1.0098, 1.0104, 1.0072, 0.9978, 1.0040, 1.0098, 0.9919, 0.9974, 0.9965,\n",
       "                      0.9903, 1.0093, 0.9930, 0.9957, 0.9994, 0.9998, 0.9934, 1.0082, 1.0068,\n",
       "                      1.0215, 0.9995, 1.0140, 0.9983, 1.0040, 0.9932, 0.9989, 0.9899, 1.0006,\n",
       "                      0.9857, 1.0025, 1.0075, 0.9974, 1.0033, 0.9927, 0.9902, 0.9969, 0.9970,\n",
       "                      0.9892, 1.0142, 1.0209, 1.0063, 1.0032, 0.9993, 1.0006, 1.0022, 1.0072,\n",
       "                      0.9982, 1.0006, 1.0078, 1.0050, 1.0032, 0.9932, 0.9926, 0.9948, 0.9924,\n",
       "                      1.0111, 1.0084, 0.9974, 1.0032, 0.9892, 1.0027, 1.0099, 0.9930, 0.9929,\n",
       "                      1.0147, 0.9856, 1.0137, 0.9917, 1.0072, 1.0111, 0.9892, 0.9914, 0.9988,\n",
       "                      0.9948, 1.0001, 0.9933, 0.9952, 0.9881, 1.0134, 0.9923, 1.0138, 1.0095,\n",
       "                      0.9848, 1.0021, 0.9955, 1.0043, 0.9884, 0.9922, 1.0055, 1.0143, 0.9938,\n",
       "                      1.0014, 1.0077, 1.0064, 1.0037, 1.0127, 0.9962, 1.0054, 1.0053, 0.9970,\n",
       "                      0.9932, 0.9983, 0.9868, 1.0017, 0.9964, 1.0108, 0.9867, 1.0055, 1.0093,\n",
       "                      1.0002, 0.9979, 1.0101, 1.0052, 1.0001, 0.9996, 1.0042, 1.0005, 1.0028,\n",
       "                      1.0044, 0.9985, 1.0018, 1.0022, 0.9986, 1.0037, 1.0081, 1.0019, 1.0021,\n",
       "                      0.9999, 0.9978, 0.9968, 0.9877, 1.0133, 0.9968, 0.9997, 0.9895, 1.0057,\n",
       "                      0.9953, 1.0026, 1.0027, 0.9911, 1.0004, 1.0158, 1.0155, 0.9999, 1.0108,\n",
       "                      0.9980, 1.0049, 0.9929, 0.9895, 1.0083, 0.9889, 0.9806, 0.9990, 0.9882,\n",
       "                      0.9939, 0.9898, 1.0004, 1.0112, 0.9956, 1.0209, 1.0079, 0.9932, 1.0016,\n",
       "                      0.9972, 1.0044, 0.9864, 0.9981, 1.0011, 0.9916, 0.9848, 1.0054, 1.0106,\n",
       "                      0.9889, 0.9956, 0.9923, 0.9931, 0.9963, 1.0082, 0.9917, 1.0136, 0.9998,\n",
       "                      1.0009, 0.9966, 0.9933, 0.9957, 0.9947, 0.9975, 1.0061, 0.9993, 0.9908,\n",
       "                      0.9979, 1.0026, 1.0061, 1.0079, 0.9976, 0.9819, 0.9938, 0.9930, 1.0160,\n",
       "                      1.0036, 0.9857, 1.0083, 0.9853, 1.0053, 0.9984, 0.9973, 1.0049, 1.0024,\n",
       "                      1.0028, 0.9943, 0.9974, 1.0076, 1.0001, 1.0020, 1.0084, 1.0024, 0.9960,\n",
       "                      0.9978, 0.9987, 0.9985, 1.0031, 0.9908, 0.9850, 1.0067, 0.9906, 0.9873,\n",
       "                      0.9972, 0.9881, 1.0024, 0.9970, 1.0083, 1.0045, 1.0119, 0.9971, 1.0063,\n",
       "                      1.0006, 0.9933, 0.9903, 0.9969, 0.9994, 0.9763, 0.9844, 1.0173, 1.0069,\n",
       "                      0.9842, 0.9911, 0.9994, 1.0041, 1.0062, 0.9973, 1.0025, 0.9905, 0.9843,\n",
       "                      1.0070, 1.0070, 0.9892, 0.9921, 1.0072, 1.0175, 0.9889, 0.9998, 0.9916,\n",
       "                      0.9955, 0.9966, 1.0145, 0.9899, 1.0094, 0.9951, 0.9992, 0.9996, 1.0050,\n",
       "                      1.0019, 1.0036, 1.0119, 1.0029, 1.0036, 0.9983, 0.9923, 0.9889, 1.0011,\n",
       "                      1.0085, 0.9913, 0.9928, 1.0081, 0.9947, 1.0160, 0.9906, 0.9838, 0.9950,\n",
       "                      0.9979, 0.9879, 1.0009, 0.9851, 0.9956, 1.0092, 0.9967, 1.0167, 1.0021,\n",
       "                      0.9848, 0.9934, 0.9945, 1.0054, 0.9974, 1.0123, 0.9891, 0.9910, 0.9973,\n",
       "                      0.9875, 0.9945, 0.9940, 0.9964, 1.0079, 0.9997, 0.9971, 0.9923, 0.9972,\n",
       "                      1.0115, 0.9891, 1.0003, 1.0007, 0.9966, 1.0088, 0.9981, 0.9895, 1.0023,\n",
       "                      1.0006, 1.0116, 0.9869, 0.9898, 0.9836, 1.0014, 0.9961, 1.0117, 0.9957,\n",
       "                      0.9874, 0.9888, 0.9987, 1.0050, 1.0049, 0.9874, 1.0072, 0.9932, 1.0063,\n",
       "                      1.0134, 0.9942, 0.9986, 0.9953, 1.0021, 1.0067, 0.9864, 0.9942, 0.9937,\n",
       "                      0.9901, 0.9921, 1.0027, 0.9987, 1.0036, 1.0014, 0.9958, 1.0008, 0.9876,\n",
       "                      1.0099, 1.0030, 1.0147, 0.9883, 1.0101, 1.0043, 0.9851, 0.9991, 0.9804,\n",
       "                      1.0013, 0.9937, 0.9980, 0.9888, 1.0042, 0.9877, 1.0007, 0.9984, 1.0028,\n",
       "                      0.9920, 1.0061, 1.0000, 1.0053, 1.0022, 1.0029, 1.0026, 0.9835, 1.0122,\n",
       "                      1.0026, 0.9922, 0.9840, 1.0098, 1.0098, 1.0021, 1.0015, 0.9932, 1.0009,\n",
       "                      0.9994, 0.9976, 1.0036, 0.9920, 0.9898, 0.9972, 0.9867, 0.9978, 1.0045,\n",
       "                      0.9939, 0.9964, 1.0092, 1.0084, 0.9961, 1.0062, 0.9864, 0.9863, 0.9848,\n",
       "                      0.9922, 0.9892, 1.0075, 1.0049, 1.0001, 1.0055, 1.0022, 0.9862, 0.9850,\n",
       "                      1.0039, 0.9943, 0.9859, 0.9989, 1.0054, 0.9905, 1.0032, 0.9950, 0.9985,\n",
       "                      1.0114, 0.9982, 1.0037, 0.9897, 0.9959, 0.9935, 0.9843, 1.0002, 0.9874,\n",
       "                      1.0052, 0.9922, 0.9984, 1.0055, 0.9909, 0.9996, 0.9878, 0.9979, 0.9997,\n",
       "                      0.9832, 1.0060, 0.9932, 0.9981, 0.9982, 0.9981, 1.0071, 0.9996, 0.9857,\n",
       "                      0.9861, 1.0081, 1.0078, 0.9915, 0.9908, 1.0001, 1.0067, 1.0150])),\n",
       "             ('bottom_up.0.bn1.bias',\n",
       "              tensor([ 1.8891e-02,  1.6313e-02,  1.0568e-02,  1.4102e-02, -7.4774e-03,\n",
       "                       6.5564e-03, -1.6121e-02,  1.9061e-02, -1.5723e-02, -1.7935e-02,\n",
       "                       5.8281e-03,  7.3068e-03, -1.6233e-03,  4.8851e-03, -1.0083e-02,\n",
       "                      -2.0913e-02, -5.5603e-03,  1.2540e-02,  1.2335e-02,  3.5395e-03,\n",
       "                      -6.1506e-04, -3.4795e-03,  4.7586e-03,  8.8278e-03,  9.1012e-03,\n",
       "                       7.8534e-03, -9.7098e-03,  3.1643e-02,  1.2264e-03,  1.7043e-02,\n",
       "                       2.2465e-02, -5.7017e-03, -5.6769e-03, -1.7388e-02, -4.5971e-03,\n",
       "                       6.7547e-03,  8.8606e-03, -4.7673e-03, -1.1671e-02,  2.5327e-02,\n",
       "                       2.5169e-02,  2.4084e-02,  1.4101e-02,  1.7025e-02,  1.5639e-02,\n",
       "                       2.4532e-02,  1.6587e-02,  2.4619e-03, -3.3604e-03,  3.1165e-02,\n",
       "                       1.5501e-02,  6.0214e-03,  1.3389e-02, -6.9059e-03, -6.0831e-03,\n",
       "                       2.2619e-02, -1.4062e-02, -1.1387e-02,  5.6118e-03,  6.6657e-03,\n",
       "                      -5.3824e-03,  2.0659e-02,  1.1406e-02,  2.6303e-02, -6.7323e-03,\n",
       "                       2.1941e-02,  8.7393e-03,  3.0443e-03, -5.5413e-03,  4.6133e-03,\n",
       "                      -1.3477e-02,  1.3693e-02,  2.8154e-03, -7.2242e-03,  1.5213e-02,\n",
       "                       4.7835e-03,  7.7375e-03,  1.4170e-03, -3.2520e-03,  1.2476e-02,\n",
       "                       1.0596e-02, -1.4046e-02,  1.8847e-02,  2.0636e-02,  1.2131e-02,\n",
       "                       1.3892e-02,  1.4084e-02, -1.1581e-03,  4.9527e-03,  1.0034e-02,\n",
       "                       3.7295e-03, -1.2445e-03,  6.9343e-03,  2.8122e-04,  1.5746e-02,\n",
       "                       5.5251e-03, -7.9001e-03,  3.6147e-03, -1.1951e-03,  2.0556e-02,\n",
       "                       2.7849e-02,  3.5663e-03,  9.0935e-03,  7.7850e-04,  5.5006e-03,\n",
       "                       5.1453e-03, -8.1913e-03, -5.4858e-03,  1.8163e-02, -1.3546e-02,\n",
       "                       1.5802e-02,  4.8601e-03,  1.6134e-02,  2.1243e-02, -3.4893e-03,\n",
       "                      -1.2530e-04, -1.0427e-02, -3.2413e-03,  4.1280e-03,  6.4816e-03,\n",
       "                       1.1661e-02, -2.4042e-03,  1.8740e-02, -8.4082e-03,  1.2485e-02,\n",
       "                       1.2169e-02, -1.1840e-02,  2.1220e-03, -9.3055e-03,  1.5228e-02,\n",
       "                      -5.7112e-04, -2.9823e-03,  6.0941e-03,  2.3822e-02,  1.5047e-03,\n",
       "                       5.4772e-03,  1.0088e-02,  1.5794e-02,  2.4174e-02,  2.6132e-02,\n",
       "                      -3.4823e-04,  7.9918e-03,  1.7978e-02, -4.3757e-03, -1.6962e-02,\n",
       "                       1.4062e-02,  3.9755e-03,  4.2657e-03, -1.4758e-03,  2.2387e-02,\n",
       "                      -5.4558e-03,  1.9778e-02,  1.9983e-02,  1.6998e-02,  2.7378e-04,\n",
       "                       1.6841e-02,  2.4544e-02,  1.2140e-03,  1.1522e-02,  9.2172e-03,\n",
       "                       2.0118e-02,  8.5310e-03,  1.2158e-02,  6.3840e-03,  6.0969e-03,\n",
       "                       3.0340e-03,  1.3342e-02,  1.3516e-02,  1.1265e-02,  9.3140e-04,\n",
       "                       8.1810e-03,  7.5015e-03,  2.1673e-02, -7.9343e-04, -1.1037e-02,\n",
       "                       1.8343e-03,  7.5310e-03, -1.0929e-02, -8.5905e-03,  6.2927e-03,\n",
       "                       2.2227e-04,  1.4960e-02,  7.6591e-03, -5.8800e-03,  5.0984e-04,\n",
       "                       2.4911e-02,  2.8388e-02,  7.7112e-03,  6.0359e-03,  2.0636e-02,\n",
       "                       1.7197e-02,  3.3981e-03, -8.6243e-03,  1.7672e-02, -1.0158e-02,\n",
       "                      -1.1174e-02, -7.2715e-03,  4.8923e-03, -6.5151e-03, -5.8976e-03,\n",
       "                      -6.3984e-03,  1.9487e-02, -2.8147e-03,  2.0847e-02,  1.7975e-02,\n",
       "                       2.1318e-03,  8.3293e-03, -6.8464e-04,  7.2243e-03, -4.1614e-03,\n",
       "                       1.1448e-02,  9.0171e-03,  1.1120e-03, -6.0527e-03,  2.4806e-02,\n",
       "                       1.1738e-02, -6.1282e-03,  9.2189e-03, -8.5890e-04, -8.7830e-03,\n",
       "                       2.1247e-03,  9.4776e-03, -1.7721e-02,  1.9313e-02,  7.7979e-03,\n",
       "                       9.4079e-03, -2.4486e-03,  5.2672e-03, -5.0777e-03, -8.1806e-03,\n",
       "                      -3.1976e-03,  9.9083e-03,  4.6644e-03,  4.0840e-03,  2.9502e-03,\n",
       "                       1.1624e-03,  1.2614e-02,  2.0487e-02,  5.6890e-03, -1.2713e-02,\n",
       "                      -1.0723e-02, -4.8570e-03,  1.6581e-02,  4.8911e-03, -1.1228e-02,\n",
       "                       6.9527e-03, -8.8896e-03,  1.4673e-02,  1.8601e-02, -3.7563e-03,\n",
       "                       1.4014e-02,  5.1439e-03,  1.9317e-02,  1.5852e-03, -4.8319e-03,\n",
       "                       1.2369e-02,  4.0273e-03,  4.5878e-03,  1.9208e-02,  5.4134e-03,\n",
       "                      -6.8906e-03,  3.3551e-03,  1.1812e-02,  1.1188e-03,  2.3579e-02,\n",
       "                      -1.5789e-02, -5.2391e-03,  1.9454e-02,  1.0688e-03, -9.7392e-03,\n",
       "                      -1.2156e-03, -3.0234e-03,  2.1023e-03,  9.8279e-03,  1.8237e-02,\n",
       "                      -2.5613e-03,  5.1850e-03,  1.3264e-02,  4.7094e-03,  1.2901e-02,\n",
       "                       4.7186e-03,  6.7598e-03, -6.9301e-03,  1.1543e-02, -1.5096e-02,\n",
       "                      -8.5934e-03,  2.1518e-02,  3.3328e-03, -9.2149e-03, -6.0788e-03,\n",
       "                      -4.9494e-03,  8.8760e-03,  1.8054e-02, -9.7316e-03,  2.0881e-03,\n",
       "                      -4.4358e-03, -2.3642e-02,  7.0449e-03,  1.1788e-02,  2.6823e-03,\n",
       "                      -1.6694e-04,  2.1320e-02,  2.6619e-02, -8.4638e-03,  6.0369e-03,\n",
       "                      -8.2640e-03, -5.9365e-03,  2.5793e-03,  1.6373e-02, -4.8847e-03,\n",
       "                       1.5354e-02,  9.2122e-03,  2.7277e-02,  1.0852e-02,  2.7632e-03,\n",
       "                       4.0961e-03,  2.3240e-02,  8.5856e-03,  1.3235e-02,  1.9571e-02,\n",
       "                      -2.8906e-03, -2.8203e-03, -8.5933e-03, -4.4220e-03,  2.0304e-02,\n",
       "                      -7.9705e-03, -4.1698e-03,  3.1436e-02, -4.1763e-03,  2.1397e-02,\n",
       "                      -3.8587e-03, -4.9598e-03, -1.5765e-02, -1.1624e-02,  8.5937e-04,\n",
       "                       2.8026e-03, -8.5816e-04,  5.5631e-03,  2.2328e-02,  2.4035e-03,\n",
       "                       1.3503e-02,  1.0493e-02, -9.8724e-03, -7.9694e-04, -2.0628e-03,\n",
       "                       2.1628e-02,  5.6072e-03,  1.6339e-02,  2.9479e-03,  5.4965e-03,\n",
       "                       1.0970e-02, -6.2321e-04,  2.3315e-03,  3.9291e-04,  9.9813e-03,\n",
       "                       1.7807e-02,  1.3526e-02,  1.5903e-03, -7.2908e-03, -6.2089e-05,\n",
       "                       2.5687e-02, -6.4783e-03,  1.3071e-02,  2.3475e-02,  1.4357e-03,\n",
       "                       1.2491e-02,  5.1207e-03, -1.8311e-02,  7.3590e-03,  6.5310e-03,\n",
       "                       2.3138e-02, -1.0399e-02, -8.3755e-03, -1.5725e-02,  2.0092e-02,\n",
       "                       1.6798e-03,  2.4616e-02,  7.9004e-03, -1.8723e-02, -1.6641e-02,\n",
       "                       1.5793e-02,  9.3530e-03,  1.6180e-02, -6.4766e-03,  1.9079e-02,\n",
       "                      -7.2978e-05,  2.5423e-04,  2.7580e-02, -5.2150e-03,  6.9552e-03,\n",
       "                      -4.6361e-03,  1.0496e-02,  2.3798e-02, -7.1493e-03,  7.8015e-03,\n",
       "                      -7.0034e-03, -1.2677e-02, -6.5489e-03,  2.7029e-02, -9.6416e-03,\n",
       "                       6.0775e-03, -2.0038e-03,  1.0152e-03, -4.7968e-03, -8.9779e-03,\n",
       "                       8.9458e-03,  1.2538e-02,  1.1102e-02, -6.7805e-03,  1.8058e-02,\n",
       "                       1.1473e-02, -4.7366e-03,  4.5669e-03, -7.3979e-03,  1.3343e-02,\n",
       "                      -7.0262e-03, -4.3293e-03, -5.6395e-03,  1.8680e-02,  9.2531e-03,\n",
       "                      -8.0481e-03, -7.5373e-03,  1.9434e-03, -8.7207e-03,  1.5839e-02,\n",
       "                       5.2856e-03,  2.1112e-02,  1.2775e-02,  1.1423e-02,  1.7807e-02,\n",
       "                      -2.2930e-03,  1.8657e-02,  5.0831e-03, -1.5075e-02, -6.5257e-03,\n",
       "                       2.5486e-02,  8.6550e-03, -8.7006e-03,  1.2233e-02,  1.3326e-02,\n",
       "                       9.9332e-03,  1.0150e-02, -1.6208e-03,  1.0493e-02, -1.1563e-02,\n",
       "                       1.8654e-03, -2.2935e-03, -1.4654e-02, -6.4762e-03,  3.0418e-03,\n",
       "                      -2.6689e-03,  6.2672e-03,  2.2341e-02,  1.6816e-02, -2.1339e-03,\n",
       "                       9.6291e-03, -6.9151e-03, -1.0927e-02, -4.6697e-03, -5.8884e-03,\n",
       "                      -9.2943e-03,  1.1908e-04,  1.1307e-03,  1.2792e-02, -1.1725e-02,\n",
       "                       3.1630e-03, -5.9084e-03, -1.1665e-02,  8.7616e-03, -2.6178e-04,\n",
       "                      -7.1122e-03,  1.3780e-02,  7.9570e-03, -6.9400e-03,  6.6137e-03,\n",
       "                      -6.2161e-03,  5.9436e-03,  2.8172e-02,  1.7803e-03,  1.0116e-02,\n",
       "                       3.6414e-03,  6.5519e-03,  1.7804e-04, -2.1482e-03,  1.8743e-02,\n",
       "                       8.7574e-04,  9.7445e-03, -1.6819e-02,  4.9693e-04,  2.0405e-02,\n",
       "                      -6.7117e-05,  4.1090e-03, -6.3219e-03, -9.0758e-03,  6.7186e-03,\n",
       "                      -1.1624e-03,  8.7327e-03,  1.6769e-03, -8.4184e-05,  1.9525e-03,\n",
       "                      -1.1512e-03,  2.6755e-02,  1.0895e-02, -8.3391e-03, -1.0940e-02,\n",
       "                       1.4795e-02,  7.3316e-04, -7.9753e-03,  9.8206e-04,  6.6265e-03,\n",
       "                       1.2324e-02,  2.1004e-02])),\n",
       "             ('bottom_up.0.bn1.running_mean',\n",
       "              tensor([ 1.0812e-02, -7.5163e-03, -4.2492e-03, -2.2816e-03, -4.5682e-02,\n",
       "                       3.7497e-02,  1.0324e-01, -2.6171e-03,  6.8357e-02,  4.7242e-02,\n",
       "                       3.8696e-02, -3.5796e-02,  1.8426e-02, -4.7134e-02,  3.8178e-02,\n",
       "                      -6.9558e-02, -7.0496e-03,  5.2879e-02, -1.6661e-02, -3.0646e-02,\n",
       "                      -6.9267e-02,  7.3489e-02,  6.0532e-03, -1.2827e-02, -7.2471e-02,\n",
       "                      -6.7699e-02,  2.2888e-03, -1.2090e-03,  1.5861e-02,  4.3530e-02,\n",
       "                       3.9536e-03, -1.8904e-02,  1.2118e-02, -3.4627e-03, -8.8286e-03,\n",
       "                      -2.2106e-02,  3.4506e-02, -1.8751e-02,  6.6094e-02, -1.9887e-02,\n",
       "                      -3.9697e-02, -2.7169e-02, -3.1249e-03, -8.0550e-03,  1.8508e-02,\n",
       "                       2.0745e-02, -1.7171e-02, -2.7631e-02, -2.0257e-02,  2.0562e-02,\n",
       "                      -1.4975e-02, -2.8496e-03, -1.9488e-02, -4.4335e-02, -1.4208e-02,\n",
       "                       2.2131e-02, -1.0117e-02, -1.6592e-02,  9.9421e-03, -1.7263e-02,\n",
       "                      -4.9039e-02,  1.6535e-02,  5.1429e-02,  1.0163e-02,  4.0474e-02,\n",
       "                       2.4077e-02,  5.4751e-02, -4.0729e-02,  2.8494e-02,  1.8100e-02,\n",
       "                       2.1546e-02,  9.5592e-02,  1.4230e-02, -3.8456e-02,  2.3417e-02,\n",
       "                       5.6587e-02, -2.5545e-02, -2.2021e-02,  1.4602e-02,  6.9706e-02,\n",
       "                      -3.8897e-03,  3.8139e-02, -3.3346e-02, -4.1760e-02,  2.3367e-02,\n",
       "                       3.6709e-02, -4.5818e-02, -9.9093e-03, -3.1043e-02, -1.0372e-02,\n",
       "                      -4.7968e-02, -9.0235e-02,  9.2338e-03,  3.1594e-02, -9.3173e-03,\n",
       "                      -8.0179e-02,  9.8599e-02, -5.0300e-02,  4.7524e-03,  4.7794e-02,\n",
       "                      -1.6988e-02,  1.3585e-02, -2.2305e-02,  2.5334e-02, -4.4563e-02,\n",
       "                      -6.9866e-02,  1.1964e-02, -9.6593e-03,  2.9714e-02,  2.4138e-02,\n",
       "                      -2.4630e-02, -1.9795e-02, -2.6910e-02,  2.1735e-02,  8.1513e-02,\n",
       "                       1.4088e-02, -8.0504e-02, -3.1404e-02,  2.5536e-03,  3.5405e-02,\n",
       "                       5.6058e-02, -2.6847e-02,  3.6925e-02, -4.3714e-02,  4.6343e-03,\n",
       "                      -1.7430e-02,  3.2129e-02, -9.1081e-03, -5.0488e-02, -5.1253e-02,\n",
       "                       2.1352e-02, -7.2868e-02,  5.3924e-04, -1.8082e-02,  8.1929e-02,\n",
       "                       3.9944e-02,  1.0998e-02,  8.3351e-02, -3.0616e-02, -8.2591e-03,\n",
       "                      -2.1180e-02, -2.7117e-03,  1.9330e-02, -4.7281e-02,  1.8280e-02,\n",
       "                       7.3193e-02,  1.1568e-02, -1.4011e-02,  6.8006e-03,  3.8344e-02,\n",
       "                      -3.2254e-02, -5.8972e-02, -3.8967e-02, -5.2054e-03, -7.2866e-03,\n",
       "                      -3.8601e-02, -2.3021e-02, -1.6527e-02,  1.0805e-01, -5.2546e-02,\n",
       "                      -3.1897e-03, -2.2290e-02,  9.5130e-03, -6.0859e-02,  1.7797e-02,\n",
       "                      -1.7306e-02, -1.9445e-02,  6.9947e-03, -2.5889e-02,  1.5520e-02,\n",
       "                       3.3796e-02, -5.9465e-03, -1.8477e-02, -1.9347e-02, -9.7356e-03,\n",
       "                      -4.4237e-02,  1.2273e-02, -5.1415e-02, -4.3482e-02, -7.6671e-03,\n",
       "                       9.9063e-03, -6.4453e-02, -2.6130e-02,  1.1886e-01, -6.5224e-02,\n",
       "                      -3.3335e-02,  1.3492e-02,  7.3935e-02,  5.5056e-02,  1.7512e-02,\n",
       "                      -6.3560e-02, -1.4273e-02,  1.3934e-02, -3.4669e-02,  4.6141e-03,\n",
       "                      -1.9297e-02, -1.4545e-02, -9.7587e-02, -6.3317e-02,  5.5493e-02,\n",
       "                       1.6448e-03,  7.6436e-03, -4.9867e-02, -6.5646e-02,  5.2121e-03,\n",
       "                       4.6888e-02, -5.8376e-03, -3.4256e-02, -5.8853e-02,  4.9317e-02,\n",
       "                       2.7155e-02, -1.0098e-01,  1.3628e-03,  5.7817e-02,  4.2286e-02,\n",
       "                       1.1784e-02,  1.0412e-02,  5.8181e-02, -5.1975e-02, -1.7734e-02,\n",
       "                      -1.3888e-02, -2.1048e-02, -6.2312e-02,  2.1909e-02, -5.0389e-02,\n",
       "                      -5.3721e-02, -2.7397e-02,  1.5814e-02,  2.7903e-03, -3.6128e-02,\n",
       "                      -1.5311e-02, -1.9045e-02, -7.1617e-02,  3.7656e-04, -4.4672e-02,\n",
       "                       2.4405e-02, -9.3190e-03,  2.9212e-02,  1.8011e-02, -9.6690e-03,\n",
       "                      -6.4423e-02,  3.7809e-02, -6.5833e-02, -5.6559e-02, -2.7148e-02,\n",
       "                      -3.9899e-02,  1.2920e-02, -3.9886e-02,  1.7927e-03,  3.3975e-02,\n",
       "                       8.9415e-03, -3.1431e-02,  3.6623e-02, -1.6672e-02, -4.8713e-03,\n",
       "                       4.3972e-03,  1.0315e-02, -3.0267e-02, -5.4816e-03, -2.2474e-02,\n",
       "                       5.0393e-02, -5.2508e-04,  8.5798e-02,  2.7395e-02,  1.9334e-02,\n",
       "                      -3.2596e-02,  7.0131e-02,  2.5731e-02,  6.7315e-02,  4.6813e-03,\n",
       "                       2.1092e-02,  3.3596e-03,  8.7940e-03,  4.5387e-02,  2.9698e-02,\n",
       "                       3.1024e-02, -1.8707e-02, -5.7003e-03, -3.4682e-02, -2.2711e-02,\n",
       "                       9.6453e-02, -3.4094e-03, -1.7280e-03, -2.0920e-02, -4.6872e-02,\n",
       "                       2.8033e-02, -1.5422e-02, -2.2902e-02,  5.4567e-02, -6.4246e-02,\n",
       "                       2.8730e-02, -5.4736e-02,  1.7145e-03,  3.7523e-02, -6.6319e-02,\n",
       "                      -5.6016e-02,  3.0367e-02,  3.7978e-02, -8.8665e-03,  2.0339e-02,\n",
       "                       2.8193e-02, -8.5358e-02, -1.9340e-02,  1.0023e-02, -5.6150e-02,\n",
       "                       7.9490e-02, -5.8316e-02,  1.8399e-02,  2.5710e-03, -4.2052e-02,\n",
       "                       1.2279e-01,  7.1767e-02, -3.9963e-03,  7.1269e-03,  6.4987e-03,\n",
       "                      -6.0691e-02,  1.5910e-03, -5.4340e-02,  4.9335e-02,  8.0572e-02,\n",
       "                      -5.6565e-02, -8.4233e-03, -6.0267e-02,  8.9928e-03,  1.6815e-02,\n",
       "                      -1.0645e-01,  4.2707e-02, -3.0823e-02, -4.8771e-03, -1.4217e-02,\n",
       "                      -3.1667e-03,  4.9400e-02, -7.4235e-02, -6.5229e-02, -2.7812e-02,\n",
       "                      -4.7401e-02,  3.0446e-02, -4.7706e-04, -1.8975e-02,  1.5937e-03,\n",
       "                       3.0921e-03,  6.0641e-02, -2.6500e-02,  3.4244e-02, -3.7279e-02,\n",
       "                       5.0244e-02, -2.3120e-02, -1.8292e-05, -3.1234e-02,  3.0076e-02,\n",
       "                      -3.0526e-03,  3.3391e-03, -1.8280e-03, -2.3670e-02,  1.2210e-03,\n",
       "                       9.4422e-02, -2.4067e-02,  9.0053e-02,  3.1730e-02,  1.3495e-02,\n",
       "                      -2.7905e-04,  4.7085e-02,  4.8446e-03,  8.8608e-03,  3.1147e-02,\n",
       "                      -3.7823e-02,  7.7476e-03,  5.6147e-02, -4.9666e-04, -3.3324e-02,\n",
       "                       5.1843e-02,  2.3740e-02, -4.0571e-02,  2.2975e-02, -1.9144e-03,\n",
       "                       1.5374e-02, -3.2695e-02,  3.2703e-02, -3.3587e-02,  1.7945e-02,\n",
       "                      -5.3898e-02,  1.7985e-02,  5.6539e-02, -5.8611e-03, -3.3638e-03,\n",
       "                       2.5236e-02, -4.5784e-02, -2.8206e-02, -1.6823e-02,  1.9422e-02,\n",
       "                       3.9623e-02, -1.4066e-02, -3.7912e-02,  2.6261e-02, -1.3063e-02,\n",
       "                      -4.2356e-02, -2.0440e-02,  1.2111e-02,  3.3459e-02, -2.5001e-02,\n",
       "                      -6.6348e-02, -8.3198e-04, -2.8845e-02, -5.2296e-02, -7.0467e-03,\n",
       "                      -5.9309e-02, -4.8895e-03,  1.1906e-02, -8.4663e-02, -3.6466e-02,\n",
       "                      -1.2848e-02,  1.5875e-02, -2.9935e-02, -1.8725e-02,  6.3703e-02,\n",
       "                       3.4356e-03,  4.7645e-02, -3.5236e-02, -1.7594e-02,  1.5114e-02,\n",
       "                       2.3101e-02,  2.3915e-02,  3.4236e-02, -4.2038e-02,  2.6701e-02,\n",
       "                      -1.9803e-02,  6.6351e-02, -5.5959e-02, -1.9419e-02,  2.0006e-02,\n",
       "                       1.1531e-01,  7.6986e-03, -2.3630e-02, -1.1952e-02,  4.2042e-02,\n",
       "                       5.6492e-02, -6.5865e-02, -9.9777e-03, -6.7730e-02, -1.3406e-02,\n",
       "                       3.9519e-02,  8.3938e-02, -5.5888e-03, -3.7527e-03, -7.1735e-02,\n",
       "                      -1.8123e-02, -2.9791e-02,  8.0040e-03,  3.2695e-02,  2.1425e-02,\n",
       "                       2.3401e-02,  2.3995e-02,  2.0452e-03,  4.8540e-02, -6.0763e-03,\n",
       "                      -1.0238e-02, -2.4291e-02, -5.2412e-02, -2.8663e-02, -7.2535e-03,\n",
       "                      -5.0857e-02, -1.7674e-02, -3.5367e-02, -4.5324e-02, -4.9332e-02,\n",
       "                      -1.0114e-02, -1.0864e-01, -2.8662e-02,  5.8372e-02, -3.3847e-02,\n",
       "                       2.4993e-02,  6.9753e-04,  4.5646e-02, -6.0724e-02, -3.8409e-02,\n",
       "                      -6.3993e-02,  1.2149e-04, -3.4290e-02, -4.1885e-02, -1.4910e-02,\n",
       "                       1.7084e-02, -3.7551e-02, -5.9101e-02, -6.6954e-02,  2.2564e-03,\n",
       "                      -2.4832e-02,  4.4096e-03, -5.3631e-02,  4.7487e-02,  4.0756e-02,\n",
       "                      -2.2329e-05, -4.5657e-02, -3.2953e-02, -2.4830e-02, -1.0230e-01,\n",
       "                       3.1817e-02,  6.8871e-02,  9.2921e-04,  1.6664e-02,  3.6021e-03,\n",
       "                       7.9402e-02,  6.7512e-03,  7.1697e-02,  1.1588e-01, -4.4157e-02,\n",
       "                       1.8310e-03, -1.5645e-02, -3.3809e-03,  5.0028e-02,  8.8601e-03,\n",
       "                      -1.3527e-02,  3.7284e-02])),\n",
       "             ('bottom_up.0.bn1.running_var',\n",
       "              tensor([0.0020, 0.0020, 0.0019, 0.0018, 0.0017, 0.0017, 0.0018, 0.0019, 0.0018,\n",
       "                      0.0017, 0.0016, 0.0019, 0.0019, 0.0019, 0.0016, 0.0016, 0.0018, 0.0017,\n",
       "                      0.0023, 0.0019, 0.0020, 0.0017, 0.0017, 0.0016, 0.0016, 0.0018, 0.0017,\n",
       "                      0.0023, 0.0018, 0.0017, 0.0019, 0.0016, 0.0017, 0.0017, 0.0016, 0.0021,\n",
       "                      0.0019, 0.0017, 0.0015, 0.0021, 0.0019, 0.0021, 0.0018, 0.0021, 0.0020,\n",
       "                      0.0019, 0.0018, 0.0020, 0.0018, 0.0019, 0.0020, 0.0016, 0.0017, 0.0017,\n",
       "                      0.0017, 0.0018, 0.0016, 0.0017, 0.0016, 0.0017, 0.0020, 0.0020, 0.0018,\n",
       "                      0.0020, 0.0019, 0.0019, 0.0019, 0.0018, 0.0018, 0.0018, 0.0016, 0.0018,\n",
       "                      0.0017, 0.0019, 0.0018, 0.0018, 0.0020, 0.0018, 0.0017, 0.0018, 0.0021,\n",
       "                      0.0016, 0.0019, 0.0021, 0.0018, 0.0019, 0.0021, 0.0017, 0.0020, 0.0019,\n",
       "                      0.0020, 0.0017, 0.0018, 0.0019, 0.0020, 0.0016, 0.0017, 0.0019, 0.0017,\n",
       "                      0.0020, 0.0024, 0.0017, 0.0017, 0.0018, 0.0017, 0.0016, 0.0016, 0.0018,\n",
       "                      0.0020, 0.0017, 0.0020, 0.0022, 0.0020, 0.0020, 0.0017, 0.0017, 0.0017,\n",
       "                      0.0018, 0.0020, 0.0017, 0.0016, 0.0016, 0.0017, 0.0018, 0.0019, 0.0018,\n",
       "                      0.0018, 0.0021, 0.0020, 0.0020, 0.0020, 0.0017, 0.0017, 0.0018, 0.0021,\n",
       "                      0.0019, 0.0018, 0.0020, 0.0019, 0.0022, 0.0018, 0.0018, 0.0019, 0.0018,\n",
       "                      0.0017, 0.0018, 0.0017, 0.0016, 0.0021, 0.0018, 0.0017, 0.0017, 0.0022,\n",
       "                      0.0019, 0.0018, 0.0020, 0.0018, 0.0017, 0.0017, 0.0018, 0.0019, 0.0019,\n",
       "                      0.0018, 0.0018, 0.0017, 0.0020, 0.0019, 0.0021, 0.0019, 0.0018, 0.0018,\n",
       "                      0.0019, 0.0020, 0.0017, 0.0016, 0.0020, 0.0016, 0.0018, 0.0020, 0.0018,\n",
       "                      0.0018, 0.0017, 0.0018, 0.0018, 0.0017, 0.0019, 0.0019, 0.0018, 0.0017,\n",
       "                      0.0018, 0.0017, 0.0018, 0.0018, 0.0022, 0.0017, 0.0017, 0.0018, 0.0021,\n",
       "                      0.0018, 0.0017, 0.0017, 0.0019, 0.0017, 0.0018, 0.0019, 0.0017, 0.0018,\n",
       "                      0.0016, 0.0018, 0.0017, 0.0018, 0.0018, 0.0018, 0.0016, 0.0018, 0.0022,\n",
       "                      0.0015, 0.0021, 0.0017, 0.0018, 0.0019, 0.0019, 0.0016, 0.0018, 0.0018,\n",
       "                      0.0017, 0.0017, 0.0020, 0.0016, 0.0021, 0.0017, 0.0018, 0.0020, 0.0019,\n",
       "                      0.0017, 0.0016, 0.0017, 0.0018, 0.0020, 0.0018, 0.0020, 0.0019, 0.0020,\n",
       "                      0.0018, 0.0018, 0.0018, 0.0017, 0.0017, 0.0019, 0.0017, 0.0017, 0.0018,\n",
       "                      0.0021, 0.0018, 0.0018, 0.0015, 0.0018, 0.0019, 0.0018, 0.0017, 0.0017,\n",
       "                      0.0017, 0.0020, 0.0019, 0.0018, 0.0017, 0.0016, 0.0019, 0.0016, 0.0016,\n",
       "                      0.0022, 0.0017, 0.0018, 0.0017, 0.0018, 0.0017, 0.0017, 0.0017, 0.0018,\n",
       "                      0.0019, 0.0017, 0.0018, 0.0017, 0.0020, 0.0019, 0.0017, 0.0020, 0.0019,\n",
       "                      0.0016, 0.0015, 0.0017, 0.0017, 0.0017, 0.0016, 0.0015, 0.0017, 0.0016,\n",
       "                      0.0018, 0.0017, 0.0015, 0.0019, 0.0022, 0.0020, 0.0017, 0.0017, 0.0017,\n",
       "                      0.0020, 0.0017, 0.0019, 0.0016, 0.0022, 0.0016, 0.0019, 0.0017, 0.0016,\n",
       "                      0.0017, 0.0019, 0.0019, 0.0018, 0.0019, 0.0019, 0.0017, 0.0015, 0.0021,\n",
       "                      0.0020, 0.0017, 0.0017, 0.0019, 0.0016, 0.0020, 0.0018, 0.0016, 0.0017,\n",
       "                      0.0018, 0.0016, 0.0017, 0.0019, 0.0019, 0.0022, 0.0019, 0.0019, 0.0019,\n",
       "                      0.0018, 0.0018, 0.0019, 0.0020, 0.0016, 0.0019, 0.0019, 0.0018, 0.0015,\n",
       "                      0.0017, 0.0018, 0.0017, 0.0017, 0.0020, 0.0020, 0.0016, 0.0018, 0.0016,\n",
       "                      0.0019, 0.0017, 0.0019, 0.0020, 0.0018, 0.0020, 0.0017, 0.0018, 0.0017,\n",
       "                      0.0017, 0.0021, 0.0017, 0.0017, 0.0016, 0.0016, 0.0021, 0.0020, 0.0017,\n",
       "                      0.0017, 0.0017, 0.0018, 0.0018, 0.0020, 0.0018, 0.0020, 0.0017, 0.0018,\n",
       "                      0.0022, 0.0016, 0.0018, 0.0018, 0.0018, 0.0020, 0.0018, 0.0019, 0.0017,\n",
       "                      0.0016, 0.0017, 0.0019, 0.0018, 0.0018, 0.0017, 0.0017, 0.0016, 0.0016,\n",
       "                      0.0020, 0.0021, 0.0019, 0.0018, 0.0020, 0.0018, 0.0017, 0.0022, 0.0018,\n",
       "                      0.0018, 0.0015, 0.0018, 0.0017, 0.0020, 0.0019, 0.0019, 0.0019, 0.0018,\n",
       "                      0.0016, 0.0017, 0.0020, 0.0018, 0.0019, 0.0018, 0.0020, 0.0020, 0.0018,\n",
       "                      0.0017, 0.0018, 0.0017, 0.0021, 0.0016, 0.0019, 0.0018, 0.0019, 0.0022,\n",
       "                      0.0018, 0.0019, 0.0019, 0.0018, 0.0016, 0.0019, 0.0018, 0.0017, 0.0016,\n",
       "                      0.0018, 0.0018, 0.0020, 0.0021, 0.0016, 0.0019, 0.0017, 0.0017, 0.0020,\n",
       "                      0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0022, 0.0017, 0.0017, 0.0016,\n",
       "                      0.0018, 0.0018, 0.0017, 0.0018, 0.0020, 0.0016, 0.0017, 0.0017, 0.0018,\n",
       "                      0.0019, 0.0017, 0.0016, 0.0018, 0.0018, 0.0016, 0.0016, 0.0019, 0.0016,\n",
       "                      0.0017, 0.0015, 0.0018, 0.0019, 0.0017, 0.0017, 0.0016, 0.0017, 0.0019,\n",
       "                      0.0024, 0.0018, 0.0018, 0.0016, 0.0018, 0.0016, 0.0022, 0.0018, 0.0017,\n",
       "                      0.0017, 0.0021, 0.0017, 0.0017, 0.0017, 0.0018, 0.0017, 0.0022])),\n",
       "             ('bottom_up.0.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.0.dense2.weight',\n",
       "              tensor([[ 0.0249,  0.0276, -0.0047,  ...,  0.0028, -0.0126, -0.0211],\n",
       "                      [-0.0078,  0.0438,  0.0426,  ...,  0.0065,  0.0128,  0.0147],\n",
       "                      [ 0.0178, -0.0246,  0.0078,  ...,  0.0249,  0.0140,  0.0312],\n",
       "                      ...,\n",
       "                      [-0.0153,  0.0034, -0.0146,  ...,  0.0395, -0.0390, -0.0012],\n",
       "                      [-0.0109, -0.0181, -0.0137,  ..., -0.0179, -0.0261,  0.0135],\n",
       "                      [ 0.0489, -0.0447, -0.0154,  ...,  0.0196, -0.0501, -0.0564]])),\n",
       "             ('bottom_up.0.bn2.weight',\n",
       "              tensor([0.9901, 1.0107, 0.9955, 0.9982, 1.0105, 0.9912, 0.9955, 1.0005, 0.9989,\n",
       "                      0.9991, 0.9943, 1.0135, 1.0013, 1.0008, 1.0178, 1.0092, 1.0043, 0.9977,\n",
       "                      1.0123, 1.0156, 0.9857, 0.9951, 0.9897, 0.9916, 1.0032, 0.9950, 0.9881,\n",
       "                      1.0028, 0.9996, 0.9839, 0.9884, 0.9947, 1.0019, 0.9961, 0.9960, 1.0015,\n",
       "                      0.9928, 0.9876, 0.9922, 1.0090, 1.0107, 0.9877, 0.9996, 1.0034, 0.9947,\n",
       "                      0.9867, 1.0089, 1.0083, 1.0066, 1.0065, 1.0008, 0.9948, 1.0064, 0.9894,\n",
       "                      0.9870, 0.9836, 0.9918, 1.0033, 1.0038, 1.0079, 1.0014, 1.0009, 0.9888,\n",
       "                      0.9856, 1.0006, 0.9988, 0.9983, 1.0143, 0.9936, 0.9896, 0.9863, 0.9961,\n",
       "                      1.0143, 1.0029, 0.9924, 1.0016, 1.0082, 0.9998, 0.9904, 0.9950, 0.9966,\n",
       "                      0.9915, 0.9925, 0.9982, 0.9892, 0.9988, 0.9870, 0.9977, 0.9863, 1.0060,\n",
       "                      0.9830, 0.9911, 0.9962, 0.9910, 1.0060, 0.9930, 1.0081, 1.0019, 0.9834,\n",
       "                      1.0147, 0.9957, 1.0096, 1.0087, 0.9926, 0.9866, 1.0106, 1.0002, 1.0139,\n",
       "                      0.9948, 0.9947, 0.9956, 1.0009, 0.9967, 0.9827, 1.0032, 0.9902, 0.9906,\n",
       "                      0.9938, 1.0040, 0.9872, 1.0129, 1.0041, 0.9902, 0.9978, 1.0062, 0.9956,\n",
       "                      0.9947, 0.9805, 0.9956, 1.0045, 0.9944, 0.9976, 1.0004, 0.9928, 0.9948,\n",
       "                      1.0046, 1.0075, 0.9976, 0.9950, 1.0070, 0.9866, 1.0121, 1.0112, 1.0065,\n",
       "                      1.0002, 0.9889, 1.0072, 1.0094, 0.9926, 0.9903, 0.9969, 0.9814, 0.9976,\n",
       "                      0.9970, 1.0142, 0.9965, 0.9934, 0.9921, 0.9788, 1.0081, 1.0144, 1.0040,\n",
       "                      1.0064, 0.9948, 0.9990, 0.9965, 1.0096, 0.9948, 0.9949, 1.0027, 1.0018,\n",
       "                      1.0144, 0.9988, 0.9920, 0.9990, 0.9997, 0.9931, 0.9901, 0.9913, 1.0098,\n",
       "                      1.0004, 1.0122, 0.9919, 0.9964, 0.9966, 0.9865, 1.0117, 0.9950, 0.9956,\n",
       "                      0.9846, 1.0072, 0.9969, 1.0000, 0.9955, 1.0066, 1.0005, 1.0110, 0.9895,\n",
       "                      0.9920, 0.9939, 0.9825, 0.9935, 0.9963, 0.9981, 1.0180, 0.9981, 1.0122,\n",
       "                      0.9937, 0.9918, 1.0117, 1.0066, 0.9936, 1.0015, 0.9928, 1.0119, 1.0163,\n",
       "                      0.9982, 0.9945, 0.9976, 1.0161, 1.0099, 0.9930, 0.9887, 0.9914, 0.9975,\n",
       "                      0.9942, 1.0043, 1.0095, 0.9968, 1.0022, 1.0063, 0.9913, 1.0002, 1.0111,\n",
       "                      0.9863, 1.0113, 0.9865, 0.9961, 0.9985, 0.9934, 1.0065, 0.9828, 0.9954,\n",
       "                      0.9991, 1.0015, 0.9887, 0.9952, 1.0015, 0.9936, 0.9979, 0.9848, 1.0218,\n",
       "                      0.9937, 0.9949, 1.0059, 0.9978, 1.0074, 1.0084, 1.0103, 1.0120, 0.9939,\n",
       "                      0.9900, 1.0132, 1.0003, 0.9958, 0.9968, 1.0129, 0.9990, 0.9927, 0.9966,\n",
       "                      0.9962, 1.0016, 1.0030, 0.9847, 0.9993, 0.9952, 0.9957, 0.9992, 0.9859,\n",
       "                      0.9895, 0.9887, 1.0007, 0.9832, 1.0030, 1.0045, 1.0028, 1.0095, 1.0136,\n",
       "                      1.0056, 0.9847, 1.0152, 0.9953, 1.0072, 0.9964, 1.0031, 0.9903, 1.0030,\n",
       "                      0.9855, 0.9904, 1.0167, 1.0090, 0.9987, 1.0004, 1.0073, 1.0044, 0.9760,\n",
       "                      1.0130, 1.0005, 0.9948, 1.0052, 1.0062, 0.9980, 0.9918, 0.9920, 1.0000,\n",
       "                      1.0066, 1.0013, 0.9984, 1.0099, 0.9967, 0.9992, 1.0061, 0.9956, 0.9900,\n",
       "                      1.0007, 1.0001, 0.9873, 1.0034, 0.9989, 1.0027, 1.0072, 0.9859, 0.9967,\n",
       "                      0.9946, 0.9934, 0.9967, 0.9833, 0.9975, 0.9972, 0.9810, 0.9998, 1.0039,\n",
       "                      0.9920, 0.9903, 0.9994, 0.9974, 1.0047, 0.9997, 1.0154, 1.0210, 0.9884,\n",
       "                      0.9992, 0.9910, 0.9824, 0.9936, 1.0057, 0.9962, 0.9970, 0.9901, 0.9998,\n",
       "                      0.9933, 1.0072, 0.9936, 0.9954, 1.0101, 1.0157, 0.9912, 0.9904, 1.0060,\n",
       "                      0.9814, 0.9937, 0.9988, 1.0067, 1.0085, 0.9829, 0.9951, 1.0086, 0.9922,\n",
       "                      0.9937, 1.0189, 1.0015, 1.0087, 0.9905, 1.0252, 0.9891, 1.0050, 0.9912,\n",
       "                      0.9880, 0.9963, 0.9970, 1.0114, 1.0090, 0.9954, 0.9963, 0.9873, 0.9896,\n",
       "                      0.9869, 1.0098, 1.0131, 0.9977, 0.9919, 1.0037, 1.0055, 0.9994, 1.0079,\n",
       "                      0.9953, 0.9919, 0.9990, 0.9959, 1.0143, 1.0049, 0.9881, 0.9996, 1.0014,\n",
       "                      0.9867, 0.9987, 1.0192, 1.0009, 1.0068, 0.9958, 1.0043, 1.0028, 1.0095,\n",
       "                      0.9923, 0.9903, 1.0021, 0.9958, 1.0002, 0.9822, 1.0009, 1.0009, 1.0138,\n",
       "                      0.9980, 0.9966, 1.0104, 0.9924, 0.9927, 0.9956, 1.0093, 0.9910, 1.0104,\n",
       "                      0.9904, 0.9920, 1.0066, 0.9947, 0.9893, 0.9978, 0.9966, 0.9965, 1.0083,\n",
       "                      1.0012, 0.9881, 0.9970, 0.9976, 0.9901, 1.0173, 1.0012, 0.9869, 1.0019,\n",
       "                      1.0005, 1.0022, 1.0132, 1.0024, 0.9864, 1.0069, 0.9917, 1.0007, 0.9989,\n",
       "                      1.0128, 0.9914, 0.9985, 0.9940, 0.9849, 0.9937, 0.9976, 1.0098, 0.9801,\n",
       "                      0.9985, 0.9985, 1.0057, 0.9929, 1.0121, 1.0000, 1.0039, 0.9993, 1.0013,\n",
       "                      0.9911, 0.9948, 0.9976, 1.0177, 0.9894, 1.0004, 0.9925, 0.9875, 1.0052,\n",
       "                      0.9953, 1.0150, 1.0020, 1.0008, 1.0014, 0.9854, 0.9858, 0.9882, 0.9990,\n",
       "                      0.9927, 1.0069, 1.0067, 1.0084, 1.0036, 1.0095, 1.0086, 1.0166])),\n",
       "             ('bottom_up.0.bn2.bias',\n",
       "              tensor([-1.4976e-02,  1.8115e-02,  1.3407e-02,  5.5281e-03,  2.1685e-02,\n",
       "                      -3.1216e-03,  1.2859e-02,  7.5125e-03,  6.6031e-03,  2.3157e-02,\n",
       "                       1.4160e-03,  2.6525e-02,  2.2837e-02,  6.0465e-03,  1.8093e-02,\n",
       "                       2.8288e-02,  2.1632e-02,  1.1376e-02,  2.0902e-02,  1.7389e-02,\n",
       "                       1.6671e-02,  7.4279e-03, -9.3333e-03, -9.2209e-04, -6.0240e-03,\n",
       "                       1.0411e-02, -1.3130e-03,  9.5953e-03,  6.6687e-03, -5.8931e-03,\n",
       "                       1.5591e-02,  8.4113e-03,  2.4101e-02,  3.5784e-03,  1.9847e-02,\n",
       "                       1.5785e-02, -3.0963e-03, -7.2780e-03, -4.2287e-03,  1.9388e-02,\n",
       "                       2.2112e-02,  2.7921e-03,  3.7191e-03, -2.5324e-03,  9.7572e-03,\n",
       "                      -2.9096e-04,  2.0485e-02,  2.3414e-02,  2.4221e-02,  1.1811e-02,\n",
       "                       1.1092e-02,  2.6879e-03,  1.2411e-02, -1.3917e-02,  6.7911e-03,\n",
       "                      -5.1014e-03,  1.6909e-02,  2.3254e-02,  1.3286e-02,  2.5051e-02,\n",
       "                       1.2470e-02,  3.1776e-03,  1.7590e-03, -3.8623e-03,  7.3287e-03,\n",
       "                       8.5722e-03, -1.0209e-02,  2.1042e-02,  1.0250e-02, -5.3404e-03,\n",
       "                      -7.7018e-03, -3.0939e-03,  2.0652e-02,  1.5067e-02,  1.4307e-03,\n",
       "                       2.3513e-02,  8.0916e-03,  9.7404e-03,  1.4660e-02,  1.5338e-02,\n",
       "                       6.1630e-03,  1.2749e-03, -1.2720e-03, -4.9459e-03, -6.2021e-03,\n",
       "                      -4.5216e-03,  7.7448e-03,  2.3533e-03, -1.2404e-02,  1.2733e-02,\n",
       "                       7.0284e-03,  2.0522e-02, -3.2965e-03, -1.2540e-02,  1.4421e-02,\n",
       "                       3.6001e-04,  1.7979e-02,  1.2994e-02, -9.2994e-03,  2.4477e-02,\n",
       "                      -1.3392e-02,  1.5471e-02,  1.7550e-02,  1.8106e-02, -7.3041e-03,\n",
       "                       1.3652e-03,  3.9493e-03,  2.1091e-02,  9.4145e-03,  1.3797e-02,\n",
       "                       1.2462e-02,  4.5062e-03,  1.6306e-02, -1.6618e-02,  1.1112e-02,\n",
       "                      -6.5257e-03,  8.9063e-04, -1.5492e-03,  1.8280e-02, -4.0334e-03,\n",
       "                       2.1844e-02,  1.5942e-02,  1.2097e-03,  1.2564e-02,  2.0436e-02,\n",
       "                      -1.2630e-02, -6.6809e-03, -1.8769e-02, -6.8824e-03,  1.2930e-02,\n",
       "                       1.0042e-02,  1.5063e-02,  9.5564e-03,  1.6146e-02, -8.4910e-03,\n",
       "                       2.0824e-02,  1.4373e-02,  1.6959e-02,  3.3909e-03,  1.8646e-02,\n",
       "                       1.9080e-03,  1.5606e-02,  1.2004e-02,  1.5627e-02,  1.1845e-02,\n",
       "                      -8.9453e-03,  2.1361e-02,  2.2369e-02,  4.7770e-03,  2.0497e-03,\n",
       "                      -4.0321e-03, -6.5082e-03,  7.5856e-03, -9.9362e-03,  2.5306e-02,\n",
       "                      -1.9967e-03,  4.8839e-03, -1.8969e-03, -6.7437e-03, -5.7865e-03,\n",
       "                       2.3927e-02,  1.6074e-02,  2.5371e-02,  2.3550e-03,  2.1381e-02,\n",
       "                       1.4729e-02,  2.6639e-02,  8.5668e-03,  9.3239e-03,  1.7081e-02,\n",
       "                       1.6063e-02,  1.6831e-02,  1.0019e-03,  1.0239e-02,  1.5101e-03,\n",
       "                       2.7691e-02,  4.0052e-03, -1.0556e-02, -1.3591e-02,  2.0753e-02,\n",
       "                       2.3513e-03,  2.1116e-02, -8.1265e-03,  1.8962e-02,  5.7804e-03,\n",
       "                      -3.0715e-03,  5.8792e-03, -1.7579e-04,  6.3381e-03,  8.9815e-03,\n",
       "                       1.5434e-02,  4.4633e-03,  1.5652e-02, -4.3935e-03,  1.7831e-02,\n",
       "                       1.4116e-02,  2.2617e-02, -1.0125e-02,  4.3873e-03,  4.0271e-03,\n",
       "                      -1.3900e-02,  2.6413e-03, -2.1532e-02,  1.9959e-02,  2.5841e-02,\n",
       "                       6.2252e-04,  2.1005e-02, -6.3310e-03,  2.8990e-03,  1.3593e-02,\n",
       "                       2.1134e-02,  1.1705e-02,  2.6648e-02,  8.4904e-03,  2.9326e-02,\n",
       "                       1.7668e-02, -8.1320e-03,  6.1464e-03,  1.2142e-02,  1.7190e-02,\n",
       "                       2.5966e-02,  1.6778e-04,  9.7324e-04,  5.9439e-03,  1.2761e-02,\n",
       "                      -1.4599e-02,  5.5100e-03,  1.8664e-02, -3.2520e-03,  1.7331e-03,\n",
       "                       1.0051e-02,  1.0450e-03,  1.5880e-02,  1.5567e-02, -1.3340e-03,\n",
       "                       9.4331e-03, -9.1746e-03,  1.3187e-02,  1.6561e-02,  3.3691e-03,\n",
       "                       8.1942e-03, -1.1775e-02,  4.8197e-03,  1.1996e-02,  9.1228e-03,\n",
       "                      -9.9487e-03, -3.6043e-03,  2.1913e-02, -5.6116e-03,  1.7905e-02,\n",
       "                      -7.7171e-03,  2.1052e-02, -9.2410e-03,  9.1528e-03,  1.5190e-02,\n",
       "                      -9.6362e-03,  2.0703e-02,  2.5873e-02,  1.1941e-02,  2.0197e-02,\n",
       "                       1.8835e-02, -4.5134e-04,  2.3374e-02,  4.2138e-03,  6.8718e-03,\n",
       "                       1.6511e-02,  2.0450e-02,  1.3396e-02,  1.4666e-02,  1.7215e-02,\n",
       "                       2.3146e-02,  2.6623e-02,  2.1346e-02, -1.2629e-02,  1.7377e-02,\n",
       "                       8.8302e-03, -5.7412e-03,  1.5423e-02,  2.9899e-03, -8.6940e-03,\n",
       "                       1.7747e-02,  1.4468e-02,  7.7165e-03,  1.6892e-02,  2.1184e-02,\n",
       "                       2.4356e-03,  2.5109e-02,  1.9703e-02,  1.6303e-02, -9.0527e-03,\n",
       "                       2.3594e-02, -4.1624e-03,  3.5535e-03,  5.9143e-03,  1.3195e-02,\n",
       "                       1.4158e-02,  5.9528e-03, -1.2224e-02, -5.0689e-03,  2.7738e-02,\n",
       "                       1.3104e-03,  1.8206e-02,  1.3801e-02,  2.2355e-02,  1.5866e-02,\n",
       "                      -1.4126e-03,  2.5678e-02,  1.2973e-02, -8.2347e-04,  1.3212e-02,\n",
       "                       1.7642e-02,  1.4008e-02,  2.1631e-02, -8.2662e-03,  9.6678e-03,\n",
       "                       2.2400e-02,  1.2354e-02,  7.6847e-03,  2.1648e-02,  4.9124e-03,\n",
       "                       2.0457e-02,  1.5460e-02,  7.1021e-03,  1.0274e-02,  8.3991e-03,\n",
       "                       2.3820e-02, -5.7263e-04,  3.9110e-03,  8.1613e-03, -3.4836e-03,\n",
       "                       2.1651e-02, -4.5640e-03,  1.2055e-02,  7.5249e-03, -2.4111e-04,\n",
       "                       2.4225e-02,  8.2704e-04,  3.3703e-03,  3.2374e-03, -3.1066e-03,\n",
       "                      -1.2573e-02,  1.2340e-02, -6.2155e-03,  4.7630e-04,  1.2714e-02,\n",
       "                       9.9816e-03,  1.6473e-02,  6.7242e-03,  2.5193e-02,  2.1231e-02,\n",
       "                      -1.5957e-02,  1.8103e-02,  5.6724e-04, -2.0181e-02,  3.4896e-03,\n",
       "                       7.1304e-03, -3.5380e-03,  1.2113e-02,  1.0480e-02,  1.4065e-02,\n",
       "                      -7.7033e-03,  5.0896e-03, -6.3128e-03, -6.8851e-04,  2.3066e-02,\n",
       "                       2.8490e-02, -1.6571e-03,  2.7039e-03,  5.5735e-03, -1.2256e-02,\n",
       "                      -1.6065e-02,  2.5057e-03,  1.4590e-02, -3.7464e-03, -1.2804e-02,\n",
       "                      -1.1277e-02,  1.6440e-02,  6.6957e-03, -7.4305e-03,  1.4884e-02,\n",
       "                       1.6686e-02,  2.8094e-02, -8.7565e-05,  2.7396e-02, -4.0971e-03,\n",
       "                       2.3961e-02, -4.4373e-03,  6.1198e-03, -1.5534e-02,  1.6665e-02,\n",
       "                       1.8751e-02,  1.8250e-02,  6.9098e-03, -9.2190e-03,  6.5736e-03,\n",
       "                       1.4327e-03,  2.4913e-02,  2.0405e-02,  2.2792e-02,  8.0196e-04,\n",
       "                      -4.4125e-03,  2.5875e-02, -5.4538e-04,  4.0111e-03,  1.4375e-02,\n",
       "                       1.6751e-02,  4.9862e-03,  1.9237e-02, -9.7957e-03,  2.2505e-02,\n",
       "                       1.8121e-02,  4.2728e-03,  1.1055e-02,  2.9237e-02, -1.0703e-02,\n",
       "                       1.2396e-02,  2.1789e-02,  8.6322e-03,  1.3935e-02, -6.6787e-03,\n",
       "                       5.3392e-03,  1.0803e-02,  1.7681e-02, -1.7334e-02,  9.8073e-03,\n",
       "                       1.0792e-02, -4.9985e-03,  1.5396e-02, -2.7732e-03,  8.4969e-03,\n",
       "                       6.8075e-03,  1.9591e-02,  3.2362e-03,  1.7923e-03,  2.0183e-02,\n",
       "                       1.1118e-02,  6.3936e-03,  2.4603e-03,  2.3689e-02, -6.2051e-05,\n",
       "                       2.1306e-02, -2.7335e-03,  1.5583e-04,  2.2771e-02,  4.4893e-03,\n",
       "                       1.4245e-02,  1.5368e-02,  1.6059e-02,  1.7093e-02,  1.5541e-02,\n",
       "                      -3.5606e-03,  1.3213e-02,  6.0619e-03,  6.2448e-03, -7.5151e-03,\n",
       "                       2.3775e-02,  2.0537e-02, -1.0344e-02,  1.8562e-02,  2.5766e-02,\n",
       "                       2.1007e-02,  2.1182e-02,  1.6026e-02, -4.9660e-03,  1.9019e-02,\n",
       "                      -4.2899e-03,  2.4103e-03,  1.4693e-02,  1.9381e-02, -2.8248e-03,\n",
       "                       5.6804e-03,  9.5083e-03,  1.1102e-02,  1.5718e-02,  1.6539e-03,\n",
       "                       2.4818e-02, -1.1700e-02,  2.1361e-02,  2.4827e-02,  1.8603e-02,\n",
       "                      -4.0933e-03,  1.9620e-02,  1.7833e-02,  1.6650e-02,  3.2596e-03,\n",
       "                       1.3159e-02, -1.1642e-02,  1.2688e-02,  7.4598e-03,  1.9194e-02,\n",
       "                      -3.8172e-03,  2.3238e-02,  1.6331e-02, -1.4435e-02,  1.6421e-02,\n",
       "                       1.1330e-02,  2.3322e-02,  3.8377e-04,  7.1636e-03,  8.1189e-03,\n",
       "                       5.5272e-03, -7.0175e-03, -4.7796e-03,  2.1099e-02,  9.4580e-03,\n",
       "                       1.8961e-02,  2.1915e-02,  2.0831e-02,  2.2613e-02,  2.2411e-02,\n",
       "                       7.6014e-03,  2.2335e-02])),\n",
       "             ('bottom_up.0.bn2.running_mean',\n",
       "              tensor([ 0.1789,  0.4047, -0.0782,  0.4415,  0.1159,  0.1221, -0.2170,  0.1527,\n",
       "                      -0.3501, -0.2649,  0.3693, -0.3913, -0.6118, -0.0703, -0.0701, -0.9103,\n",
       "                      -0.8315,  0.3120, -0.3057,  0.3585,  0.1476,  0.3694,  0.0830,  0.4643,\n",
       "                      -0.0270, -0.4415,  0.0867, -0.2350, -0.2029, -0.5751, -0.4522, -0.0322,\n",
       "                      -0.7534, -0.1964, -0.1304, -0.5130, -0.1338, -0.2494, -0.3167, -0.2031,\n",
       "                      -0.4477,  0.0075,  0.0071,  0.6181,  0.3353, -0.1765,  0.1072, -0.2733,\n",
       "                      -0.5560,  0.0502,  0.2074, -0.7510,  0.4645,  0.3276, -0.4244, -0.1385,\n",
       "                      -0.2109, -0.0179,  0.2284, -0.0689,  0.1555,  0.0029, -0.2485, -0.0673,\n",
       "                       0.2268, -0.2909,  0.1242, -0.4944, -0.3652, -0.7132, -0.0302,  0.5293,\n",
       "                       0.1640, -0.0012, -0.6113, -0.4207,  0.0443, -0.0509, -0.5714, -0.1978,\n",
       "                       0.0234, -0.1175, -0.6413,  0.3494,  0.3113, -0.1309,  0.0731, -0.1919,\n",
       "                      -0.0438,  0.0224, -0.3029, -0.4669,  0.0034,  0.6838, -0.4744, -0.4028,\n",
       "                      -0.5022,  0.0312,  0.2969, -0.1331,  0.5190,  0.4119, -0.0633, -0.0580,\n",
       "                       0.1199,  0.5497, -0.4117, -0.5007,  0.1739, -0.1033, -0.3772, -0.2266,\n",
       "                      -0.5693,  0.2333,  0.3670, -0.4011,  0.0200, -0.2497, -0.0973,  0.3143,\n",
       "                      -0.2345,  0.0814,  0.2753, -0.3902, -0.0463,  0.0847, -0.0348,  0.1156,\n",
       "                       0.4831,  0.5931,  0.2074,  0.2855,  0.0707,  0.0048,  0.5672, -0.0808,\n",
       "                       0.5454, -0.1995, -0.3816,  0.3948,  0.2474,  0.5104,  0.2984, -0.1475,\n",
       "                       0.3970, -0.2772, -0.0914, -0.5455, -0.3908, -0.0668,  0.0213, -0.7347,\n",
       "                      -0.1866,  0.5653,  0.0349,  0.2761,  0.1839, -0.3590, -0.4035,  0.5752,\n",
       "                      -0.6497, -0.2455,  0.0361,  0.0167, -0.2956, -0.2239, -0.0626,  0.1094,\n",
       "                       0.0061, -0.2343, -0.3348, -0.5526, -0.1194,  0.1396, -0.8930, -0.3923,\n",
       "                      -0.5121, -0.1720,  0.4290, -0.2734, -0.0113,  0.0461,  0.0296, -0.4538,\n",
       "                       0.1540, -0.0606,  0.6403,  0.3391,  0.4611, -0.5391, -0.3618, -0.2190,\n",
       "                      -0.1600,  0.2078, -0.3481, -0.0832, -0.7097,  0.1479, -0.5533,  0.3062,\n",
       "                       0.2042, -0.2281,  0.7799, -0.0993, -0.5325,  0.0685, -0.6556, -0.0152,\n",
       "                       0.4520,  0.0041, -0.2852,  0.3710, -0.3683, -0.7394, -0.4805,  0.0606,\n",
       "                       0.2648,  0.2673,  0.2970,  0.3073, -0.7195, -0.0226, -0.0577, -0.6219,\n",
       "                      -0.0200, -0.4130, -0.4770,  0.2198, -0.4674, -0.5123,  0.1523, -0.1845,\n",
       "                      -0.2725,  0.5561, -0.2936,  0.6299, -0.3113, -0.0283, -0.7272,  0.6728,\n",
       "                       0.1723,  0.2646, -0.1444, -0.0102, -0.6652,  0.0656, -0.0489, -0.0706,\n",
       "                      -0.0598, -0.2786, -0.2862, -0.2999,  0.2067, -0.4863,  0.2131,  0.3016,\n",
       "                       0.2496, -0.5686, -0.3099, -0.2935, -0.5869,  0.0483,  0.2798,  0.0068,\n",
       "                      -0.0534,  0.0990, -0.4689, -0.5692,  0.0401, -0.5670, -0.2815, -0.4419,\n",
       "                      -0.1632, -0.2696, -0.2879, -0.0438,  0.7319, -0.0120, -0.2947, -0.5364,\n",
       "                      -0.3281, -0.4632, -0.7336,  0.1571,  0.1419,  0.0966, -0.4406, -0.5681,\n",
       "                      -0.1104,  0.3471,  0.0765,  0.0939,  0.0334,  0.0361, -0.0907, -0.1344,\n",
       "                       0.0809, -0.5433, -0.1945, -0.5210,  0.2342,  0.5380, -0.0865,  0.1798,\n",
       "                       0.2794,  0.1441, -0.4264, -0.2754, -0.5307, -0.0698, -0.1539, -0.2469,\n",
       "                      -0.3094,  0.5105, -0.5524,  0.0222, -0.3595,  0.1571, -0.6940, -0.1758,\n",
       "                      -0.3191, -0.0325, -0.3644, -0.3140,  0.1861,  0.1432,  0.4086,  0.2421,\n",
       "                      -0.5127,  0.6681, -0.8940, -0.7049, -0.4167, -0.5012,  0.2301, -0.0600,\n",
       "                       0.1635, -0.3768, -0.6050,  0.1669,  0.3672, -0.3258, -0.2511, -0.6158,\n",
       "                      -0.8697, -0.1421,  0.3170,  0.1336, -0.1619,  0.0313,  0.3499, -0.3806,\n",
       "                      -0.4584, -0.4337, -0.1952, -0.1162,  0.3256, -0.6840, -0.4662, -0.1369,\n",
       "                       0.0549,  0.2770,  0.3802,  0.2394,  0.1053, -1.2000,  0.1628, -0.1129,\n",
       "                       0.4436, -0.3443, -0.1381,  0.0557, -0.2577,  0.8853,  0.0388,  0.2633,\n",
       "                      -0.5773, -0.0851, -0.2689,  0.1739,  0.3436, -0.4947,  0.0741, -0.7009,\n",
       "                      -0.2451, -0.0756, -0.0280,  0.2962,  0.6058, -0.0017, -0.1437,  0.2955,\n",
       "                       0.1913,  0.4597,  0.2743, -0.8744, -0.2717, -0.5942, -0.6611,  0.2935,\n",
       "                      -0.5585, -0.0441,  0.5896,  0.6017, -0.1259, -0.5035, -0.1340, -0.0860,\n",
       "                       0.7007, -0.4792,  0.4237, -0.7781, -0.3726, -0.2349, -0.2240, -0.2167,\n",
       "                      -0.5321, -0.8472,  0.5333,  0.2252, -0.1066,  0.4587,  0.1467,  0.1347,\n",
       "                       0.0979, -0.3729, -0.1697, -0.0175,  0.3830, -0.4386, -0.1235, -0.4105,\n",
       "                      -0.2861, -0.4038, -0.6179, -0.1806, -0.4564,  0.0128,  0.0371,  0.2889,\n",
       "                      -0.5511, -0.3251,  0.1689,  0.0610,  0.3040, -0.5272, -0.1535, -0.2047,\n",
       "                      -0.2772,  0.3629,  0.2626, -0.0042, -0.3594, -0.4440,  0.1982,  0.0302,\n",
       "                       0.0938,  0.2399, -0.4086, -0.6258, -0.1922, -0.0118, -0.4084, -0.1580,\n",
       "                      -0.0897, -0.6108, -0.0639, -0.3022, -0.3818,  0.0183,  0.0935,  0.1971,\n",
       "                      -0.3915, -0.0310, -0.2331, -0.7307, -0.2106, -0.2194, -0.1232, -0.1607,\n",
       "                      -0.1054,  0.0577,  0.5708,  0.4493, -0.2581, -0.0282,  0.4012,  0.3363,\n",
       "                       0.4344, -0.2264, -0.1648, -0.2351, -0.0266,  0.0850,  0.5347, -0.2366,\n",
       "                       0.2482,  0.2229,  0.3888,  0.0333, -0.1710, -0.0942,  0.2049,  0.2063,\n",
       "                      -0.1428,  0.2366, -0.3076, -0.5732, -0.2691, -0.1656, -0.1315, -0.3658])),\n",
       "             ('bottom_up.0.bn2.running_var',\n",
       "              tensor([0.3405, 1.0695, 1.5896, 0.3727, 1.5022, 0.2803, 0.9698, 0.6889, 0.7342,\n",
       "                      1.0260, 0.5458, 1.9534, 0.6380, 1.3168, 3.6268, 1.7263, 1.6878, 1.3262,\n",
       "                      2.2559, 1.8320, 0.5296, 0.9606, 0.3131, 0.4939, 0.8437, 1.8159, 0.3014,\n",
       "                      0.4077, 0.8104, 0.3994, 0.7885, 1.2687, 2.4206, 0.4140, 1.4833, 0.9130,\n",
       "                      0.7345, 0.3239, 1.1422, 2.3502, 2.4033, 0.3132, 0.6848, 0.3292, 0.9335,\n",
       "                      0.7958, 1.7811, 0.6735, 1.0623, 1.7205, 1.3498, 0.3510, 2.1125, 0.3519,\n",
       "                      1.0837, 0.6181, 0.8514, 1.4764, 1.4037, 0.9987, 0.9546, 0.5333, 0.2628,\n",
       "                      1.5655, 0.5987, 0.5815, 0.4429, 4.0273, 1.0560, 0.3021, 0.2586, 0.3458,\n",
       "                      2.3331, 1.1471, 0.3979, 2.8440, 1.2857, 0.3556, 0.4910, 0.7748, 0.3000,\n",
       "                      0.4744, 0.3274, 0.3399, 0.5373, 0.3021, 0.6905, 1.1873, 0.4992, 0.8719,\n",
       "                      1.1343, 0.7304, 0.2987, 0.3353, 0.7655, 0.9243, 2.3104, 1.2550, 0.8190,\n",
       "                      2.3519, 0.3487, 1.1002, 2.1289, 0.4836, 0.7227, 0.3917, 0.6118, 3.7777,\n",
       "                      0.8896, 0.5581, 1.1892, 0.2919, 0.6173, 0.4070, 1.5243, 0.3112, 0.9362,\n",
       "                      0.5415, 1.0739, 0.4553, 3.3450, 1.3327, 0.4852, 1.0233, 0.8071, 0.4978,\n",
       "                      0.2664, 0.2774, 0.3012, 0.5994, 1.3308, 2.2324, 1.3626, 1.2543, 0.5893,\n",
       "                      1.8303, 0.9379, 1.8682, 0.5010, 0.9986, 0.9636, 0.9265, 1.5973, 1.8794,\n",
       "                      1.1368, 0.4336, 2.1649, 2.1038, 1.3543, 0.6373, 0.2450, 0.3042, 1.3214,\n",
       "                      0.3903, 3.1833, 0.6762, 0.5345, 1.0162, 0.3299, 0.2778, 1.6283, 1.6670,\n",
       "                      1.5258, 0.3559, 1.0535, 1.9807, 1.1513, 1.3072, 1.0873, 1.8529, 2.0871,\n",
       "                      0.4691, 0.2789, 1.3333, 0.3731, 0.8207, 1.1205, 0.5605, 0.9501, 3.1724,\n",
       "                      0.6980, 1.7911, 0.6260, 1.1665, 0.8669, 0.3396, 1.2459, 0.2860, 0.5571,\n",
       "                      0.5043, 0.9768, 0.7831, 1.6297, 0.2606, 1.0615, 1.0927, 2.4274, 0.3507,\n",
       "                      0.3671, 0.6045, 0.2118, 0.8672, 0.4323, 1.1504, 1.5956, 0.5845, 2.3198,\n",
       "                      0.3083, 0.6245, 2.5408, 1.5956, 1.0542, 0.8456, 1.3492, 2.9432, 1.6869,\n",
       "                      0.3952, 2.1136, 0.9403, 2.3160, 0.9400, 0.2809, 1.0458, 0.4912, 0.5848,\n",
       "                      1.0482, 0.6651, 0.6643, 0.3214, 0.4381, 0.5022, 0.6530, 0.7827, 1.5400,\n",
       "                      0.3174, 0.3349, 0.3992, 1.0408, 1.6509, 1.1889, 0.2558, 0.5745, 0.6209,\n",
       "                      1.5232, 0.4447, 0.3891, 0.3760, 0.9192, 0.4229, 1.4702, 0.5506, 2.7263,\n",
       "                      0.4875, 1.2461, 0.9057, 0.2545, 0.9877, 3.0423, 0.6419, 3.0679, 1.0091,\n",
       "                      0.3673, 1.6470, 1.2273, 0.4284, 0.8435, 2.8421, 0.5776, 1.1208, 1.2661,\n",
       "                      1.0824, 1.1392, 1.6086, 0.4457, 1.6426, 1.0158, 0.3621, 1.5953, 0.8352,\n",
       "                      0.3852, 0.6644, 1.7506, 0.4145, 0.9338, 1.0292, 0.3082, 2.5601, 2.6391,\n",
       "                      1.1701, 0.4618, 1.5713, 0.4084, 0.2723, 0.5740, 1.6174, 0.9477, 0.9818,\n",
       "                      1.6915, 0.9131, 1.3348, 0.3347, 1.1135, 1.1620, 1.0141, 1.5163, 0.2626,\n",
       "                      1.9324, 1.3840, 0.3529, 1.1759, 0.9542, 0.7712, 1.5823, 0.2596, 0.3822,\n",
       "                      1.6736, 1.0309, 0.5921, 2.1126, 0.5078, 0.9765, 1.2719, 0.3386, 0.5630,\n",
       "                      1.2925, 0.8029, 0.2884, 0.3643, 0.3926, 0.4970, 2.5948, 0.3460, 0.8347,\n",
       "                      0.8456, 0.4522, 1.1179, 0.7242, 0.7443, 0.4575, 0.9104, 0.3361, 2.5055,\n",
       "                      0.3376, 0.8164, 0.8067, 1.1706, 1.4479, 0.2823, 0.9711, 2.3911, 1.0304,\n",
       "                      1.8093, 0.6108, 0.7125, 0.4769, 0.2354, 0.7116, 0.4906, 0.5405, 1.0304,\n",
       "                      0.5955, 0.6785, 0.3376, 0.4452, 1.9952, 1.0478, 0.2700, 0.3381, 0.3515,\n",
       "                      0.5681, 0.2708, 0.6861, 0.4817, 0.3677, 0.3298, 0.5975, 0.8597, 0.7995,\n",
       "                      0.2647, 1.2249, 1.5264, 1.7774, 0.8811, 1.9758, 0.4719, 1.3754, 0.4733,\n",
       "                      1.2431, 0.8353, 1.0421, 2.4279, 1.1976, 1.2646, 0.3157, 1.0721, 0.4514,\n",
       "                      0.8962, 1.8168, 3.0302, 0.3630, 0.7037, 0.9451, 0.7380, 0.3432, 1.3134,\n",
       "                      1.3647, 1.4402, 1.7520, 0.3387, 2.5613, 1.2717, 0.6508, 1.7887, 1.1309,\n",
       "                      0.5057, 1.3964, 2.5405, 0.3944, 2.3177, 0.2374, 0.7028, 0.5830, 2.0125,\n",
       "                      0.5969, 1.3063, 1.2283, 0.2460, 0.9222, 1.0615, 0.5974, 1.6876, 2.7349,\n",
       "                      0.3438, 0.3606, 2.6019, 0.6359, 0.7320, 0.8424, 1.3077, 0.5721, 3.0159,\n",
       "                      0.4291, 0.4462, 2.0256, 0.6426, 1.2201, 1.7411, 1.0897, 1.3333, 1.1497,\n",
       "                      0.9948, 0.9096, 1.3326, 0.3629, 0.3653, 2.0705, 0.6493, 0.3399, 0.6682,\n",
       "                      1.2043, 1.1366, 2.0398, 1.4738, 0.2531, 1.2401, 0.3847, 1.2244, 1.6778,\n",
       "                      1.0551, 0.4434, 0.8085, 0.8063, 1.7888, 0.7131, 0.2189, 1.8226, 0.6769,\n",
       "                      1.2568, 0.4909, 1.3989, 0.3286, 1.4759, 1.0804, 1.5091, 0.3188, 1.0178,\n",
       "                      0.3454, 0.9378, 0.3602, 2.4568, 0.3729, 1.0187, 1.4291, 0.6347, 1.0557,\n",
       "                      1.0097, 2.1714, 0.2785, 0.6845, 1.3758, 0.8601, 0.2762, 0.9802, 1.7576,\n",
       "                      1.2218, 1.7603, 1.3330, 2.2067, 2.0088, 1.1507, 0.6889, 2.6468])),\n",
       "             ('bottom_up.0.bn2.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.0.dense3.weight',\n",
       "              tensor([[ 0.0180, -0.0144,  0.0153,  ..., -0.0533, -0.0116, -0.0125],\n",
       "                      [-0.0138,  0.0050,  0.0373,  ..., -0.0131,  0.0106, -0.0246],\n",
       "                      [-0.0277,  0.0128, -0.0169,  ...,  0.0397,  0.0247, -0.0539],\n",
       "                      ...,\n",
       "                      [-0.0005,  0.0023, -0.0012,  ..., -0.0364, -0.0333,  0.0509],\n",
       "                      [ 0.0011, -0.0526, -0.0054,  ..., -0.0304, -0.0361, -0.0051],\n",
       "                      [ 0.0135,  0.0110,  0.0113,  ...,  0.0093, -0.0115,  0.0102]])),\n",
       "             ('bottom_up.0.bn3.weight',\n",
       "              tensor([1.0041, 1.0182, 1.0009, 1.0194, 0.9971, 0.9810, 1.0072, 1.0116, 1.0152,\n",
       "                      0.9985, 0.9936, 0.9845, 0.9869, 0.9928, 1.0013, 1.0016, 0.9900, 0.9984,\n",
       "                      0.9847, 0.9989, 0.9989, 0.9934, 0.9784, 1.0080, 1.0041, 0.9974, 0.9875,\n",
       "                      1.0025, 0.9985, 0.9985, 1.0139, 0.9868, 0.9811, 1.0128, 0.9860, 1.0113,\n",
       "                      0.9989, 0.9796, 1.0024, 1.0061, 1.0183, 1.0186, 1.0149, 0.9922, 0.9992,\n",
       "                      0.9883, 0.9939, 1.0222, 0.9799, 1.0112, 0.9879, 0.9814, 1.0000, 1.0183,\n",
       "                      1.0109, 0.9878, 1.0142, 1.0048, 1.0057, 1.0101, 0.9974, 0.9871, 0.9889,\n",
       "                      1.0222, 1.0143, 1.0166, 1.0163, 0.9795, 0.9832, 0.9948, 1.0019, 0.9852,\n",
       "                      1.0005, 0.9950, 0.9857, 0.9977, 1.0001, 0.9845, 1.0128, 1.0016, 1.0092,\n",
       "                      0.9959, 1.0045, 0.9926, 1.0183, 0.9987, 1.0142, 0.9822, 1.0064, 1.0098,\n",
       "                      0.9936, 1.0055, 0.9886, 1.0136, 0.9954, 0.9959, 0.9986, 1.0214, 0.9971,\n",
       "                      0.9961, 0.9851, 0.9826, 1.0137, 1.0104, 0.9977, 1.0243, 0.9884, 0.9816,\n",
       "                      0.9845, 0.9850, 1.0085, 0.9854, 0.9879, 1.0090, 0.9939, 0.9909, 0.9891,\n",
       "                      0.9975, 0.9890, 1.0205, 0.9797, 0.9852, 1.0040, 0.9923, 1.0057, 0.9824,\n",
       "                      0.9931, 0.9941, 0.9943, 1.0034, 0.9828, 1.0080, 1.0170, 1.0150, 1.0051,\n",
       "                      0.9783, 1.0027, 0.9854, 0.9922, 1.0125, 1.0130, 0.9855, 0.9975, 1.0019,\n",
       "                      0.9799, 1.0148, 0.9996, 1.0175, 0.9905, 1.0046, 0.9900, 0.9854, 0.9896,\n",
       "                      1.0213, 0.9947, 1.0020, 1.0176, 0.9967, 1.0133, 1.0032, 1.0127, 0.9978,\n",
       "                      0.9884, 1.0040, 1.0020, 0.9931, 1.0021, 1.0000, 0.9863, 0.9986, 0.9888,\n",
       "                      0.9887, 0.9921, 0.9956, 0.9814, 0.9897, 1.0094, 0.9939, 0.9922, 0.9993,\n",
       "                      0.9912, 1.0039, 0.9886, 1.0034, 0.9933, 0.9892, 0.9933, 0.9892, 0.9965,\n",
       "                      0.9870, 1.0108, 0.9875, 0.9873, 0.9912, 1.0005, 1.0107, 1.0107, 0.9839,\n",
       "                      1.0161, 1.0126, 0.9937, 1.0127, 1.0171, 0.9922, 0.9954, 1.0048, 1.0126,\n",
       "                      0.9855, 0.9887, 0.9995, 1.0119, 0.9951, 0.9865, 0.9884, 1.0112, 0.9830,\n",
       "                      0.9877, 0.9904, 1.0153, 0.9893, 0.9980, 0.9857, 1.0202, 0.9927, 0.9977,\n",
       "                      1.0246, 1.0010, 0.9943, 0.9952, 1.0108, 0.9896, 0.9936, 1.0150, 1.0078,\n",
       "                      1.0073, 0.9987, 0.9856, 0.9974, 1.0069, 1.0204, 0.9875, 0.9773, 0.9744,\n",
       "                      0.9962, 0.9878, 0.9925, 1.0153, 1.0168, 1.0063, 1.0076, 1.0167, 1.0139,\n",
       "                      0.9974, 0.9914, 0.9920, 0.9764])),\n",
       "             ('bottom_up.0.bn3.bias',\n",
       "              tensor([ 0.0085,  0.0197,  0.0379,  0.0236, -0.0049, -0.0034,  0.0117,  0.0187,\n",
       "                       0.0124,  0.0232,  0.0080, -0.0005, -0.0007, -0.0051,  0.0186,  0.0164,\n",
       "                      -0.0010,  0.0180,  0.0023,  0.0164,  0.0170,  0.0219, -0.0047,  0.0093,\n",
       "                       0.0190, -0.0099,  0.0035,  0.0186,  0.0226,  0.0077,  0.0183,  0.0219,\n",
       "                      -0.0021,  0.0238, -0.0118,  0.0111,  0.0158, -0.0272,  0.0231,  0.0215,\n",
       "                       0.0219,  0.0271,  0.0176,  0.0172,  0.0283, -0.0035,  0.0006,  0.0347,\n",
       "                       0.0155,  0.0155,  0.0004, -0.0102,  0.0088,  0.0211,  0.0118, -0.0147,\n",
       "                       0.0187,  0.0180,  0.0243,  0.0226, -0.0126, -0.0115, -0.0012,  0.0270,\n",
       "                       0.0134,  0.0230,  0.0186, -0.0104, -0.0120,  0.0017, -0.0039,  0.0125,\n",
       "                       0.0207,  0.0042,  0.0197,  0.0181,  0.0134, -0.0166,  0.0261,  0.0291,\n",
       "                       0.0273,  0.0056,  0.0011,  0.0205,  0.0178,  0.0132,  0.0220, -0.0081,\n",
       "                       0.0159,  0.0205,  0.0118,  0.0246,  0.0152,  0.0241,  0.0119,  0.0256,\n",
       "                       0.0116,  0.0359,  0.0136, -0.0218, -0.0095,  0.0023,  0.0286,  0.0270,\n",
       "                      -0.0004,  0.0230,  0.0119, -0.0210, -0.0038,  0.0081,  0.0152, -0.0181,\n",
       "                       0.0428,  0.0169,  0.0097,  0.0172, -0.0144, -0.0029, -0.0050,  0.0245,\n",
       "                      -0.0184,  0.0067,  0.0113, -0.0062,  0.0133, -0.0136,  0.0011,  0.0115,\n",
       "                       0.0224,  0.0207, -0.0077,  0.0126,  0.0307,  0.0292,  0.0245, -0.0077,\n",
       "                       0.0073, -0.0040,  0.0176,  0.0153,  0.0309,  0.0139, -0.0166,  0.0120,\n",
       "                      -0.0166,  0.0211,  0.0026,  0.0158,  0.0096,  0.0139,  0.0099,  0.0112,\n",
       "                       0.0096,  0.0293, -0.0032, -0.0064,  0.0330,  0.0187,  0.0182,  0.0144,\n",
       "                       0.0385,  0.0297,  0.0197,  0.0078,  0.0059, -0.0010,  0.0200,  0.0145,\n",
       "                      -0.0046,  0.0186, -0.0028,  0.0132,  0.0051, -0.0060, -0.0138,  0.0166,\n",
       "                       0.0254,  0.0082,  0.0182,  0.0187, -0.0202,  0.0011, -0.0145,  0.0219,\n",
       "                       0.0161, -0.0023, -0.0026, -0.0061,  0.0041,  0.0129,  0.0061, -0.0055,\n",
       "                      -0.0091,  0.0068,  0.0184,  0.0284,  0.0235,  0.0109,  0.0227,  0.0174,\n",
       "                       0.0261,  0.0200,  0.0062,  0.0012, -0.0120,  0.0115,  0.0254, -0.0038,\n",
       "                       0.0097,  0.0230,  0.0129,  0.0267, -0.0075, -0.0024,  0.0215, -0.0202,\n",
       "                      -0.0141, -0.0023,  0.0169,  0.0067,  0.0118, -0.0154,  0.0225, -0.0059,\n",
       "                       0.0116,  0.0252,  0.0105, -0.0014,  0.0056,  0.0193,  0.0051,  0.0309,\n",
       "                       0.0218,  0.0223,  0.0218,  0.0117, -0.0094,  0.0009,  0.0159,  0.0256,\n",
       "                      -0.0128,  0.0021, -0.0145, -0.0063,  0.0125, -0.0005,  0.0261,  0.0244,\n",
       "                       0.0230,  0.0118,  0.0185,  0.0162,  0.0252,  0.0098,  0.0048, -0.0068])),\n",
       "             ('bottom_up.0.bn3.running_mean',\n",
       "              tensor([-0.0794, -0.5076, -0.4647, -0.4315, -0.7237, -0.2132,  0.2025,  0.3686,\n",
       "                      -0.2042, -0.1872, -0.0555, -0.2290, -0.4059,  0.4751, -0.2486, -0.0277,\n",
       "                      -0.0165, -0.1739, -0.6155, -0.4289, -0.2847, -0.5755, -0.7484,  0.2709,\n",
       "                      -0.1632,  0.2177, -0.3297, -0.1184, -0.3102,  0.0183, -0.0507, -0.2428,\n",
       "                      -0.3050, -1.2423,  0.0315,  0.5342, -0.3612, -0.0378,  0.0752, -0.7664,\n",
       "                      -0.1467, -0.3582, -0.0422, -0.5494, -0.6626, -0.0562, -0.2696, -0.8210,\n",
       "                      -0.5134,  0.0570, -0.8791, -0.3901, -0.0984, -0.3172,  0.2544, -0.4171,\n",
       "                       0.0682,  0.3011, -0.6732, -0.0521,  0.3654,  0.4232, -0.4651, -0.8154,\n",
       "                       0.0632, -0.2563, -0.3363, -0.1286,  0.3584, -0.1478,  0.2433, -0.1456,\n",
       "                      -0.6130, -0.6589, -0.5511, -0.1187,  0.1845,  0.2120, -0.2537, -0.3094,\n",
       "                      -0.4230, -0.2359,  0.5763, -0.2811, -0.1649, -0.0791,  0.0239,  0.2243,\n",
       "                       0.3359, -0.4845, -0.0359,  0.1941, -0.4136, -0.1240, -0.3511, -1.1010,\n",
       "                      -0.3733, -0.6412, -0.4731,  0.9667, -0.4643, -0.8068, -0.7521, -1.1332,\n",
       "                      -0.0122, -0.1262, -0.3950,  0.3252,  0.3305, -0.6673,  0.0558,  0.2686,\n",
       "                      -0.7533, -0.3555, -0.0609, -0.3458, -0.4261, -0.4046, -0.4024,  0.2639,\n",
       "                      -0.2506, -0.4939,  0.1994, -0.0738, -0.4164, -0.5737, -0.5200, -0.0507,\n",
       "                      -0.0027,  0.3508, -0.1175, -0.7321, -0.4494, -0.3061, -0.6957, -0.5089,\n",
       "                      -0.4011, -0.1777, -0.4807,  0.2651, -0.2295, -0.4442,  0.3767, -0.0748,\n",
       "                       0.5454, -0.3865, -0.3412, -0.2956,  0.0271, -0.0141, -0.1953, -0.1375,\n",
       "                      -0.3406, -0.4288,  0.5834,  0.1390, -0.5696, -0.2504, -0.1500, -0.6699,\n",
       "                      -0.9715, -0.8785, -0.7916,  0.5951,  0.1420, -0.1050, -0.1174,  0.3749,\n",
       "                       0.3873, -0.9293, -0.8284, -0.7389,  0.1959,  0.4996,  0.1057, -0.5428,\n",
       "                      -0.0335, -0.9203, -0.7643, -0.4531,  0.2342,  0.3444, -0.4274, -0.1588,\n",
       "                      -0.8222, -0.9391,  0.3835,  0.3091, -0.0656, -0.3679,  0.3863, -0.2093,\n",
       "                       0.2594, -0.3197, -0.4815,  0.1566,  0.2271, -0.7439,  0.1646,  0.2967,\n",
       "                      -0.4558, -0.1387,  0.0244,  0.3581,  0.3314, -0.3356, -0.5167, -0.1167,\n",
       "                      -0.4009, -0.2173, -0.0609, -0.7875, -1.0470,  0.1038, -0.0025,  0.0911,\n",
       "                       0.2790,  0.3299,  0.4238,  0.3034,  0.8167, -0.0045, -0.0615,  0.2179,\n",
       "                      -0.4583, -0.1781, -0.7168, -0.1512,  0.3210, -0.3175,  0.2129, -0.7753,\n",
       "                      -0.0909,  0.4305,  0.3203,  0.0886, -0.1909, -0.0945,  0.0379, -0.2498,\n",
       "                       0.1671, -0.2631, -0.2817,  0.4563, -0.3610, -0.4549, -0.5341, -0.3998,\n",
       "                       0.1478, -0.0348,  0.1786,  0.1893, -0.6136, -0.1103, -0.6283, -0.3592])),\n",
       "             ('bottom_up.0.bn3.running_var',\n",
       "              tensor([1.3699, 2.7190, 0.4700, 4.6290, 3.1892, 1.7203, 3.2450, 5.2971, 4.2072,\n",
       "                      3.0146, 3.2056, 2.0888, 0.7786, 2.4260, 2.5575, 5.9155, 2.1058, 5.2027,\n",
       "                      0.9248, 2.4150, 2.3084, 2.4609, 0.5825, 2.7491, 2.3960, 1.0836, 2.5209,\n",
       "                      3.9470, 3.4827, 1.6337, 6.4349, 1.9186, 2.0590, 1.7632, 1.7878, 1.2613,\n",
       "                      3.2572, 0.2395, 1.7498, 2.4936, 4.5965, 2.3179, 3.2795, 0.7726, 3.2364,\n",
       "                      1.4380, 2.6661, 3.0692, 1.6912, 5.6002, 0.3668, 3.1120, 2.8473, 5.7059,\n",
       "                      3.8899, 1.6799, 5.5382, 2.4679, 2.2807, 5.6513, 1.0132, 0.3231, 2.0494,\n",
       "                      3.1666, 4.0044, 4.0935, 4.2098, 0.9465, 1.2630, 1.0972, 7.0540, 2.2581,\n",
       "                      1.7670, 0.6572, 1.0391, 3.4426, 2.3214, 1.7359, 6.4120, 2.5520, 1.6302,\n",
       "                      2.4537, 2.1881, 2.0141, 6.3356, 4.3704, 3.9643, 0.2935, 4.9630, 2.8113,\n",
       "                      1.6222, 3.4926, 1.3650, 4.8354, 0.2801, 0.8073, 3.1979, 2.2372, 1.1324,\n",
       "                      0.6013, 0.8417, 0.7486, 3.6996, 1.2627, 3.0634, 6.2881, 3.6950, 1.3814,\n",
       "                      1.4036, 1.3840, 2.8416, 1.5513, 1.5220, 3.5290, 1.7243, 2.9770, 0.3660,\n",
       "                      1.7205, 0.3128, 5.1193, 1.1324, 1.8822, 3.8234, 1.0675, 3.1391, 0.4613,\n",
       "                      1.5125, 1.3757, 3.4421, 3.2445, 1.7416, 1.4040, 4.7371, 2.2717, 1.1743,\n",
       "                      0.4267, 1.1488, 1.3879, 1.9228, 2.1173, 5.3973, 0.7227, 2.5222, 2.9556,\n",
       "                      0.2690, 6.7788, 4.2540, 6.3536, 2.0826, 3.8665, 2.5992, 2.6932, 0.9859,\n",
       "                      4.0179, 0.5272, 5.7862, 4.4678, 3.8707, 4.2605, 1.3870, 2.2380, 2.0984,\n",
       "                      2.0432, 2.9705, 2.9663, 1.7147, 2.6782, 4.8063, 1.1157, 1.5259, 0.7727,\n",
       "                      0.7764, 0.5955, 1.0053, 1.0562, 5.3243, 3.9308, 1.4214, 0.9775, 3.5487,\n",
       "                      1.0417, 2.1689, 0.2420, 2.5006, 0.3419, 0.8111, 1.0218, 1.0492, 4.6176,\n",
       "                      2.1051, 6.3513, 0.9524, 0.4153, 1.1487, 2.9211, 3.0941, 3.6612, 1.5174,\n",
       "                      6.3256, 2.5934, 0.6192, 5.5379, 3.7230, 1.8588, 0.3082, 2.3857, 5.6485,\n",
       "                      2.6344, 0.4363, 3.4538, 2.6463, 1.2724, 0.8505, 1.3057, 5.0596, 0.6969,\n",
       "                      0.5688, 3.2629, 2.7778, 0.9994, 1.3398, 0.4405, 3.1805, 0.5244, 1.4802,\n",
       "                      3.7024, 0.6875, 2.1694, 3.2032, 3.7428, 2.4244, 1.0325, 4.4363, 2.9309,\n",
       "                      2.1643, 2.6636, 0.3622, 3.3813, 5.3095, 5.6907, 0.1657, 0.9277, 0.5215,\n",
       "                      1.2325, 2.0476, 3.5973, 2.2475, 3.9746, 3.0007, 3.4592, 5.9897, 4.2634,\n",
       "                      1.9217, 3.0693, 0.4378, 0.7480])),\n",
       "             ('bottom_up.0.bn3.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.0.dense4.weight',\n",
       "              tensor([[-0.0687,  0.0532,  0.0674,  ...,  0.0456,  0.0403,  0.0437],\n",
       "                      [ 0.0267,  0.0141, -0.0238,  ...,  0.0518,  0.0440, -0.0252],\n",
       "                      [ 0.0148, -0.0575,  0.0213,  ...,  0.0480, -0.0318,  0.0270],\n",
       "                      ...,\n",
       "                      [-0.0366,  0.0591,  0.0562,  ...,  0.0103, -0.0392,  0.0524],\n",
       "                      [-0.0441,  0.0074,  0.0084,  ..., -0.0648,  0.0558,  0.0395],\n",
       "                      [-0.0550,  0.0327,  0.0200,  ...,  0.0513,  0.0254, -0.0203]])),\n",
       "             ('bottom_up.0.bn4.weight',\n",
       "              tensor([1.0035, 1.0143, 1.0145, 1.0088, 1.0015, 0.9813, 0.9980, 0.9811, 0.9900,\n",
       "                      0.9799, 0.9793, 0.9874, 0.9807, 0.9825, 0.9869, 1.0062, 1.0031, 1.0158,\n",
       "                      1.0063, 1.0103, 0.9864, 1.0124, 0.9788, 0.9850, 0.9915, 0.9962, 1.0215,\n",
       "                      1.0045, 1.0099, 1.0068, 1.0138, 0.9831, 0.9854, 0.9816, 1.0036, 0.9951,\n",
       "                      0.9889, 0.9932, 1.0008, 1.0033, 1.0203, 0.9900, 0.9944, 0.9979, 1.0191,\n",
       "                      0.9799, 0.9881, 0.9825, 1.0190, 1.0047, 0.9829, 0.9820, 0.9994, 0.9903,\n",
       "                      1.0056, 0.9807, 1.0112, 1.0172, 0.9866, 0.9915, 0.9944, 0.9987, 0.9894,\n",
       "                      0.9914, 0.9906, 0.9840, 1.0131, 0.9809, 1.0106, 0.9993, 1.0049, 1.0093,\n",
       "                      0.9918, 0.9880, 1.0151, 0.9935, 1.0026, 0.9818, 1.0183, 0.9969, 0.9874,\n",
       "                      0.9845, 0.9995, 1.0026, 0.9936, 1.0112, 1.0191, 1.0053, 1.0141, 1.0047,\n",
       "                      0.9864, 1.0011, 0.9857, 1.0161, 0.9977, 1.0057, 0.9876, 1.0157, 0.9807,\n",
       "                      0.9943, 1.0139, 0.9994, 1.0127, 0.9852, 1.0055, 1.0134, 0.9840, 1.0108,\n",
       "                      0.9882, 1.0078, 0.9917, 1.0007, 1.0023, 0.9944, 0.9851, 0.9848, 0.9848,\n",
       "                      0.9976, 0.9859, 1.0146, 0.9813, 1.0181, 1.0003, 1.0180, 0.9789, 0.9917,\n",
       "                      0.9835, 1.0091])),\n",
       "             ('bottom_up.0.bn4.bias',\n",
       "              tensor([ 0.0246,  0.0309,  0.0198,  0.0180,  0.0207, -0.0149, -0.0071, -0.0212,\n",
       "                      -0.0178, -0.0110,  0.0270,  0.0042, -0.0065, -0.0142,  0.0070,  0.0156,\n",
       "                       0.0148,  0.0212,  0.0283,  0.0229,  0.0015,  0.0230, -0.0193,  0.0038,\n",
       "                       0.0106, -0.0024,  0.0305,  0.0197,  0.0211,  0.0200,  0.0176,  0.0224,\n",
       "                       0.0101,  0.0405,  0.0189,  0.0116,  0.0077,  0.0157,  0.0103,  0.0237,\n",
       "                       0.0199,  0.0085,  0.0168,  0.0276,  0.0214,  0.0020, -0.0061,  0.0187,\n",
       "                       0.0254,  0.0165,  0.0041, -0.0139,  0.0196,  0.0176,  0.0183, -0.0244,\n",
       "                       0.0279,  0.0237, -0.0070, -0.0039,  0.0249,  0.0166, -0.0058,  0.0037,\n",
       "                       0.0111, -0.0145,  0.0115, -0.0178,  0.0192,  0.0178, -0.0036,  0.0209,\n",
       "                       0.0161,  0.0055,  0.0148, -0.0097,  0.0139, -0.0078,  0.0206,  0.0196,\n",
       "                       0.0015, -0.0036,  0.0178,  0.0107,  0.0176,  0.0263,  0.0244,  0.0207,\n",
       "                       0.0202,  0.0177, -0.0006,  0.0133,  0.0098,  0.0175,  0.0098,  0.0159,\n",
       "                      -0.0070,  0.0254, -0.0189,  0.0045,  0.0194,  0.0170,  0.0141, -0.0108,\n",
       "                       0.0257,  0.0292,  0.0152,  0.0173,  0.0075,  0.0254,  0.0044,  0.0237,\n",
       "                       0.0224, -0.0034,  0.0119,  0.0016, -0.0043,  0.0118, -0.0359,  0.0185,\n",
       "                       0.0047,  0.0149,  0.0209,  0.0227, -0.0176,  0.0178,  0.0238,  0.0179])),\n",
       "             ('bottom_up.0.bn4.running_mean',\n",
       "              tensor([-0.1403, -0.7722, -0.3347, -0.0083, -0.7266, -0.2869,  0.1908,  0.0283,\n",
       "                       0.7266, -0.0384, -0.2085, -0.0178, -0.2431, -0.4483, -0.6365, -0.3821,\n",
       "                      -0.0761, -0.1817, -0.7560, -0.3857,  0.0692, -0.1612, -0.0978,  0.1637,\n",
       "                      -0.7627,  0.1320, -0.3861, -0.1862, -0.1338,  0.1970, -0.1298, -0.4865,\n",
       "                      -0.0608, -0.5206,  0.2301, -0.3446, -0.1692, -0.4132,  0.1561, -0.4044,\n",
       "                       0.0165,  0.1193,  0.1264, -0.6522, -0.1420,  0.0502, -0.1590,  0.2951,\n",
       "                      -0.7832,  0.0904,  0.3168,  0.1656,  0.0631,  0.0403, -0.5791,  0.0586,\n",
       "                      -0.7408, -0.7588,  0.2142,  0.0476, -0.4224,  0.1115, -0.5170,  0.1675,\n",
       "                      -0.1577,  0.0782,  0.2192,  0.1283, -0.6248, -0.0113,  0.2887, -0.2446,\n",
       "                      -0.6698, -0.0126, -0.2062,  0.2087, -0.1459,  0.3446, -0.1315, -0.2821,\n",
       "                      -0.6143, -0.0552, -0.5081,  0.2912, -0.4811, -0.4043, -0.5691,  0.0118,\n",
       "                      -0.1167, -0.0786, -0.2119, -0.8489, -0.1386, -0.5078,  0.1107,  0.5569,\n",
       "                      -0.3180, -0.4585, -0.3443,  0.9427, -0.1131, -0.3254, -0.0053, -0.2743,\n",
       "                      -0.8715, -0.8070, -0.1178,  0.0027,  0.4564, -0.2637,  0.1003, -0.6720,\n",
       "                      -0.1086, -0.0532, -0.0653,  0.1807,  0.1520,  0.2234,  0.2121,  0.1554,\n",
       "                      -0.4111, -0.1559, -0.3355,  0.0941,  0.4568, -0.3554, -0.3054, -0.0940])),\n",
       "             ('bottom_up.0.bn4.running_var',\n",
       "              tensor([3.8674, 1.5330, 1.7220, 3.0207, 0.6657, 0.4336, 1.1165, 0.3278, 0.6132,\n",
       "                      0.1720, 1.0227, 2.0856, 1.6704, 0.4323, 0.4938, 1.8307, 2.7754, 2.8284,\n",
       "                      1.3334, 3.7820, 2.6422, 1.5007, 0.8594, 1.0566, 0.4324, 0.5975, 1.9292,\n",
       "                      1.6084, 2.4489, 2.9088, 3.6556, 0.6571, 2.6393, 0.7232, 2.9175, 1.2582,\n",
       "                      1.3139, 1.0296, 3.1261, 1.2362, 3.3125, 1.4117, 1.8105, 2.1081, 4.5279,\n",
       "                      2.1516, 1.6908, 1.5528, 1.5987, 2.6047, 0.8650, 0.9259, 1.8514, 0.6032,\n",
       "                      0.7521, 0.5250, 0.6632, 0.4587, 0.9858, 0.7442, 0.6816, 3.2117, 0.6083,\n",
       "                      1.6854, 0.7490, 0.6627, 3.6386, 0.4909, 3.1197, 1.8438, 2.1587, 2.9473,\n",
       "                      1.1557, 2.4693, 2.5507, 2.0361, 2.9084, 0.3364, 3.3343, 2.1989, 1.4247,\n",
       "                      0.8506, 2.6384, 1.9953, 1.3448, 2.3842, 1.2649, 3.6544, 3.6135, 2.8385,\n",
       "                      0.8519, 0.4763, 1.3634, 0.3843, 2.4122, 1.0523, 3.4274, 1.6599, 0.1411,\n",
       "                      0.4624, 2.6312, 1.3454, 3.4543, 1.2947, 0.5575, 0.8094, 1.5725, 2.5294,\n",
       "                      0.8810, 1.8157, 2.1398, 0.6560, 2.0516, 2.5508, 0.8946, 1.2864, 2.4371,\n",
       "                      1.8823, 0.3470, 1.8757, 0.7684, 4.4506, 2.0147, 2.4568, 0.1465, 1.2094,\n",
       "                      1.6149, 3.6628])),\n",
       "             ('bottom_up.0.bn4.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.1.dense1.weight',\n",
       "              tensor([[-0.0521, -0.0395, -0.0645,  ...,  0.0089,  0.0754,  0.0150],\n",
       "                      [ 0.0164,  0.0739, -0.0025,  ...,  0.0025,  0.0801,  0.0739],\n",
       "                      [ 0.0239, -0.0206, -0.0662,  ...,  0.0422,  0.0534, -0.0493],\n",
       "                      ...,\n",
       "                      [ 0.0260,  0.0481,  0.0283,  ..., -0.0429,  0.0257, -0.0868],\n",
       "                      [ 0.0900,  0.0357, -0.0840,  ...,  0.0223, -0.0165, -0.0822],\n",
       "                      [-0.0964,  0.0220, -0.0027,  ..., -0.0782,  0.0129, -0.0466]])),\n",
       "             ('bottom_up.1.bn1.weight',\n",
       "              tensor([1.0024, 1.0206, 1.0264, 1.0000, 1.0027, 1.0148, 1.0102, 1.0199, 1.0019,\n",
       "                      1.0098, 0.9903, 0.9778, 1.0038, 1.0150, 1.0197, 1.0107, 1.0046, 1.0056,\n",
       "                      1.0275, 1.0169, 1.0222, 0.9917, 1.0225, 1.0174, 1.0131, 1.0026, 1.0084,\n",
       "                      0.9883, 0.9980, 1.0183, 1.0161, 1.0161, 1.0127, 1.0178, 1.0142, 1.0111,\n",
       "                      1.0043, 1.0159, 1.0258, 0.9979, 1.0151, 1.0111, 1.0155, 1.0153, 1.0119,\n",
       "                      0.9984, 1.0047, 1.0205, 1.0147, 1.0226, 1.0121, 0.9960, 1.0079, 1.0069,\n",
       "                      1.0008, 0.9980, 1.0098, 1.0042, 1.0182, 1.0169, 1.0047, 1.0134, 1.0224,\n",
       "                      0.9986, 1.0101, 1.0108, 1.0109, 1.0154, 1.0140, 0.9926, 1.0041, 1.0002,\n",
       "                      1.0163, 0.9814, 1.0054, 0.9859, 1.0060, 0.9967, 1.0149, 1.0117, 1.0147,\n",
       "                      1.0182, 1.0038, 1.0188, 1.0100, 1.0064, 1.0186, 1.0106, 1.0097, 1.0185,\n",
       "                      1.0045, 0.9886, 1.0215, 0.9925, 1.0036, 1.0101, 1.0138, 1.0107, 0.9935,\n",
       "                      1.0235, 1.0131, 0.9958, 0.9868, 0.9883, 1.0215, 1.0014, 1.0210, 1.0148,\n",
       "                      1.0065, 0.9982, 0.9885, 1.0118, 1.0133, 1.0136, 1.0178, 1.0176, 1.0021,\n",
       "                      0.9920, 1.0092, 0.9932, 1.0217, 1.0140, 0.9984, 0.9895, 0.9874, 1.0145,\n",
       "                      0.9995, 1.0203])),\n",
       "             ('bottom_up.1.bn1.bias',\n",
       "              tensor([ 1.9428e-02,  1.6153e-02,  2.4307e-02, -5.9900e-03,  1.3604e-02,\n",
       "                       1.8851e-02,  2.2266e-02,  2.2550e-02,  2.0663e-02,  1.6893e-02,\n",
       "                       1.4134e-02,  1.2008e-02,  2.6248e-02,  2.1897e-02,  2.5878e-02,\n",
       "                       1.9634e-02,  9.0585e-03,  1.7702e-03,  3.2325e-02,  3.2776e-02,\n",
       "                       2.3263e-02,  2.3665e-02,  2.1167e-02,  2.4655e-02,  1.9522e-02,\n",
       "                       7.1440e-03,  2.0496e-02, -8.7171e-04,  2.2831e-02,  3.2076e-02,\n",
       "                       2.7083e-02,  2.0031e-02,  2.2522e-02,  2.3385e-02,  2.0899e-02,\n",
       "                       1.5899e-02,  2.1277e-02,  1.1035e-02,  1.6874e-02, -1.2945e-03,\n",
       "                       1.8764e-02,  1.9956e-02,  1.8072e-02,  2.1273e-02,  2.2354e-02,\n",
       "                       2.2044e-02,  1.2988e-02,  2.4092e-02,  2.0584e-02,  2.6091e-02,\n",
       "                       2.0787e-02,  2.2845e-02,  2.2816e-03,  1.1328e-02,  7.0089e-03,\n",
       "                       1.6724e-02,  1.1109e-02,  1.9082e-02,  2.7599e-02,  2.3343e-02,\n",
       "                       1.6637e-02,  1.3258e-02,  2.5713e-02, -6.6920e-03,  1.2837e-02,\n",
       "                       2.1042e-02,  1.0898e-02,  2.1606e-02,  1.7596e-02,  1.0846e-02,\n",
       "                       2.2874e-02,  2.1882e-02,  3.1195e-02,  1.9081e-02,  2.2362e-02,\n",
       "                      -1.5777e-02,  1.0054e-02,  1.3349e-02,  2.7527e-02,  1.4662e-02,\n",
       "                       1.7528e-02,  2.0732e-02,  3.0193e-02,  1.9523e-02,  2.4306e-02,\n",
       "                       1.8722e-02,  2.1838e-02,  2.1073e-02,  1.8299e-02,  1.8200e-02,\n",
       "                       1.7433e-02,  1.0867e-02,  1.3819e-02,  2.6801e-03,  1.1111e-02,\n",
       "                       3.0424e-03,  1.8928e-02,  1.2948e-02,  2.0120e-02,  2.9078e-02,\n",
       "                       2.2337e-02, -3.2735e-05, -3.6286e-03, -2.9315e-03,  2.8611e-02,\n",
       "                       6.6840e-03,  4.7995e-03,  2.1452e-02,  2.2425e-02,  9.0598e-03,\n",
       "                      -1.1424e-02,  3.6968e-02,  1.5902e-02,  1.9649e-02,  2.2634e-02,\n",
       "                       2.7100e-02,  1.8177e-02,  1.6055e-02,  1.3253e-02, -3.2177e-03,\n",
       "                       2.9949e-02,  1.6928e-02, -5.4648e-04, -1.5655e-02,  1.4629e-03,\n",
       "                       1.9750e-02,  2.1055e-03,  3.2657e-02])),\n",
       "             ('bottom_up.1.bn1.running_mean',\n",
       "              tensor([-0.0229, -0.0577, -0.5156,  0.6404, -0.5420, -0.0260, -0.1015, -0.1240,\n",
       "                       0.0344, -0.2839, -0.4643, -0.2064, -0.0402, -0.2435, -0.6123, -0.2405,\n",
       "                       0.0305,  0.0908, -0.3819, -0.0752, -0.0592, -0.1410, -0.0552, -0.4116,\n",
       "                      -0.3961, -0.2976, -0.3044,  0.2849, -0.0297,  0.1108, -0.3870, -0.1971,\n",
       "                      -0.1184,  0.0847, -0.1269, -0.2185,  0.0555, -0.0143, -0.5943,  0.5254,\n",
       "                       0.0056,  0.0307, -0.3333, -0.1656,  0.0088, -0.2893, -0.2117,  0.0062,\n",
       "                      -0.0821,  0.1750,  0.2710,  0.1291,  0.4870,  0.4440,  0.1007,  0.0488,\n",
       "                       0.1077,  0.0326, -0.1967, -0.4602, -0.0272, -0.3092, -0.0514, -0.2355,\n",
       "                      -0.1948, -0.1492,  0.3257, -0.1178, -0.1112, -0.0945,  0.2137,  0.3808,\n",
       "                      -0.3887, -0.7179,  0.1156,  0.1478, -0.3008,  0.0077, -0.0796, -0.1408,\n",
       "                       0.1721,  0.0806, -0.4446,  0.0702, -0.2685,  0.1228, -0.1205, -0.2457,\n",
       "                       0.1374, -0.2810,  0.2967, -0.1681, -0.1331, -0.3991, -0.2398, -0.0216,\n",
       "                      -0.0495,  0.4436, -0.2743, -0.5205,  0.3806,  0.2120, -0.1818,  0.0168,\n",
       "                      -0.1791, -0.0453, -0.0977, -0.3245, -0.0961,  0.2541, -0.0538, -0.4539,\n",
       "                       0.0793, -0.3218, -0.0243, -0.3823,  0.5536,  0.2192, -0.1993, -0.1848,\n",
       "                      -0.7538, -0.3846,  0.3294,  0.0589,  0.0413, -0.1516,  0.0462, -0.2698])),\n",
       "             ('bottom_up.1.bn1.running_var',\n",
       "              tensor([0.8755, 0.5042, 0.2018, 0.0760, 0.4132, 0.3514, 0.7902, 0.6880, 0.9676,\n",
       "                      0.8819, 0.5594, 0.3627, 1.2506, 1.1003, 0.0682, 0.6787, 1.1890, 0.2253,\n",
       "                      0.2219, 0.9795, 1.3180, 0.2964, 1.0872, 0.3956, 1.5526, 1.2515, 0.9643,\n",
       "                      0.5387, 0.6488, 0.5595, 0.4529, 1.2518, 2.3458, 1.4678, 0.7916, 0.7367,\n",
       "                      0.8750, 0.9296, 0.0640, 0.1897, 2.2864, 1.0548, 0.3699, 1.4311, 1.5164,\n",
       "                      0.6734, 0.5312, 0.7204, 1.5742, 1.8561, 0.1414, 0.2054, 0.1340, 0.1340,\n",
       "                      0.1403, 0.5018, 0.8366, 0.5927, 0.6081, 1.4944, 0.1523, 0.7752, 1.2531,\n",
       "                      0.5016, 0.6013, 1.8759, 1.4352, 1.1521, 1.6669, 1.0277, 0.6714, 0.6674,\n",
       "                      0.3148, 1.0622, 0.8574, 0.6975, 0.3688, 1.1244, 0.9720, 1.1452, 1.3730,\n",
       "                      0.8597, 0.3145, 0.9884, 0.8137, 0.6234, 1.1357, 1.5396, 0.6051, 0.3207,\n",
       "                      0.1091, 0.6229, 1.3640, 0.0681, 0.4125, 1.4156, 0.6706, 0.8706, 0.5839,\n",
       "                      0.4346, 1.5912, 0.1466, 0.3627, 0.7078, 2.2949, 0.2431, 0.7341, 0.6502,\n",
       "                      0.2481, 0.1231, 0.2384, 0.2371, 0.8318, 0.2777, 1.6024, 0.3997, 0.8546,\n",
       "                      1.4560, 0.9481, 0.1202, 0.0749, 1.3775, 0.1353, 0.3132, 0.1030, 0.5408,\n",
       "                      0.5416, 0.5155])),\n",
       "             ('bottom_up.1.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.1.mu.weight',\n",
       "              tensor([[-0.0488,  0.0140, -0.0059,  ...,  0.0160, -0.0112,  0.0254],\n",
       "                      [-0.0101, -0.0391,  0.0360,  ..., -0.0425,  0.0875,  0.0171],\n",
       "                      [-0.0720,  0.0319, -0.0339,  ...,  0.0620, -0.0079, -0.0212],\n",
       "                      ...,\n",
       "                      [ 0.0273, -0.0471, -0.0200,  ..., -0.0648,  0.0200,  0.0207],\n",
       "                      [-0.0394,  0.0584, -0.0366,  ..., -0.0228, -0.0640, -0.0216],\n",
       "                      [-0.0566, -0.0824,  0.0825,  ..., -0.0431,  0.0477, -0.0765]])),\n",
       "             ('bottom_up.1.mu.bias',\n",
       "              tensor([-0.0747,  0.0273, -0.0415,  0.0657, -0.0182, -0.0244, -0.0668,  0.0297,\n",
       "                       0.0330, -0.0659,  0.0650,  0.0643, -0.0664,  0.0365, -0.0578, -0.0361,\n",
       "                       0.0012, -0.0791, -0.0256, -0.0826,  0.0695,  0.0553, -0.0371,  0.0178,\n",
       "                       0.0295, -0.0839, -0.0755, -0.0254, -0.0048, -0.0125,  0.0021,  0.0495])),\n",
       "             ('bottom_up.1.sigma.weight',\n",
       "              tensor([[-8.5238e-02, -2.1158e-02, -4.4824e-02,  ...,  8.6987e-02,\n",
       "                       -6.2412e-03, -8.1991e-03],\n",
       "                      [ 5.0874e-02, -7.9328e-02, -3.0499e-02,  ..., -8.5326e-04,\n",
       "                       -6.5809e-02, -1.7505e-04],\n",
       "                      [ 3.1275e-02,  6.6000e-02,  6.2162e-02,  ..., -8.6959e-05,\n",
       "                       -8.5006e-02, -4.5626e-02],\n",
       "                      ...,\n",
       "                      [ 4.0559e-02, -3.4495e-02, -2.9529e-02,  ...,  7.2442e-02,\n",
       "                        6.6238e-02,  1.9129e-02],\n",
       "                      [-4.5623e-02, -3.5906e-02,  7.2142e-02,  ...,  6.7054e-02,\n",
       "                       -7.7230e-02,  3.6447e-02],\n",
       "                      [-7.8081e-03,  8.2599e-02, -8.0240e-02,  ...,  7.8684e-03,\n",
       "                        6.0567e-02,  5.9852e-03]])),\n",
       "             ('bottom_up.1.sigma.bias',\n",
       "              tensor([ 0.0817,  0.0114, -0.0418, -0.0658, -0.0229,  0.0354, -0.0419, -0.0168,\n",
       "                      -0.0388,  0.0290,  0.0762,  0.0082, -0.0692, -0.0471, -0.0049, -0.0024,\n",
       "                      -0.0878,  0.0100,  0.0870,  0.0849, -0.0801,  0.0446, -0.0109,  0.0375,\n",
       "                      -0.0066,  0.0770, -0.0576,  0.0208, -0.0648,  0.0882,  0.0396,  0.0094])),\n",
       "             ('bottom_up.2.dense1.weight',\n",
       "              tensor([[ 8.2302e-02,  6.2541e-02,  4.2930e-02,  ...,  1.8696e-02,\n",
       "                       -1.7412e-03,  6.8076e-02],\n",
       "                      [-1.0140e-01, -6.0029e-02, -2.3774e-02,  ..., -5.4419e-02,\n",
       "                       -3.5506e-02, -1.5711e-02],\n",
       "                      [-2.7926e-03, -2.2496e-02,  3.9624e-02,  ..., -6.6153e-02,\n",
       "                        8.6448e-03, -1.0168e-02],\n",
       "                      ...,\n",
       "                      [ 2.1743e-02, -2.0312e-02,  9.6056e-03,  ..., -4.1653e-02,\n",
       "                        2.4522e-02, -1.6469e-02],\n",
       "                      [ 2.4053e-02, -5.2792e-02, -3.9058e-02,  ...,  7.5945e-02,\n",
       "                       -1.5787e-02, -3.9809e-02],\n",
       "                      [-7.6802e-05,  3.7346e-02, -2.2674e-02,  ..., -5.1790e-02,\n",
       "                       -1.9261e-02,  3.6725e-02]])),\n",
       "             ('bottom_up.2.bn1.weight',\n",
       "              tensor([1.0033, 1.0179, 0.9966, 0.9813, 1.0085, 1.0133, 0.9963, 0.9913, 0.9999,\n",
       "                      0.9996, 1.0070, 1.0151, 1.0131, 0.9822, 0.9816, 1.0112, 0.9857, 0.9938,\n",
       "                      1.0208, 1.0153, 1.0152, 1.0179, 1.0081, 0.9817, 1.0015, 1.0000, 0.9959,\n",
       "                      1.0055, 1.0019, 1.0178, 1.0101, 1.0118, 0.9873, 0.9787, 0.9854, 0.9824,\n",
       "                      1.0137, 1.0115, 1.0034, 1.0057, 1.0120, 1.0119, 1.0005, 0.9939, 0.9948,\n",
       "                      0.9882, 1.0170, 0.9850, 1.0073, 0.9872, 1.0082, 0.9839, 0.9909, 1.0083,\n",
       "                      0.9890, 0.9885, 1.0179, 0.9881, 0.9937, 1.0060, 0.9817, 1.0143, 0.9756,\n",
       "                      1.0133, 1.0133, 1.0137, 0.9841, 1.0109, 0.9958, 1.0198, 1.0053, 1.0181,\n",
       "                      1.0180, 0.9896, 0.9859, 1.0049, 1.0106, 0.9946, 1.0109, 1.0133, 1.0018,\n",
       "                      1.0070, 0.9913, 0.9972, 1.0079, 0.9937, 0.9775, 1.0125, 1.0130, 0.9774,\n",
       "                      0.9886, 1.0190, 1.0264, 0.9854, 1.0108, 0.9857, 0.9880, 1.0028, 0.9871,\n",
       "                      1.0093, 1.0017, 0.9853, 0.9870, 0.9942, 0.9869, 0.9902, 0.9800, 0.9825,\n",
       "                      1.0124, 0.9958, 1.0110, 0.9861, 0.9781, 0.9802, 1.0052, 1.0125, 1.0007,\n",
       "                      1.0113, 1.0082, 1.0105, 0.9894, 0.9926, 1.0120, 1.0110, 0.9771, 0.9939,\n",
       "                      1.0020, 1.0071])),\n",
       "             ('bottom_up.2.bn1.bias',\n",
       "              tensor([ 0.0190,  0.0209,  0.0228, -0.0152,  0.0146,  0.0169, -0.0145,  0.0190,\n",
       "                       0.0023,  0.0144,  0.0175,  0.0302,  0.0215, -0.0174, -0.0172,  0.0260,\n",
       "                      -0.0056,  0.0144,  0.0264,  0.0088,  0.0192,  0.0173,  0.0197,  0.0092,\n",
       "                       0.0156,  0.0151,  0.0239,  0.0218,  0.0164,  0.0243,  0.0073,  0.0181,\n",
       "                       0.0096, -0.0131, -0.0127, -0.0041,  0.0187,  0.0281,  0.0074,  0.0099,\n",
       "                       0.0214,  0.0194,  0.0090,  0.0019,  0.0068, -0.0126,  0.0354, -0.0054,\n",
       "                       0.0181, -0.0035,  0.0182, -0.0207,  0.0198,  0.0124, -0.0085, -0.0062,\n",
       "                       0.0175,  0.0078, -0.0005,  0.0102, -0.0075,  0.0173, -0.0197,  0.0182,\n",
       "                       0.0189,  0.0213, -0.0025,  0.0082,  0.0065,  0.0209,  0.0056,  0.0196,\n",
       "                       0.0146,  0.0108, -0.0089,  0.0207,  0.0180,  0.0010,  0.0216,  0.0121,\n",
       "                       0.0174,  0.0044,  0.0130,  0.0085,  0.0180,  0.0026, -0.0181,  0.0206,\n",
       "                       0.0210, -0.0066,  0.0201,  0.0212,  0.0095, -0.0054,  0.0116, -0.0011,\n",
       "                      -0.0031,  0.0106, -0.0010,  0.0167,  0.0096, -0.0126, -0.0018, -0.0008,\n",
       "                       0.0097,  0.0138,  0.0111, -0.0163,  0.0234,  0.0044,  0.0215, -0.0094,\n",
       "                      -0.0226, -0.0081,  0.0238,  0.0261,  0.0117,  0.0172,  0.0111,  0.0197,\n",
       "                       0.0137, -0.0070,  0.0153,  0.0164, -0.0132, -0.0110,  0.0133,  0.0183])),\n",
       "             ('bottom_up.2.bn1.running_mean',\n",
       "              tensor([ 0.1507, -0.0148,  0.2803,  0.0802,  0.0209, -0.4316, -0.4225, -0.1034,\n",
       "                      -0.1686, -0.1312,  0.1466, -0.2654, -0.0609, -0.2271, -0.0131,  0.2262,\n",
       "                       0.0637,  0.1095,  0.0148,  0.2677, -0.2245, -0.5632, -0.1531, -0.1404,\n",
       "                      -0.2989, -0.3689,  0.0605, -0.0790, -0.0441,  0.0897, -0.2316, -0.3838,\n",
       "                      -0.3647, -0.1371,  0.2360, -0.0092, -0.1729, -0.4023, -0.0598, -0.5765,\n",
       "                       0.3372,  0.1862, -0.0049, -0.5269, -0.0652, -0.1349, -0.1003,  0.0612,\n",
       "                      -0.0288,  0.3065,  0.1792, -0.0521, -0.1044, -0.2427,  0.2865,  0.2740,\n",
       "                      -0.2274,  0.0034,  0.0852, -0.4452,  0.1769,  0.6953,  0.3417, -0.2147,\n",
       "                      -0.1582, -0.1912, -0.2822,  0.3358, -0.1210, -0.3564, -0.1562, -0.4283,\n",
       "                      -0.2586, -0.2492,  0.2978,  0.0430, -0.5204, -0.1156,  0.1449, -0.2690,\n",
       "                       0.0672, -0.0761, -0.0505, -0.0301, -0.1407, -0.1631, -0.1384, -0.2056,\n",
       "                      -0.2938,  0.0137, -0.0310, -0.0156, -0.4519,  0.0965,  0.1529,  0.0667,\n",
       "                      -0.6785, -0.0991, -0.1034,  0.0769, -0.1776, -0.1657,  0.3741, -0.0968,\n",
       "                      -0.2009,  0.0067,  0.1756,  0.2116,  0.0308,  0.5016, -0.2240, -0.4010,\n",
       "                       0.0646, -0.0263, -0.0566, -0.0221, -0.1750,  0.2608, -0.5940, -0.2348,\n",
       "                       0.1636, -0.1353,  0.0959,  0.0039,  0.3992,  0.5712,  0.0661, -0.1164])),\n",
       "             ('bottom_up.2.bn1.running_var',\n",
       "              tensor([0.6333, 1.2425, 0.9099, 0.0849, 0.7158, 0.6448, 0.0478, 0.4412, 1.0319,\n",
       "                      1.2516, 0.5676, 1.1501, 1.7806, 0.1751, 0.2270, 1.5293, 0.3709, 0.8355,\n",
       "                      0.1967, 0.4892, 1.3876, 0.4767, 1.2799, 0.2564, 0.9564, 0.1622, 0.6349,\n",
       "                      0.2398, 0.5108, 0.9572, 0.3415, 1.5200, 0.4865, 0.5594, 0.1843, 0.4079,\n",
       "                      0.5813, 0.7367, 0.9890, 0.0827, 0.0767, 1.3443, 0.2808, 0.0903, 0.3458,\n",
       "                      0.1938, 0.9119, 0.2988, 0.6766, 0.4006, 1.4445, 0.2433, 0.7150, 0.4185,\n",
       "                      0.1801, 0.3389, 0.9959, 0.7502, 0.9577, 2.2384, 0.3583, 1.1354, 0.0538,\n",
       "                      1.0856, 0.7899, 0.7311, 0.4023, 0.9510, 0.0665, 0.4126, 0.5781, 1.4723,\n",
       "                      0.3931, 0.2856, 0.1996, 0.7663, 0.8832, 0.0268, 1.4195, 0.0655, 0.5588,\n",
       "                      1.2183, 1.1271, 0.8304, 1.2026, 0.1272, 0.5594, 1.4954, 0.8456, 1.2983,\n",
       "                      0.8715, 1.2381, 0.1548, 0.2871, 0.6735, 0.6079, 0.0901, 0.2991, 0.3869,\n",
       "                      0.5745, 0.4712, 1.3388, 0.1797, 0.2500, 0.6985, 1.2264, 0.3488, 0.2665,\n",
       "                      0.7322, 0.1175, 0.8991, 0.0337, 0.0599, 0.2631, 0.4846, 0.6509, 0.6153,\n",
       "                      1.2567, 0.0629, 0.6177, 0.4941, 0.0927, 0.9570, 0.8140, 0.1646, 0.1682,\n",
       "                      0.6203, 0.8951])),\n",
       "             ('bottom_up.2.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.2.mu.weight',\n",
       "              tensor([[ 0.0440, -0.0264, -0.0797,  ..., -0.0712, -0.0450, -0.0843],\n",
       "                      [-0.0279,  0.0451, -0.0129,  ..., -0.0146, -0.0129, -0.0265],\n",
       "                      [-0.0557, -0.0697,  0.0177,  ..., -0.0155, -0.0437, -0.0035],\n",
       "                      ...,\n",
       "                      [-0.0676,  0.0677,  0.0477,  ..., -0.0361,  0.0741,  0.0383],\n",
       "                      [-0.0459,  0.0854,  0.0543,  ...,  0.0763, -0.0740, -0.0143],\n",
       "                      [-0.0162, -0.0860, -0.0212,  ..., -0.0489,  0.0164,  0.0362]])),\n",
       "             ('bottom_up.2.mu.bias',\n",
       "              tensor([ 0.0421, -0.0252,  0.0203,  0.0827, -0.0535,  0.0042,  0.0185, -0.0795,\n",
       "                       0.0811, -0.0394, -0.0449, -0.0484, -0.0370,  0.0108,  0.0652,  0.0677,\n",
       "                       0.0506,  0.0600, -0.0016, -0.0681,  0.0390, -0.0384, -0.0338,  0.0793,\n",
       "                      -0.0498, -0.0672, -0.0563, -0.0311,  0.0513, -0.0844,  0.0411,  0.0490])),\n",
       "             ('bottom_up.2.sigma.weight',\n",
       "              tensor([[-0.0457, -0.0546, -0.0689,  ...,  0.0155,  0.0127,  0.0289],\n",
       "                      [-0.0021, -0.0846,  0.0150,  ..., -0.0170,  0.0306, -0.0204],\n",
       "                      [-0.0776,  0.0451, -0.0654,  ...,  0.0233,  0.0286, -0.0260],\n",
       "                      ...,\n",
       "                      [ 0.0307,  0.0850,  0.0545,  ...,  0.0466, -0.0250, -0.0818],\n",
       "                      [ 0.0241,  0.0503,  0.0021,  ...,  0.0216, -0.0650, -0.0046],\n",
       "                      [-0.0171, -0.0793, -0.0324,  ...,  0.0677,  0.0202, -0.0513]])),\n",
       "             ('bottom_up.2.sigma.bias',\n",
       "              tensor([ 0.0865,  0.0411, -0.0251,  0.0294,  0.0578, -0.0035,  0.0434, -0.0119,\n",
       "                       0.0174, -0.0042,  0.0631,  0.0020,  0.0689,  0.0590, -0.0741,  0.0388,\n",
       "                      -0.0807,  0.0424, -0.0808, -0.0191, -0.0452,  0.0062, -0.0741,  0.0815,\n",
       "                      -0.0640,  0.0131, -0.0550, -0.0006,  0.0525,  0.0086, -0.0146, -0.0166])),\n",
       "             ('transformations.1.dense1.weight',\n",
       "              tensor([[-0.1781, -0.0983,  0.1499,  ...,  0.0250, -0.0317,  0.1177],\n",
       "                      [ 0.0530, -0.1313,  0.1512,  ..., -0.1064, -0.0022,  0.0844],\n",
       "                      [-0.0990,  0.1601,  0.0641,  ...,  0.1124, -0.0079,  0.0283],\n",
       "                      ...,\n",
       "                      [-0.0558,  0.1352,  0.0816,  ...,  0.1157, -0.1688,  0.0320],\n",
       "                      [ 0.0886,  0.1775, -0.0163,  ..., -0.1504,  0.0005,  0.0858],\n",
       "                      [ 0.0746, -0.0256,  0.0650,  ..., -0.0478, -0.1126,  0.1683]])),\n",
       "             ('transformations.1.bn1.weight',\n",
       "              tensor([1.0085, 1.0188, 1.0121, 1.0212, 0.9990, 1.0015, 0.9959, 0.9965, 1.0130,\n",
       "                      1.0161, 0.9991, 0.9971, 0.9934, 1.0015, 1.0124, 0.9992, 1.0069, 1.0001,\n",
       "                      1.0076, 1.0119, 1.0055, 1.0027, 0.9836, 0.9857, 0.9929, 0.9961, 1.0033,\n",
       "                      1.0144, 1.0000, 1.0048, 0.9921, 1.0064, 1.0195, 0.9946, 1.0171, 1.0054,\n",
       "                      1.0262, 1.0033, 1.0145, 0.9829, 0.9996, 1.0038, 0.9914, 0.9853, 0.9897,\n",
       "                      0.9932, 1.0093, 1.0037, 0.9894, 1.0050, 0.9995, 1.0037, 1.0083, 1.0124,\n",
       "                      0.9862, 0.9866, 0.9979, 0.9963, 0.9945, 1.0186, 0.9827, 0.9925, 1.0148,\n",
       "                      1.0198, 1.0231, 0.9990, 0.9981, 1.0052, 1.0114, 0.9921, 1.0177, 0.9879,\n",
       "                      0.9930, 0.9888, 1.0078, 1.0013, 1.0049, 0.9948, 0.9946, 0.9984, 0.9919,\n",
       "                      1.0170, 0.9833, 1.0152, 0.9922, 0.9987, 1.0023, 1.0009, 0.9962, 0.9968,\n",
       "                      0.9853, 0.9980, 1.0071, 0.9935, 0.9989, 0.9863, 1.0001, 0.9868, 1.0002,\n",
       "                      0.9963, 0.9904, 1.0175, 1.0003, 1.0205, 1.0250, 1.0140, 1.0146, 0.9801,\n",
       "                      0.9916, 1.0183, 1.0124, 0.9894, 1.0016, 1.0056, 1.0132, 1.0144, 0.9938,\n",
       "                      0.9955, 1.0115, 0.9957, 1.0230, 1.0012, 1.0058, 1.0195, 0.9989, 1.0045,\n",
       "                      0.9848, 1.0119])),\n",
       "             ('transformations.1.bn1.bias',\n",
       "              tensor([ 0.0126,  0.0216,  0.0229,  0.0172, -0.0049,  0.0138,  0.0052, -0.0134,\n",
       "                       0.0160,  0.0038, -0.0048, -0.0124, -0.0197,  0.0111,  0.0124, -0.0007,\n",
       "                       0.0100,  0.0011,  0.0137,  0.0160, -0.0042,  0.0213, -0.0141, -0.0145,\n",
       "                       0.0074, -0.0101,  0.0031,  0.0129,  0.0166,  0.0126, -0.0108,  0.0108,\n",
       "                       0.0247,  0.0119,  0.0069, -0.0077,  0.0282, -0.0059,  0.0240, -0.0182,\n",
       "                       0.0127,  0.0160, -0.0122, -0.0005, -0.0089, -0.0029,  0.0110,  0.0116,\n",
       "                       0.0190,  0.0002,  0.0077,  0.0092,  0.0184,  0.0162,  0.0046, -0.0161,\n",
       "                       0.0018,  0.0037, -0.0087,  0.0233, -0.0176, -0.0049,  0.0202, -0.0082,\n",
       "                       0.0211,  0.0138, -0.0073,  0.0047,  0.0108,  0.0004,  0.0096,  0.0007,\n",
       "                      -0.0015, -0.0082,  0.0144, -0.0086, -0.0004,  0.0002,  0.0055, -0.0049,\n",
       "                       0.0023,  0.0034, -0.0026,  0.0252, -0.0124,  0.0125,  0.0105, -0.0028,\n",
       "                      -0.0034,  0.0102, -0.0019,  0.0015,  0.0064, -0.0048,  0.0107, -0.0169,\n",
       "                      -0.0013, -0.0106,  0.0071,  0.0166,  0.0018,  0.0229, -0.0100,  0.0289,\n",
       "                       0.0248,  0.0073,  0.0171, -0.0183, -0.0116,  0.0162,  0.0046, -0.0101,\n",
       "                       0.0109,  0.0146,  0.0168,  0.0232,  0.0064,  0.0107,  0.0011, -0.0114,\n",
       "                       0.0136, -0.0098, -0.0076,  0.0216,  0.0053,  0.0071, -0.0001,  0.0099])),\n",
       "             ('transformations.1.bn1.running_mean',\n",
       "              tensor([ 2.9254e-04, -2.4707e-03,  4.5087e-03, -3.6498e-04,  5.6105e-03,\n",
       "                       5.2117e-03,  3.3163e-03,  1.2054e-02, -4.2125e-03, -3.8414e-04,\n",
       "                      -4.3536e-03, -1.8876e-03,  1.1571e-02,  7.3063e-04,  7.2902e-03,\n",
       "                       1.0332e-02, -9.0667e-03,  3.9823e-03, -3.4296e-03, -7.9441e-03,\n",
       "                      -5.2567e-03, -3.7560e-04, -1.6610e-03, -5.2819e-03,  1.6354e-03,\n",
       "                      -6.6826e-03, -1.1372e-04,  1.8871e-02, -4.7300e-04, -3.0607e-03,\n",
       "                      -2.5228e-03, -1.2003e-03, -9.9015e-03, -5.2288e-03,  9.0167e-03,\n",
       "                      -1.0062e-02,  5.8113e-03, -1.4471e-03, -5.0006e-03, -8.6081e-03,\n",
       "                       8.6444e-04, -5.7172e-04, -6.5696e-03,  1.2463e-02,  5.9349e-03,\n",
       "                      -1.8175e-03,  4.9987e-03,  6.1049e-03, -1.9066e-03, -1.3176e-02,\n",
       "                      -1.1798e-02, -6.0773e-03, -7.4226e-04, -3.8431e-03,  5.7490e-05,\n",
       "                      -5.8593e-03,  9.1877e-03, -5.1705e-03,  6.3246e-03, -1.4048e-02,\n",
       "                      -3.2557e-03,  1.2694e-02,  1.4172e-02, -1.4616e-03,  2.2587e-03,\n",
       "                      -7.3198e-03,  3.0155e-03, -1.2732e-02, -2.3642e-03,  4.1605e-03,\n",
       "                       1.1581e-02, -5.4007e-03, -3.7116e-03,  1.1687e-02,  1.0016e-02,\n",
       "                      -3.3173e-03, -6.7065e-03, -2.1250e-03, -9.2483e-03,  3.2072e-03,\n",
       "                       9.0942e-03, -1.2459e-03,  4.1874e-03,  7.7883e-03, -1.4219e-03,\n",
       "                      -1.2115e-02,  1.0626e-02, -1.6168e-03,  1.8823e-02, -1.1680e-02,\n",
       "                      -1.3263e-02, -3.3624e-03,  2.8108e-05, -5.0267e-03,  9.1562e-03,\n",
       "                       1.2061e-04, -1.7146e-02, -3.1401e-03,  9.4390e-03,  3.6969e-03,\n",
       "                      -7.8031e-03, -2.7455e-04,  1.3927e-03,  1.3165e-03,  1.9958e-03,\n",
       "                      -1.7307e-03, -3.1326e-03,  7.8464e-03, -1.3161e-02,  6.4129e-03,\n",
       "                      -6.6021e-03, -3.2704e-03, -5.4577e-04, -5.2567e-03,  5.8076e-04,\n",
       "                       1.3583e-03, -7.4743e-03, -8.8747e-03,  2.4196e-03,  3.6370e-03,\n",
       "                      -1.3346e-02, -8.5544e-03,  1.7426e-03,  1.6841e-02, -1.9385e-03,\n",
       "                      -1.6376e-03,  1.3867e-02,  2.4915e-03])),\n",
       "             ('transformations.1.bn1.running_var',\n",
       "              tensor([0.5105, 0.7984, 0.5535, 2.4176, 0.3277, 0.6261, 0.5657, 0.6212, 1.5138,\n",
       "                      0.5887, 1.8148, 0.4051, 0.8659, 0.8226, 1.1135, 0.4873, 0.4759, 0.3491,\n",
       "                      0.9704, 0.5727, 0.3307, 0.6698, 0.2939, 0.4841, 0.3974, 0.3615, 0.5740,\n",
       "                      1.0880, 0.5852, 1.0590, 0.3462, 0.9006, 1.8390, 0.4034, 0.7585, 1.0374,\n",
       "                      1.3035, 0.4488, 0.6771, 0.2373, 0.4047, 0.4461, 0.5060, 0.2370, 0.2275,\n",
       "                      0.2022, 0.3146, 0.5623, 0.8008, 2.1083, 0.4466, 1.6933, 0.3190, 0.3201,\n",
       "                      0.2705, 0.3851, 0.5817, 0.5540, 0.3832, 2.2950, 0.3532, 0.2027, 0.8047,\n",
       "                      0.4550, 1.7677, 0.5507, 0.4893, 0.2309, 1.4134, 0.3008, 1.8953, 0.7084,\n",
       "                      0.3240, 0.5793, 0.7753, 0.4803, 0.9280, 0.4408, 1.2617, 0.4149, 0.7404,\n",
       "                      0.9401, 0.6788, 1.0266, 0.8735, 0.4376, 0.6482, 0.2606, 0.5531, 0.4887,\n",
       "                      0.3681, 0.3374, 0.5428, 0.4627, 0.3595, 0.5642, 0.2684, 1.9050, 0.5753,\n",
       "                      0.6879, 1.7883, 1.8769, 0.4847, 0.8091, 0.5846, 0.6476, 0.2913, 0.2831,\n",
       "                      0.6734, 0.7189, 0.3654, 0.2917, 0.5904, 1.3408, 1.0380, 2.3306, 0.4508,\n",
       "                      0.2373, 1.7070, 0.4983, 0.6370, 0.6421, 0.8098, 1.2395, 0.4709, 0.1933,\n",
       "                      0.9709, 0.5768])),\n",
       "             ('transformations.1.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('transformations.1.mu.weight',\n",
       "              tensor([[ 0.0361, -0.0153,  0.0084,  ..., -0.0593, -0.0434, -0.0426],\n",
       "                      [ 0.0645, -0.0057,  0.0465,  ...,  0.0583,  0.0097, -0.0512],\n",
       "                      [ 0.0696,  0.0508, -0.0115,  ...,  0.0307,  0.0488, -0.0457],\n",
       "                      ...,\n",
       "                      [-0.0610, -0.0940, -0.0040,  ..., -0.0278, -0.0492,  0.0701],\n",
       "                      [ 0.0263, -0.0689,  0.0420,  ..., -0.0116, -0.0092,  0.0401],\n",
       "                      [ 0.0031,  0.0013,  0.0908,  ..., -0.0681, -0.0172,  0.0711]])),\n",
       "             ('transformations.1.mu.bias',\n",
       "              tensor([ 0.0004,  0.0138, -0.0245,  0.0173,  0.0446, -0.0728,  0.0600, -0.0259,\n",
       "                       0.0179, -0.0321, -0.0584, -0.0023, -0.0499, -0.0351,  0.0547,  0.0345,\n",
       "                      -0.0539,  0.0666,  0.0351, -0.0177, -0.0691, -0.0058,  0.0831, -0.0262,\n",
       "                      -0.0224, -0.0325, -0.0415, -0.0771, -0.0187, -0.0208, -0.0289, -0.0946])),\n",
       "             ('transformations.1.sigma.weight',\n",
       "              tensor([[-0.0580, -0.0551,  0.0974,  ..., -0.0040, -0.0893, -0.0881],\n",
       "                      [-0.0474, -0.0774, -0.0263,  ...,  0.0378,  0.0344,  0.0275],\n",
       "                      [ 0.0629,  0.0268, -0.0067,  ...,  0.0869,  0.0372, -0.0785],\n",
       "                      ...,\n",
       "                      [-0.0102, -0.0570,  0.0859,  ...,  0.0292,  0.0119,  0.0392],\n",
       "                      [ 0.0437,  0.0457,  0.0565,  ..., -0.0766, -0.0462, -0.0347],\n",
       "                      [-0.0339, -0.0513,  0.0311,  ...,  0.0004, -0.0303,  0.0247]])),\n",
       "             ('transformations.1.sigma.bias',\n",
       "              tensor([ 0.0898,  0.0605,  0.0645,  0.0616,  0.0047,  0.0853,  0.0227, -0.0559,\n",
       "                      -0.0415,  0.0813, -0.0606, -0.0502, -0.0283, -0.0316,  0.0252,  0.0329,\n",
       "                       0.0410,  0.0307, -0.0131,  0.0249,  0.0203,  0.0839,  0.0684, -0.0731,\n",
       "                      -0.0172,  0.0441, -0.0228,  0.0015,  0.0555,  0.0429, -0.0009, -0.0829])),\n",
       "             ('transformations.2.dense1.weight',\n",
       "              tensor([[-0.1705,  0.1350,  0.1144,  ..., -0.0042, -0.1674,  0.1146],\n",
       "                      [-0.1474,  0.0063, -0.0498,  ..., -0.1089,  0.1080,  0.0608],\n",
       "                      [ 0.1550, -0.0746,  0.1889,  ..., -0.1575, -0.0373,  0.0663],\n",
       "                      ...,\n",
       "                      [-0.1506, -0.1857,  0.1486,  ..., -0.0399,  0.0283,  0.0341],\n",
       "                      [-0.0567,  0.1366,  0.1677,  ...,  0.0354, -0.0542, -0.0759],\n",
       "                      [ 0.0827, -0.1332,  0.0236,  ...,  0.0914, -0.1211,  0.0480]])),\n",
       "             ('transformations.2.bn1.weight',\n",
       "              tensor([1.0067, 0.9975, 1.0204, 0.9864, 0.9992, 1.0164, 1.0245, 0.9920, 0.9939,\n",
       "                      1.0236, 0.9967, 0.9944, 1.0003, 0.9936, 1.0041, 1.0198, 0.9886, 0.9888,\n",
       "                      0.9833, 1.0177, 0.9860, 1.0045, 1.0048, 0.9994, 1.0159, 1.0105, 1.0005,\n",
       "                      1.0051, 0.9865, 0.9901, 1.0065, 1.0099, 0.9996, 1.0180, 0.9858, 1.0018,\n",
       "                      1.0197, 0.9955, 1.0221, 1.0155, 0.9935, 1.0056, 1.0147, 0.9841, 1.0157,\n",
       "                      1.0139, 1.0157, 0.9869, 1.0099, 1.0005, 0.9890, 0.9864, 1.0083, 1.0073,\n",
       "                      1.0161, 1.0074, 0.9974, 1.0154, 1.0039, 1.0032, 0.9986, 0.9937, 0.9997,\n",
       "                      1.0166, 0.9936, 0.9909, 1.0214, 1.0018, 1.0202, 1.0124, 0.9869, 1.0156,\n",
       "                      1.0087, 0.9942, 0.9936, 1.0044, 1.0146, 0.9938, 0.9968, 1.0151, 0.9863,\n",
       "                      0.9859, 0.9941, 0.9951, 1.0160, 1.0090, 1.0193, 0.9873, 1.0061, 0.9828,\n",
       "                      1.0094, 0.9850, 1.0210, 0.9919, 1.0126, 1.0012, 1.0001, 1.0110, 1.0084,\n",
       "                      0.9894, 1.0122, 0.9930, 1.0075, 1.0037, 1.0084, 1.0139, 1.0019, 0.9859,\n",
       "                      0.9986, 1.0038, 1.0111, 0.9820, 0.9851, 0.9941, 1.0084, 0.9886, 1.0227,\n",
       "                      0.9944, 1.0106, 0.9918, 0.9819, 1.0101, 0.9910, 1.0018, 1.0201, 1.0148,\n",
       "                      1.0066, 1.0194])),\n",
       "             ('transformations.2.bn1.bias',\n",
       "              tensor([ 2.3631e-02,  2.1493e-03,  2.1923e-02, -1.8332e-02, -1.7337e-03,\n",
       "                       1.8074e-02,  2.9398e-02, -1.1058e-02,  7.0324e-03,  2.4752e-02,\n",
       "                       5.4624e-03, -5.3856e-03, -5.4442e-05, -1.4859e-02,  6.5853e-03,\n",
       "                       3.4362e-02, -4.9610e-03,  8.9756e-03,  6.8982e-04,  2.3175e-02,\n",
       "                      -5.1066e-03,  7.9863e-03,  5.6944e-03,  3.9504e-04,  1.8644e-02,\n",
       "                       1.8754e-02, -7.9535e-03,  1.3037e-02, -1.6247e-02, -5.5134e-03,\n",
       "                       8.3359e-03,  2.2122e-02,  2.5121e-03,  2.0343e-02, -1.2768e-02,\n",
       "                       2.1795e-02,  2.2320e-02,  2.7143e-03,  1.8358e-02, -1.0642e-02,\n",
       "                      -1.7576e-02, -3.6454e-03,  1.9106e-02, -1.3756e-02,  2.7188e-02,\n",
       "                       2.0968e-02,  2.1078e-02, -1.5757e-02, -2.1290e-03,  5.4956e-04,\n",
       "                      -1.1115e-02, -1.3596e-02,  1.8470e-02,  8.9391e-03,  1.4758e-02,\n",
       "                      -3.1461e-03,  1.6082e-03,  1.4681e-02,  7.9865e-03, -6.0577e-03,\n",
       "                      -3.5569e-03, -1.1365e-02, -5.4691e-03,  2.1217e-02, -1.1779e-02,\n",
       "                      -4.0311e-03,  2.6175e-02,  2.8727e-04,  2.8085e-02, -3.3877e-03,\n",
       "                      -5.9934e-03,  2.6375e-02,  1.9119e-02,  9.9069e-03,  1.5035e-03,\n",
       "                       2.1418e-03,  1.5573e-02,  7.3875e-03, -1.4876e-02,  2.9109e-02,\n",
       "                      -1.7569e-02, -7.2604e-03, -8.4134e-04,  9.2409e-03,  6.1413e-03,\n",
       "                       1.1133e-02,  1.5377e-02, -1.2104e-02,  1.4474e-02, -1.7161e-02,\n",
       "                       1.1928e-02,  5.2115e-03,  2.2250e-02,  4.6347e-04,  1.7778e-02,\n",
       "                      -1.4320e-02,  1.7408e-02,  1.8926e-02,  1.3111e-02, -8.1890e-03,\n",
       "                       1.4530e-02,  1.0385e-02,  1.6878e-02,  2.0883e-02,  2.2200e-02,\n",
       "                       2.1305e-02,  2.3059e-03, -6.6859e-03, -1.2444e-02,  2.3426e-02,\n",
       "                       9.2193e-03, -8.8781e-03, -1.1684e-04, -2.9014e-03,  1.4942e-02,\n",
       "                      -1.5988e-02,  1.6891e-02, -3.4148e-03,  1.9022e-02,  1.0501e-03,\n",
       "                       1.2297e-02,  1.8349e-02, -9.4494e-03,  1.7377e-02,  2.2501e-02,\n",
       "                       2.5852e-02,  1.6127e-02,  2.5389e-02])),\n",
       "             ('transformations.2.bn1.running_mean',\n",
       "              tensor([-0.0004,  0.0065, -0.0098,  0.0030,  0.0044, -0.0099,  0.0016, -0.0022,\n",
       "                       0.0077, -0.0086,  0.0057,  0.0018, -0.0012,  0.0020,  0.0084,  0.0065,\n",
       "                       0.0013,  0.0068,  0.0095,  0.0033, -0.0066,  0.0119, -0.0017,  0.0127,\n",
       "                      -0.0080,  0.0015, -0.0004, -0.0057, -0.0037,  0.0052, -0.0166,  0.0071,\n",
       "                       0.0097, -0.0048,  0.0100,  0.0043,  0.0050,  0.0011,  0.0054,  0.0034,\n",
       "                      -0.0031,  0.0039, -0.0027,  0.0121, -0.0051, -0.0111,  0.0022, -0.0025,\n",
       "                       0.0050, -0.0022,  0.0091, -0.0061,  0.0095, -0.0024,  0.0060,  0.0060,\n",
       "                       0.0096, -0.0050,  0.0003, -0.0093, -0.0128, -0.0002, -0.0004, -0.0018,\n",
       "                      -0.0101,  0.0040,  0.0096,  0.0017, -0.0102,  0.0105, -0.0020, -0.0123,\n",
       "                       0.0027, -0.0150,  0.0084, -0.0125, -0.0075, -0.0132, -0.0048,  0.0045,\n",
       "                      -0.0080, -0.0088,  0.0087,  0.0044, -0.0004, -0.0075, -0.0107,  0.0070,\n",
       "                      -0.0018,  0.0038, -0.0135,  0.0125,  0.0021,  0.0011,  0.0110,  0.0065,\n",
       "                      -0.0075,  0.0192,  0.0029, -0.0036, -0.0088,  0.0048, -0.0005,  0.0093,\n",
       "                       0.0093, -0.0030,  0.0149,  0.0039, -0.0150,  0.0123,  0.0009, -0.0049,\n",
       "                       0.0067, -0.0059,  0.0140,  0.0146, -0.0029, -0.0015,  0.0042, -0.0056,\n",
       "                       0.0071,  0.0036,  0.0029,  0.0004, -0.0036,  0.0068, -0.0210, -0.0084])),\n",
       "             ('transformations.2.bn1.running_var',\n",
       "              tensor([0.5589, 0.3275, 0.7119, 0.6703, 0.1915, 0.8374, 1.8801, 0.4213, 0.5152,\n",
       "                      1.0459, 0.3203, 0.4780, 0.3568, 0.2305, 0.5118, 0.4149, 0.5364, 0.6469,\n",
       "                      0.4681, 1.5193, 0.5187, 0.4528, 0.2728, 1.1456, 1.5619, 1.1199, 0.6946,\n",
       "                      0.2089, 0.3582, 0.3162, 1.7561, 0.7419, 0.2723, 0.6142, 0.2691, 0.4482,\n",
       "                      1.8000, 0.5837, 1.2794, 0.4828, 0.2765, 1.6397, 1.7525, 0.2687, 1.0954,\n",
       "                      2.2798, 0.5794, 0.3249, 0.7657, 0.3778, 0.2920, 0.1955, 0.3730, 2.5803,\n",
       "                      0.4411, 1.0399, 0.4203, 0.9676, 0.7282, 0.7318, 0.3001, 0.2682, 1.0483,\n",
       "                      2.4750, 0.4746, 0.4603, 0.5689, 0.4926, 1.8678, 0.4328, 0.1807, 0.5651,\n",
       "                      0.3240, 0.4094, 0.3171, 0.4508, 0.6258, 0.2473, 0.3586, 1.8432, 0.7165,\n",
       "                      0.3238, 0.5299, 0.4053, 0.5945, 1.2602, 0.3642, 1.2024, 0.3102, 0.5583,\n",
       "                      0.3800, 0.2701, 0.6268, 0.3911, 0.2943, 0.7092, 0.4705, 0.9375, 0.7491,\n",
       "                      0.3370, 0.5152, 0.2684, 0.4801, 0.9440, 0.2498, 2.6107, 0.6609, 0.4010,\n",
       "                      0.7823, 0.7957, 1.6195, 0.4349, 0.4460, 0.3423, 0.4276, 0.3394, 1.1031,\n",
       "                      0.4633, 1.2144, 0.2885, 0.3236, 1.1207, 0.4864, 0.4287, 1.1679, 0.4689,\n",
       "                      0.3470, 0.6022])),\n",
       "             ('transformations.2.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('transformations.2.mu.weight',\n",
       "              tensor([[-0.0333,  0.0673, -0.0246,  ...,  0.0716,  0.0637, -0.0680],\n",
       "                      [-0.1059,  0.0921,  0.0786,  ..., -0.0185, -0.0257,  0.0286],\n",
       "                      [-0.0549,  0.0717, -0.0313,  ..., -0.0042,  0.0161,  0.0481],\n",
       "                      ...,\n",
       "                      [ 0.0236, -0.0555,  0.0513,  ...,  0.0268, -0.0363, -0.0986],\n",
       "                      [ 0.0087, -0.0336,  0.0760,  ..., -0.0366,  0.0300,  0.0043],\n",
       "                      [-0.0399,  0.0163,  0.0543,  ...,  0.0031,  0.0322,  0.0270]])),\n",
       "             ('transformations.2.mu.bias',\n",
       "              tensor([ 0.0773, -0.0575, -0.0479, -0.0072,  0.0935, -0.0639,  0.0479,  0.0276,\n",
       "                      -0.0903, -0.0147,  0.0135, -0.0265,  0.0736, -0.0455,  0.0220,  0.0226,\n",
       "                       0.0782, -0.0778, -0.0908, -0.0654, -0.0035, -0.0338, -0.0225,  0.0476,\n",
       "                      -0.0232,  0.0849, -0.0750,  0.0562,  0.0536, -0.0246,  0.0328,  0.0732])),\n",
       "             ('transformations.2.sigma.weight',\n",
       "              tensor([[-0.0021, -0.0839, -0.0493,  ...,  0.0295,  0.0507, -0.0600],\n",
       "                      [ 0.0838,  0.0343,  0.0160,  ..., -0.0087,  0.0492, -0.0137],\n",
       "                      [ 0.0429,  0.0384, -0.0557,  ...,  0.0131,  0.0483,  0.0696],\n",
       "                      ...,\n",
       "                      [-0.0349,  0.0394,  0.0179,  ...,  0.0968, -0.0834,  0.0615],\n",
       "                      [ 0.0250, -0.0261,  0.0131,  ..., -0.0060,  0.0690, -0.0037],\n",
       "                      [-0.1067,  0.0615, -0.0739,  ..., -0.0029,  0.0367, -0.0243]])),\n",
       "             ('transformations.2.sigma.bias',\n",
       "              tensor([ 0.0387,  0.0430,  0.0186,  0.0641, -0.0853,  0.0047, -0.0735, -0.0225,\n",
       "                       0.0373, -0.0551, -0.0738,  0.0318, -0.0822,  0.0764, -0.0700, -0.0086,\n",
       "                       0.0021, -0.0477,  0.0428,  0.0434,  0.0024, -0.0319,  0.0242, -0.0378,\n",
       "                       0.0136, -0.0685, -0.0500,  0.0435, -0.0703, -0.0513,  0.0499, -0.0300])),\n",
       "             ('transformations.3.dense1.weight',\n",
       "              tensor([[-0.0345,  0.0277,  0.0807,  ..., -0.1397, -0.0360,  0.0133],\n",
       "                      [-0.0734, -0.0327, -0.1154,  ...,  0.1582, -0.0130,  0.0653],\n",
       "                      [-0.0198, -0.1517, -0.1092,  ..., -0.0521,  0.1888,  0.1617],\n",
       "                      ...,\n",
       "                      [ 0.0206, -0.0347,  0.1265,  ...,  0.0626,  0.0536, -0.0594],\n",
       "                      [ 0.1574, -0.0599,  0.0573,  ..., -0.0325, -0.0940, -0.0072],\n",
       "                      [ 0.1192, -0.0800,  0.1286,  ...,  0.0906, -0.1819,  0.0586]])),\n",
       "             ('transformations.3.bn1.weight',\n",
       "              tensor([1.0162, 1.0184, 1.0154, 1.0120, 1.0229, 0.9975, 1.0245, 0.9876, 0.9931,\n",
       "                      1.0183, 0.9933, 1.0201, 1.0177, 1.0007, 1.0239, 1.0063, 1.0219, 1.0035,\n",
       "                      1.0089, 0.9893, 1.0275, 1.0400, 1.0143, 0.9854, 0.9920, 1.0088, 0.9898,\n",
       "                      1.0239, 0.9838, 1.0116, 1.0222, 0.9897, 1.0354, 1.0201, 0.9818, 1.0163,\n",
       "                      0.9942, 1.0281, 0.9947, 1.0136, 0.9958, 1.0121, 1.0146, 1.0217, 0.9950,\n",
       "                      1.0176, 1.0006, 1.0105, 1.0202, 0.9996, 0.9810, 1.0085, 1.0101, 0.9874,\n",
       "                      1.0065, 0.9902, 1.0181, 0.9875, 0.9847, 1.0207, 0.9952, 0.9856, 0.9901,\n",
       "                      0.9889, 0.9960, 1.0160, 0.9875, 1.0232, 0.9913, 1.0073, 1.0005, 0.9960,\n",
       "                      1.0177, 0.9955, 1.0089, 1.0110, 1.0088, 0.9916, 1.0018, 0.9975, 1.0179,\n",
       "                      0.9888, 1.0028, 1.0180, 1.0288, 0.9909, 1.0040, 1.0138, 1.0184, 1.0134,\n",
       "                      0.9938, 1.0222, 0.9920, 0.9950, 0.9991, 1.0140, 0.9919, 0.9978, 1.0193,\n",
       "                      1.0157, 0.9944, 0.9932, 1.0208, 1.0096, 0.9911, 0.9960, 1.0111, 1.0216,\n",
       "                      0.9870, 1.0121, 0.9859, 0.9829, 0.9946, 0.9949, 1.0184, 1.0107, 0.9876,\n",
       "                      1.0174, 0.9863, 0.9889, 1.0153, 1.0299, 1.0058, 0.9902, 1.0059, 1.0054,\n",
       "                      1.0021, 1.0179])),\n",
       "             ('transformations.3.bn1.bias',\n",
       "              tensor([ 0.0199,  0.0293,  0.0110, -0.0125,  0.0179,  0.0122,  0.0388, -0.0126,\n",
       "                       0.0062,  0.0253,  0.0166,  0.0176,  0.0134,  0.0236,  0.0538, -0.0051,\n",
       "                       0.0386,  0.0163, -0.0104,  0.0122,  0.0455,  0.0358,  0.0056, -0.0170,\n",
       "                       0.0386, -0.0099, -0.0255,  0.0422, -0.0153,  0.0107,  0.0263,  0.0100,\n",
       "                       0.0452,  0.0405, -0.0201,  0.0083, -0.0099,  0.0382, -0.0194, -0.0087,\n",
       "                       0.0067,  0.0258,  0.0047,  0.0313,  0.0239,  0.0345,  0.0021,  0.0188,\n",
       "                       0.0334,  0.0043, -0.0191,  0.0332, -0.0130, -0.0038,  0.0084, -0.0155,\n",
       "                       0.0307, -0.0080,  0.0070,  0.0141,  0.0032, -0.0145,  0.0095, -0.0165,\n",
       "                      -0.0071, -0.0097, -0.0126,  0.0307, -0.0058,  0.0168,  0.0256, -0.0072,\n",
       "                       0.0230, -0.0055,  0.0265, -0.0035,  0.0185,  0.0112, -0.0248, -0.0099,\n",
       "                       0.0441,  0.0266,  0.0212, -0.0042,  0.0497,  0.0116,  0.0178,  0.0024,\n",
       "                       0.0123,  0.0073, -0.0273,  0.0349, -0.0071, -0.0064,  0.0012,  0.0216,\n",
       "                      -0.0099, -0.0117,  0.0580,  0.0178,  0.0089,  0.0079,  0.0083,  0.0363,\n",
       "                      -0.0211, -0.0151, -0.0161,  0.0450, -0.0124, -0.0308,  0.0152,  0.0060,\n",
       "                       0.0066,  0.0236,  0.0077,  0.0348, -0.0217,  0.0268, -0.0182, -0.0202,\n",
       "                       0.0087,  0.0371,  0.0344, -0.0249,  0.0033,  0.0144,  0.0276,  0.0169])),\n",
       "             ('transformations.3.bn1.running_mean',\n",
       "              tensor([-0.3024, -0.1644, -0.3622,  0.0711, -0.3551,  0.1212,  0.4982,  0.2490,\n",
       "                       0.2144, -0.0018, -0.0689, -0.2268, -0.0451, -0.0396,  0.0897, -0.1495,\n",
       "                      -0.1349, -0.2592, -0.0611, -0.1477,  0.0166,  0.2813, -0.0820,  0.2412,\n",
       "                       0.1442, -0.1308,  0.0688,  0.3246,  0.0785, -0.2881,  0.4109, -0.1127,\n",
       "                       0.3238,  0.1369, -0.1211, -0.2663, -0.1726,  0.1266, -0.0079, -0.1935,\n",
       "                       0.0656,  0.2280,  0.0061, -0.4032,  0.0677, -0.1884, -0.3909,  0.1929,\n",
       "                       0.2294, -0.2012, -0.1674, -0.0483, -0.0472,  0.1659,  0.2043,  0.0136,\n",
       "                       0.3118,  0.2940,  0.2270,  0.0700,  0.1090, -0.4934,  0.1328, -0.4069,\n",
       "                      -0.1317, -0.3404,  0.3903,  0.1165, -0.3138,  0.0816,  0.2648, -0.0290,\n",
       "                       0.2818, -0.0514, -0.0466,  0.0288, -0.1746,  0.0927,  0.0546,  0.2837,\n",
       "                       0.1465, -0.1520, -0.3592, -0.4358,  0.1692, -0.1583,  0.0334, -0.3161,\n",
       "                      -0.1835, -0.1802,  0.0105,  0.1853, -0.0806,  0.0070, -0.0141,  0.1898,\n",
       "                      -0.0469, -0.2124,  0.1061,  0.1694, -0.1933, -0.0973, -0.2969,  0.3350,\n",
       "                      -0.5255, -0.2575, -0.0240,  0.2054, -0.4103,  0.1560,  0.0284, -0.1615,\n",
       "                      -0.0688,  0.2540, -0.0969, -0.1971, -0.0337, -0.0611, -0.1135, -0.1065,\n",
       "                      -0.1914,  0.1918,  0.3508, -0.0167, -0.0788,  0.2463,  0.1733, -0.0261])),\n",
       "             ('transformations.3.bn1.running_var',\n",
       "              tensor([0.7027, 0.4746, 0.2857, 0.2011, 0.2704, 0.1205, 0.8594, 0.3916, 0.4819,\n",
       "                      0.2318, 0.1248, 0.2993, 0.6829, 0.1591, 0.1468, 0.1074, 0.1178, 0.3868,\n",
       "                      0.1997, 0.1573, 0.3162, 0.1130, 0.1155, 0.4507, 0.1911, 0.1392, 0.1829,\n",
       "                      0.3739, 0.1077, 0.2577, 1.1453, 0.2974, 0.2035, 0.2132, 0.1568, 0.1894,\n",
       "                      0.1250, 0.1224, 0.1253, 0.5560, 0.1187, 0.3966, 0.1119, 0.9462, 0.0888,\n",
       "                      0.4836, 1.1482, 0.2229, 0.1905, 0.1955, 0.2530, 0.1412, 0.1254, 0.2935,\n",
       "                      0.1151, 0.1457, 0.3832, 1.1028, 0.3263, 0.1559, 0.1857, 2.0711, 0.3736,\n",
       "                      0.5400, 0.1156, 0.6032, 1.2374, 0.2630, 0.7621, 0.1619, 0.1955, 0.1277,\n",
       "                      0.3159, 0.0948, 0.0975, 0.1592, 0.4313, 0.0944, 0.2010, 0.2969, 0.2468,\n",
       "                      0.1173, 0.2132, 0.6575, 0.2803, 0.1345, 0.1809, 0.2496, 0.2588, 0.1218,\n",
       "                      0.1190, 0.2485, 0.1208, 0.1251, 0.4038, 0.1425, 0.1044, 0.5023, 0.5412,\n",
       "                      0.1414, 0.2890, 0.4714, 0.1915, 0.4268, 1.3624, 0.1599, 0.1265, 0.3804,\n",
       "                      0.4182, 0.1436, 0.1402, 0.1412, 0.1012, 0.1183, 0.2219, 0.1172, 0.1333,\n",
       "                      0.1708, 0.1106, 0.1402, 0.2249, 0.3750, 0.8203, 0.1418, 0.1420, 0.2397,\n",
       "                      0.2763, 0.2324])),\n",
       "             ('transformations.3.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.3.mu.weight',\n",
       "              tensor([[ 0.0617, -0.0324, -0.0371,  ...,  0.0855, -0.0774, -0.0709],\n",
       "                      [ 0.0868,  0.0571,  0.0294,  ..., -0.0119, -0.0616, -0.0150],\n",
       "                      [-0.0121, -0.0821,  0.0856,  ..., -0.0773,  0.0162,  0.0479],\n",
       "                      ...,\n",
       "                      [ 0.0344, -0.0246, -0.0772,  ..., -0.0240,  0.0683,  0.0955],\n",
       "                      [-0.0601,  0.0011,  0.0201,  ...,  0.0460,  0.0587,  0.0263],\n",
       "                      [ 0.0603, -0.0089,  0.0060,  ...,  0.0070, -0.0418, -0.0146]])),\n",
       "             ('transformations.3.mu.bias',\n",
       "              tensor([ 0.0113, -0.0950, -0.0566, -0.0343, -0.0214, -0.0916,  0.0801,  0.0894,\n",
       "                       0.1062,  0.0088, -0.0016,  0.0967, -0.0630, -0.0432, -0.0540,  0.0516,\n",
       "                      -0.0779, -0.0984, -0.0071,  0.0012, -0.0861,  0.0370,  0.0273, -0.0298,\n",
       "                       0.0724, -0.0308, -0.0130, -0.0183, -0.0885,  0.0201, -0.0369,  0.0456])),\n",
       "             ('transformations.3.sigma.weight',\n",
       "              tensor([[-0.0492,  0.0347,  0.0762,  ...,  0.0553,  0.0282, -0.0250],\n",
       "                      [ 0.0178, -0.0543, -0.0190,  ...,  0.0231,  0.0439,  0.0142],\n",
       "                      [ 0.0033, -0.0303, -0.0928,  ...,  0.0673, -0.0594,  0.0449],\n",
       "                      ...,\n",
       "                      [ 0.0977, -0.0048, -0.0124,  ..., -0.0844, -0.0258,  0.0523],\n",
       "                      [-0.0013, -0.0918, -0.0566,  ..., -0.0049, -0.0796, -0.1055],\n",
       "                      [-0.0936,  0.0283, -0.0862,  ...,  0.0638, -0.0081, -0.0687]])),\n",
       "             ('transformations.3.sigma.bias',\n",
       "              tensor([-0.0423, -0.0689,  0.0680, -0.0565,  0.0224,  0.0091,  0.1025, -0.0167,\n",
       "                      -0.0164,  0.1151,  0.0503,  0.0700,  0.0310,  0.0099, -0.0928,  0.0817,\n",
       "                       0.0414,  0.0536,  0.0393, -0.0132,  0.0440, -0.0671,  0.0667,  0.0666,\n",
       "                      -0.0328,  0.0093,  0.0280, -0.0909, -0.0445, -0.0517, -0.0346, -0.0245])),\n",
       "             ('transformations.4.dense1.weight',\n",
       "              tensor([[-0.0715, -0.0250, -0.0816,  ..., -0.0213, -0.0298,  0.0325],\n",
       "                      [ 0.0018, -0.1309,  0.0763,  ...,  0.1339, -0.0602,  0.1474],\n",
       "                      [ 0.0721, -0.1204,  0.1413,  ..., -0.1603,  0.1273,  0.1616],\n",
       "                      ...,\n",
       "                      [ 0.0276,  0.0637, -0.0732,  ..., -0.0959, -0.0921, -0.0687],\n",
       "                      [ 0.0969,  0.1176, -0.1331,  ...,  0.0057, -0.0534, -0.0978],\n",
       "                      [ 0.1541,  0.1076, -0.0098,  ...,  0.0942, -0.1516, -0.0238]])),\n",
       "             ('transformations.4.bn1.weight',\n",
       "              tensor([0.9812, 0.9844, 1.0029, 1.0113, 0.9846, 1.0102, 0.9794, 0.9884, 1.0030,\n",
       "                      0.9932, 1.0206, 1.0028, 1.0126, 0.9872, 0.9865, 0.9909, 0.9853, 1.0032,\n",
       "                      1.0167, 1.0043, 0.9937, 0.9991, 0.9999, 1.0053, 0.9851, 0.9848, 0.9960,\n",
       "                      0.9902, 0.9934, 0.9906, 1.0045, 0.9855, 1.0019, 0.9797, 0.9935, 1.0085,\n",
       "                      0.9865, 1.0106, 0.9980, 0.9785, 0.9922, 0.9956, 1.0095, 0.9995, 1.0022,\n",
       "                      1.0023, 0.9789, 0.9872, 0.9987, 0.9905, 0.9875, 0.9835, 0.9887, 0.9823,\n",
       "                      1.0103, 1.0000, 0.9939, 0.9979, 0.9966, 0.9929, 0.9877, 0.9983, 1.0066,\n",
       "                      1.0147, 1.0051, 1.0172, 0.9991, 0.9996, 1.0116, 1.0081, 1.0037, 0.9929,\n",
       "                      1.0015, 1.0103, 0.9817, 0.9897, 0.9998, 0.9955, 1.0122, 0.9910, 1.0183,\n",
       "                      0.9954, 1.0087, 1.0119, 1.0011, 0.9956, 1.0048, 1.0100, 0.9892, 0.9914,\n",
       "                      0.9940, 1.0152, 0.9920, 1.0107, 1.0134, 1.0035, 0.9956, 0.9796, 0.9987,\n",
       "                      1.0071, 1.0071, 1.0101, 1.0167, 1.0093, 1.0150, 0.9815, 0.9892, 1.0199,\n",
       "                      0.9910, 0.9906, 0.9931, 0.9842, 1.0040, 0.9913, 0.9891, 1.0065, 1.0080,\n",
       "                      0.9904, 0.9967, 1.0059, 0.9831, 1.0038, 0.9833, 1.0030, 0.9916, 1.0040,\n",
       "                      1.0068, 0.9980])),\n",
       "             ('transformations.4.bn1.bias',\n",
       "              tensor([ 0.0079,  0.0121, -0.0004,  0.0147, -0.0232, -0.0145, -0.0222,  0.0031,\n",
       "                       0.0003,  0.0007,  0.0252,  0.0125,  0.0110, -0.0226, -0.0091, -0.0137,\n",
       "                      -0.0182,  0.0095,  0.0164,  0.0124,  0.0006,  0.0092,  0.0101,  0.0019,\n",
       "                      -0.0137, -0.0145,  0.0210, -0.0193, -0.0153, -0.0041, -0.0146, -0.0246,\n",
       "                       0.0005, -0.0136, -0.0106,  0.0080, -0.0199,  0.0151,  0.0153, -0.0219,\n",
       "                      -0.0077, -0.0091, -0.0027, -0.0058, -0.0019,  0.0113, -0.0172, -0.0145,\n",
       "                      -0.0078, -0.0179, -0.0193, -0.0167, -0.0037, -0.0188,  0.0180, -0.0138,\n",
       "                       0.0048, -0.0025, -0.0010, -0.0039, -0.0126,  0.0055,  0.0063,  0.0173,\n",
       "                      -0.0151,  0.0069,  0.0069, -0.0111,  0.0129,  0.0148,  0.0053, -0.0115,\n",
       "                      -0.0083, -0.0019, -0.0114, -0.0154,  0.0070, -0.0059,  0.0126, -0.0022,\n",
       "                       0.0077, -0.0080,  0.0089,  0.0171, -0.0174,  0.0033, -0.0241,  0.0062,\n",
       "                      -0.0154,  0.0015, -0.0028,  0.0234, -0.0056,  0.0157,  0.0141,  0.0029,\n",
       "                      -0.0126, -0.0223, -0.0091,  0.0197,  0.0086,  0.0188,  0.0096,  0.0247,\n",
       "                       0.0237, -0.0133, -0.0174,  0.0158,  0.0028,  0.0016, -0.0119, -0.0154,\n",
       "                      -0.0023,  0.0031, -0.0009,  0.0053,  0.0082, -0.0214, -0.0188,  0.0152,\n",
       "                      -0.0119,  0.0090, -0.0190,  0.0321, -0.0136,  0.0117,  0.0061, -0.0349])),\n",
       "             ('transformations.4.bn1.running_mean',\n",
       "              tensor([ 0.0695, -0.0280, -0.3140,  0.3135,  0.0457,  0.0277,  0.4657, -0.0333,\n",
       "                       0.3411,  0.0428,  0.2189,  0.1735, -0.3978,  0.2359,  0.0519,  0.1339,\n",
       "                      -0.2541, -0.1610,  0.0251,  0.3458, -0.0982, -0.0978,  0.1620,  0.2833,\n",
       "                      -0.1010, -0.0078,  0.1355,  0.0278,  0.3553, -0.3577, -0.2890, -0.0322,\n",
       "                      -0.1909,  0.0181,  0.1043,  0.2306, -0.3424,  0.1411, -0.3236,  0.2141,\n",
       "                      -0.2456, -0.1148,  0.0675,  0.4190, -0.1186,  0.3568, -0.0659, -0.2051,\n",
       "                       0.2731, -0.0142,  0.0330,  0.2682, -0.2379,  0.0470, -0.1888, -0.2317,\n",
       "                       0.1185,  0.1695, -0.0447,  0.4773,  0.0576,  0.1806, -0.1172, -0.0632,\n",
       "                       0.0373, -0.1217,  0.0598,  0.3634, -0.0234,  0.0068,  0.0510, -0.0271,\n",
       "                       0.0335, -0.1823,  0.2347,  0.2168,  0.0132,  0.3078,  0.0944,  0.1314,\n",
       "                       0.0331, -0.1815,  0.0881,  0.2737, -0.2063,  0.0440, -0.2015,  0.0837,\n",
       "                       0.0397,  0.0673, -0.1475,  0.0446,  0.2770,  0.5186,  0.4580,  0.3249,\n",
       "                       0.2512, -0.2361, -0.1248,  0.0912,  0.3975,  0.4480,  0.0135, -0.0585,\n",
       "                       0.1437,  0.1471, -0.1119,  0.1118, -0.0266,  0.0186, -0.0828,  0.1964,\n",
       "                      -0.3632,  0.0936, -0.0560, -0.0763, -0.2415, -0.0949,  0.2250,  0.2396,\n",
       "                       0.0921, -0.0664,  0.1368, -0.5006, -0.2057,  0.0954,  0.3305, -0.0414])),\n",
       "             ('transformations.4.bn1.running_var',\n",
       "              tensor([0.2299, 0.1387, 0.2141, 0.1307, 0.2243, 0.1095, 0.7081, 0.1557, 0.6446,\n",
       "                      0.1180, 0.1134, 0.3121, 0.7688, 0.2765, 0.0992, 0.3407, 0.2604, 0.5179,\n",
       "                      0.1969, 0.4905, 0.2415, 0.1432, 0.1776, 0.4496, 0.2390, 0.1368, 0.1441,\n",
       "                      0.2291, 0.9525, 2.0488, 0.2147, 0.0972, 0.3020, 0.3967, 0.3980, 0.1399,\n",
       "                      1.0178, 0.2094, 0.3424, 0.1066, 0.3954, 0.3244, 0.3457, 1.0629, 0.1445,\n",
       "                      0.9842, 0.1773, 0.4801, 0.6613, 0.1171, 0.1019, 0.1635, 0.3297, 0.1494,\n",
       "                      0.1726, 0.2216, 0.4455, 0.2204, 0.1655, 0.8136, 0.0992, 0.1687, 0.1299,\n",
       "                      0.2048, 0.1165, 0.1760, 0.1768, 0.5093, 0.1628, 0.2007, 0.1523, 0.1171,\n",
       "                      0.1595, 0.4314, 0.2442, 0.6512, 0.1647, 0.2856, 0.1292, 0.1504, 0.1003,\n",
       "                      0.3262, 0.1776, 0.3763, 0.4728, 0.1294, 0.1876, 0.1279, 0.1242, 0.3351,\n",
       "                      0.4370, 0.1285, 0.7860, 0.3116, 0.5884, 0.1535, 0.2179, 0.9550, 0.2826,\n",
       "                      0.2243, 0.4789, 0.7324, 0.1745, 0.0864, 0.1696, 0.3568, 0.5150, 0.4934,\n",
       "                      0.1891, 0.1772, 0.1546, 0.1561, 0.5604, 0.1016, 0.1175, 0.2004, 0.1904,\n",
       "                      0.2094, 0.1955, 0.1459, 0.1761, 0.3735, 0.1468, 0.4207, 0.4405, 0.1528,\n",
       "                      0.1851, 0.0887])),\n",
       "             ('transformations.4.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.4.mu.weight',\n",
       "              tensor([[ 0.0338, -0.0675, -0.0110,  ..., -0.0889,  0.0025,  0.0742],\n",
       "                      [-0.0685, -0.0555, -0.0602,  ...,  0.0268,  0.0787, -0.0158],\n",
       "                      [-0.0334,  0.0645,  0.0177,  ...,  0.0117,  0.0687,  0.0326],\n",
       "                      ...,\n",
       "                      [-0.0053,  0.0120,  0.0162,  ...,  0.0567,  0.0723, -0.0411],\n",
       "                      [-0.0047,  0.0029,  0.0483,  ...,  0.0892,  0.0746,  0.0500],\n",
       "                      [ 0.0467, -0.0423, -0.0540,  ..., -0.0218, -0.0405, -0.0342]])),\n",
       "             ('transformations.4.mu.bias',\n",
       "              tensor([ 0.0722,  0.0643,  0.0354,  0.0245, -0.0776, -0.0760,  0.0275, -0.0100,\n",
       "                      -0.0162,  0.0838, -0.0814, -0.0292, -0.0213, -0.0520,  0.0571,  0.0613,\n",
       "                       0.0135, -0.0142,  0.0609, -0.0293,  0.0758,  0.0134,  0.0380, -0.0603,\n",
       "                      -0.0229, -0.0265,  0.0390,  0.0042, -0.0468, -0.0116,  0.0267, -0.0729])),\n",
       "             ('transformations.4.sigma.weight',\n",
       "              tensor([[-0.0764, -0.0300, -0.0102,  ...,  0.0134, -0.0343,  0.0031],\n",
       "                      [-0.0470, -0.0174, -0.0822,  ..., -0.0605,  0.0241,  0.0731],\n",
       "                      [ 0.0463,  0.0105,  0.0131,  ...,  0.0298, -0.0242, -0.0750],\n",
       "                      ...,\n",
       "                      [-0.0563,  0.0321, -0.0922,  ...,  0.0630,  0.0748, -0.0094],\n",
       "                      [-0.0782, -0.0309,  0.0344,  ..., -0.0176, -0.0594, -0.0316],\n",
       "                      [ 0.0199, -0.0648,  0.0565,  ..., -0.0018,  0.0705, -0.0104]])),\n",
       "             ('transformations.4.sigma.bias',\n",
       "              tensor([ 0.0396,  0.0437,  0.0217,  0.0385,  0.0056,  0.0151, -0.0458, -0.0811,\n",
       "                       0.0030,  0.0022, -0.0030,  0.0804, -0.0746, -0.0348, -0.0126, -0.0475,\n",
       "                      -0.0197,  0.0461,  0.0483, -0.0897,  0.0525,  0.0870,  0.0289,  0.0065,\n",
       "                       0.0439, -0.0978,  0.0063,  0.0190, -0.0581,  0.0485, -0.0667, -0.0218])),\n",
       "             ('transformations.5.dense1.weight',\n",
       "              tensor([[-0.0789, -0.1252, -0.1132,  ...,  0.0343, -0.0685, -0.1174],\n",
       "                      [ 0.1659,  0.1052, -0.0627,  ..., -0.0391,  0.1447, -0.1460],\n",
       "                      [-0.0113,  0.0665,  0.1997,  ..., -0.1258,  0.0698,  0.0055],\n",
       "                      ...,\n",
       "                      [-0.1194, -0.1213,  0.1215,  ...,  0.1200,  0.0148,  0.0134],\n",
       "                      [-0.1012, -0.1195,  0.0312,  ...,  0.1599, -0.1391,  0.0737],\n",
       "                      [ 0.1326,  0.0945,  0.0717,  ..., -0.0648, -0.0947, -0.1089]])),\n",
       "             ('transformations.5.bn1.weight',\n",
       "              tensor([0.9826, 1.0102, 1.0311, 0.9909, 1.0022, 1.0060, 0.9814, 0.9979, 0.9983,\n",
       "                      1.0062, 1.0246, 1.0075, 0.9958, 1.0196, 0.9902, 1.0064, 1.0132, 1.0179,\n",
       "                      1.0055, 1.0049, 0.9806, 1.0444, 1.0256, 0.9935, 1.0172, 1.0225, 1.0182,\n",
       "                      1.0138, 0.9950, 1.0222, 0.9881, 1.0189, 0.9883, 1.0179, 1.0254, 0.9868,\n",
       "                      0.9994, 0.9936, 0.9980, 0.9942, 1.0213, 0.9943, 1.0226, 1.0347, 1.0192,\n",
       "                      0.9950, 1.0094, 1.0175, 1.0105, 1.0209, 1.0092, 0.9985, 1.0159, 1.0046,\n",
       "                      1.0258, 0.9977, 1.0088, 1.0189, 1.0252, 1.0205, 1.0037, 1.0176, 0.9878,\n",
       "                      1.0158, 1.0254, 1.0072, 1.0192, 1.0006, 1.0207, 1.0013, 0.9973, 0.9830,\n",
       "                      0.9933, 1.0232, 1.0024, 1.0200, 1.0176, 1.0170, 1.0150, 1.0033, 1.0101,\n",
       "                      0.9851, 1.0194, 1.0082, 1.0144, 1.0064, 1.0161, 1.0159, 1.0383, 1.0208,\n",
       "                      0.9925, 1.0118, 1.0173, 1.0196, 1.0220, 1.0054, 1.0129, 0.9910, 1.0273,\n",
       "                      1.0170, 0.9914, 1.0068, 1.0206, 1.0175, 0.9943, 1.0003, 1.0055, 1.0150,\n",
       "                      1.0028, 0.9940, 1.0233, 0.9806, 1.0016, 1.0172, 1.0134, 0.9838, 1.0120,\n",
       "                      1.0002, 1.0189, 1.0170, 1.0076, 1.0066, 1.0132, 1.0319, 1.0002, 0.9989,\n",
       "                      1.0067, 1.0197])),\n",
       "             ('transformations.5.bn1.bias',\n",
       "              tensor([-0.0171,  0.0377,  0.0378, -0.0076,  0.0178,  0.0286, -0.0095,  0.0041,\n",
       "                      -0.0110,  0.0079,  0.0369, -0.0371, -0.0144,  0.0065, -0.0145,  0.0145,\n",
       "                       0.0373,  0.0130,  0.0295,  0.0111, -0.0252,  0.0893,  0.0180, -0.0080,\n",
       "                      -0.0260,  0.0125,  0.0059,  0.0153, -0.0070,  0.0354,  0.0235,  0.0036,\n",
       "                      -0.0115,  0.0213,  0.0141,  0.0126,  0.0014, -0.0078, -0.0050,  0.0009,\n",
       "                       0.0059, -0.0469,  0.0098,  0.0713,  0.0085, -0.0073, -0.0050, -0.0094,\n",
       "                       0.0228,  0.0133,  0.0142, -0.0106,  0.0097,  0.0009,  0.0106, -0.0063,\n",
       "                       0.0243,  0.0178,  0.0422,  0.0325,  0.0044,  0.0270, -0.0100,  0.0016,\n",
       "                       0.0262, -0.0286,  0.0206,  0.0178,  0.0082,  0.0144,  0.0102, -0.0141,\n",
       "                      -0.0068,  0.0195,  0.0003,  0.0148,  0.0242,  0.0073,  0.0066,  0.0016,\n",
       "                      -0.0144, -0.0053,  0.0146,  0.0079,  0.0297,  0.0197,  0.0037,  0.0160,\n",
       "                       0.0814,  0.0148, -0.0022,  0.0104,  0.0032,  0.0379,  0.0158, -0.0145,\n",
       "                       0.0143, -0.0158,  0.0371,  0.0103, -0.0084,  0.0280,  0.0195,  0.0110,\n",
       "                       0.0103, -0.0197, -0.0029,  0.0186,  0.0140, -0.0172,  0.0115, -0.0211,\n",
       "                       0.0222,  0.0111, -0.0248, -0.0225,  0.0291,  0.0024,  0.0113,  0.0305,\n",
       "                      -0.0056,  0.0209,  0.0402,  0.0482, -0.0056, -0.0143,  0.0019,  0.0356])),\n",
       "             ('transformations.5.bn1.running_mean',\n",
       "              tensor([ 1.9924e-01,  1.0973e-01, -7.0050e-02,  2.9704e-01,  4.3839e-01,\n",
       "                       2.7656e-01, -1.9080e-01, -5.5868e-02, -2.4850e-01, -6.7604e-01,\n",
       "                       2.3801e-01,  3.2657e-02,  6.4806e-03, -4.2207e-01, -9.3388e-02,\n",
       "                       3.8823e-02,  1.6355e-01, -5.1473e-01,  3.2210e-01, -1.8376e-01,\n",
       "                      -5.4587e-01,  2.2758e-01,  3.4650e-01, -4.4739e-01, -2.4663e-01,\n",
       "                      -4.2976e-02, -7.1246e-01, -7.9102e-01,  4.2406e-02,  2.6261e-01,\n",
       "                       2.6154e-01,  2.6910e-01, -3.9442e-01,  1.7252e-01,  6.5515e-01,\n",
       "                      -3.7201e-01,  5.9007e-02, -1.4361e-01,  1.5294e-01,  1.4586e-01,\n",
       "                      -4.8098e-01, -1.4822e-01, -2.1021e-01,  4.4542e-01, -6.2056e-02,\n",
       "                       1.0913e-01, -3.6297e-01, -3.3840e-01,  8.2554e-02, -5.0013e-01,\n",
       "                       3.3852e-01, -2.2591e-01,  1.5215e-02, -1.1401e-01,  2.5768e-01,\n",
       "                       4.9482e-01,  2.8314e-01, -3.8388e-01,  3.2045e-01, -5.1036e-02,\n",
       "                       5.2311e-02,  4.1150e-01, -2.3671e-01, -1.0438e-01,  2.0742e-01,\n",
       "                      -3.1910e-01,  9.2980e-02,  3.1336e-01, -1.4567e-01,  3.0585e-01,\n",
       "                       4.3123e-01,  3.3219e-01, -2.4600e-01, -5.0839e-02,  5.3077e-02,\n",
       "                      -3.3445e-01,  8.0354e-02, -3.5573e-01, -4.9005e-02,  1.8605e-02,\n",
       "                      -2.3668e-01,  2.3584e-01, -4.3957e-01,  8.4988e-02,  3.9695e-01,\n",
       "                      -3.7028e-04, -2.7232e-01, -3.2064e-01,  7.8538e-02, -2.4588e-01,\n",
       "                       1.6104e-01, -8.2577e-02,  1.0641e-02, -1.4204e-01,  2.2364e-02,\n",
       "                      -1.7819e-01,  1.2594e-01,  6.1847e-02,  2.5418e-01, -3.6430e-01,\n",
       "                      -1.4991e-01,  4.4459e-01, -3.4773e-01, -8.3598e-02,  8.2684e-02,\n",
       "                      -4.2294e-01,  3.6151e-01, -1.2897e-01, -1.8160e-01,  1.0942e-01,\n",
       "                      -3.1583e-01,  9.1147e-02,  5.0579e-01,  6.6013e-02, -1.8178e-01,\n",
       "                       2.2379e-01,  5.8045e-01,  2.6677e-01, -5.1086e-01,  8.4732e-02,\n",
       "                      -4.5034e-01,  4.3931e-01, -1.4428e-01,  2.8858e-01, -1.7860e-01,\n",
       "                      -5.3035e-02, -1.2287e-01, -9.3786e-02])),\n",
       "             ('transformations.5.bn1.running_var',\n",
       "              tensor([0.1364, 0.2183, 0.1194, 0.6562, 0.4578, 0.2350, 0.1805, 0.1288, 0.3129,\n",
       "                      0.4660, 0.3997, 0.1504, 0.2293, 0.3657, 0.1976, 0.0945, 0.1690, 0.4419,\n",
       "                      0.2343, 0.1845, 0.3724, 0.1524, 0.4563, 0.5338, 0.2264, 0.1591, 0.9885,\n",
       "                      1.1916, 0.1499, 0.2409, 0.1521, 0.2683, 0.2775, 0.2185, 0.7917, 0.3023,\n",
       "                      0.0857, 0.1373, 0.1175, 0.1216, 0.5624, 0.1327, 0.4320, 0.5869, 0.2112,\n",
       "                      0.2380, 0.2932, 0.2565, 0.1637, 0.4916, 0.2766, 0.1438, 0.1983, 0.1015,\n",
       "                      0.1728, 0.3166, 0.1723, 0.3534, 0.4775, 0.1305, 0.1265, 0.3050, 0.3582,\n",
       "                      0.2293, 0.1514, 0.2526, 0.1207, 0.1661, 0.1533, 0.3037, 0.5692, 0.4620,\n",
       "                      0.1567, 0.2413, 0.1514, 0.4724, 0.1530, 0.3008, 0.1997, 0.1494, 0.2068,\n",
       "                      0.2202, 0.7160, 0.0934, 0.2170, 0.1167, 0.1360, 0.2497, 0.1156, 0.3594,\n",
       "                      0.1458, 0.1500, 0.1524, 0.1234, 0.2210, 0.1757, 0.2148, 0.1083, 0.1901,\n",
       "                      0.5313, 0.1434, 0.4287, 0.3323, 0.1736, 0.1247, 0.2471, 0.5734, 0.1074,\n",
       "                      0.1772, 0.1238, 0.2360, 0.1346, 0.3987, 0.1769, 0.1606, 0.3166, 0.6761,\n",
       "                      0.2151, 0.7286, 0.1306, 0.3704, 0.3974, 0.1458, 0.4117, 0.1517, 0.1285,\n",
       "                      0.1937, 0.1536])),\n",
       "             ('transformations.5.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.5.mu.weight',\n",
       "              tensor([[-0.0290,  0.0416,  0.0295,  ..., -0.0544, -0.0330,  0.0127],\n",
       "                      [-0.0563,  0.0929,  0.0857,  ..., -0.0647,  0.0036,  0.0529],\n",
       "                      [-0.1062, -0.0047, -0.0186,  ...,  0.0381,  0.0308,  0.0678],\n",
       "                      ...,\n",
       "                      [-0.0345, -0.0270,  0.0015,  ...,  0.0365, -0.0897,  0.1003],\n",
       "                      [ 0.0532,  0.0563,  0.0614,  ..., -0.0236, -0.0862, -0.0091],\n",
       "                      [-0.0455,  0.0254, -0.1055,  ...,  0.0489,  0.0624,  0.0345]])),\n",
       "             ('transformations.5.mu.bias',\n",
       "              tensor([ 0.0409,  0.1089,  0.0832, -0.0506, -0.0013,  0.0703,  0.0704, -0.0170,\n",
       "                      -0.1414,  0.0036,  0.0906,  0.0450,  0.1440, -0.0260, -0.0068, -0.0662,\n",
       "                       0.0691, -0.0343, -0.0382,  0.0083, -0.0315, -0.0024, -0.0690,  0.0359,\n",
       "                       0.0523,  0.1010,  0.0446, -0.0758,  0.0884, -0.0331, -0.0529, -0.0506])),\n",
       "             ('transformations.5.sigma.weight',\n",
       "              tensor([[-0.0163,  0.0240,  0.0133,  ...,  0.0463, -0.0379,  0.0403],\n",
       "                      [-0.0284, -0.0264, -0.1041,  ..., -0.0766,  0.0343, -0.0397],\n",
       "                      [ 0.0703, -0.0871, -0.0624,  ..., -0.0684, -0.0361, -0.0208],\n",
       "                      ...,\n",
       "                      [ 0.0007, -0.0521, -0.0085,  ...,  0.0133, -0.0510,  0.0524],\n",
       "                      [-0.0027, -0.0586,  0.0112,  ..., -0.0092,  0.0188,  0.0865],\n",
       "                      [-0.0429, -0.0544, -0.0531,  ...,  0.0595,  0.0264,  0.0405]])),\n",
       "             ('transformations.5.sigma.bias',\n",
       "              tensor([ 0.0354, -0.0191, -0.0402,  0.0154, -0.0513, -0.0163, -0.0478,  0.0467,\n",
       "                       0.0431,  0.0418, -0.0152,  0.0376, -0.0769,  0.0184, -0.0977, -0.0118,\n",
       "                       0.0889, -0.0318, -0.0373,  0.0262, -0.0122, -0.1034, -0.0027, -0.0233,\n",
       "                      -0.0481,  0.0505,  0.0133,  0.0731,  0.0715,  0.0182, -0.0301, -0.0435])),\n",
       "             ('transformations.6.dense1.weight',\n",
       "              tensor([[-0.0871, -0.0970, -0.0662,  ..., -0.0659, -0.0233, -0.1783],\n",
       "                      [ 0.0267, -0.1621, -0.0172,  ...,  0.0334,  0.1065, -0.0496],\n",
       "                      [ 0.1435, -0.0376, -0.0356,  ..., -0.0330,  0.0759, -0.0285],\n",
       "                      ...,\n",
       "                      [ 0.0652, -0.0611,  0.1279,  ...,  0.1337, -0.0432, -0.1294],\n",
       "                      [ 0.1027,  0.0304,  0.1735,  ..., -0.1225,  0.1001,  0.0335],\n",
       "                      [ 0.1461, -0.0851, -0.0512,  ..., -0.1630,  0.0861,  0.1513]])),\n",
       "             ('transformations.6.bn1.weight',\n",
       "              tensor([1.0072, 1.0033, 0.9959, 1.0047, 0.9962, 0.9822, 1.0109, 0.9847, 1.0058,\n",
       "                      1.0154, 1.0108, 1.0059, 1.0045, 0.9907, 0.9985, 1.0065, 1.0041, 1.0066,\n",
       "                      1.0044, 0.9847, 1.0131, 0.9880, 1.0129, 0.9910, 1.0119, 1.0025, 0.9985,\n",
       "                      0.9869, 0.9738, 1.0103, 0.9840, 1.0054, 0.9858, 0.9864, 0.9980, 1.0015,\n",
       "                      1.0153, 1.0095, 0.9928, 1.0072, 1.0086, 0.9976, 1.0166, 1.0096, 0.9880,\n",
       "                      0.9847, 0.9887, 1.0147, 1.0057, 1.0132, 1.0154, 0.9825, 0.9850, 0.9884,\n",
       "                      0.9995, 0.9835, 1.0133, 0.9848, 0.9988, 1.0032, 1.0117, 0.9984, 1.0091,\n",
       "                      0.9823, 0.9931, 0.9773, 0.9961, 1.0050, 0.9903, 0.9935, 1.0140, 0.9927,\n",
       "                      0.9962, 1.0013, 1.0078, 1.0030, 0.9964, 0.9966, 1.0068, 0.9772, 1.0045,\n",
       "                      1.0072, 0.9880, 1.0044, 1.0193, 0.9993, 1.0044, 0.9968, 0.9955, 1.0051,\n",
       "                      1.0055, 0.9857, 0.9771, 1.0122, 1.0059, 0.9871, 0.9993, 1.0123, 0.9962,\n",
       "                      0.9926, 1.0004, 1.0081, 1.0011, 0.9881, 0.9865, 0.9963, 1.0103, 0.9878,\n",
       "                      0.9839, 1.0005, 1.0040, 0.9972, 1.0046, 1.0198, 1.0144, 0.9864, 1.0035,\n",
       "                      0.9976, 0.9937, 1.0128, 1.0081, 0.9847, 0.9936, 0.9836, 0.9936, 1.0024,\n",
       "                      0.9855, 0.9994])),\n",
       "             ('transformations.6.bn1.bias',\n",
       "              tensor([ 8.4218e-03, -1.2985e-02,  6.4266e-03, -2.1949e-03, -6.8758e-03,\n",
       "                      -8.2945e-03,  7.6174e-03, -1.5673e-02,  5.3929e-03,  4.1534e-03,\n",
       "                       1.3197e-02,  4.6575e-03,  9.9260e-03, -1.1154e-02,  5.5103e-03,\n",
       "                       1.0284e-02,  1.3219e-02,  1.5595e-02, -1.0459e-03, -1.5039e-02,\n",
       "                       1.2559e-02, -1.4074e-02,  1.2146e-02, -9.3374e-03,  1.7980e-02,\n",
       "                      -2.7404e-03,  3.8928e-03, -1.0829e-02, -2.5414e-02,  1.5236e-02,\n",
       "                      -1.5217e-02, -2.1837e-03, -1.4283e-02, -1.4483e-02, -2.7336e-04,\n",
       "                       1.4755e-02,  1.0124e-02, -1.5230e-03,  1.0875e-02, -1.2331e-02,\n",
       "                       9.7928e-04, -7.1282e-04,  1.1033e-02,  7.0808e-03, -1.2963e-02,\n",
       "                      -1.7015e-02, -1.8387e-02,  1.3380e-02,  2.0895e-02,  1.4973e-02,\n",
       "                       6.6667e-03, -2.3740e-02, -2.0419e-03, -1.7027e-02, -1.9749e-02,\n",
       "                      -1.0996e-02,  1.2671e-02,  6.4224e-03,  1.0198e-02,  9.7110e-03,\n",
       "                       1.1815e-02, -1.3190e-02,  5.7356e-03, -1.6264e-02, -1.3119e-02,\n",
       "                       6.2349e-05,  1.5344e-02,  1.3056e-02, -2.2311e-02,  1.4104e-02,\n",
       "                       1.3094e-02, -1.0345e-02, -5.9168e-03,  1.5622e-02,  8.1245e-03,\n",
       "                       6.6525e-03,  5.4889e-03,  8.7800e-04,  1.4798e-02, -3.7706e-03,\n",
       "                       1.4878e-02,  7.2330e-03, -1.2200e-02, -3.0755e-03,  1.7797e-02,\n",
       "                      -3.1795e-03,  5.9118e-03, -2.4447e-03, -1.0803e-02,  1.2987e-02,\n",
       "                       1.0202e-02, -1.3092e-02, -2.4062e-02, -1.0651e-02, -1.2548e-02,\n",
       "                      -9.6416e-03, -2.2087e-02,  1.2980e-02, -2.8695e-02, -3.2207e-03,\n",
       "                       2.9624e-03,  1.3117e-02,  1.5662e-02,  7.1329e-03, -1.5620e-02,\n",
       "                       5.6200e-03,  1.0976e-02, -4.6048e-03, -1.6610e-02,  1.0941e-02,\n",
       "                       3.9881e-03, -8.9419e-03,  1.5696e-03,  1.9669e-02,  1.0575e-02,\n",
       "                      -1.5021e-02,  5.4720e-03,  1.2913e-02,  1.2585e-02,  1.2867e-02,\n",
       "                      -1.9865e-03, -1.0309e-02,  7.5479e-03, -2.7931e-02,  2.2213e-03,\n",
       "                      -2.4513e-03, -1.3074e-02,  1.8352e-03])),\n",
       "             ('transformations.6.bn1.running_mean',\n",
       "              tensor([-0.5579,  0.4300, -0.3912,  0.4242,  0.0164,  0.0108, -0.6161, -0.2726,\n",
       "                      -0.0546,  0.2519,  0.4999,  0.3506,  0.1418,  0.5082, -0.2931, -0.7116,\n",
       "                      -0.0372,  0.5080, -0.3058,  0.4104,  0.3009,  0.3362, -0.0976,  0.0424,\n",
       "                       0.1840, -0.0648, -0.1487,  0.0191,  0.4050,  0.2070,  0.3014, -0.3026,\n",
       "                      -0.6095, -0.5940,  0.2391, -0.1583,  0.5015, -0.4964, -0.1991,  0.0600,\n",
       "                      -0.0281,  0.0229, -0.3806,  0.2596, -0.0447,  0.1990, -0.0892,  0.4042,\n",
       "                      -0.0569, -0.0028,  0.4894, -0.2172,  0.2618,  0.0653, -0.0496, -0.2083,\n",
       "                       0.2320,  0.2616,  0.2221, -0.0369, -0.3097, -0.6710,  0.3385,  0.1605,\n",
       "                       0.4462,  0.1247,  0.2606, -0.1264, -0.3259, -0.1766,  0.1348, -0.1433,\n",
       "                       0.3557,  0.2682,  0.2412, -0.1449, -0.0444, -0.1522, -0.1274, -0.2778,\n",
       "                       0.3403,  0.0137, -0.3946, -0.3982,  0.3780, -0.3010, -0.3082,  0.7112,\n",
       "                      -0.3182,  0.1778, -0.0878,  0.2648,  0.4938,  0.3055, -0.8228,  0.1454,\n",
       "                      -0.5808,  0.0063,  0.4182,  0.3636, -0.5486, -0.0967, -0.4708, -0.1936,\n",
       "                      -0.1882,  0.3839,  0.0969, -0.0283,  0.0910,  0.0988,  0.5786,  0.3380,\n",
       "                      -0.2622,  0.4224, -0.1728, -0.1325, -0.2369, -0.2604,  0.2666, -0.5332,\n",
       "                      -0.0121,  0.0177, -0.3122,  0.2719, -0.0868, -0.0297, -0.0017, -0.2041])),\n",
       "             ('transformations.6.bn1.running_var',\n",
       "              tensor([0.5424, 0.2996, 0.3672, 0.3485, 0.1222, 0.1314, 0.4754, 0.1940, 0.0934,\n",
       "                      0.3310, 0.3583, 0.3406, 0.2508, 0.2503, 0.4115, 0.5009, 0.1692, 0.2055,\n",
       "                      0.2989, 0.3792, 0.2766, 0.2378, 0.3536, 0.1021, 0.1789, 0.1504, 0.1832,\n",
       "                      0.1003, 0.7169, 0.1650, 0.2291, 0.5861, 0.9675, 1.0783, 0.1377, 0.2438,\n",
       "                      0.9041, 0.5416, 0.1975, 0.1836, 0.1202, 0.1398, 0.2960, 0.2229, 0.1479,\n",
       "                      0.2839, 0.0913, 0.3557, 0.0994, 0.1385, 0.3758, 0.1853, 0.2901, 0.1532,\n",
       "                      0.1584, 0.1832, 0.2354, 0.1319, 0.1293, 0.1037, 0.2452, 0.6389, 0.2424,\n",
       "                      0.1067, 0.5971, 0.1214, 0.1971, 0.1251, 0.4327, 0.1281, 0.1938, 0.0758,\n",
       "                      0.3274, 0.1699, 0.2354, 0.0901, 0.1347, 0.0981, 0.1628, 0.1247, 0.1726,\n",
       "                      0.1582, 0.4849, 0.2130, 0.5561, 0.2354, 0.2025, 0.7598, 0.1398, 0.1452,\n",
       "                      0.1166, 0.1360, 0.4247, 0.3685, 1.0886, 0.2212, 0.5392, 0.1860, 0.6406,\n",
       "                      0.4557, 0.5923, 0.2290, 0.4110, 0.1255, 0.2458, 0.4888, 0.1321, 0.1042,\n",
       "                      0.1034, 0.0915, 0.8187, 0.4435, 0.1365, 0.3776, 0.1944, 0.1873, 0.1566,\n",
       "                      0.1743, 0.1467, 0.6218, 0.0967, 0.0873, 0.2193, 0.1108, 0.1268, 0.1579,\n",
       "                      0.1774, 0.2310])),\n",
       "             ('transformations.6.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.6.mu.weight',\n",
       "              tensor([[ 0.0884,  0.0266,  0.0697,  ..., -0.0730, -0.0645, -0.0751],\n",
       "                      [-0.0861,  0.0518,  0.0220,  ..., -0.0573,  0.0007, -0.0869],\n",
       "                      [-0.0351,  0.0688,  0.0867,  ...,  0.0287, -0.0477, -0.0532],\n",
       "                      ...,\n",
       "                      [-0.0604, -0.0188, -0.0250,  ..., -0.0389, -0.0093,  0.0712],\n",
       "                      [ 0.0362,  0.0392,  0.0195,  ..., -0.0499,  0.0103, -0.0671],\n",
       "                      [ 0.0139, -0.0040,  0.0520,  ...,  0.0471, -0.0017, -0.0076]])),\n",
       "             ('transformations.6.mu.bias',\n",
       "              tensor([-0.0248, -0.0186, -0.0413,  0.0673,  0.0733,  0.0575,  0.0648, -0.0206,\n",
       "                      -0.0766, -0.0914,  0.0363,  0.0871,  0.0489, -0.0892,  0.0112, -0.0687,\n",
       "                      -0.0804,  0.0007, -0.0345, -0.0886,  0.0522,  0.0406,  0.0660,  0.0855,\n",
       "                      -0.0724,  0.0229,  0.0687,  0.0099, -0.0267,  0.0298, -0.0367, -0.0319])),\n",
       "             ('transformations.6.sigma.weight',\n",
       "              tensor([[ 0.0162, -0.0065, -0.0063,  ..., -0.0200,  0.0975,  0.0574],\n",
       "                      [-0.0707, -0.0839, -0.0614,  ..., -0.0622, -0.0258,  0.0655],\n",
       "                      [-0.0396, -0.0790,  0.0193,  ..., -0.0565,  0.0702, -0.0350],\n",
       "                      ...,\n",
       "                      [-0.0704,  0.0893, -0.0408,  ..., -0.0323,  0.0830, -0.0688],\n",
       "                      [-0.0166,  0.0647, -0.0937,  ..., -0.0120, -0.0455,  0.0574],\n",
       "                      [-0.0042,  0.0714,  0.0753,  ..., -0.0385,  0.0301, -0.0332]])),\n",
       "             ('transformations.6.sigma.bias',\n",
       "              tensor([-0.0413,  0.0631, -0.0704, -0.0924,  0.0319,  0.0046, -0.0554, -0.0156,\n",
       "                       0.0460, -0.0590, -0.0010,  0.0667, -0.0394,  0.0314,  0.0652, -0.0087,\n",
       "                      -0.0659, -0.0682,  0.0331,  0.0578,  0.0569, -0.0277, -0.0672, -0.0653,\n",
       "                      -0.0122, -0.0145, -0.0309, -0.0519,  0.0449, -0.0631, -0.0271, -0.0717])),\n",
       "             ('denses.0.mu.weight',\n",
       "              tensor([[-0.0639,  0.0222, -0.0931,  ..., -0.0281, -0.0317, -0.0277],\n",
       "                      [ 0.0120, -0.0803, -0.0392,  ...,  0.0685,  0.0430, -0.0786],\n",
       "                      [ 0.0306, -0.0334, -0.0751,  ..., -0.0198,  0.0163, -0.0045],\n",
       "                      ...,\n",
       "                      [ 0.0609,  0.0614, -0.0449,  ..., -0.0721,  0.0942,  0.0777],\n",
       "                      [-0.0650,  0.0792, -0.0913,  ..., -0.0231,  0.0377,  0.0510],\n",
       "                      [ 0.0837, -0.0091,  0.0321,  ..., -0.0108, -0.0595, -0.0490]])),\n",
       "             ('denses.0.mu.bias',\n",
       "              tensor([ 0.1181, -0.0141,  0.4884, -0.2003, -0.4351,  0.0716, -0.0981, -0.1780,\n",
       "                       0.1326,  0.1938,  0.3715, -0.0622,  0.1394, -0.1689, -0.0739, -0.0564,\n",
       "                      -0.2042,  0.0121,  0.4056,  0.0254, -0.0704, -0.2546,  0.4579,  0.1398,\n",
       "                      -0.1968,  0.2335, -0.0399,  0.2681, -0.2128, -0.1615,  0.2536, -0.0399])),\n",
       "             ('denses.0.sigma.weight',\n",
       "              tensor([[-0.0367, -0.0347, -0.0826,  ..., -0.0867, -0.0766, -0.0243],\n",
       "                      [-0.0025, -0.0655,  0.0779,  ...,  0.0157,  0.0384, -0.0336],\n",
       "                      [ 0.0199,  0.0086,  0.0439,  ..., -0.0392, -0.0792, -0.0234],\n",
       "                      ...,\n",
       "                      [-0.0875, -0.0862, -0.0919,  ...,  0.0397, -0.0870, -0.0647],\n",
       "                      [ 0.0354,  0.0075,  0.0334,  ..., -0.0944,  0.0195,  0.0227],\n",
       "                      [-0.0688, -0.0793,  0.0022,  ..., -0.0251,  0.0727,  0.0150]])),\n",
       "             ('denses.0.sigma.bias',\n",
       "              tensor([ 0.0254, -0.0630, -0.0508,  0.0006, -0.0369, -0.0063,  0.0661,  0.0503,\n",
       "                      -0.0743,  0.0183, -0.0416, -0.1030, -0.0473, -0.0697, -0.0477, -0.0384,\n",
       "                       0.0119,  0.0404,  0.0775,  0.0434, -0.0008, -0.0464, -0.0267,  0.0080,\n",
       "                      -0.0344, -0.0400, -0.0723, -0.0018,  0.0751,  0.0284, -0.0623, -0.0030])),\n",
       "             ('denses.1.mu.weight',\n",
       "              tensor([[-0.0088, -0.0666,  0.0182,  ..., -0.0700, -0.0696, -0.0608],\n",
       "                      [-0.0260, -0.0163,  0.0595,  ..., -0.0169, -0.0336, -0.0486],\n",
       "                      [ 0.0003, -0.0076, -0.0278,  ...,  0.0672, -0.0141, -0.0686],\n",
       "                      ...,\n",
       "                      [ 0.0968, -0.0567, -0.0099,  ..., -0.0403, -0.0467, -0.0114],\n",
       "                      [-0.0591,  0.0515, -0.0594,  ...,  0.0112, -0.0135, -0.0505],\n",
       "                      [-0.0063,  0.0236, -0.0727,  ...,  0.0216, -0.0130,  0.0279]])),\n",
       "             ('denses.1.mu.bias',\n",
       "              tensor([ 0.0144,  0.0058, -0.0729,  0.0827, -0.0652,  0.0468,  0.0728, -0.0529,\n",
       "                      -0.0372,  0.0509, -0.0494,  0.0690,  0.0338,  0.0098, -0.0871,  0.0464,\n",
       "                      -0.0726,  0.0747,  0.0807,  0.0697,  0.0618, -0.0904, -0.0555, -0.0406,\n",
       "                      -0.0155, -0.0042, -0.0618, -0.0303,  0.0711, -0.0112,  0.0643,  0.1009])),\n",
       "             ('denses.1.sigma.weight',\n",
       "              tensor([[ 0.0268, -0.0084,  0.0277,  ...,  0.0662, -0.0523,  0.0308],\n",
       "                      [ 0.0199,  0.0032, -0.0751,  ..., -0.0651, -0.0464, -0.0552],\n",
       "                      [-0.0147, -0.0592, -0.0692,  ..., -0.0086, -0.0333, -0.0935],\n",
       "                      ...,\n",
       "                      [-0.0374,  0.0608,  0.0378,  ...,  0.0029,  0.0629, -0.0649],\n",
       "                      [-0.0835, -0.0603,  0.0797,  ..., -0.0646,  0.0645, -0.0138],\n",
       "                      [-0.0499,  0.0137,  0.0692,  ..., -0.0630,  0.0400,  0.0495]])),\n",
       "             ('denses.1.sigma.bias',\n",
       "              tensor([ 0.0184, -0.0681, -0.0730,  0.0039,  0.0375, -0.0048, -0.0065, -0.0350,\n",
       "                      -0.0873, -0.0159,  0.0541, -0.0879, -0.1080, -0.0262,  0.0148, -0.0404,\n",
       "                      -0.0847,  0.0709, -0.0969,  0.0283,  0.0148,  0.0466,  0.0188,  0.0856,\n",
       "                       0.0699, -0.0580, -0.0830,  0.0316, -0.0294, -0.0114, -0.0508, -0.0370])),\n",
       "             ('denses.2.mu.weight',\n",
       "              tensor([[ 0.0883, -0.0734,  0.0103,  ..., -0.0344,  0.0436,  0.0053],\n",
       "                      [-0.0672, -0.0703,  0.0541,  ..., -0.0585, -0.0668,  0.0414],\n",
       "                      [-0.0541, -0.0729,  0.0218,  ...,  0.0648,  0.0390,  0.0091],\n",
       "                      ...,\n",
       "                      [ 0.0444, -0.0117,  0.0862,  ..., -0.0695,  0.0283,  0.0714],\n",
       "                      [-0.0654,  0.0480,  0.0618,  ...,  0.0074, -0.0739,  0.0595],\n",
       "                      [-0.0522, -0.0395,  0.0491,  ..., -0.0182, -0.0400, -0.0386]])),\n",
       "             ('denses.2.mu.bias',\n",
       "              tensor([-0.0788, -0.0480, -0.0381, -0.0086,  0.0670, -0.0472,  0.0447, -0.0272,\n",
       "                       0.0916, -0.0591, -0.0418,  0.0017,  0.0459, -0.0561,  0.0280,  0.1147,\n",
       "                      -0.0414,  0.0730, -0.0274, -0.0855,  0.0378,  0.0633,  0.0605, -0.0514,\n",
       "                       0.0460,  0.0298, -0.0037,  0.0283,  0.0453,  0.0780,  0.0205,  0.0567])),\n",
       "             ('denses.2.sigma.weight',\n",
       "              tensor([[ 0.0218,  0.0229,  0.0944,  ...,  0.0348,  0.0747, -0.0499],\n",
       "                      [ 0.0159,  0.0380,  0.0383,  ..., -0.0357,  0.0249, -0.0958],\n",
       "                      [-0.0644, -0.0563, -0.0906,  ..., -0.0574, -0.0149,  0.0759],\n",
       "                      ...,\n",
       "                      [ 0.0817, -0.0271, -0.0609,  ...,  0.0433, -0.0481,  0.0628],\n",
       "                      [ 0.0265,  0.0273,  0.0599,  ..., -0.0660,  0.0298,  0.0670],\n",
       "                      [-0.0160, -0.0902,  0.0170,  ...,  0.0065, -0.0879, -0.0190]])),\n",
       "             ('denses.2.sigma.bias',\n",
       "              tensor([-0.0317, -0.0457, -0.0089,  0.0089,  0.0439,  0.0187, -0.0531, -0.0541,\n",
       "                      -0.0589, -0.1000, -0.0889,  0.0783, -0.0475, -0.0487,  0.0658,  0.0624,\n",
       "                      -0.0991,  0.0022, -0.0408,  0.0052,  0.0634, -0.0356, -0.0063, -0.0715,\n",
       "                      -0.0203, -0.0425, -0.0604, -0.0706,  0.0224, -0.0835, -0.0624, -0.0242])),\n",
       "             ('denses.3.mu.weight',\n",
       "              tensor([[ 0.1110,  0.0852,  0.0155,  ...,  0.0685, -0.0226,  0.0606],\n",
       "                      [ 0.0601, -0.0392, -0.0835,  ...,  0.0280, -0.0030,  0.0885],\n",
       "                      [ 0.0287,  0.0914,  0.0224,  ...,  0.1031, -0.0602, -0.0013],\n",
       "                      ...,\n",
       "                      [-0.0940, -0.0548, -0.0108,  ..., -0.0142, -0.0441, -0.0323],\n",
       "                      [ 0.0604, -0.0494, -0.0534,  ...,  0.0350,  0.0667, -0.0808],\n",
       "                      [-0.0126,  0.0419,  0.0445,  ...,  0.0339, -0.0488, -0.0765]])),\n",
       "             ('denses.3.mu.bias',\n",
       "              tensor([ 0.1241, -0.0581,  0.0566,  0.0064, -0.0776, -0.0014, -0.1155, -0.0470,\n",
       "                      -0.0691,  0.0832, -0.0052, -0.0943, -0.0417, -0.1012,  0.0318, -0.0390,\n",
       "                       0.0785,  0.0880, -0.1188, -0.0210,  0.0881, -0.0102,  0.0047, -0.0456,\n",
       "                       0.0058, -0.0318,  0.0621, -0.0860,  0.0734, -0.0846,  0.0736,  0.0567])),\n",
       "             ('denses.3.sigma.weight',\n",
       "              tensor([[-0.0100,  0.0339, -0.0945,  ..., -0.0116, -0.0326, -0.0122],\n",
       "                      [ 0.0856, -0.0483, -0.0261,  ...,  0.0687, -0.0056,  0.0552],\n",
       "                      [-0.0470,  0.0106,  0.0373,  ..., -0.0220, -0.0764, -0.0831],\n",
       "                      ...,\n",
       "                      [ 0.0518, -0.0900,  0.0589,  ...,  0.0530,  0.0315, -0.0265],\n",
       "                      [ 0.0396, -0.0528,  0.0508,  ..., -0.0056,  0.0662,  0.0151],\n",
       "                      [ 0.0465, -0.0689,  0.0045,  ..., -0.1018,  0.0630, -0.0171]])),\n",
       "             ('denses.3.sigma.bias',\n",
       "              tensor([ 0.0583, -0.0601,  0.0478, -0.0518, -0.0524,  0.0386,  0.0648,  0.0031,\n",
       "                       0.0433,  0.0505,  0.0494, -0.0944,  0.0839, -0.0861, -0.0198,  0.0560,\n",
       "                       0.0579,  0.0277, -0.0693, -0.0816,  0.0159, -0.0707,  0.0356, -0.0658,\n",
       "                      -0.0606,  0.0212,  0.0099, -0.0842,  0.0155, -0.0404, -0.0164, -0.0862])),\n",
       "             ('denses.4.mu.weight',\n",
       "              tensor([[ 0.0171,  0.0320, -0.0027,  ..., -0.0508, -0.0659,  0.0338],\n",
       "                      [-0.0536,  0.0257, -0.0518,  ..., -0.0877,  0.0533,  0.0315],\n",
       "                      [-0.0373,  0.1139,  0.0279,  ...,  0.0665,  0.0442,  0.0109],\n",
       "                      ...,\n",
       "                      [ 0.0941, -0.0179,  0.0647,  ...,  0.0921, -0.0324,  0.0451],\n",
       "                      [-0.0531,  0.0449,  0.0094,  ..., -0.0865, -0.0293, -0.0336],\n",
       "                      [ 0.0493,  0.0678, -0.0139,  ..., -0.0706,  0.0613, -0.0222]])),\n",
       "             ('denses.4.mu.bias',\n",
       "              tensor([-0.0508,  0.0509, -0.0400, -0.0388,  0.0999,  0.0154, -0.0014,  0.1263,\n",
       "                      -0.0093,  0.0312,  0.0026,  0.0314, -0.0462,  0.0933, -0.0507,  0.0422,\n",
       "                      -0.0475,  0.0205, -0.0220,  0.0291,  0.0375,  0.0334,  0.0723,  0.0206,\n",
       "                       0.0136,  0.0734, -0.0143,  0.0914,  0.0514,  0.0597,  0.0441,  0.0099])),\n",
       "             ('denses.4.sigma.weight',\n",
       "              tensor([[-0.0036, -0.0378,  0.0428,  ..., -0.0116,  0.0070, -0.0692],\n",
       "                      [-0.0410,  0.0548, -0.0985,  ...,  0.1061,  0.0157,  0.0345],\n",
       "                      [ 0.0160,  0.0031, -0.0301,  ...,  0.1087, -0.0485,  0.1040],\n",
       "                      ...,\n",
       "                      [ 0.0719, -0.0084, -0.0174,  ...,  0.0973, -0.0758, -0.0719],\n",
       "                      [ 0.0742, -0.0024,  0.0625,  ..., -0.0721, -0.0588,  0.0852],\n",
       "                      [-0.0362,  0.0052, -0.0142,  ..., -0.0316, -0.0390,  0.0808]])),\n",
       "             ('denses.4.sigma.bias',\n",
       "              tensor([ 0.0809, -0.0657, -0.1053, -0.1016,  0.0799, -0.0934, -0.0546, -0.0366,\n",
       "                      -0.0381, -0.0904,  0.0546,  0.0158, -0.0734, -0.0237,  0.0276, -0.0313,\n",
       "                      -0.0829, -0.0172, -0.0959, -0.0064, -0.0259,  0.0450,  0.0301,  0.0669,\n",
       "                      -0.0827, -0.0241, -0.0307, -0.0513, -0.0122,  0.0769,  0.0636,  0.0786])),\n",
       "             ('denses.5.mu.weight',\n",
       "              tensor([[ 0.0547,  0.0581,  0.0301,  ..., -0.0572, -0.0527, -0.0060],\n",
       "                      [ 0.0914, -0.0120, -0.0898,  ...,  0.0565, -0.0138,  0.0229],\n",
       "                      [ 0.0602,  0.0143, -0.0493,  ..., -0.0251,  0.0993,  0.0107],\n",
       "                      ...,\n",
       "                      [ 0.0930, -0.0620, -0.0493,  ...,  0.0510,  0.0688,  0.0213],\n",
       "                      [-0.0671, -0.0243, -0.0623,  ...,  0.0066,  0.0282,  0.0775],\n",
       "                      [-0.0586, -0.0641, -0.0451,  ...,  0.0535, -0.0904,  0.0708]])),\n",
       "             ('denses.5.mu.bias',\n",
       "              tensor([-0.0244, -0.0582,  0.0124,  0.0002, -0.0379, -0.0334,  0.0576,  0.0237,\n",
       "                       0.1175,  0.0013, -0.0006,  0.0401, -0.0637, -0.0434, -0.0314,  0.0589,\n",
       "                      -0.1278, -0.0286, -0.0436,  0.0129,  0.0166, -0.0359, -0.0977,  0.1020,\n",
       "                      -0.0564, -0.1193,  0.0537,  0.0730,  0.0409,  0.0041, -0.0808, -0.0483])),\n",
       "             ('denses.5.sigma.weight',\n",
       "              tensor([[-0.0696, -0.0033, -0.0434,  ..., -0.0435,  0.0030,  0.0269],\n",
       "                      [-0.0954,  0.0499, -0.0107,  ..., -0.0766,  0.0748, -0.0509],\n",
       "                      [-0.0088,  0.0760, -0.0336,  ...,  0.0214,  0.0799, -0.0080],\n",
       "                      ...,\n",
       "                      [-0.0261,  0.0065,  0.0146,  ..., -0.0806, -0.0659,  0.0258],\n",
       "                      [-0.0586,  0.0059, -0.0497,  ...,  0.0140, -0.0190, -0.0961],\n",
       "                      [-0.0454,  0.0224,  0.0860,  ...,  0.0521,  0.0238,  0.0250]])),\n",
       "             ('denses.5.sigma.bias',\n",
       "              tensor([ 0.0311,  0.0454,  0.0493, -0.0129,  0.0194,  0.0511,  0.0514, -0.0280,\n",
       "                       0.0329, -0.1097, -0.0440, -0.0398,  0.0211,  0.0385,  0.0334,  0.0066,\n",
       "                      -0.0961, -0.0832,  0.0035, -0.0829, -0.0868, -0.0406,  0.0488, -0.0145,\n",
       "                      -0.0646, -0.0657,  0.0464,  0.0344, -0.0883, -0.0570, -0.0010, -0.0337])),\n",
       "             ('denses.6.mu.weight',\n",
       "              tensor([[-0.0843,  0.0828, -0.0507,  ...,  0.0522, -0.0665, -0.0365],\n",
       "                      [-0.0547, -0.0607, -0.0783,  ..., -0.0471,  0.0200, -0.0460],\n",
       "                      [ 0.0469, -0.0068,  0.0791,  ...,  0.0514,  0.0276, -0.0485],\n",
       "                      ...,\n",
       "                      [ 0.0428,  0.0554, -0.0675,  ..., -0.0321, -0.0079,  0.0249],\n",
       "                      [-0.0018,  0.0027,  0.0642,  ..., -0.0559, -0.0948,  0.0568],\n",
       "                      [ 0.0265,  0.0220, -0.0278,  ..., -0.0313, -0.0093, -0.0621]])),\n",
       "             ('denses.6.mu.bias',\n",
       "              tensor([-0.0751, -0.0169,  0.0188,  0.0979, -0.0257,  0.0834,  0.0834,  0.0361,\n",
       "                       0.0616,  0.0531,  0.0219, -0.0452,  0.0543, -0.0502, -0.0159, -0.0575,\n",
       "                      -0.0171,  0.0666, -0.0874, -0.0007,  0.0096,  0.0586, -0.0125, -0.0059,\n",
       "                       0.0668, -0.0173, -0.0225, -0.0481, -0.0186,  0.1008, -0.0784,  0.0460])),\n",
       "             ('denses.6.sigma.weight',\n",
       "              tensor([[-0.0254,  0.0657, -0.0087,  ...,  0.0448, -0.0107, -0.0563],\n",
       "                      [ 0.0741, -0.0470,  0.0733,  ..., -0.0806, -0.0343, -0.0310],\n",
       "                      [-0.0307, -0.0187, -0.0823,  ..., -0.0520, -0.0451, -0.0444],\n",
       "                      ...,\n",
       "                      [ 0.0319,  0.0353, -0.0590,  ..., -0.0561,  0.0740, -0.0098],\n",
       "                      [ 0.0658,  0.0605,  0.0749,  ..., -0.0921, -0.0763,  0.0339],\n",
       "                      [ 0.0098,  0.0334,  0.0677,  ...,  0.0660,  0.0055, -0.0720]])),\n",
       "             ('denses.6.sigma.bias',\n",
       "              tensor([-0.0686, -0.0436, -0.0635, -0.0908,  0.0060, -0.0701,  0.0784,  0.0043,\n",
       "                       0.0026, -0.0721,  0.0644, -0.0839, -0.0530, -0.0503,  0.0689, -0.0796,\n",
       "                       0.0515,  0.0244, -0.0454,  0.0609,  0.0382,  0.0688, -0.0047, -0.0976,\n",
       "                       0.0351, -0.0514,  0.0519, -0.0712,  0.0218, -0.0758,  0.0014,  0.0090])),\n",
       "             ('decisions.0.dense1.weight',\n",
       "              tensor([[ 0.0834, -0.0084,  0.0516,  ...,  0.0612,  0.0793,  0.0477],\n",
       "                      [-0.0488,  0.0011,  0.0092,  ..., -0.0143, -0.0376, -0.0267],\n",
       "                      [-0.0084, -0.0543,  0.0021,  ...,  0.0352, -0.0073, -0.0425],\n",
       "                      ...,\n",
       "                      [-0.0393,  0.0217, -0.0557,  ..., -0.0754, -0.0137,  0.0822],\n",
       "                      [ 0.0291, -0.0029,  0.0226,  ...,  0.0003,  0.0424, -0.0075],\n",
       "                      [ 0.0447,  0.0011, -0.0637,  ...,  0.0687, -0.0172, -0.0141]])),\n",
       "             ('decisions.0.dense2.weight',\n",
       "              tensor([[ 0.0013, -0.0188,  0.0008,  ...,  0.0039,  0.0032,  0.0204],\n",
       "                      [-0.0001, -0.0042, -0.0005,  ...,  0.0006, -0.0035,  0.0170],\n",
       "                      [-0.0069,  0.0006, -0.0110,  ...,  0.0102, -0.0101, -0.0079],\n",
       "                      ...,\n",
       "                      [-0.0120, -0.0005, -0.0079,  ...,  0.0134, -0.0036, -0.0162],\n",
       "                      [-0.0082, -0.0002, -0.0068,  ...,  0.0077, -0.0068, -0.0041],\n",
       "                      [-0.0127,  0.0052, -0.0067,  ...,  0.0176, -0.0004, -0.0037]])),\n",
       "             ('decisions.0.bn1.weight',\n",
       "              tensor([0.5430, 0.5096, 0.5061, 0.5306, 0.5093, 0.5212, 0.4858, 0.4773, 0.4971,\n",
       "                      0.5640, 0.5608, 0.5303, 0.5015, 0.5084, 0.5348, 0.5060, 0.5610, 0.5405,\n",
       "                      0.5384, 0.5090, 0.5251, 0.5725, 0.5123, 0.5290, 0.4875, 0.5623, 0.5136,\n",
       "                      0.5162, 0.5501, 0.5452, 0.4926, 0.5446, 0.4982, 0.5294, 0.5177, 0.5225,\n",
       "                      0.5757, 0.5846, 0.5234, 0.5326, 0.5196, 0.5102, 0.5241, 0.4920, 0.4723,\n",
       "                      0.5197, 0.5910, 0.5503, 0.5193, 0.5411, 0.5345, 0.4686, 0.5213, 0.5343,\n",
       "                      0.5046, 0.5406, 0.5494, 0.5058, 0.5163, 0.5014, 0.5473, 0.4764, 0.4905,\n",
       "                      0.4867, 0.5336, 0.6284, 0.5343, 0.6190, 0.5091, 0.5834, 0.5127, 0.5481,\n",
       "                      0.5218, 0.4907, 0.5184, 0.5373, 0.5511, 0.5403, 0.5144, 0.4974, 0.4783,\n",
       "                      0.6214, 0.5924, 0.4940, 0.5304, 0.4759, 0.5520, 0.5943, 0.5147, 0.4887,\n",
       "                      0.6054, 0.5222, 0.5335, 0.5019, 0.4965, 0.5430, 0.5123, 0.5924, 0.4935,\n",
       "                      0.5196, 0.5269, 0.5545, 0.4967, 0.5346, 0.4898, 0.5045, 0.5088, 0.5426,\n",
       "                      0.5313, 0.5376, 0.6329, 0.5362, 0.4713, 0.5052, 0.5836, 0.5577, 0.5139,\n",
       "                      0.4797, 0.5327, 0.5729, 0.5121, 0.5091, 0.6028, 0.6518, 0.4913, 0.5502,\n",
       "                      0.5340, 0.5960])),\n",
       "             ('decisions.0.bn1.bias',\n",
       "              tensor([ 0.0203,  0.0628,  0.0500,  0.0319,  0.0075,  0.0540,  0.0005,  0.0154,\n",
       "                       0.0598,  0.0626,  0.0542,  0.0135,  0.0305,  0.0111,  0.0833,  0.0584,\n",
       "                       0.0392,  0.0411,  0.0165,  0.0793,  0.0416,  0.0587,  0.0316,  0.0381,\n",
       "                       0.0173,  0.0610,  0.0694,  0.0404,  0.0290,  0.0294,  0.0108,  0.0595,\n",
       "                       0.0273,  0.0796,  0.0518,  0.0288,  0.0318,  0.0846,  0.0014,  0.0323,\n",
       "                       0.0963,  0.0462,  0.0351,  0.0076, -0.0002,  0.0218,  0.0593,  0.0708,\n",
       "                       0.0141,  0.0290,  0.0459,  0.0075,  0.0448,  0.0627,  0.0264,  0.0409,\n",
       "                       0.0327,  0.0390,  0.0306,  0.0319,  0.0423,  0.0087,  0.0076, -0.0003,\n",
       "                       0.0757,  0.0006,  0.0153,  0.0824,  0.0210,  0.0466,  0.0574,  0.0502,\n",
       "                       0.0475,  0.0166,  0.0538,  0.0535,  0.0555,  0.0495,  0.0707, -0.0006,\n",
       "                      -0.0001,  0.0646,  0.0722,  0.0426,  0.0200,  0.0130,  0.0556,  0.0310,\n",
       "                       0.0572,  0.0346,  0.0400,  0.0347,  0.0338,  0.0124,  0.0118,  0.0632,\n",
       "                       0.0826,  0.0538,  0.0269,  0.0193,  0.0275,  0.0758,  0.0060,  0.0468,\n",
       "                       0.0103,  0.0044,  0.0195,  0.0269,  0.0691,  0.0715, -0.0134,  0.0337,\n",
       "                       0.0018,  0.0150,  0.0712,  0.0230,  0.0680,  0.0279,  0.0347,  0.0705,\n",
       "                       0.0141,  0.0070,  0.0521,  0.0007, -0.0120,  0.0149,  0.0385,  0.0693])),\n",
       "             ('decisions.0.bn1.running_mean',\n",
       "              tensor([-8.0333e-03,  3.0796e-03, -3.2429e-03, -1.9738e-03,  3.5563e-03,\n",
       "                      -4.4811e-03, -1.9590e-03,  2.8606e-03, -9.2164e-04, -4.7741e-03,\n",
       "                      -2.0194e-03, -1.4826e-03, -6.7641e-03, -6.9695e-03,  6.3565e-03,\n",
       "                      -5.1613e-03,  2.7160e-03, -4.8416e-03,  5.7495e-03, -7.8198e-03,\n",
       "                      -4.4540e-03,  2.4938e-03,  4.3647e-03,  7.7208e-04, -5.4741e-03,\n",
       "                       4.9940e-04, -6.3083e-03,  2.1368e-03, -1.3698e-03,  3.3439e-03,\n",
       "                      -1.4874e-03, -4.6984e-03, -4.8706e-03,  2.8828e-04, -1.3208e-03,\n",
       "                      -3.4859e-03,  4.2455e-03, -9.8426e-05,  2.5211e-03,  4.0742e-03,\n",
       "                      -7.7043e-03, -2.7306e-03,  3.9307e-03,  2.7447e-03, -3.8212e-03,\n",
       "                       1.8740e-03,  4.0418e-04, -6.4576e-03,  1.4691e-03,  3.3411e-03,\n",
       "                       2.5960e-03, -2.4388e-03,  5.8494e-03,  3.6771e-03,  5.1146e-03,\n",
       "                      -3.8229e-03,  3.7616e-03, -5.8368e-03, -4.5010e-03, -1.6333e-03,\n",
       "                      -3.6301e-03, -3.0011e-03,  7.1725e-03, -1.2495e-04, -2.3999e-03,\n",
       "                       1.3246e-03, -1.2603e-03, -4.6617e-04,  2.1183e-03, -6.1395e-04,\n",
       "                      -1.9113e-03, -4.0339e-03,  1.3237e-03,  1.0482e-03, -3.7821e-03,\n",
       "                       9.0228e-03, -7.7549e-03, -4.3408e-03, -5.3256e-03,  2.5227e-03,\n",
       "                      -4.9771e-03, -3.7443e-04, -3.3023e-03,  1.9465e-03,  5.8653e-03,\n",
       "                       6.6930e-04, -7.2752e-03, -3.0773e-03, -9.2547e-03,  2.1902e-03,\n",
       "                       8.0973e-03, -4.9419e-03, -3.9009e-03,  2.6061e-03,  5.0248e-03,\n",
       "                       8.3611e-04,  3.0421e-03, -7.5260e-04, -3.3165e-04,  2.9025e-03,\n",
       "                       4.8576e-04, -5.3408e-03,  1.6185e-03, -7.6615e-03,  2.7122e-03,\n",
       "                       2.9028e-03, -3.5035e-03, -5.6945e-03,  9.7423e-04, -1.4837e-03,\n",
       "                      -5.8592e-03,  5.0197e-03,  1.6376e-03,  1.4859e-03,  4.5139e-03,\n",
       "                       5.8192e-03, -2.4015e-03, -1.2069e-03, -2.5517e-03, -3.6954e-03,\n",
       "                      -1.7330e-04,  2.7349e-03, -2.6354e-03,  4.7658e-05, -1.3223e-03,\n",
       "                       1.5121e-03, -1.7748e-03, -1.8083e-03])),\n",
       "             ('decisions.0.bn1.running_var',\n",
       "              tensor([0.7274, 0.8911, 0.8203, 0.7838, 0.6145, 0.8918, 0.5319, 0.3793, 0.5884,\n",
       "                      0.9724, 1.0234, 0.7558, 0.7851, 0.8116, 0.7377, 0.8863, 0.6363, 0.7708,\n",
       "                      0.4210, 0.7524, 0.7772, 0.5131, 0.6932, 0.7142, 0.6684, 0.4729, 0.9532,\n",
       "                      0.6372, 0.7328, 0.4410, 0.5570, 1.0407, 0.7081, 0.4364, 0.7604, 0.9101,\n",
       "                      0.6745, 1.0136, 0.2461, 0.5311, 0.9922, 0.9849, 0.4985, 0.3722, 0.4596,\n",
       "                      0.4526, 0.7761, 1.0742, 0.5432, 0.5836, 0.6651, 0.3782, 0.4924, 0.6327,\n",
       "                      0.4822, 1.0803, 0.5567, 0.7806, 0.7799, 0.5417, 0.4243, 0.4821, 0.2328,\n",
       "                      0.2463, 0.6378, 0.3064, 0.6656, 0.6983, 0.7372, 0.6144, 0.7475, 1.1033,\n",
       "                      0.8850, 0.4712, 0.9920, 0.7402, 0.5860, 0.8530, 0.7276, 0.2662, 0.6037,\n",
       "                      0.7722, 1.0756, 0.3864, 0.3052, 0.3536, 0.7509, 0.6734, 1.2795, 0.4178,\n",
       "                      0.5742, 0.4791, 0.6409, 0.4978, 0.3918, 0.6484, 0.8689, 0.7081, 0.4709,\n",
       "                      0.3455, 0.5175, 0.7354, 0.3898, 0.8609, 0.5167, 0.5383, 0.7691, 0.9853,\n",
       "                      0.7510, 0.7967, 0.2480, 0.6050, 0.2090, 0.5402, 0.6132, 0.6322, 0.9778,\n",
       "                      0.5700, 0.6709, 1.1818, 0.4585, 0.6272, 0.6105, 0.2505, 0.5012, 0.4868,\n",
       "                      0.7740, 0.7916])),\n",
       "             ('decisions.0.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('decisions.0.bn2.weight',\n",
       "              tensor([0.5614, 0.5544, 0.5033, 0.5233, 0.5205, 0.5487, 0.5295, 0.5359, 0.5253,\n",
       "                      0.5448, 0.5501, 0.5175, 0.5375, 0.5193, 0.5158, 0.5359, 0.5181, 0.5173,\n",
       "                      0.5167, 0.5311, 0.5249, 0.5319, 0.5148, 0.5078, 0.5264, 0.5533, 0.5168,\n",
       "                      0.5386, 0.5399, 0.5433, 0.5166, 0.5251, 0.5226, 0.5105, 0.5282, 0.5070,\n",
       "                      0.5280, 0.5197, 0.5264, 0.5078, 0.5465, 0.5120, 0.5059, 0.5235, 0.5234,\n",
       "                      0.5046, 0.5143, 0.5384, 0.4965, 0.5461, 0.5297, 0.5086, 0.5303, 0.5068,\n",
       "                      0.4949, 0.5443, 0.5077, 0.5273, 0.5368, 0.5128, 0.5347, 0.5283, 0.5250,\n",
       "                      0.5101, 0.5216, 0.5253, 0.5134, 0.5134, 0.5267, 0.5491, 0.5323, 0.5312,\n",
       "                      0.5223, 0.5464, 0.5010, 0.5459, 0.5088, 0.5305, 0.5144, 0.5412, 0.5202,\n",
       "                      0.5157, 0.5062, 0.5115, 0.5173, 0.5281, 0.5351, 0.5039, 0.5118, 0.5135,\n",
       "                      0.5231, 0.5015, 0.5057, 0.5543, 0.5043, 0.5266, 0.5274, 0.5089, 0.5191,\n",
       "                      0.5074, 0.5274, 0.5355, 0.5542, 0.5418, 0.5273, 0.5139, 0.5070, 0.5243,\n",
       "                      0.4967, 0.5334, 0.5170, 0.5325, 0.5302, 0.5234, 0.5083, 0.5026, 0.5277,\n",
       "                      0.5154, 0.5087, 0.5039, 0.5146, 0.5205, 0.5101, 0.5160, 0.5278, 0.5108,\n",
       "                      0.5038, 0.5266])),\n",
       "             ('decisions.0.bn2.bias',\n",
       "              tensor([0.0551, 0.0553, 0.0087, 0.0206, 0.0200, 0.0358, 0.0426, 0.0564, 0.0509,\n",
       "                      0.0271, 0.0593, 0.0490, 0.0627, 0.0248, 0.0026, 0.0539, 0.0172, 0.0346,\n",
       "                      0.0193, 0.0566, 0.0602, 0.0244, 0.0507, 0.0316, 0.0230, 0.0530, 0.0162,\n",
       "                      0.0399, 0.0300, 0.0260, 0.0180, 0.0575, 0.0558, 0.0139, 0.0345, 0.0479,\n",
       "                      0.0439, 0.0433, 0.0594, 0.0143, 0.0516, 0.0382, 0.0272, 0.0458, 0.0571,\n",
       "                      0.0213, 0.0097, 0.0636, 0.0061, 0.0382, 0.0446, 0.0236, 0.0298, 0.0299,\n",
       "                      0.0187, 0.0245, 0.0120, 0.0573, 0.0525, 0.0066, 0.0512, 0.0365, 0.0385,\n",
       "                      0.0148, 0.0195, 0.0293, 0.0480, 0.0095, 0.0386, 0.0526, 0.0390, 0.0436,\n",
       "                      0.0212, 0.0508, 0.0079, 0.0658, 0.0096, 0.0235, 0.0472, 0.0499, 0.0202,\n",
       "                      0.0344, 0.0158, 0.0291, 0.0260, 0.0242, 0.0356, 0.0235, 0.0403, 0.0225,\n",
       "                      0.0467, 0.0038, 0.0181, 0.0283, 0.0146, 0.0357, 0.0606, 0.0228, 0.0138,\n",
       "                      0.0118, 0.0479, 0.0232, 0.0420, 0.0383, 0.0477, 0.0179, 0.0311, 0.0403,\n",
       "                      0.0024, 0.0619, 0.0409, 0.0504, 0.0092, 0.0375, 0.0230, 0.0407, 0.0294,\n",
       "                      0.0302, 0.0329, 0.0122, 0.0254, 0.0161, 0.0495, 0.0476, 0.0456, 0.0169,\n",
       "                      0.0109, 0.0187])),\n",
       "             ('decisions.0.bn2.running_mean',\n",
       "              tensor([-0.1145, -0.1866, -0.1777, -0.1750, -0.1757, -0.3372, -0.1278, -0.1699,\n",
       "                      -0.0968, -0.2665, -0.1691, -0.1544, -0.2259, -0.1789, -0.0990, -0.1314,\n",
       "                      -0.1761, -0.1249, -0.1775, -0.1557, -0.2030, -0.2147, -0.1418, -0.1281,\n",
       "                      -0.1829, -0.1206, -0.1606, -0.3371, -0.2736, -0.2512, -0.2008, -0.1891,\n",
       "                      -0.1341, -0.1784, -0.1033, -0.1081, -0.1268, -0.1201, -0.1480, -0.1799,\n",
       "                      -0.1035, -0.1219, -0.2422, -0.1848, -0.1279, -0.1743, -0.1629, -0.1533,\n",
       "                      -0.1526, -0.1660, -0.1150, -0.2299, -0.3058, -0.1184, -0.1136, -0.2455,\n",
       "                      -0.1692, -0.1221, -0.1427, -0.1075, -0.1034, -0.1298, -0.1420, -0.1901,\n",
       "                      -0.1692, -0.2569, -0.1200, -0.1721, -0.3227, -0.1438, -0.1219, -0.1499,\n",
       "                      -0.1577, -0.1276, -0.1016, -0.2427, -0.1403, -0.1906, -0.1161, -0.1088,\n",
       "                      -0.1446, -0.1137, -0.1675, -0.0954, -0.2547, -0.2108, -0.3221, -0.2139,\n",
       "                      -0.1272, -0.2262, -0.0768, -0.1260, -0.1769, -0.3213, -0.1710, -0.3192,\n",
       "                      -0.1594, -0.1687, -0.1811, -0.1685, -0.1395, -0.2739, -0.3237, -0.3357,\n",
       "                      -0.1264, -0.1906, -0.2419, -0.1458, -0.1136, -0.1183, -0.1156, -0.1246,\n",
       "                      -0.1521, -0.1117, -0.1691, -0.1162, -0.2155, -0.2323, -0.2707, -0.1627,\n",
       "                      -0.1240, -0.1565, -0.1500, -0.1278, -0.1208, -0.1748, -0.1437, -0.1840])),\n",
       "             ('decisions.0.bn2.running_var',\n",
       "              tensor([0.1411, 0.1798, 0.1298, 0.1747, 0.1813, 0.1965, 0.1389, 0.2679, 0.1921,\n",
       "                      0.2341, 0.2077, 0.2249, 0.2135, 0.1699, 0.1210, 0.2100, 0.1674, 0.1188,\n",
       "                      0.1536, 0.2393, 0.2296, 0.2539, 0.2894, 0.1926, 0.1623, 0.1349, 0.1616,\n",
       "                      0.2629, 0.2237, 0.1910, 0.1559, 0.2411, 0.3219, 0.1654, 0.1809, 0.2405,\n",
       "                      0.1774, 0.1547, 0.3148, 0.1477, 0.1550, 0.1441, 0.2206, 0.2363, 0.2627,\n",
       "                      0.1500, 0.1482, 0.2756, 0.1327, 0.1924, 0.1548, 0.2177, 0.2385, 0.1172,\n",
       "                      0.1061, 0.2162, 0.1557, 0.2344, 0.1700, 0.1289, 0.1346, 0.1374, 0.1719,\n",
       "                      0.1458, 0.1831, 0.1949, 0.1810, 0.1364, 0.2684, 0.1445, 0.1251, 0.1878,\n",
       "                      0.1769, 0.1479, 0.1211, 0.2574, 0.1496, 0.1810, 0.1802, 0.1468, 0.1482,\n",
       "                      0.1438, 0.1579, 0.1082, 0.2110, 0.1666, 0.2244, 0.2092, 0.1963, 0.1901,\n",
       "                      0.1454, 0.1620, 0.1502, 0.1330, 0.1392, 0.2309, 0.3206, 0.1730, 0.1459,\n",
       "                      0.1434, 0.1856, 0.1670, 0.2610, 0.1979, 0.1512, 0.1467, 0.1600, 0.1822,\n",
       "                      0.1216, 0.3570, 0.1179, 0.2099, 0.1394, 0.1223, 0.1632, 0.1444, 0.2264,\n",
       "                      0.1987, 0.2198, 0.1498, 0.1015, 0.1806, 0.2326, 0.3340, 0.1501, 0.1452,\n",
       "                      0.1203, 0.1576])),\n",
       "             ('decisions.0.bn2.num_batches_tracked', tensor(906)),\n",
       "             ('decisions.0.dense3.weight',\n",
       "              tensor([[ 0.2164,  0.2246, -0.1245, -0.1713, -0.1699, -0.1655,  0.1663,  0.1951,\n",
       "                        0.1697, -0.1673,  0.2051,  0.1578,  0.2004, -0.1208, -0.1407,  0.1913,\n",
       "                       -0.1609,  0.1394, -0.1620,  0.1808,  0.1914, -0.1549,  0.1507,  0.1337,\n",
       "                       -0.1614,  0.1933, -0.1544, -0.1953, -0.1722, -0.1848, -0.1440,  0.1921,\n",
       "                        0.1692, -0.1416,  0.1588,  0.1639,  0.1612,  0.1591,  0.1853, -0.1344,\n",
       "                        0.1959,  0.1424, -0.1242,  0.1600,  0.1863, -0.1378, -0.1366,  0.2182,\n",
       "                       -0.1055,  0.1821,  0.1719, -0.1327, -0.1765,  0.1267,  0.0983, -0.1662,\n",
       "                       -0.1320,  0.1856,  0.1997, -0.1376,  0.1856,  0.1534,  0.1540, -0.1403,\n",
       "                       -0.1769, -0.1738,  0.1603, -0.1363, -0.1783,  0.2021,  0.1627,  0.1599,\n",
       "                       -0.1693,  0.1963, -0.1299,  0.2099, -0.1263, -0.1831,  0.1665,  0.1879,\n",
       "                       -0.1840,  0.1426, -0.1355,  0.1290, -0.1517, -0.1869, -0.1408, -0.1268,\n",
       "                        0.1372, -0.1426,  0.1779, -0.1224, -0.1396, -0.1596, -0.1291, -0.1519,\n",
       "                        0.1758, -0.1482, -0.1479, -0.1260,  0.1731, -0.1827, -0.1800, -0.1526,\n",
       "                        0.1811, -0.1455, -0.1188,  0.1535, -0.0902,  0.1821,  0.1514,  0.1837,\n",
       "                       -0.1599,  0.1485, -0.1549,  0.1367, -0.1783, -0.1627, -0.1296, -0.1275,\n",
       "                        0.1284, -0.1658,  0.1576,  0.1452,  0.1599, -0.1385, -0.1284, -0.1570]])),\n",
       "             ('decisions.0.dense3.bias', tensor([0.0688])),\n",
       "             ('decisions.1.dense1.weight',\n",
       "              tensor([[-0.0878, -0.1494, -0.0036,  ...,  0.1467,  0.0751, -0.0314],\n",
       "                      [ 0.0994, -0.0879,  0.1672,  ...,  0.0667,  0.0792, -0.0530],\n",
       "                      [ 0.0546, -0.0137, -0.0032,  ..., -0.0024,  0.1547,  0.0133],\n",
       "                      ...,\n",
       "                      [-0.0729,  0.0302, -0.0428,  ...,  0.0961, -0.0899, -0.0948],\n",
       "                      [-0.0326, -0.0482, -0.0047,  ...,  0.1198, -0.0782, -0.0547],\n",
       "                      [ 0.0063, -0.0991, -0.0211,  ...,  0.0282, -0.0644, -0.1030]])),\n",
       "             ('decisions.1.dense2.weight',\n",
       "              tensor([[ 0.0007, -0.0007,  0.0038,  ...,  0.0069, -0.0015,  0.0058],\n",
       "                      [-0.0007,  0.0173,  0.0814,  ..., -0.0483, -0.0321, -0.0185],\n",
       "                      [ 0.0002, -0.0154,  0.0773,  ..., -0.0005, -0.0024,  0.0065],\n",
       "                      ...,\n",
       "                      [ 0.0139, -0.0287, -0.0091,  ...,  0.0274, -0.0010,  0.0160],\n",
       "                      [ 0.0574,  0.0158,  0.0858,  ...,  0.0053,  0.0364,  0.0268],\n",
       "                      [ 0.0004, -0.0230,  0.0605,  ..., -0.0155,  0.0396, -0.0354]])),\n",
       "             ('decisions.1.bn1.weight',\n",
       "              tensor([0.7963, 0.8461, 0.9362, 0.8802, 0.7640, 0.8224, 0.8779, 0.8655, 0.7963,\n",
       "                      0.8689, 0.8909, 0.8273, 0.7760, 0.8822, 0.8623, 0.8911, 0.7812, 0.8900,\n",
       "                      0.8493, 0.8748, 0.7950, 0.9273, 0.9001, 0.7980, 0.7744, 0.8081, 0.8702,\n",
       "                      0.8457, 0.9156, 0.8524, 0.8228, 0.9292, 0.7680, 0.8812, 0.8911, 0.7747,\n",
       "                      0.7532, 0.8053, 0.8750, 0.8901, 0.8298, 0.8598, 0.8168, 0.8159, 0.8523,\n",
       "                      0.8597, 0.8655, 0.8430, 0.8176, 0.7933, 0.8533, 0.8070, 0.7208, 0.9059,\n",
       "                      0.8560, 0.9178, 0.8590, 0.7713, 0.8095, 0.8923, 0.7577, 0.7757, 0.7988,\n",
       "                      0.8779, 0.7824, 0.8031, 0.8595, 0.7784, 0.8940, 0.9180, 0.7508, 0.8309,\n",
       "                      0.7241, 0.7847, 0.8918, 0.8628, 0.8887, 0.8924, 0.8754, 0.8666, 0.8914,\n",
       "                      0.8431, 0.7168, 0.9137, 0.8198, 0.8097, 0.7902, 0.8767, 0.7663, 0.8421,\n",
       "                      0.8489, 0.8944, 0.9055, 0.8050, 0.7805, 0.8617, 0.8806, 0.7767, 0.7879,\n",
       "                      0.8412, 0.8601, 0.8829, 0.9227, 0.8600, 0.7576, 0.8291, 0.8187, 0.8660,\n",
       "                      0.8084, 0.7739, 0.8591, 0.9029, 0.8367, 0.8294, 0.8981, 0.8488, 0.7978,\n",
       "                      0.7735, 0.8529, 0.7506, 0.7693, 0.9086, 0.8247, 0.7429, 0.8476, 0.8102,\n",
       "                      0.7360, 0.7706])),\n",
       "             ('decisions.1.bn1.bias',\n",
       "              tensor([-9.5894e-03, -9.9580e-03,  3.4796e-02,  4.2350e-04, -1.1542e-02,\n",
       "                      -8.1127e-03, -7.4680e-04,  2.5258e-02, -3.1353e-03, -8.0506e-03,\n",
       "                       6.8430e-05, -1.1526e-02, -1.6306e-02, -4.5194e-03, -1.4509e-02,\n",
       "                       1.9371e-02, -6.0176e-02,  4.9566e-02, -7.6565e-04,  9.9638e-03,\n",
       "                      -4.2582e-02,  7.2912e-03,  4.1305e-03, -1.7228e-02, -4.2180e-02,\n",
       "                      -5.2554e-04, -2.1828e-02,  1.8717e-02,  1.1714e-02, -1.3298e-02,\n",
       "                       2.0737e-02,  4.4494e-02, -8.4349e-04, -1.3470e-02,  7.1663e-04,\n",
       "                      -2.6213e-02, -2.5567e-02,  4.7916e-03, -2.1129e-02,  3.1044e-02,\n",
       "                       7.3963e-03,  3.3311e-02, -4.2498e-04,  2.3969e-02,  9.2003e-03,\n",
       "                       2.9839e-02,  2.3946e-02, -1.5142e-03, -5.4716e-04, -3.5087e-02,\n",
       "                       6.7780e-04,  6.9422e-04, -4.3929e-02,  5.8632e-03,  8.0739e-03,\n",
       "                       4.3537e-02,  1.4052e-02, -1.3524e-02, -1.7720e-03,  4.4012e-02,\n",
       "                      -1.3362e-02, -2.5931e-04, -2.2299e-03,  2.2526e-02, -2.1873e-02,\n",
       "                      -3.0341e-02,  1.6917e-02, -4.1977e-02,  1.8636e-02,  1.4870e-03,\n",
       "                      -2.9052e-02, -1.6417e-02, -3.7133e-02, -1.9030e-02,  4.1211e-02,\n",
       "                      -4.0220e-03,  1.3254e-02,  3.2097e-03,  7.0957e-03, -4.5349e-04,\n",
       "                       6.0835e-03, -2.7311e-02, -5.0059e-02,  7.2656e-03,  1.0849e-03,\n",
       "                      -4.0685e-02, -8.7889e-03,  2.9438e-05, -2.7117e-02,  9.7759e-03,\n",
       "                      -3.3217e-02, -4.7717e-03,  1.6023e-02, -1.3925e-02, -1.2206e-03,\n",
       "                      -6.0513e-05, -8.6308e-03, -3.8249e-02, -2.0569e-04, -9.3871e-03,\n",
       "                       2.1034e-02, -9.7438e-03,  2.0381e-04,  2.1654e-03, -2.3664e-02,\n",
       "                      -7.2791e-04, -3.2134e-02,  2.5733e-02, -1.0427e-03, -1.8069e-02,\n",
       "                      -5.2071e-04,  6.1338e-02, -1.6993e-02, -2.6778e-02,  2.5340e-02,\n",
       "                      -2.2438e-02, -1.5520e-04, -2.4741e-02,  3.3239e-03, -6.7079e-03,\n",
       "                      -3.9801e-02,  3.6002e-02,  2.2529e-02, -2.0329e-02, -1.3457e-02,\n",
       "                      -5.3887e-03, -3.1841e-02,  1.3841e-02])),\n",
       "             ('decisions.1.bn1.running_mean',\n",
       "              tensor([ 0.0592, -0.1126, -0.1234, -0.0118, -0.0463, -0.0449, -0.0183, -0.2991,\n",
       "                       0.4958,  0.1248, -0.3470, -0.0126,  0.1795, -0.1894, -0.1157,  0.1710,\n",
       "                      -0.0254, -0.4479,  0.1246, -0.2921,  0.1210, -0.0615,  0.2597, -0.2068,\n",
       "                      -0.1447,  0.2494, -0.2139,  0.2830,  0.0762,  0.4560, -0.2395, -0.1293,\n",
       "                       0.2939,  0.4122,  0.0609, -0.0779, -0.0500,  0.0237, -0.1108, -0.2972,\n",
       "                       0.1873,  0.2379,  0.3462, -0.0722, -0.2826,  0.2517,  0.2595,  0.0589,\n",
       "                       0.0391, -0.0675,  0.1990,  0.0892,  0.0679, -0.1399,  0.0243, -0.3560,\n",
       "                       0.2780, -0.0347, -0.1149, -0.2254, -0.0194,  0.3277, -0.0141,  0.0027,\n",
       "                      -0.0839,  0.2739,  0.0987, -0.2207, -0.0909, -0.1152, -0.1454,  0.1636,\n",
       "                       0.0737,  0.0930, -0.2471,  0.1525, -0.3763, -0.1992,  0.4365,  0.5659,\n",
       "                       0.0903, -0.2028,  0.1255, -0.0350,  0.1471,  0.1623,  0.2084, -0.1216,\n",
       "                       0.1537,  0.2557,  0.0767, -0.3162,  0.2037, -0.0926,  0.1541, -0.3464,\n",
       "                       0.1783, -0.1060,  0.1160, -0.0417, -0.4700, -0.3350, -0.0598,  0.1750,\n",
       "                      -0.1771,  0.1197, -0.2229,  0.0107,  0.2041,  0.1243, -0.2802, -0.1856,\n",
       "                       0.0299,  0.2054,  0.4168, -0.0025,  0.4334,  0.2904,  0.2283,  0.4404,\n",
       "                      -0.1945, -0.4220,  0.1589,  0.0911, -0.3445, -0.0036,  0.3411,  0.0480])),\n",
       "             ('decisions.1.bn1.running_var',\n",
       "              tensor([0.1136, 0.1217, 0.1509, 0.2852, 0.1087, 0.2604, 0.1177, 0.1235, 0.4229,\n",
       "                      0.2422, 0.3699, 0.1500, 0.3189, 0.1422, 0.1037, 0.1933, 0.0784, 0.6013,\n",
       "                      0.1023, 0.3443, 0.0961, 0.1554, 0.5026, 0.3938, 0.1160, 0.2199, 0.4553,\n",
       "                      0.2956, 0.2707, 1.0047, 0.2287, 0.1721, 0.6031, 0.4173, 0.0798, 0.1133,\n",
       "                      0.1336, 0.1080, 0.1477, 0.1946, 0.1402, 0.5966, 0.3571, 0.1110, 0.5630,\n",
       "                      0.3300, 0.2536, 0.1115, 0.1043, 0.2471, 0.1096, 0.1555, 0.0622, 0.1131,\n",
       "                      0.0866, 0.6845, 0.3540, 0.1973, 0.1605, 0.2830, 0.1239, 0.3401, 0.0841,\n",
       "                      0.0924, 0.0793, 0.2884, 0.1129, 0.2471, 0.2013, 0.1747, 0.2138, 0.1098,\n",
       "                      0.0707, 0.1258, 0.4130, 0.1193, 0.4070, 0.2788, 0.2693, 0.4340, 0.1936,\n",
       "                      0.1746, 0.1237, 0.1130, 0.3101, 0.0890, 0.2019, 0.1629, 0.2237, 0.1422,\n",
       "                      0.1594, 0.3444, 0.2611, 0.0797, 0.1256, 0.4737, 0.2175, 0.0838, 0.1954,\n",
       "                      0.1695, 0.4176, 0.1671, 0.1302, 0.1037, 0.2894, 0.1508, 0.0778, 0.1039,\n",
       "                      0.3727, 0.2343, 0.1758, 0.1417, 0.0946, 0.4144, 0.3400, 0.1014, 0.7825,\n",
       "                      0.2021, 0.1660, 0.8186, 0.0856, 0.1738, 0.2152, 0.1673, 0.8038, 0.1349,\n",
       "                      0.0994, 0.0950])),\n",
       "             ('decisions.1.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.1.bn2.weight',\n",
       "              tensor([0.7022, 0.8125, 0.7276, 0.7135, 0.7132, 0.7992, 0.7330, 0.7318, 0.7644,\n",
       "                      0.7556, 0.8228, 0.7908, 0.8526, 0.8369, 0.7708, 0.7086, 0.7895, 0.7764,\n",
       "                      0.7651, 0.8346, 0.7336, 0.7519, 0.7051, 0.7565, 0.8315, 0.8176, 0.8035,\n",
       "                      0.8373, 0.8129, 0.7179, 0.7958, 0.8324, 0.8377, 0.7043, 0.7403, 0.8015,\n",
       "                      0.8176, 0.7647, 0.7490, 0.7080, 0.8080, 0.8768, 0.7727, 0.8078, 0.8336,\n",
       "                      0.8059, 0.7528, 0.7168, 0.7820, 0.7241, 0.7940, 0.8008, 0.8281, 0.8161,\n",
       "                      0.8180, 0.7887, 0.8576, 0.7277, 0.8045, 0.8530, 0.8256, 0.7652, 0.7781,\n",
       "                      0.7161, 0.7672, 0.7663, 0.8093, 0.8508, 0.7130, 0.7198, 0.7607, 0.7061,\n",
       "                      0.7434, 0.7021, 0.8499, 0.7825, 0.8305, 0.7305, 0.8416, 0.7720, 0.8329,\n",
       "                      0.8031, 0.7472, 0.8435, 0.7744, 0.8405, 0.7451, 0.8344, 0.8455, 0.7849,\n",
       "                      0.7428, 0.8415, 0.8286, 0.7035, 0.7027, 0.7819, 0.7646, 0.8042, 0.7989,\n",
       "                      0.8192, 0.7511, 0.7922, 0.8220, 0.8627, 0.8296, 0.8102, 0.7766, 0.8169,\n",
       "                      0.7776, 0.7352, 0.8082, 0.8491, 0.8433, 0.8086, 0.7576, 0.7185, 0.7742,\n",
       "                      0.7649, 0.7928, 0.7123, 0.7509, 0.7454, 0.7863, 0.8449, 0.8066, 0.7365,\n",
       "                      0.7906, 0.7745])),\n",
       "             ('decisions.1.bn2.bias',\n",
       "              tensor([-1.6926e-02, -3.5217e-02, -3.8614e-02, -3.4545e-02, -1.2086e-02,\n",
       "                      -3.1122e-02, -1.1181e-05, -1.0112e-02, -3.9460e-02, -3.4359e-02,\n",
       "                       5.2803e-03, -2.2081e-02, -2.3115e-02, -3.0551e-02, -3.0407e-02,\n",
       "                      -1.0442e-02, -5.2690e-02,  2.3712e-03,  1.8214e-03, -2.8559e-02,\n",
       "                       7.7026e-04, -5.0912e-03, -1.5670e-02, -7.7258e-04,  5.6587e-03,\n",
       "                       4.0975e-03, -2.4875e-02,  2.1092e-03,  9.9335e-05, -3.8530e-04,\n",
       "                      -1.8249e-02, -1.6388e-02, -2.7243e-02, -1.9450e-02, -7.0481e-03,\n",
       "                      -5.9091e-02,  1.5689e-02, -2.7098e-02, -4.2501e-03, -2.1679e-02,\n",
       "                      -2.7582e-02, -1.9433e-02,  1.1311e-02,  1.4222e-02, -2.5582e-02,\n",
       "                       8.1461e-04, -5.5270e-04, -3.2899e-02,  1.8246e-03, -3.2850e-02,\n",
       "                       4.1424e-03,  2.2415e-03,  5.0425e-04, -6.0730e-04, -3.4528e-02,\n",
       "                      -2.7023e-02, -1.8876e-02,  7.7252e-04, -2.2381e-02, -1.9524e-02,\n",
       "                      -3.1092e-02, -6.7070e-04, -2.8760e-02, -3.2396e-03, -7.4810e-04,\n",
       "                      -1.2309e-02,  1.2760e-03, -3.3790e-02, -1.0567e-02, -2.4146e-02,\n",
       "                      -4.2837e-02, -1.2716e-02, -3.3801e-02, -1.2911e-02, -3.2159e-02,\n",
       "                      -1.1144e-03,  7.2670e-03, -3.3506e-03, -2.2980e-02,  8.8715e-04,\n",
       "                       5.5975e-03,  1.9947e-03, -1.2452e-02,  5.8127e-03,  8.1863e-04,\n",
       "                       4.0696e-03, -3.8305e-02,  2.1382e-02,  1.4697e-02, -3.0222e-02,\n",
       "                      -6.9592e-04,  1.7028e-03,  2.6528e-04, -5.4555e-03, -1.2439e-02,\n",
       "                      -3.4702e-02, -4.1890e-02, -1.6217e-02, -3.8578e-02,  1.1300e-03,\n",
       "                      -8.0309e-03, -1.1244e-02,  1.5688e-02, -3.9235e-02,  6.3514e-04,\n",
       "                      -4.2901e-03,  5.4216e-05, -3.4183e-02, -1.8186e-03, -3.9856e-02,\n",
       "                       5.4678e-04, -3.8631e-02, -4.1648e-02, -2.8035e-02,  6.3132e-03,\n",
       "                       7.7306e-04, -2.5306e-04, -2.6912e-02, -3.0802e-02, -2.8525e-02,\n",
       "                      -3.6502e-02, -4.4863e-03,  5.5251e-03, -3.9279e-02, -3.2685e-02,\n",
       "                      -1.0684e-02, -2.8596e-02, -3.4237e-02])),\n",
       "             ('decisions.1.bn2.running_mean',\n",
       "              tensor([-0.0305,  0.1843,  0.2700,  0.1378, -0.0685,  0.0702, -0.2486,  0.0252,\n",
       "                       0.2040,  0.0946, -0.0061,  0.3240,  0.1704,  0.2663,  0.2779, -0.0809,\n",
       "                      -0.1428, -0.1635, -0.1851,  0.1885, -0.0370,  0.0638,  0.1418, -0.3122,\n",
       "                      -0.3766, -0.2853,  0.2903, -0.0408, -0.1305, -0.0729,  0.2847,  0.2043,\n",
       "                       0.2147,  0.1631,  0.0398,  0.2277, -0.3696,  0.2715, -0.0159,  0.1183,\n",
       "                       0.3836,  0.2582, -0.0997, -0.3920,  0.3088, -0.1554, -0.0383,  0.1628,\n",
       "                       0.0371,  0.1502, -0.1906, -0.1904, -0.0871, -0.1037,  0.3698,  0.2619,\n",
       "                       0.1053, -0.1008,  0.3696,  0.1557,  0.2514, -0.0900,  0.1175, -0.1795,\n",
       "                      -0.2914,  0.1611, -0.2038,  0.1033,  0.1821,  0.1615,  0.2920, -0.0849,\n",
       "                       0.2199,  0.0754,  0.2817, -0.2670, -0.3878, -0.1159,  0.1478, -0.1634,\n",
       "                      -0.0287, -0.0825,  0.0884, -0.0706, -0.1584, -0.2541,  0.1442, -0.0824,\n",
       "                      -0.2710,  0.0445, -0.2265, -0.2244, -0.1374,  0.0223,  0.0862,  0.3285,\n",
       "                       0.1859,  0.3549,  0.1370, -0.1500, -0.0289, -0.1005, -0.2380,  0.3479,\n",
       "                      -0.1139, -0.1224, -0.3299,  0.4171, -0.1166,  0.2216, -0.1421,  0.3455,\n",
       "                       0.1836,  0.2467, -0.1624, -0.1340, -0.2128,  0.1224,  0.1595,  0.1126,\n",
       "                       0.2970, -0.0300, -0.0624,  0.1918,  0.1794, -0.0305,  0.0758,  0.2057])),\n",
       "             ('decisions.1.bn2.running_var',\n",
       "              tensor([0.1777, 0.6715, 0.1068, 0.3331, 0.3054, 0.5583, 0.3827, 0.5492, 0.4234,\n",
       "                      0.6628, 0.9215, 0.6694, 0.3990, 0.5013, 0.2250, 0.2932, 0.8731, 0.7173,\n",
       "                      0.6955, 0.7097, 0.4542, 0.6098, 0.1550, 0.2924, 0.5077, 0.6639, 0.4044,\n",
       "                      0.9925, 0.9467, 0.4378, 0.5113, 0.6514, 0.8600, 0.1911, 0.5030, 0.7541,\n",
       "                      0.5627, 0.3510, 0.6201, 0.2879, 0.2959, 0.5852, 0.4317, 0.5283, 0.3745,\n",
       "                      0.8722, 0.6361, 0.2503, 0.5268, 0.3873, 0.7134, 0.7848, 1.0770, 0.7398,\n",
       "                      0.5948, 0.6018, 0.4845, 0.3596, 0.7069, 0.6378, 0.6254, 0.6464, 0.3223,\n",
       "                      0.2032, 0.3799, 0.2931, 0.8458, 0.5256, 0.1948, 0.2775, 0.4414, 0.2467,\n",
       "                      0.2963, 0.1368, 0.4580, 0.8735, 0.8399, 0.4918, 0.5000, 0.4796, 1.1573,\n",
       "                      0.6585, 0.6978, 0.9657, 0.7429, 1.1321, 0.5073, 0.5372, 0.9293, 0.5729,\n",
       "                      0.5775, 0.7575, 0.8175, 0.2262, 0.1036, 0.5101, 0.3345, 0.3804, 0.4155,\n",
       "                      0.7566, 0.6747, 0.7296, 0.8797, 0.2395, 0.8856, 1.0416, 0.7474, 0.5017,\n",
       "                      0.7845, 0.1010, 0.8718, 0.2561, 0.2951, 0.3895, 0.6004, 0.4161, 0.5791,\n",
       "                      0.5976, 0.5645, 0.1597, 0.3970, 0.7021, 0.7666, 0.5253, 0.6513, 0.5351,\n",
       "                      0.2584, 0.5020])),\n",
       "             ('decisions.1.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.1.dense3.weight',\n",
       "              tensor([[-4.0566e-04, -6.8337e-02, -1.7487e-02, -5.2027e-03,  1.0181e-02,\n",
       "                       -4.6401e-02,  1.5110e-02,  2.4624e-02, -3.4231e-02, -2.1037e-02,\n",
       "                        8.0405e-02, -5.3971e-02, -9.9431e-02, -6.9484e-02, -3.7334e-02,\n",
       "                        5.1995e-03, -4.0349e-02,  4.2597e-02,  3.7298e-02, -8.3830e-02,\n",
       "                        1.4966e-02,  3.0084e-02, -1.1704e-04,  2.3522e-02,  7.4429e-02,\n",
       "                        4.7387e-02, -4.7790e-02,  9.1052e-02,  7.6109e-02,  1.0459e-02,\n",
       "                       -5.6189e-02, -7.2931e-02, -8.8799e-02,  4.9927e-04,  2.3813e-02,\n",
       "                       -5.7031e-02,  7.1430e-02, -3.0838e-02,  3.2023e-02, -7.4975e-04,\n",
       "                       -6.5612e-02, -1.1901e-01,  3.3111e-02,  5.3000e-02, -8.2192e-02,\n",
       "                        6.3417e-02,  3.0102e-02, -8.4321e-03,  4.7600e-02, -1.2862e-02,\n",
       "                        5.8911e-02,  6.2081e-02,  7.3701e-02,  7.3160e-02, -7.3691e-02,\n",
       "                       -4.9473e-02, -1.0449e-01,  1.0200e-02, -6.1544e-02, -1.0678e-01,\n",
       "                       -8.1298e-02,  3.5495e-02, -3.1613e-02,  8.7758e-03,  2.7002e-02,\n",
       "                       -3.2587e-02,  6.5690e-02, -9.2444e-02, -3.4948e-03, -1.0302e-02,\n",
       "                       -2.9680e-02,  8.7477e-04, -1.9857e-02,  7.5418e-04, -8.8434e-02,\n",
       "                        5.6280e-02,  7.8984e-02,  1.9791e-02, -9.1017e-02,  3.3234e-02,\n",
       "                        9.0084e-02,  7.1371e-02,  3.0435e-02,  9.5265e-02,  4.0487e-02,\n",
       "                        9.5711e-02, -1.4411e-02,  6.5437e-02,  9.9509e-02, -4.0621e-02,\n",
       "                        2.2978e-02,  9.1656e-02,  7.1400e-02, -7.4753e-04,  4.3384e-04,\n",
       "                       -4.9473e-02, -2.6454e-02, -5.6630e-02, -5.0826e-02,  7.4688e-02,\n",
       "                        3.4157e-02,  6.6502e-02,  6.8746e-02, -9.8367e-02,  7.8556e-02,\n",
       "                        7.6603e-02,  4.2079e-02, -7.1959e-02,  4.4773e-02, -2.1066e-02,\n",
       "                        7.0525e-02, -6.3119e-02, -5.7443e-02, -5.9220e-02,  3.5221e-02,\n",
       "                        1.0445e-02,  3.7565e-02, -3.3807e-02, -4.4763e-02, -4.7831e-03,\n",
       "                       -2.8330e-02,  2.9577e-02,  4.2398e-02, -9.0508e-02, -5.5221e-02,\n",
       "                        2.7638e-02, -4.9568e-02, -4.5844e-02]])),\n",
       "             ('decisions.1.dense3.bias', tensor([0.0676])),\n",
       "             ('decisions.2.dense1.weight',\n",
       "              tensor([[-0.0012, -0.0439, -0.0114,  ..., -0.0136,  0.0665,  0.0176],\n",
       "                      [ 0.0497,  0.0671,  0.1559,  ..., -0.1454,  0.0192, -0.0881],\n",
       "                      [ 0.1060, -0.0764, -0.1741,  ..., -0.0190,  0.1000,  0.1158],\n",
       "                      ...,\n",
       "                      [ 0.0653, -0.0210, -0.2333,  ..., -0.0007, -0.0196, -0.0105],\n",
       "                      [ 0.0183,  0.0825,  0.0290,  ..., -0.0033, -0.0090,  0.0756],\n",
       "                      [-0.0634,  0.0949, -0.0262,  ...,  0.0470,  0.0047,  0.0952]])),\n",
       "             ('decisions.2.dense2.weight',\n",
       "              tensor([[ 0.0125,  0.0199, -0.0534,  ...,  0.0291,  0.0169,  0.0328],\n",
       "                      [ 0.0324, -0.0085,  0.0336,  ...,  0.0124, -0.0148,  0.0197],\n",
       "                      [ 0.0069,  0.0299, -0.0181,  ..., -0.0593, -0.0269,  0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0203, -0.0225,  0.0173,  ...,  0.0291,  0.0002,  0.0372],\n",
       "                      [ 0.0546,  0.0150,  0.0244,  ..., -0.0131, -0.0162, -0.0051],\n",
       "                      [ 0.0485,  0.0185, -0.0073,  ..., -0.0265, -0.0237,  0.0005]])),\n",
       "             ('decisions.2.bn1.weight',\n",
       "              tensor([0.8181, 0.8529, 0.8518, 0.7346, 0.7392, 0.7790, 0.8270, 0.7243, 0.8485,\n",
       "                      0.7350, 0.8133, 0.7229, 0.8804, 0.8539, 0.8023, 0.8145, 0.7972, 0.8906,\n",
       "                      0.8354, 0.7819, 0.8084, 0.8037, 0.8225, 0.8580, 0.7322, 0.7364, 0.8308,\n",
       "                      0.8535, 0.7691, 0.8522, 0.7384, 0.7586, 0.8145, 0.8500, 0.8448, 0.8299,\n",
       "                      0.8410, 0.7947, 0.7691, 0.7437, 0.8336, 0.8329, 0.7155, 0.8567, 0.7202,\n",
       "                      0.7386, 0.7798, 0.7893, 0.8887, 0.7462, 0.7651, 0.8279, 0.7993, 0.8576,\n",
       "                      0.7600, 0.7798, 0.8547, 0.8292, 0.8183, 0.7780, 0.8190, 0.8332, 0.8112,\n",
       "                      0.7520, 0.7321, 0.8327, 0.7515, 0.7310, 0.7426, 0.7794, 0.8465, 0.8269,\n",
       "                      0.7855, 0.8409, 0.8733, 0.8451, 0.8229, 0.7331, 0.8718, 0.8072, 0.7951,\n",
       "                      0.7381, 0.7420, 0.8577, 0.8534, 0.8343, 0.7959, 0.8289, 0.7405, 0.8518,\n",
       "                      0.8526, 0.8011, 0.7667, 0.8195, 0.7321, 0.8359, 0.7570, 0.7083, 0.8199,\n",
       "                      0.8681, 0.8478, 0.8615, 0.7405, 0.8347, 0.8390, 0.8020, 0.7436, 0.8563,\n",
       "                      0.7694, 0.7323, 0.8793, 0.7327, 0.7815, 0.7562, 0.7950, 0.8679, 0.7778,\n",
       "                      0.7209, 0.8134, 0.8156, 0.7518, 0.8510, 0.8258, 0.7224, 0.7956, 0.8461,\n",
       "                      0.7393, 0.8022])),\n",
       "             ('decisions.2.bn1.bias',\n",
       "              tensor([-0.0032,  0.0244,  0.0157, -0.0010, -0.0246, -0.0085,  0.0537, -0.0139,\n",
       "                       0.0111, -0.0420,  0.0151, -0.0321,  0.0097,  0.0252,  0.0025,  0.0019,\n",
       "                       0.0035,  0.0500, -0.0009, -0.0209, -0.0209, -0.0094,  0.0086,  0.0310,\n",
       "                      -0.0285, -0.0091,  0.0210, -0.0051, -0.0288,  0.0373, -0.0538, -0.0022,\n",
       "                       0.0121, -0.0168, -0.0142,  0.0101,  0.0262,  0.0060, -0.0002, -0.0274,\n",
       "                      -0.0091, -0.0005, -0.0278,  0.0523, -0.0231, -0.0093, -0.0319, -0.0015,\n",
       "                       0.0333, -0.0229, -0.0070,  0.0294,  0.0007,  0.0141, -0.0117,  0.0123,\n",
       "                       0.0109, -0.0005,  0.0279, -0.0025,  0.0238,  0.0216, -0.0061, -0.0223,\n",
       "                      -0.0354,  0.0376, -0.0160, -0.0268, -0.0290,  0.0179,  0.0032, -0.0019,\n",
       "                      -0.0171,  0.0338,  0.0030,  0.0204,  0.0180, -0.0119,  0.0179,  0.0051,\n",
       "                      -0.0008, -0.0472, -0.0195,  0.0132,  0.0155,  0.0008,  0.0074,  0.0002,\n",
       "                       0.0013,  0.0196,  0.0001,  0.0243, -0.0240,  0.0231, -0.0369,  0.0151,\n",
       "                      -0.0407, -0.0200,  0.0219, -0.0005,  0.0045,  0.0209, -0.0098,  0.0554,\n",
       "                       0.0428, -0.0063, -0.0382,  0.0195, -0.0194, -0.0435, -0.0008, -0.0392,\n",
       "                       0.0247, -0.0103,  0.0040,  0.0318, -0.0054, -0.0283,  0.0185,  0.0116,\n",
       "                       0.0007, -0.0003,  0.0149, -0.0493, -0.0004,  0.0440,  0.0006,  0.0020])),\n",
       "             ('decisions.2.bn1.running_mean',\n",
       "              tensor([-0.1074,  0.5498, -0.2166,  0.0234, -0.4607, -0.1799,  0.2445,  0.2156,\n",
       "                      -0.3232,  0.1556,  0.4648,  0.0353, -0.0623, -0.0712,  0.4304, -0.0383,\n",
       "                      -0.0250,  0.1664, -0.1145, -0.4529,  0.2077,  0.4762, -0.4617, -0.2360,\n",
       "                       0.2140, -0.3918,  0.1163,  0.1498, -0.0333, -0.2563, -0.1024,  0.1711,\n",
       "                       0.1603,  0.0621,  0.0267, -0.4587,  0.0723,  0.6385, -0.3779, -0.2250,\n",
       "                      -0.4908, -0.2571,  0.1275, -0.4034,  0.3498, -0.5053, -0.0021,  0.0652,\n",
       "                      -0.0904,  0.3936, -0.0683,  0.3482,  0.0027,  0.4881,  0.2985,  0.4958,\n",
       "                       0.1164, -0.1608,  0.1690,  0.2908,  0.2589, -0.0578,  0.0947,  0.4120,\n",
       "                      -0.1158, -0.1081,  0.3681, -0.2970,  0.4526,  0.4842, -0.0724, -0.0413,\n",
       "                      -0.1442,  0.1494, -0.0929, -0.3792, -0.1708,  0.2060, -0.2969,  0.0594,\n",
       "                      -0.4452, -0.2516,  0.2835, -0.2083,  0.4391, -0.3651, -0.5466,  0.6291,\n",
       "                       0.0801, -0.3624, -0.4598,  0.1774, -0.0959,  0.1176,  0.0287, -0.2521,\n",
       "                      -0.4042,  0.0093,  0.5871, -0.0560, -0.0470, -0.2201,  0.2548,  0.2254,\n",
       "                       0.3818, -0.4445,  0.0051,  0.0316, -0.1332, -0.2440,  0.1139,  0.1660,\n",
       "                       0.5447, -0.3604,  0.3028,  0.0575,  0.5649,  0.2859, -0.3647, -0.0789,\n",
       "                       0.4288,  0.0403,  0.1547,  0.3800,  0.1505, -0.4331,  0.2286, -0.4409])),\n",
       "             ('decisions.2.bn1.running_var',\n",
       "              tensor([0.1461, 0.6582, 0.3672, 0.0595, 0.4161, 0.1781, 0.3442, 0.1407, 0.2302,\n",
       "                      0.0779, 0.4787, 0.0462, 0.1691, 0.1310, 0.3135, 0.1146, 0.1004, 0.3098,\n",
       "                      0.0904, 0.3818, 0.1872, 0.5176, 0.3297, 0.2094, 0.1276, 0.2232, 0.1632,\n",
       "                      0.0691, 0.0774, 0.2919, 0.0894, 0.0963, 0.1870, 0.1342, 0.1672, 0.2636,\n",
       "                      0.1529, 0.8286, 0.2557, 0.1205, 0.5053, 0.2828, 0.1033, 0.5801, 0.1704,\n",
       "                      0.5754, 0.0679, 0.0960, 0.2132, 0.2619, 0.0548, 0.3165, 0.1016, 0.5867,\n",
       "                      0.1710, 0.2738, 0.1192, 0.0863, 0.1622, 0.2224, 0.3023, 0.1872, 0.0983,\n",
       "                      0.4162, 0.0611, 0.1520, 0.2291, 0.1224, 0.3574, 0.4701, 0.1990, 0.1160,\n",
       "                      0.1153, 0.1841, 0.1546, 0.2546, 0.1819, 0.1261, 0.3471, 0.1246, 0.3822,\n",
       "                      0.0884, 0.1528, 0.3349, 0.4537, 0.3177, 0.3345, 0.5220, 0.1061, 0.4004,\n",
       "                      0.5638, 0.1546, 0.0720, 0.1619, 0.0583, 0.2233, 0.5068, 0.0576, 0.4300,\n",
       "                      0.0937, 0.1531, 0.3183, 0.1489, 0.2614, 0.3548, 0.3730, 0.0705, 0.1361,\n",
       "                      0.1420, 0.1586, 0.1234, 0.0806, 0.5069, 0.1361, 0.2980, 0.1640, 0.6144,\n",
       "                      0.1861, 0.2773, 0.1837, 0.3587, 0.1515, 0.1487, 0.2042, 0.1774, 0.4348,\n",
       "                      0.0950, 0.4701])),\n",
       "             ('decisions.2.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.2.bn2.weight',\n",
       "              tensor([0.7603, 0.7123, 0.7416, 0.7481, 0.7953, 0.7136, 0.7959, 0.7993, 0.7576,\n",
       "                      0.7741, 0.7589, 0.7433, 0.7705, 0.7061, 0.7308, 0.7232, 0.7691, 0.7474,\n",
       "                      0.7298, 0.7647, 0.7607, 0.7749, 0.7448, 0.7649, 0.7560, 0.7770, 0.7470,\n",
       "                      0.7174, 0.7255, 0.7235, 0.7878, 0.7626, 0.7325, 0.8010, 0.7101, 0.7107,\n",
       "                      0.7236, 0.7275, 0.8009, 0.7501, 0.7739, 0.7056, 0.7686, 0.7524, 0.7480,\n",
       "                      0.7540, 0.7154, 0.7216, 0.7547, 0.7340, 0.7148, 0.7904, 0.7197, 0.7670,\n",
       "                      0.7511, 0.7782, 0.7379, 0.7907, 0.7793, 0.7435, 0.7475, 0.7497, 0.7520,\n",
       "                      0.7781, 0.7433, 0.7910, 0.7810, 0.7312, 0.7305, 0.7486, 0.7304, 0.7356,\n",
       "                      0.7240, 0.7650, 0.7766, 0.7404, 0.7576, 0.7756, 0.7651, 0.7767, 0.7735,\n",
       "                      0.7312, 0.7287, 0.7233, 0.7093, 0.7169, 0.8019, 0.7463, 0.7298, 0.7694,\n",
       "                      0.7790, 0.7906, 0.7512, 0.7217, 0.7772, 0.7167, 0.7895, 0.7211, 0.7853,\n",
       "                      0.8044, 0.7955, 0.7607, 0.7853, 0.7714, 0.7707, 0.7652, 0.7767, 0.7479,\n",
       "                      0.7347, 0.7582, 0.8036, 0.7756, 0.7563, 0.7292, 0.7474, 0.7271, 0.7175,\n",
       "                      0.7111, 0.7987, 0.7633, 0.7038, 0.7584, 0.7064, 0.7553, 0.7401, 0.7249,\n",
       "                      0.7842, 0.8055])),\n",
       "             ('decisions.2.bn2.bias',\n",
       "              tensor([ 1.0860e-02, -2.0994e-02,  6.1917e-04, -2.8900e-02, -1.8374e-02,\n",
       "                      -1.1756e-02, -9.8359e-03, -1.2401e-02, -5.2944e-03,  4.3106e-03,\n",
       "                      -2.2949e-02, -5.2987e-03, -6.0830e-03, -6.5958e-03, -1.2199e-02,\n",
       "                       7.0892e-04, -2.6292e-03, -3.5510e-02, -7.6950e-04,  6.5233e-04,\n",
       "                      -2.4262e-02,  1.1423e-02,  1.1554e-03, -1.7365e-02,  8.9638e-03,\n",
       "                      -3.3117e-03, -8.3810e-03, -1.5764e-02, -2.2400e-02, -1.3647e-02,\n",
       "                      -1.4759e-02, -6.7027e-03, -5.4027e-05,  7.0574e-03, -1.6086e-02,\n",
       "                      -1.4389e-02, -9.6574e-03, -3.4321e-02, -1.8643e-02,  1.3388e-02,\n",
       "                      -1.7782e-02, -1.9197e-02, -2.3320e-02, -2.5164e-03, -6.6835e-04,\n",
       "                      -5.5911e-04, -1.3643e-02, -2.6591e-02, -3.4144e-02, -2.4956e-02,\n",
       "                      -1.6476e-02,  2.9405e-03, -2.0697e-02,  1.0940e-02,  1.0253e-02,\n",
       "                      -1.9207e-02, -1.2417e-02, -2.5823e-02,  1.6475e-02, -2.1491e-02,\n",
       "                      -5.7055e-03, -1.8079e-02, -2.1539e-03,  5.6692e-04, -2.4203e-03,\n",
       "                      -1.5988e-03, -1.0825e-02, -1.4456e-02, -7.1898e-03, -1.3265e-02,\n",
       "                      -1.4374e-02, -1.5283e-02, -9.6151e-03, -1.5162e-02, -1.8354e-02,\n",
       "                       5.9227e-03, -9.5920e-03,  2.0918e-03, -2.1823e-02, -1.1962e-02,\n",
       "                      -2.3827e-04, -6.8887e-03,  5.3441e-03, -2.4249e-02, -2.6791e-02,\n",
       "                      -2.7579e-02, -1.0488e-02, -2.6473e-02, -1.9142e-02,  1.0466e-02,\n",
       "                      -2.1130e-02, -1.0969e-02,  5.4896e-05, -6.3772e-03,  3.8331e-03,\n",
       "                      -3.2684e-02, -3.5841e-04, -2.2784e-02, -4.3987e-03,  5.3277e-04,\n",
       "                      -5.7636e-03,  7.8680e-03, -2.9409e-04,  1.8614e-03, -9.9420e-03,\n",
       "                       3.7103e-03, -2.1398e-02, -8.3180e-03, -2.4118e-02, -7.5561e-03,\n",
       "                       7.0419e-03,  9.7031e-03, -5.9354e-05,  5.9631e-04,  1.0377e-04,\n",
       "                       1.0708e-04, -1.1874e-02, -1.6208e-02,  1.1810e-02,  7.7326e-04,\n",
       "                      -6.0461e-03,  1.0330e-02, -1.8959e-02,  1.1575e-02, -1.8464e-03,\n",
       "                      -2.5871e-02, -1.1463e-02, -2.3100e-02])),\n",
       "             ('decisions.2.bn2.running_mean',\n",
       "              tensor([-0.2079,  0.2288, -0.2022,  0.3493,  0.1658,  0.0037,  0.2410,  0.3393,\n",
       "                       0.0994,  0.1299,  0.4415,  0.1283, -0.0352,  0.0043,  0.2793, -0.0653,\n",
       "                       0.0639,  0.2757,  0.0831,  0.1259,  0.2030, -0.2087, -0.0641,  0.2088,\n",
       "                      -0.0048,  0.0551,  0.0643, -0.0009,  0.2409,  0.1362,  0.3976,  0.1930,\n",
       "                       0.0251, -0.1669,  0.1379,  0.0291,  0.0137,  0.2903,  0.3314, -0.0572,\n",
       "                       0.2893,  0.1942,  0.2306,  0.0208, -0.1146,  0.2460,  0.0809,  0.2521,\n",
       "                       0.2132,  0.0374,  0.0527, -0.0120,  0.1186, -0.3345, -0.0659,  0.3005,\n",
       "                       0.0650,  0.3477, -0.0716,  0.4344,  0.2450,  0.2870,  0.0409, -0.0024,\n",
       "                       0.2841,  0.3222,  0.3039,  0.2487,  0.2251,  0.2497,  0.1678,  0.1438,\n",
       "                       0.2401,  0.2186,  0.3578, -0.0552,  0.2087, -0.0809,  0.2453,  0.3465,\n",
       "                       0.2519,  0.1369, -0.1230,  0.2152,  0.1175,  0.2617,  0.2593,  0.3504,\n",
       "                       0.2991, -0.2228,  0.2395,  0.2857,  0.0481,  0.1087, -0.0665,  0.2339,\n",
       "                       0.2723,  0.0743,  0.1434,  0.3103,  0.2236, -0.2204,  0.0224, -0.1107,\n",
       "                       0.2665,  0.0538,  0.1712,  0.3143,  0.3882,  0.1931,  0.1294, -0.1155,\n",
       "                       0.0915, -0.0049,  0.0240,  0.0357,  0.0739,  0.0580, -0.2796, -0.0983,\n",
       "                       0.0609, -0.0833,  0.2033, -0.1197,  0.0368,  0.2634,  0.1960,  0.2576])),\n",
       "             ('decisions.2.bn2.running_var',\n",
       "              tensor([1.0100, 0.4117, 0.7120, 0.4729, 0.8054, 0.5443, 0.6242, 0.7552, 0.8910,\n",
       "                      1.2063, 0.4924, 0.8942, 0.9224, 0.2666, 0.4696, 0.8214, 1.1752, 0.6167,\n",
       "                      0.9260, 1.2150, 0.7499, 0.8347, 0.9431, 0.9909, 0.8876, 1.0535, 0.5862,\n",
       "                      0.6226, 0.5372, 0.5753, 0.5784, 0.8560, 0.8997, 0.8998, 0.2812, 0.4860,\n",
       "                      0.7686, 0.4371, 0.8637, 1.1197, 0.8836, 0.2947, 0.7976, 1.0003, 0.7654,\n",
       "                      0.5154, 0.6205, 0.6077, 0.8333, 0.8336, 0.6690, 1.0925, 0.6075, 0.8511,\n",
       "                      0.6625, 0.8313, 0.8716, 0.6407, 0.8832, 0.6532, 0.7037, 0.5226, 1.0280,\n",
       "                      1.1700, 0.5559, 0.8428, 0.7199, 0.6059, 0.7826, 0.7059, 0.6375, 0.6355,\n",
       "                      0.4543, 0.7503, 0.7346, 0.7780, 0.5641, 0.8178, 0.8282, 0.7532, 0.7058,\n",
       "                      0.6825, 0.7266, 0.4660, 0.5467, 0.4271, 0.8963, 0.6281, 0.2684, 1.0728,\n",
       "                      0.9021, 0.8296, 0.9928, 0.7544, 0.9958, 0.4248, 0.4433, 0.6813, 0.9887,\n",
       "                      0.4718, 0.9947, 1.0378, 1.0733, 1.0428, 0.8578, 0.8590, 0.9102, 0.6191,\n",
       "                      0.4386, 0.7992, 0.5410, 1.0007, 0.9677, 0.7868, 0.9597, 0.8372, 0.6895,\n",
       "                      0.5730, 1.1978, 0.8497, 0.1836, 0.7401, 0.2665, 0.8061, 0.9729, 0.5255,\n",
       "                      0.7243, 0.7889])),\n",
       "             ('decisions.2.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.2.dense3.weight',\n",
       "              tensor([[ 0.0981, -0.0268,  0.0662, -0.0789, -0.1135,  0.0382, -0.1188, -0.1452,\n",
       "                        0.1167,  0.1381, -0.0938,  0.0909,  0.0792,  0.0040, -0.0605,  0.0553,\n",
       "                        0.1088, -0.0663,  0.0776,  0.1136, -0.0819,  0.1079,  0.0966, -0.0990,\n",
       "                        0.0969,  0.1305, -0.0603,  0.0443, -0.0509,  0.0573, -0.1277,  0.1081,\n",
       "                        0.0656,  0.1360, -0.0101,  0.0293,  0.0608, -0.0465, -0.1466,  0.1025,\n",
       "                       -0.1053, -0.0163, -0.0920,  0.0863,  0.0750, -0.0823,  0.0448, -0.0447,\n",
       "                       -0.0759,  0.0626,  0.0417,  0.1240,  0.0522,  0.0808,  0.0960, -0.1137,\n",
       "                        0.0657, -0.1138,  0.1102, -0.0725, -0.0822, -0.0844,  0.0981,  0.1266,\n",
       "                       -0.0766, -0.1279, -0.1017, -0.0640,  0.0532, -0.0808, -0.0485, -0.0568,\n",
       "                       -0.0471, -0.0975, -0.1158,  0.0768, -0.0929,  0.1132, -0.1118, -0.1155,\n",
       "                       -0.1118,  0.0636,  0.0532, -0.0444,  0.0318, -0.0397, -0.1320, -0.0861,\n",
       "                       -0.0551,  0.1082, -0.1128, -0.1359,  0.0978,  0.0598,  0.1242, -0.0389,\n",
       "                       -0.1212,  0.0557,  0.1450, -0.1413, -0.1294,  0.0880,  0.1248,  0.1223,\n",
       "                       -0.1115,  0.1145, -0.1133, -0.0793, -0.0695, -0.0944, -0.1198,  0.1240,\n",
       "                        0.1104,  0.0652,  0.0847,  0.0686,  0.0451,  0.0301,  0.1272,  0.1047,\n",
       "                        0.0032,  0.0986, -0.0147,  0.0927,  0.0817, -0.0567, -0.1189, -0.1344]])),\n",
       "             ('decisions.2.dense3.bias', tensor([-0.0281])),\n",
       "             ('decisions_q.0.dense1.weight',\n",
       "              tensor([[ 0.0132,  0.0761, -0.0456,  ...,  0.0294, -0.0715, -0.0559],\n",
       "                      [-0.0286, -0.0595, -0.0714,  ...,  0.0606,  0.0855,  0.0326],\n",
       "                      [ 0.0314,  0.0860,  0.0034,  ..., -0.0979,  0.0428, -0.0861],\n",
       "                      ...,\n",
       "                      [-0.0283,  0.0639, -0.0552,  ..., -0.0780,  0.0377, -0.0246],\n",
       "                      [-0.0629,  0.0501, -0.1055,  ..., -0.0283,  0.0468, -0.0490],\n",
       "                      [ 0.0287, -0.0749, -0.0688,  ...,  0.0057, -0.0201,  0.0166]])),\n",
       "             ('decisions_q.0.dense2.weight',\n",
       "              tensor([[-0.0775, -0.0447, -0.0668,  ...,  0.0495,  0.0717, -0.0270],\n",
       "                      [ 0.0168,  0.0968, -0.0769,  ..., -0.0722,  0.0571, -0.0094],\n",
       "                      [ 0.0512,  0.0072, -0.0165,  ..., -0.0854,  0.0751, -0.0271],\n",
       "                      ...,\n",
       "                      [-0.0038, -0.0229,  0.0795,  ...,  0.0758, -0.0248, -0.0310],\n",
       "                      [-0.0753,  0.0120, -0.1003,  ..., -0.0306, -0.0904, -0.0823],\n",
       "                      [ 0.0086,  0.0332,  0.0831,  ...,  0.0397, -0.0010, -0.0098]])),\n",
       "             ('decisions_q.0.bn1.weight',\n",
       "              tensor([0.9783, 0.9899, 1.0157, 1.0258, 0.9848, 1.0090, 0.9749, 0.9884, 1.0134,\n",
       "                      1.0142, 0.9797, 0.9874, 0.9889, 0.9867, 0.9981, 0.9912, 0.9745, 0.9859,\n",
       "                      0.9886, 1.0271, 1.0146, 0.9709, 0.9865, 0.9863, 0.9959, 1.0102, 0.9781,\n",
       "                      1.0125, 0.9923, 1.0224, 1.0059, 1.0115, 0.9761, 0.9870, 0.9886, 0.9823,\n",
       "                      1.0148, 0.9811, 1.0122, 1.0168, 1.0223, 0.9838, 1.0025, 1.0123, 0.9825,\n",
       "                      0.9865, 0.9958, 1.0149, 1.0183, 0.9775, 1.0239, 0.9888, 0.9912, 0.9835,\n",
       "                      0.9765, 0.9898, 1.0126, 0.9922, 0.9915, 1.0086, 0.9983, 1.0149, 1.0295,\n",
       "                      0.9874, 0.9972, 0.9844, 1.0006, 1.0056, 1.0228, 1.0127, 1.0117, 0.9805,\n",
       "                      1.0094, 1.0178, 1.0166, 0.9721, 0.9729, 0.9877, 1.0176, 0.9920, 0.9767,\n",
       "                      1.0066, 1.0114, 0.9913, 0.9891, 0.9899, 1.0111, 1.0002, 0.9971, 0.9924,\n",
       "                      0.9926, 1.0041, 1.0159, 0.9907, 1.0212, 1.0139, 1.0227, 0.9948, 0.9934,\n",
       "                      0.9922, 1.0028, 1.0048, 0.9817, 1.0038, 0.9953, 1.0010, 1.0015, 0.9778,\n",
       "                      1.0138, 0.9939, 1.0048, 1.0144, 0.9811, 0.9845, 0.9701, 1.0119, 1.0277,\n",
       "                      0.9753, 0.9956, 1.0116, 1.0065, 1.0068, 0.9853, 1.0260, 1.0312, 1.0114,\n",
       "                      0.9800, 0.9865])),\n",
       "             ('decisions_q.0.bn1.bias',\n",
       "              tensor([-2.0059e-02, -2.4049e-02,  2.6927e-02,  1.6906e-02, -1.4860e-02,\n",
       "                       1.9040e-02, -1.8389e-02, -1.2864e-02,  1.3308e-02,  1.7319e-02,\n",
       "                      -1.0929e-02, -1.1511e-02,  3.5843e-03, -3.4304e-04,  1.3930e-02,\n",
       "                      -1.1538e-02,  8.4273e-03,  1.5335e-02, -2.5101e-03,  9.0644e-03,\n",
       "                       1.9742e-02, -2.5815e-02, -1.6289e-02, -1.0227e-02,  1.0217e-02,\n",
       "                       1.7041e-02,  5.9453e-03,  8.5790e-03, -9.6057e-03,  1.2575e-02,\n",
       "                       7.7977e-03,  2.6166e-02, -2.2088e-02,  5.9332e-03, -3.7694e-03,\n",
       "                      -1.1546e-02,  2.4546e-02, -5.2865e-03,  2.0842e-02,  1.2269e-02,\n",
       "                       1.2435e-02,  6.4720e-04,  3.2256e-02,  2.1909e-02, -2.1003e-02,\n",
       "                      -8.8401e-03,  8.3777e-03,  2.8138e-02,  1.5726e-02, -1.2330e-02,\n",
       "                       1.5589e-02, -1.2215e-02,  1.8682e-02, -1.5281e-02, -2.1182e-02,\n",
       "                       6.5697e-03,  1.2895e-02,  1.3854e-02,  6.2037e-03,  1.5628e-02,\n",
       "                       2.0166e-02,  1.3165e-02,  2.1037e-02,  6.9302e-03,  1.2131e-02,\n",
       "                      -5.9175e-04,  1.0532e-02,  1.2179e-02,  1.1087e-02,  2.3637e-02,\n",
       "                       2.1358e-02, -2.0598e-02,  2.0663e-02,  1.4253e-02,  1.6703e-02,\n",
       "                      -2.7063e-02, -2.7357e-02, -1.2413e-02,  1.0017e-02, -9.4498e-03,\n",
       "                      -2.1386e-02,  1.2907e-02,  1.2800e-02,  8.3087e-03,  1.0500e-02,\n",
       "                      -8.0046e-03,  7.0212e-03,  2.6927e-03, -3.2150e-03,  9.8670e-03,\n",
       "                       1.6170e-02,  1.4157e-02,  2.4761e-02,  1.4153e-02,  1.3307e-02,\n",
       "                       1.2341e-02,  1.1870e-02,  1.0616e-02,  3.2500e-03,  7.1005e-03,\n",
       "                       1.3536e-02,  6.9448e-03, -1.5117e-02,  1.4449e-02,  2.1304e-03,\n",
       "                       9.2919e-03,  1.9704e-02,  4.1661e-03,  2.7097e-02,  6.4333e-03,\n",
       "                       8.5682e-03,  1.8437e-02, -1.6062e-02,  8.0896e-03, -1.7487e-05,\n",
       "                       1.7092e-02,  1.4627e-02, -2.2834e-02,  2.5974e-02,  2.1622e-02,\n",
       "                       1.1304e-02,  1.7051e-02,  1.8954e-03,  2.4003e-02,  2.2533e-02,\n",
       "                       1.0775e-02, -1.0538e-02,  1.3243e-02])),\n",
       "             ('decisions_q.0.bn1.running_mean',\n",
       "              tensor([-0.0397, -0.1974, -0.2134, -0.2387,  0.1134, -0.2730,  0.0138,  0.1190,\n",
       "                      -0.4270, -0.1735, -0.1952, -0.0277, -0.2667,  0.0048, -0.2095, -0.2192,\n",
       "                      -0.0465,  0.1074,  0.0457,  0.0212, -0.3343,  0.0351,  0.1214, -0.0332,\n",
       "                      -0.0892, -0.0212, -0.0946, -0.1671,  0.0557,  0.1814, -0.1865, -0.0517,\n",
       "                      -0.0694,  0.1857,  0.0218,  0.0773, -0.0547, -0.1250,  0.0967,  0.0691,\n",
       "                       0.0034,  0.0543, -0.1644, -0.0053, -0.0282, -0.4342, -0.4141,  0.1796,\n",
       "                      -0.4438, -0.1448, -0.0818, -0.0283, -0.3009, -0.2129, -0.2148,  0.1335,\n",
       "                       0.1193, -0.1669, -0.4741,  0.2111, -0.0755, -0.1152, -0.0263,  0.1476,\n",
       "                       0.3582, -0.1170, -0.1848, -0.1059, -0.0534, -0.1041,  0.0128,  0.0288,\n",
       "                      -0.1010, -0.4311,  0.1043,  0.1499,  0.0428, -0.1473, -0.1715, -0.0676,\n",
       "                      -0.1313, -0.0578, -0.0315, -0.5388, -0.4844, -0.2303, -0.1541, -0.2032,\n",
       "                       0.1264,  0.2452, -0.3333, -0.0589, -0.1149, -0.2395, -0.1771, -0.0173,\n",
       "                       0.0482, -0.0091, -0.3176,  0.1081, -0.0711, -0.2487,  0.0940, -0.0618,\n",
       "                      -0.2533, -0.3011, -0.2928,  0.1102, -0.0724, -0.1905,  0.0913, -0.2425,\n",
       "                      -0.4235,  0.0255, -0.3247, -0.0959, -0.2377, -0.1590, -0.3522, -0.2933,\n",
       "                      -0.0031, -0.2121,  0.0011,  0.0866, -0.0284, -0.0379, -0.1216, -0.3469])),\n",
       "             ('decisions_q.0.bn1.running_var',\n",
       "              tensor([1.4603, 0.5797, 0.4554, 0.9267, 0.9556, 1.1685, 0.9806, 0.5812, 0.3849,\n",
       "                      0.9936, 0.5135, 0.4804, 0.9794, 1.1927, 1.0995, 1.0383, 1.0597, 1.2222,\n",
       "                      0.6839, 0.5748, 1.0490, 0.8699, 0.8420, 0.2636, 1.3832, 1.4921, 0.4476,\n",
       "                      0.9539, 0.1969, 1.5050, 0.5261, 0.6361, 0.2244, 0.8852, 1.4336, 0.5334,\n",
       "                      0.7135, 0.8114, 0.5324, 1.3993, 1.0705, 0.6970, 0.3323, 1.5478, 0.9381,\n",
       "                      0.7900, 0.1263, 0.7711, 0.8871, 0.3554, 0.5268, 1.1369, 1.9378, 0.7999,\n",
       "                      1.2060, 0.2587, 1.3010, 1.2810, 0.9089, 0.9914, 1.1907, 1.3532, 1.0420,\n",
       "                      0.4144, 0.7659, 0.2523, 1.2512, 0.5727, 0.5613, 1.1240, 0.8603, 0.6019,\n",
       "                      1.0278, 0.8864, 1.7803, 0.5283, 0.7875, 0.3949, 1.8375, 0.2056, 0.4096,\n",
       "                      0.3902, 0.8863, 0.3735, 0.8557, 1.2111, 0.6765, 1.3561, 0.2368, 1.7451,\n",
       "                      0.6722, 0.4989, 1.2903, 0.7506, 0.9940, 0.6934, 1.6781, 0.1247, 0.1592,\n",
       "                      1.3225, 1.2509, 0.4276, 0.7857, 1.2285, 1.2019, 0.8288, 0.2305, 0.5639,\n",
       "                      0.5110, 0.8511, 1.0481, 1.2149, 0.5755, 0.3210, 0.7638, 1.2592, 1.6050,\n",
       "                      0.2721, 0.2756, 0.5905, 0.5549, 1.3655, 1.3987, 0.7434, 0.7068, 0.5498,\n",
       "                      1.3253, 0.5092])),\n",
       "             ('decisions_q.0.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('decisions_q.0.bn2.weight',\n",
       "              tensor([1.0640, 1.0550, 1.0600, 1.0599, 1.0664, 1.0628, 1.0619, 1.1147, 1.0583,\n",
       "                      1.0592, 1.0555, 1.0679, 1.0624, 1.0559, 1.0776, 1.0556, 1.0520, 1.1253,\n",
       "                      1.0659, 1.1328, 1.0566, 1.0767, 1.0804, 1.0590, 1.1097, 1.0499, 1.1037,\n",
       "                      1.0504, 1.0698, 1.0536, 1.0643, 1.0560, 1.0930, 1.0632, 1.0576, 1.0392,\n",
       "                      1.0583, 1.0598, 1.0899, 1.0732, 1.1078, 1.0684, 1.0648, 1.0573, 1.0578,\n",
       "                      1.0547, 1.0636, 1.0686, 1.1719, 1.0556, 1.0580, 1.0705, 1.1261, 1.0528,\n",
       "                      1.1371, 1.0599, 1.0761, 1.0642, 1.0747, 1.0584, 1.0576, 1.0704, 1.0560,\n",
       "                      1.0514, 1.0656, 1.1033, 1.0619, 1.0573, 1.0721, 1.1843, 1.0614, 1.0605,\n",
       "                      1.0690, 1.0783, 1.0634, 1.0563, 0.9958, 1.0611, 1.0696, 1.0550, 1.0583,\n",
       "                      1.0582, 1.0737, 1.0536, 1.1811, 1.0685, 1.0571, 1.0539, 1.0614, 1.0657,\n",
       "                      1.0614, 1.0802, 1.0751, 1.0568, 1.0566, 1.0596, 1.0565, 1.0612, 1.0606,\n",
       "                      1.0769, 1.0727, 1.0821, 1.0696, 1.0458, 1.0542, 1.0650, 1.0542, 1.0563,\n",
       "                      1.0559, 1.1520, 1.0620, 1.0902, 1.0628, 1.0772, 1.0767, 1.0950, 1.0574,\n",
       "                      1.0555, 1.0690, 1.0600, 1.0871, 1.0960, 1.0569, 1.0912, 1.0555, 1.0526,\n",
       "                      1.0576, 1.0688])),\n",
       "             ('decisions_q.0.bn2.bias',\n",
       "              tensor([0.0515, 0.0407, 0.0428, 0.0422, 0.0534, 0.0424, 0.0505, 0.1091, 0.0475,\n",
       "                      0.0451, 0.0495, 0.0506, 0.0625, 0.0543, 0.0566, 0.0502, 0.0402, 0.1111,\n",
       "                      0.0537, 0.1123, 0.0409, 0.0625, 0.0635, 0.0487, 0.1072, 0.0373, 0.0811,\n",
       "                      0.0464, 0.0553, 0.0399, 0.0540, 0.0409, 0.0668, 0.0519, 0.0478, 0.0079,\n",
       "                      0.0365, 0.0442, 0.0785, 0.0627, 0.0930, 0.0554, 0.0573, 0.0454, 0.0506,\n",
       "                      0.0445, 0.0532, 0.0490, 0.1425, 0.0392, 0.0483, 0.0575, 0.1253, 0.0448,\n",
       "                      0.1067, 0.0481, 0.0590, 0.0515, 0.0602, 0.0498, 0.0490, 0.0570, 0.0471,\n",
       "                      0.0448, 0.0539, 0.1210, 0.0511, 0.0407, 0.0613, 0.1846, 0.0443, 0.0500,\n",
       "                      0.0551, 0.0655, 0.0515, 0.0482, 0.0063, 0.0489, 0.0507, 0.0369, 0.0514,\n",
       "                      0.0477, 0.0634, 0.0448, 0.1578, 0.0492, 0.0313, 0.0450, 0.0493, 0.0474,\n",
       "                      0.0522, 0.0697, 0.0623, 0.0462, 0.0483, 0.0442, 0.0422, 0.0519, 0.0420,\n",
       "                      0.0587, 0.0616, 0.0709, 0.0486, 0.0578, 0.0437, 0.0516, 0.0462, 0.0512,\n",
       "                      0.0404, 0.1471, 0.0497, 0.0718, 0.0497, 0.0696, 0.0539, 0.0764, 0.0484,\n",
       "                      0.0349, 0.0487, 0.0442, 0.0713, 0.0840, 0.0447, 0.0630, 0.0490, 0.0443,\n",
       "                      0.0376, 0.0570])),\n",
       "             ('decisions_q.0.bn2.running_mean',\n",
       "              tensor([-3.0386e-01,  2.4649e-01,  3.2804e-01,  8.4713e-02, -1.6488e-02,\n",
       "                       4.3162e-01,  3.0735e-01,  3.6034e-02,  8.6408e-02,  3.2721e-01,\n",
       "                      -3.2103e-01,  2.7170e-01,  1.3345e-01,  1.4151e-01, -7.1238e-02,\n",
       "                      -1.7723e-01, -2.9123e-01, -1.4628e-01,  1.6031e-01,  6.8778e-02,\n",
       "                      -8.4591e-02,  1.4244e-01,  2.5058e-01, -2.2157e-01, -3.0804e-01,\n",
       "                      -6.9806e-02, -1.3932e-01, -1.6995e-01,  3.8744e-01, -2.3942e-01,\n",
       "                       8.0826e-02,  1.2956e-01, -4.3987e-02,  2.4544e-02, -1.4919e-02,\n",
       "                       2.7451e-01,  1.6672e-02,  2.8439e-02,  8.3282e-02,  1.8796e-01,\n",
       "                       3.0506e-01, -3.2221e-01,  1.0699e-01, -8.3644e-02,  1.3811e-01,\n",
       "                      -2.8536e-01, -2.4251e-02,  3.5556e-02,  3.4313e-01, -3.5379e-01,\n",
       "                      -2.7108e-01,  2.0147e-01, -2.1705e-01,  2.0483e-01,  7.8075e-02,\n",
       "                      -1.6970e-01,  1.1059e-01,  1.5057e-01, -1.7960e-01, -1.5863e-01,\n",
       "                       1.9491e-01, -1.8695e-01,  1.5593e-02, -2.6080e-01, -1.7331e-01,\n",
       "                       1.3797e-01, -3.6637e-01,  3.5236e-01,  6.0365e-02,  2.1992e-01,\n",
       "                       1.6827e-01,  2.5761e-01, -8.1632e-02,  1.2287e-01,  8.4575e-02,\n",
       "                      -1.2339e-01, -8.9962e-02,  2.3147e-01,  1.3981e-01, -7.7811e-02,\n",
       "                      -1.5373e-01, -2.8337e-01, -3.6581e-01, -4.7325e-03,  5.3563e-02,\n",
       "                       1.3843e-01,  1.4566e-01, -2.5859e-01, -2.0430e-01,  2.4588e-01,\n",
       "                       7.9737e-02, -1.8772e-01, -2.3036e-01, -4.9625e-06, -3.0065e-02,\n",
       "                       1.2653e-01, -8.8939e-02,  9.7074e-02,  2.6778e-01, -1.6171e-01,\n",
       "                       3.7315e-01,  2.4088e-01,  6.8530e-02, -2.9542e-01, -5.2762e-01,\n",
       "                       3.2930e-01,  2.0532e-02, -1.4440e-01, -2.4310e-01, -7.6590e-03,\n",
       "                      -7.0959e-02,  1.1522e-02, -2.9570e-01, -1.5003e-02,  3.0381e-01,\n",
       "                      -3.1074e-02, -4.4052e-01,  1.8949e-01,  1.3027e-01,  2.3803e-02,\n",
       "                      -9.2026e-02,  3.1263e-01, -2.4218e-02, -1.0434e-01,  1.7905e-01,\n",
       "                       2.4484e-01, -1.3275e-01,  6.2220e-02])),\n",
       "             ('decisions_q.0.bn2.running_var',\n",
       "              tensor([1.6835, 1.3124, 1.0326, 1.0748, 1.2411, 1.7807, 1.6016, 0.8603, 0.8795,\n",
       "                      0.9462, 1.2031, 0.8539, 1.0596, 1.0218, 1.1301, 1.1077, 1.4016, 1.6771,\n",
       "                      0.7937, 1.4940, 1.1392, 1.2595, 1.2045, 1.2556, 0.9366, 1.3525, 2.7600,\n",
       "                      1.7952, 1.3864, 1.0849, 1.1055, 0.9376, 1.3330, 1.1410, 1.2789, 0.8774,\n",
       "                      0.7415, 0.9836, 1.3169, 1.0806, 1.7031, 1.2371, 1.0596, 1.4236, 1.2707,\n",
       "                      1.1895, 1.6840, 1.7868, 0.9272, 1.5091, 1.1142, 1.3480, 1.1922, 1.5605,\n",
       "                      0.7808, 0.6840, 0.8015, 1.2305, 1.4554, 1.2337, 1.7786, 1.3229, 1.0365,\n",
       "                      1.0841, 1.4593, 0.9597, 1.5596, 1.3312, 1.0917, 0.9588, 0.8280, 0.8700,\n",
       "                      1.2598, 1.5811, 1.1324, 1.2535, 0.9701, 1.8119, 1.1845, 0.8779, 1.3858,\n",
       "                      1.6848, 0.7496, 1.0624, 1.1244, 1.4372, 1.1284, 1.1391, 1.0841, 1.4116,\n",
       "                      0.8599, 1.0595, 1.1997, 1.8729, 1.5292, 1.9017, 1.6015, 1.2916, 1.6502,\n",
       "                      1.1229, 1.3892, 1.3463, 1.4433, 1.3687, 1.0595, 1.0437, 1.1658, 0.9934,\n",
       "                      1.3421, 0.8818, 1.1935, 0.9789, 1.2549, 1.2257, 1.9782, 1.1040, 1.0842,\n",
       "                      0.9752, 0.8091, 0.6770, 1.2559, 1.1678, 1.7406, 0.8208, 1.4721, 1.2344,\n",
       "                      1.8447, 1.3367])),\n",
       "             ('decisions_q.0.bn2.num_batches_tracked', tensor(906)),\n",
       "             ('decisions_q.0.dense3.weight',\n",
       "              tensor([[ 0.1304, -0.1331, -0.1060, -0.1212,  0.0775, -0.1002, -0.0972,  0.0680,\n",
       "                        0.0792, -0.1299,  0.1081, -0.0931,  0.0994,  0.0910, -0.0797,  0.0799,\n",
       "                       -0.1336, -0.0519,  0.0709,  0.0617, -0.1032, -0.0750, -0.0652,  0.0950,\n",
       "                        0.0636, -0.1330,  0.0617,  0.1191, -0.0742, -0.1191, -0.0876, -0.0973,\n",
       "                       -0.0579,  0.0895,  0.1236, -0.0466, -0.0859, -0.1285,  0.0606,  0.0815,\n",
       "                       -0.0566,  0.0760,  0.0704, -0.1119,  0.1245, -0.1064,  0.0759, -0.1207,\n",
       "                        0.0633, -0.1272,  0.1151, -0.0682, -0.0559,  0.1215,  0.0532,  0.1121,\n",
       "                       -0.0707, -0.0793,  0.0626,  0.0916,  0.1147,  0.0590,  0.1233,  0.1294,\n",
       "                        0.0651,  0.0468,  0.0727, -0.1309,  0.0762, -0.0648, -0.1246,  0.0896,\n",
       "                       -0.0688, -0.0749,  0.0717,  0.1364,  0.0306, -0.0876, -0.0782, -0.1377,\n",
       "                        0.0955,  0.0891,  0.0825,  0.1235,  0.0630, -0.0824, -0.1064,  0.1255,\n",
       "                        0.1094, -0.0955,  0.0804,  0.0878,  0.0807,  0.1369,  0.1107, -0.0937,\n",
       "                       -0.1185,  0.0854, -0.1060, -0.0611,  0.0634,  0.0655, -0.0877,  0.0722,\n",
       "                       -0.1037, -0.0851,  0.1151,  0.0879, -0.1132, -0.0619,  0.0904,  0.0504,\n",
       "                        0.0866, -0.0668, -0.0660,  0.0589,  0.1108, -0.1234, -0.1014, -0.1091,\n",
       "                        0.0851, -0.0595, -0.1113, -0.0611,  0.1119,  0.1156, -0.1157,  0.0978]])),\n",
       "             ('decisions_q.0.dense3.bias', tensor([0.1063])),\n",
       "             ('decisions_q.1.dense1.weight',\n",
       "              tensor([[-0.0450, -0.0108, -0.0785,  ...,  0.0435,  0.0031, -0.0564],\n",
       "                      [-0.0722, -0.0269,  0.0411,  ...,  0.0800,  0.0229, -0.0865],\n",
       "                      [ 0.0177, -0.0116, -0.0190,  ..., -0.0097, -0.0009,  0.0113],\n",
       "                      ...,\n",
       "                      [-0.0144, -0.0191,  0.0775,  ..., -0.0346, -0.0500,  0.0387],\n",
       "                      [-0.0570,  0.0014, -0.0134,  ..., -0.0161,  0.0021, -0.0433],\n",
       "                      [-0.0945,  0.0498, -0.0690,  ...,  0.0812, -0.0845,  0.0562]])),\n",
       "             ('decisions_q.1.dense2.weight',\n",
       "              tensor([[-0.0537,  0.0293,  0.0432,  ...,  0.0088, -0.0082, -0.0161],\n",
       "                      [-0.0958, -0.0643,  0.1071,  ..., -0.0631,  0.0771, -0.0513],\n",
       "                      [ 0.0362, -0.0294, -0.0331,  ..., -0.0547, -0.0600,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0229, -0.0209,  0.0719,  ...,  0.0206, -0.0321,  0.0847],\n",
       "                      [ 0.0775,  0.0018, -0.0381,  ...,  0.0906,  0.0176,  0.0301],\n",
       "                      [ 0.0201, -0.0608, -0.0338,  ...,  0.0760, -0.0167,  0.0545]])),\n",
       "             ('decisions_q.1.bn1.weight',\n",
       "              tensor([0.9762, 1.0079, 0.9861, 1.0171, 1.0169, 1.0025, 0.9975, 0.9904, 0.9766,\n",
       "                      1.0098, 1.0203, 0.9776, 1.0013, 1.0119, 0.9933, 0.9896, 0.9860, 1.0141,\n",
       "                      1.0128, 1.0235, 0.9733, 1.0055, 0.9980, 1.0212, 1.0107, 0.9781, 1.0058,\n",
       "                      1.0092, 1.0089, 0.9837, 0.9993, 1.0043, 0.9967, 0.9999, 0.9887, 0.9971,\n",
       "                      1.0167, 0.9777, 1.0267, 0.9763, 1.0001, 1.0245, 1.0097, 0.9972, 1.0139,\n",
       "                      1.0138, 1.0084, 0.9854, 1.0215, 1.0124, 0.9897, 0.9879, 0.9939, 0.9883,\n",
       "                      1.0209, 0.9891, 0.9884, 0.9810, 1.0044, 1.0169, 1.0090, 1.0069, 0.9917,\n",
       "                      1.0020, 1.0130, 0.9897, 1.0138, 1.0005, 1.0089, 0.9777, 1.0112, 0.9845,\n",
       "                      0.9811, 0.9894, 1.0060, 0.9875, 0.9748, 1.0009, 1.0189, 0.9913, 1.0103,\n",
       "                      0.9765, 0.9871, 0.9785, 1.0211, 0.9817, 1.0006, 0.9863, 1.0123, 1.0032,\n",
       "                      0.9723, 0.9819, 1.0146, 0.9986, 1.0077, 0.9957, 1.0174, 0.9822, 0.9992,\n",
       "                      1.0157, 0.9977, 1.0139, 1.0076, 0.9810, 1.0125, 1.0139, 1.0173, 1.0073,\n",
       "                      0.9969, 1.0209, 1.0056, 1.0133, 0.9858, 1.0201, 0.9992, 0.9856, 0.9922,\n",
       "                      0.9995, 0.9933, 0.9898, 1.0234, 0.9940, 0.9873, 1.0057, 1.0054, 1.0182,\n",
       "                      0.9784, 0.9989])),\n",
       "             ('decisions_q.1.bn1.bias',\n",
       "              tensor([-0.0135,  0.0295, -0.0038,  0.0250,  0.0201,  0.0151,  0.0257, -0.0012,\n",
       "                      -0.0221,  0.0214,  0.0206, -0.0297,  0.0013,  0.0160,  0.0187, -0.0240,\n",
       "                      -0.0210,  0.0155,  0.0131,  0.0298, -0.0241,  0.0128,  0.0166,  0.0237,\n",
       "                       0.0221, -0.0197,  0.0262,  0.0196,  0.0147, -0.0106,  0.0313,  0.0142,\n",
       "                       0.0081,  0.0230, -0.0062,  0.0206,  0.0157, -0.0118,  0.0307, -0.0158,\n",
       "                       0.0128,  0.0309,  0.0165,  0.0231,  0.0215,  0.0256,  0.0271, -0.0127,\n",
       "                       0.0262,  0.0193, -0.0021,  0.0126, -0.0006, -0.0025,  0.0238,  0.0183,\n",
       "                      -0.0317, -0.0173,  0.0169,  0.0185,  0.0178,  0.0006,  0.0085,  0.0240,\n",
       "                       0.0220,  0.0193,  0.0268,  0.0064,  0.0141, -0.0247,  0.0163,  0.0116,\n",
       "                      -0.0166, -0.0080,  0.0162, -0.0129, -0.0221,  0.0151,  0.0213,  0.0114,\n",
       "                       0.0194, -0.0192,  0.0167, -0.0107,  0.0218, -0.0165,  0.0079,  0.0261,\n",
       "                       0.0228,  0.0120, -0.0233,  0.0026,  0.0255,  0.0226,  0.0125,  0.0046,\n",
       "                       0.0227, -0.0182,  0.0317,  0.0218,  0.0061,  0.0141,  0.0200, -0.0209,\n",
       "                       0.0127,  0.0188,  0.0212,  0.0151,  0.0126,  0.0225,  0.0197,  0.0195,\n",
       "                       0.0171,  0.0281,  0.0012, -0.0045,  0.0004,  0.0146, -0.0168,  0.0003,\n",
       "                       0.0288, -0.0055,  0.0053,  0.0252,  0.0194,  0.0243, -0.0223,  0.0078])),\n",
       "             ('decisions_q.1.bn1.running_mean',\n",
       "              tensor([-1.8491e-01,  5.0253e-02,  3.2031e-01, -1.9156e-01,  6.4026e-02,\n",
       "                       9.8125e-02, -1.8276e-01,  2.6161e-01, -2.4275e-01, -1.2322e-02,\n",
       "                       4.6000e-02,  2.1833e-01,  3.3984e-01,  1.8330e-01, -1.3729e-02,\n",
       "                       6.5218e-01,  9.0559e-03,  3.7546e-02,  1.8500e-01, -2.3734e-01,\n",
       "                       2.3191e-03, -4.9516e-01,  1.3496e-01, -4.4465e-01,  1.7397e-01,\n",
       "                      -3.0326e-01, -1.6663e-02, -2.7964e-01,  7.7875e-02,  1.9771e-01,\n",
       "                      -3.4064e-01, -3.2481e-01,  9.6281e-02, -2.3428e-01, -3.0197e-01,\n",
       "                       1.4795e-01, -1.4687e-01,  6.2871e-02, -3.6775e-01,  1.5181e-01,\n",
       "                       3.7572e-01, -3.4254e-02,  4.0077e-01, -6.4239e-02, -4.5121e-01,\n",
       "                      -1.7124e-01, -2.4262e-01, -2.7187e-01,  4.4096e-01,  4.2596e-02,\n",
       "                      -5.5493e-02,  1.3806e-01, -1.3621e-01,  4.1611e-01, -3.8755e-02,\n",
       "                      -2.2918e-01,  4.9823e-01, -4.2106e-01,  3.5367e-01, -1.1411e-02,\n",
       "                      -2.9477e-01, -3.7027e-01, -3.0557e-01, -3.4358e-01,  1.1392e-01,\n",
       "                      -1.8559e-01,  1.0211e-01, -3.4938e-02, -4.2359e-01,  3.8850e-01,\n",
       "                      -2.1050e-01, -4.6079e-01, -1.7767e-01,  7.9217e-02,  3.9309e-01,\n",
       "                       2.4034e-01, -7.1743e-02,  9.2856e-02, -4.0660e-02, -5.9733e-02,\n",
       "                       1.1018e-01,  4.9604e-01, -1.8155e-01, -2.4357e-02, -3.7474e-01,\n",
       "                      -3.0531e-01,  5.0614e-01, -1.2795e-02, -1.7168e-01, -7.3673e-02,\n",
       "                       1.8140e-01, -4.2560e-01, -5.5530e-02, -7.9831e-02, -2.2275e-01,\n",
       "                       3.6911e-02, -1.3924e-02,  3.3561e-01, -1.0021e-01, -4.2396e-01,\n",
       "                       1.0014e-01,  2.5516e-01,  5.2820e-02, -1.0784e-01, -2.0189e-02,\n",
       "                      -2.9478e-01,  5.9214e-02, -7.5368e-03, -2.3107e-01, -2.6549e-01,\n",
       "                      -3.1609e-01, -1.6254e-01, -8.7480e-02, -6.5297e-02,  1.2165e-01,\n",
       "                      -1.3277e-01,  7.4167e-02,  6.0687e-02,  5.3510e-01,  3.4465e-02,\n",
       "                      -1.8314e-01, -1.7004e-01,  6.3591e-04,  6.1512e-02,  2.0520e-01,\n",
       "                       1.7981e-01,  5.0453e-02,  5.7546e-01])),\n",
       "             ('decisions_q.1.bn1.running_var',\n",
       "              tensor([0.4232, 0.2503, 0.3527, 0.1975, 0.1487, 0.0964, 0.0917, 0.5972, 0.1264,\n",
       "                      0.0906, 0.2368, 0.3325, 0.6596, 0.0422, 0.1079, 0.8715, 0.0765, 0.0455,\n",
       "                      0.2855, 0.1946, 0.1283, 0.5351, 0.0539, 0.3337, 0.1157, 0.4336, 0.1746,\n",
       "                      0.1834, 0.1856, 0.2321, 0.1157, 0.1593, 0.1914, 0.3176, 0.6758, 0.1447,\n",
       "                      0.1447, 0.0649, 0.1078, 0.0495, 0.7798, 0.2321, 0.6338, 0.1465, 0.4090,\n",
       "                      0.0971, 0.4415, 0.1420, 0.1881, 0.1530, 0.4704, 0.1261, 0.0696, 0.2455,\n",
       "                      0.1660, 0.1239, 1.0461, 0.1686, 0.1514, 0.0366, 0.1561, 0.1492, 0.2061,\n",
       "                      0.1574, 0.1913, 0.0625, 0.0202, 0.0469, 0.0616, 0.3288, 0.4118, 0.6085,\n",
       "                      0.5556, 0.1982, 0.9362, 0.2857, 0.1167, 0.0383, 0.0428, 0.4015, 0.1070,\n",
       "                      0.3922, 0.2745, 0.0840, 0.1287, 0.2906, 0.6354, 0.2507, 0.1543, 0.3203,\n",
       "                      0.0326, 0.7217, 0.2099, 0.0272, 0.0309, 0.1334, 0.0348, 0.7062, 0.2206,\n",
       "                      0.1070, 0.1678, 0.1793, 0.1562, 0.1182, 0.1811, 0.3139, 0.1127, 0.0654,\n",
       "                      0.1135, 0.2667, 0.1474, 0.1283, 0.1439, 0.6108, 0.3915, 0.3353, 0.7675,\n",
       "                      0.3066, 0.6623, 0.0948, 0.1288, 0.2929, 0.0625, 0.1567, 0.7125, 0.1739,\n",
       "                      0.3641, 0.6363])),\n",
       "             ('decisions_q.1.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.1.bn2.weight',\n",
       "              tensor([1.0456, 1.0435, 1.0356, 1.0460, 1.0569, 1.0608, 1.0424, 1.0463, 1.0581,\n",
       "                      1.0194, 1.0145, 1.0561, 1.0457, 1.0620, 1.0526, 1.0496, 1.0431, 1.0468,\n",
       "                      1.0511, 1.0614, 1.0031, 1.0511, 1.0486, 1.0052, 1.1542, 1.0444, 1.0506,\n",
       "                      1.0752, 1.0747, 0.9982, 1.0665, 1.0530, 1.0354, 1.0518, 1.0534, 1.0435,\n",
       "                      1.0657, 1.0478, 1.0796, 1.0470, 1.0431, 1.0540, 1.0541, 1.0450, 1.0149,\n",
       "                      1.0481, 1.0676, 1.0442, 1.0443, 1.0539, 1.0869, 1.0428, 1.1320, 1.0443,\n",
       "                      1.1476, 1.0488, 1.0587, 1.0460, 1.0710, 1.0460, 1.0498, 1.0547, 1.0531,\n",
       "                      1.0520, 1.0552, 1.0402, 1.0456, 1.0484, 1.0462, 1.0556, 1.0504, 0.9876,\n",
       "                      1.0542, 1.0507, 1.0491, 1.0502, 1.0442, 0.9895, 1.0442, 1.0471, 1.0449,\n",
       "                      1.0455, 0.9790, 1.0075, 1.0172, 1.0473, 1.0260, 0.9955, 1.0504, 1.0424,\n",
       "                      1.0505, 1.0480, 1.0583, 1.0486, 1.0341, 1.0464, 1.0506, 1.0505, 1.0472,\n",
       "                      1.0420, 1.0498, 1.0678, 1.0548, 1.0874, 1.0485, 1.0514, 1.0574, 1.0469,\n",
       "                      1.1018, 1.0482, 1.0362, 1.0051, 1.0591, 1.0566, 1.0517, 1.0609, 1.0121,\n",
       "                      1.0404, 1.1188, 1.0524, 1.0161, 1.0490, 1.0380, 1.0537, 1.0125, 1.0691,\n",
       "                      1.0410, 1.0445])),\n",
       "             ('decisions_q.1.bn2.bias',\n",
       "              tensor([ 0.0417,  0.0387,  0.0094,  0.0351,  0.0466,  0.0517,  0.0368,  0.0402,\n",
       "                       0.0462,  0.0290, -0.0036,  0.0481,  0.0389,  0.0496,  0.0422,  0.0424,\n",
       "                       0.0354,  0.0394,  0.0432,  0.0500, -0.0085,  0.0369,  0.0406, -0.0087,\n",
       "                       0.1325,  0.0411,  0.0424,  0.0403,  0.0693,  0.0108,  0.0557,  0.0386,\n",
       "                       0.0239,  0.0449,  0.0454,  0.0369,  0.0504,  0.0404,  0.0618,  0.0385,\n",
       "                       0.0340,  0.0437,  0.0397,  0.0358,  0.0243,  0.0405,  0.0512,  0.0375,\n",
       "                       0.0378,  0.0449,  0.0757,  0.0475,  0.1208,  0.0378,  0.1550,  0.0370,\n",
       "                       0.0505,  0.0359,  0.0561,  0.0415,  0.0382,  0.0445,  0.0316,  0.0452,\n",
       "                       0.0436,  0.0364,  0.0383,  0.0412,  0.0399,  0.0425,  0.0412, -0.0090,\n",
       "                       0.0447,  0.0381,  0.0377,  0.0421,  0.0358, -0.0066,  0.0350,  0.0392,\n",
       "                       0.0369,  0.0358, -0.0219,  0.0148,  0.0251,  0.0394,  0.0356, -0.0009,\n",
       "                       0.0385,  0.0368,  0.0421,  0.0403,  0.0498,  0.0427,  0.0405,  0.0412,\n",
       "                       0.0413,  0.0442,  0.0372,  0.0381,  0.0384,  0.0557,  0.0460,  0.0716,\n",
       "                       0.0416,  0.0453,  0.0478,  0.0407,  0.0779,  0.0417,  0.0187,  0.0082,\n",
       "                       0.0504,  0.0472,  0.0415,  0.0505, -0.0059,  0.0418,  0.1029,  0.0421,\n",
       "                       0.0239,  0.0367,  0.0281,  0.0423,  0.0174,  0.0591,  0.0366,  0.0343])),\n",
       "             ('decisions_q.1.bn2.running_mean',\n",
       "              tensor([-0.2278, -0.1721, -0.3131,  0.0362,  0.2133,  0.0296,  0.1174,  0.1456,\n",
       "                      -0.0268,  0.0756,  0.0591,  0.3101, -0.0259, -0.0472,  0.1301, -0.0625,\n",
       "                      -0.0164, -0.0450, -0.0313,  0.0838,  0.2289,  0.3228, -0.0252, -0.1137,\n",
       "                       0.2793,  0.1181, -0.0230,  0.0829, -0.1409, -0.0725,  0.3282,  0.2900,\n",
       "                      -0.0751, -0.0336,  0.2303, -0.0023, -0.1317,  0.0212,  0.2399, -0.2841,\n",
       "                       0.2850,  0.1653, -0.0832,  0.0086, -0.1465, -0.1205, -0.0574, -0.2462,\n",
       "                      -0.0922,  0.1452,  0.1207, -0.0756,  0.1491, -0.0539,  0.2431, -0.0855,\n",
       "                      -0.1325, -0.0755,  0.0781, -0.0019,  0.1851,  0.0307, -0.0496, -0.0269,\n",
       "                       0.0730,  0.2098,  0.0121,  0.2384,  0.0215,  0.2283,  0.1042,  0.2065,\n",
       "                       0.0478, -0.1334,  0.1888, -0.0347, -0.2449, -0.1341,  0.0689,  0.1276,\n",
       "                       0.0556,  0.0448, -0.2756,  0.4970,  0.0840,  0.1515, -0.2166,  0.1647,\n",
       "                      -0.2904, -0.0477,  0.0377,  0.1968,  0.1087, -0.0995, -0.0428,  0.1610,\n",
       "                       0.3096, -0.1563, -0.0752,  0.0128,  0.0178,  0.3078,  0.1088,  0.2235,\n",
       "                      -0.1718, -0.0843, -0.0775, -0.0867, -0.0371, -0.2471,  0.0875, -0.1755,\n",
       "                      -0.0079,  0.2236, -0.0279,  0.3040,  0.1196, -0.0069, -0.0630, -0.1979,\n",
       "                       0.2459, -0.0804,  0.3134,  0.1221,  0.0906,  0.1473,  0.2832, -0.0711])),\n",
       "             ('decisions_q.1.bn2.running_var',\n",
       "              tensor([0.5810, 0.6603, 0.8488, 0.7016, 0.5489, 0.4429, 0.6261, 1.3409, 0.8310,\n",
       "                      0.8779, 0.7211, 1.2018, 0.9794, 0.3025, 0.8096, 0.3486, 0.5226, 0.3474,\n",
       "                      0.4735, 0.5734, 0.6571, 0.6708, 0.4689, 0.8433, 0.5332, 0.2200, 0.8341,\n",
       "                      0.6769, 0.7712, 1.4556, 0.4971, 0.5800, 0.5104, 0.2725, 0.3487, 0.8743,\n",
       "                      0.7633, 0.5755, 0.1690, 1.1090, 0.3877, 0.6969, 1.1050, 0.4176, 0.7346,\n",
       "                      0.3447, 0.6385, 0.2174, 0.2910, 0.7197, 0.4506, 0.5895, 0.6199, 0.4355,\n",
       "                      0.4490, 0.6057, 0.4107, 0.6293, 0.5040, 0.7420, 0.7987, 0.6897, 0.7412,\n",
       "                      0.6386, 0.6081, 0.8195, 0.5748, 0.6791, 0.6706, 0.6627, 0.7523, 0.5443,\n",
       "                      0.8191, 0.9162, 0.4673, 1.1081, 0.6279, 0.7692, 0.4817, 0.4050, 0.3003,\n",
       "                      0.4012, 0.3742, 0.9500, 0.5888, 0.4044, 0.7268, 1.0068, 0.6884, 0.5540,\n",
       "                      0.7418, 0.3234, 0.8881, 0.5081, 0.5318, 0.6808, 1.2071, 0.3004, 0.7301,\n",
       "                      0.6981, 0.5184, 0.4340, 0.4324, 0.6171, 0.7055, 0.5499, 0.3856, 0.2591,\n",
       "                      0.6903, 0.6493, 0.9792, 1.0360, 0.3542, 0.8419, 0.6028, 1.1431, 0.7246,\n",
       "                      0.8187, 0.5540, 0.4202, 0.4834, 0.8178, 0.6599, 0.9173, 0.6942, 0.8586,\n",
       "                      0.4965, 0.6725])),\n",
       "             ('decisions_q.1.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.1.dense3.weight',\n",
       "              tensor([[ 0.0916,  0.0903, -0.0787, -0.1129, -0.0659, -0.0676,  0.1207,  0.1271,\n",
       "                        0.0691,  0.1014, -0.0848,  0.0730,  0.0978, -0.0548,  0.0984,  0.1092,\n",
       "                       -0.0897,  0.1186,  0.0917, -0.0560, -0.0205, -0.1242,  0.1041, -0.0735,\n",
       "                       -0.0492,  0.1146, -0.1153, -0.0470,  0.0445,  0.0865, -0.0530, -0.1252,\n",
       "                       -0.0577,  0.0705,  0.0814,  0.1246, -0.0610,  0.1284, -0.0373, -0.1252,\n",
       "                       -0.1156, -0.0994, -0.1046, -0.1282,  0.0726,  0.1228, -0.0658,  0.0900,\n",
       "                        0.1156,  0.0736, -0.0569,  0.0558, -0.0559,  0.1221, -0.0399, -0.1089,\n",
       "                        0.0580, -0.1180,  0.0527,  0.1198, -0.1007,  0.0679, -0.0684, -0.0611,\n",
       "                       -0.0869,  0.1204, -0.1179,  0.1086, -0.0816, -0.0704, -0.1151,  0.0614,\n",
       "                       -0.1050, -0.1088, -0.1077, -0.0744, -0.1239,  0.0526, -0.1062, -0.0939,\n",
       "                       -0.1070, -0.1300,  0.0087,  0.0894,  0.1007,  0.0986,  0.0809,  0.0479,\n",
       "                       -0.1126,  0.1114, -0.0701,  0.0952,  0.0556,  0.0969,  0.0511, -0.0731,\n",
       "                        0.1022,  0.0870, -0.1116,  0.0825, -0.1013,  0.0533, -0.0713, -0.0471,\n",
       "                        0.1221,  0.0764, -0.0921,  0.1197, -0.0488,  0.0998, -0.0865,  0.0936,\n",
       "                        0.0690, -0.0674,  0.0934,  0.0549, -0.0984,  0.0641, -0.0591,  0.0843,\n",
       "                        0.0623, -0.1255, -0.1179, -0.0992,  0.0961,  0.0829, -0.1226, -0.1291]])),\n",
       "             ('decisions_q.1.dense3.bias', tensor([-0.0416])),\n",
       "             ('decisions_q.2.dense1.weight',\n",
       "              tensor([[-0.0763, -0.0397, -0.0141,  ..., -0.0632, -0.0551,  0.0488],\n",
       "                      [-0.0561,  0.0076, -0.0671,  ...,  0.0620, -0.0084, -0.1032],\n",
       "                      [ 0.0302,  0.0777, -0.0617,  ...,  0.0390,  0.0562, -0.0183],\n",
       "                      ...,\n",
       "                      [ 0.0437,  0.0804, -0.0801,  ...,  0.0280,  0.0464,  0.0671],\n",
       "                      [ 0.0329,  0.0566, -0.0069,  ...,  0.0252,  0.0170, -0.0173],\n",
       "                      [-0.0481,  0.1029, -0.0574,  ..., -0.0066,  0.0563, -0.1018]])),\n",
       "             ('decisions_q.2.dense2.weight',\n",
       "              tensor([[ 0.0528, -0.0423,  0.0777,  ..., -0.0916,  0.0856, -0.0444],\n",
       "                      [ 0.0706,  0.0822,  0.0482,  ..., -0.0268, -0.1011, -0.0713],\n",
       "                      [-0.0566,  0.0880, -0.0679,  ...,  0.0505,  0.0452,  0.0415],\n",
       "                      ...,\n",
       "                      [-0.0705, -0.0518, -0.0118,  ..., -0.0216, -0.0918,  0.0624],\n",
       "                      [-0.0126,  0.0282, -0.0140,  ..., -0.0403, -0.0041, -0.0482],\n",
       "                      [-0.0591,  0.1034,  0.0285,  ..., -0.0225, -0.0292, -0.0601]])),\n",
       "             ('decisions_q.2.bn1.weight',\n",
       "              tensor([1.0053, 1.0074, 0.9838, 1.0010, 1.0011, 1.0118, 0.9859, 1.0174, 1.0199,\n",
       "                      0.9829, 0.9977, 0.9943, 1.0223, 0.9791, 0.9920, 0.9789, 1.0009, 1.0112,\n",
       "                      1.0146, 1.0088, 1.0114, 1.0195, 1.0065, 0.9868, 0.9824, 0.9895, 0.9944,\n",
       "                      0.9973, 0.9914, 1.0096, 0.9778, 1.0153, 1.0212, 1.0257, 0.9795, 1.0199,\n",
       "                      0.9896, 1.0021, 0.9894, 1.0063, 1.0160, 1.0151, 0.9696, 1.0032, 0.9859,\n",
       "                      0.9882, 0.9842, 0.9797, 1.0125, 1.0017, 1.0204, 1.0123, 0.9823, 0.9960,\n",
       "                      0.9994, 1.0186, 1.0198, 0.9726, 1.0104, 1.0124, 0.9945, 0.9993, 1.0089,\n",
       "                      0.9902, 1.0050, 1.0151, 1.0055, 0.9912, 0.9999, 1.0258, 1.0085, 0.9796,\n",
       "                      0.9838, 0.9824, 1.0180, 0.9816, 0.9749, 1.0146, 1.0260, 1.0209, 1.0046,\n",
       "                      0.9853, 0.9935, 0.9837, 1.0069, 0.9950, 0.9905, 1.0161, 1.0126, 0.9713,\n",
       "                      0.9958, 0.9812, 1.0238, 1.0239, 0.9909, 0.9870, 1.0106, 1.0084, 0.9814,\n",
       "                      1.0115, 0.9834, 1.0087, 0.9980, 1.0061, 0.9921, 1.0140, 1.0115, 0.9926,\n",
       "                      1.0219, 0.9932, 0.9807, 1.0205, 1.0218, 0.9859, 1.0119, 1.0104, 0.9848,\n",
       "                      0.9827, 0.9824, 0.9957, 0.9922, 1.0045, 1.0097, 1.0139, 0.9762, 1.0087,\n",
       "                      1.0229, 0.9958])),\n",
       "             ('decisions_q.2.bn1.bias',\n",
       "              tensor([ 0.0217,  0.0206, -0.0232,  0.0200,  0.0198,  0.0302,  0.0009,  0.0242,\n",
       "                       0.0238, -0.0130,  0.0225, -0.0039,  0.0217, -0.0226,  0.0194, -0.0104,\n",
       "                       0.0076,  0.0237,  0.0266,  0.0104,  0.0181,  0.0258,  0.0277, -0.0122,\n",
       "                      -0.0231, -0.0121,  0.0034,  0.0183, -0.0087,  0.0162, -0.0084,  0.0230,\n",
       "                       0.0272,  0.0288,  0.0236,  0.0265, -0.0092,  0.0162, -0.0088,  0.0158,\n",
       "                       0.0201,  0.0193, -0.0075,  0.0084, -0.0123,  0.0144, -0.0076, -0.0278,\n",
       "                       0.0221,  0.0082,  0.0273,  0.0168, -0.0033,  0.0070,  0.0084,  0.0206,\n",
       "                       0.0271, -0.0288,  0.0165,  0.0214,  0.0219,  0.0144,  0.0229, -0.0082,\n",
       "                       0.0048,  0.0223,  0.0159, -0.0059,  0.0040,  0.0246,  0.0273, -0.0084,\n",
       "                      -0.0020,  0.0091,  0.0274, -0.0138, -0.0232,  0.0178,  0.0306,  0.0253,\n",
       "                      -0.0024,  0.0032, -0.0041, -0.0114,  0.0215,  0.0139,  0.0240,  0.0254,\n",
       "                       0.0129, -0.0204,  0.0016, -0.0170,  0.0251,  0.0277, -0.0116, -0.0099,\n",
       "                       0.0268,  0.0074, -0.0060,  0.0227, -0.0157,  0.0156,  0.0163,  0.0138,\n",
       "                       0.0009,  0.0221,  0.0263, -0.0083,  0.0254, -0.0017, -0.0168,  0.0215,\n",
       "                       0.0246, -0.0129,  0.0186,  0.0186, -0.0049,  0.0214, -0.0188, -0.0209,\n",
       "                       0.0076,  0.0242,  0.0236,  0.0207, -0.0199,  0.0256,  0.0251,  0.0047])),\n",
       "             ('decisions_q.2.bn1.running_mean',\n",
       "              tensor([-0.0766,  0.2973,  0.2023,  0.0215, -0.3922,  0.2586,  0.0624,  0.1484,\n",
       "                       0.1166,  0.0902, -0.2211, -0.4523, -0.2845, -0.5714, -0.0067,  0.0293,\n",
       "                      -0.3470, -0.1027, -0.0146, -0.5391, -0.2823, -0.5775,  0.3380,  0.2642,\n",
       "                       0.4266, -0.1057, -0.4267, -0.2805, -0.5503, -0.1642,  0.2460, -0.1189,\n",
       "                       0.0288, -0.0334, -0.1425, -0.1535,  0.2695,  0.1066, -0.4096, -0.3520,\n",
       "                      -0.3213,  0.0209,  0.4270, -0.2588,  0.1085,  0.3124, -0.3973,  0.3456,\n",
       "                       0.5229,  0.1445, -0.2407, -0.5879, -0.5307, -0.0530, -0.3065, -0.5459,\n",
       "                       0.1219,  0.0799, -0.1101, -0.3467,  0.4240, -0.1604,  0.1913, -0.4697,\n",
       "                      -0.4061, -0.5814,  0.1862, -0.4165, -0.6843, -0.3504,  0.1871,  0.2642,\n",
       "                      -0.0313,  0.4602, -0.0884, -0.2146, -0.4449, -0.0522, -0.6856, -0.3047,\n",
       "                      -0.2989,  0.4957,  0.1452,  0.1637, -0.0328, -0.5128, -0.3244, -0.7426,\n",
       "                      -0.0407, -0.1434, -0.0896,  0.0349,  0.2050, -0.2316, -0.3994,  0.3239,\n",
       "                       0.2464,  0.2130, -0.2652,  0.1246,  0.4926, -0.8216,  0.6421, -0.1102,\n",
       "                       0.2939,  0.3038,  0.1754, -0.3985, -0.1530, -0.0415,  0.5576,  0.1270,\n",
       "                      -0.6041, -0.3684, -0.1427, -0.1531, -0.0248,  0.0872, -0.2714,  0.2676,\n",
       "                       0.2016,  0.4366, -0.4607, -0.1535,  0.1860,  0.3057, -0.6373,  0.4074])),\n",
       "             ('decisions_q.2.bn1.running_var',\n",
       "              tensor([0.5376, 0.3566, 0.0896, 0.1232, 0.7433, 0.4752, 0.1254, 0.5501, 0.3076,\n",
       "                      0.0873, 0.1493, 0.5471, 0.2743, 0.6738, 0.4024, 0.1302, 1.0003, 0.0780,\n",
       "                      0.2891, 1.3766, 0.1181, 0.7300, 0.7667, 0.7648, 0.4545, 0.5362, 0.3260,\n",
       "                      0.3914, 0.5348, 0.0373, 0.1486, 0.1416, 0.1997, 0.1382, 0.1385, 0.0453,\n",
       "                      0.5030, 0.1044, 1.0732, 0.0992, 0.1327, 0.2327, 0.5041, 0.1070, 0.5684,\n",
       "                      0.3835, 0.6417, 0.0331, 0.6204, 0.1244, 0.4188, 0.4469, 0.7085, 0.1392,\n",
       "                      0.0852, 0.5717, 0.0728, 0.1748, 0.0894, 0.2850, 0.8117, 0.4784, 1.0043,\n",
       "                      0.6437, 0.6456, 0.8962, 0.4119, 0.6929, 0.8174, 0.7372, 0.3687, 1.2113,\n",
       "                      0.0801, 0.3885, 0.4106, 0.3266, 0.6394, 0.3599, 0.4405, 0.4931, 0.1841,\n",
       "                      0.3642, 0.6894, 0.2028, 0.2600, 0.6732, 0.6670, 1.1220, 0.1688, 0.1642,\n",
       "                      0.4293, 0.6034, 0.2850, 0.2645, 0.3881, 0.5207, 0.1195, 0.0689, 0.2866,\n",
       "                      0.5639, 0.9957, 0.6062, 0.6998, 0.2001, 0.1375, 0.0799, 0.5036, 0.8223,\n",
       "                      0.2472, 0.1959, 1.1473, 0.2793, 0.2352, 1.1743, 0.0471, 0.2082, 0.1797,\n",
       "                      0.2183, 0.5737, 0.0648, 0.3090, 0.8314, 0.8580, 0.1453, 0.1271, 0.1576,\n",
       "                      0.7721, 0.6248])),\n",
       "             ('decisions_q.2.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.2.bn2.weight',\n",
       "              tensor([1.0454, 1.0550, 1.0535, 1.0552, 1.0558, 1.0554, 1.0546, 1.0486, 1.0948,\n",
       "                      1.0599, 1.0511, 1.0944, 1.0525, 1.0523, 1.0516, 1.0528, 1.0537, 1.0616,\n",
       "                      1.0689, 1.0472, 1.0319, 1.0522, 1.0413, 0.9979, 1.0500, 1.0506, 1.0559,\n",
       "                      1.0583, 1.0101, 1.0568, 1.0480, 1.0556, 1.0551, 1.0534, 1.0585, 1.0507,\n",
       "                      1.0543, 1.0613, 1.0618, 0.9961, 1.0497, 1.0491, 1.0533, 1.0561, 1.0601,\n",
       "                      1.0414, 1.0571, 1.0562, 1.0598, 1.0828, 1.0628, 1.0559, 1.0519, 1.1148,\n",
       "                      1.0576, 1.0568, 1.0623, 1.0567, 1.0511, 1.0666, 1.0907, 1.1122, 1.0499,\n",
       "                      1.0528, 1.0650, 1.0280, 1.0928, 1.0551, 1.0532, 1.0549, 1.0547, 1.0327,\n",
       "                      1.0553, 1.0697, 1.0520, 1.0874, 1.0510, 1.0564, 1.0659, 1.0541, 1.0512,\n",
       "                      1.0593, 1.0516, 1.0519, 1.0989, 1.0466, 1.0449, 1.0506, 1.0574, 1.0568,\n",
       "                      1.0556, 1.0732, 1.0158, 1.1090, 1.0653, 1.0521, 1.0066, 1.0508, 1.0754,\n",
       "                      1.0775, 1.0608, 1.0505, 1.0520, 1.0498, 1.0498, 1.0474, 1.0612, 1.0459,\n",
       "                      1.0495, 1.0483, 1.0509, 1.0563, 1.0397, 1.0595, 1.0490, 1.0879, 0.9854,\n",
       "                      1.0740, 1.0613, 1.0606, 1.0073, 1.0765, 1.0543, 1.0489, 1.0927, 1.1008,\n",
       "                      1.0513, 1.0619])),\n",
       "             ('decisions_q.2.bn2.bias',\n",
       "              tensor([ 0.0384,  0.0453,  0.0468,  0.0445,  0.0388,  0.0442,  0.0459,  0.0440,\n",
       "                       0.0801,  0.0452,  0.0454,  0.0782,  0.0448,  0.0446,  0.0388,  0.0441,\n",
       "                       0.0404,  0.0505,  0.0599,  0.0449,  0.0312,  0.0405,  0.0414, -0.0082,\n",
       "                       0.0360,  0.0532,  0.0405,  0.0445,  0.0048,  0.0444,  0.0359,  0.0608,\n",
       "                       0.0441,  0.0401,  0.0456,  0.0439,  0.0468,  0.0495,  0.0600, -0.0095,\n",
       "                       0.0396,  0.0403,  0.0434,  0.0433,  0.0485,  0.0404,  0.0493,  0.0473,\n",
       "                       0.0511,  0.0866,  0.0470,  0.0475,  0.0377,  0.0797,  0.0482,  0.0401,\n",
       "                       0.0475,  0.0422,  0.0435,  0.0569,  0.0743,  0.1024,  0.0449,  0.0446,\n",
       "                       0.0507,  0.0143,  0.0760,  0.0413,  0.0435,  0.0390,  0.0396,  0.0191,\n",
       "                       0.0462,  0.0564,  0.0396,  0.0695,  0.0438,  0.0474,  0.0498,  0.0406,\n",
       "                       0.0414,  0.0450,  0.0401,  0.0411,  0.0816,  0.0400,  0.0356,  0.0367,\n",
       "                       0.0431,  0.0458,  0.0471,  0.0602,  0.0038,  0.0798,  0.0514,  0.0410,\n",
       "                       0.0035,  0.0403,  0.0589,  0.0291,  0.0481,  0.0403,  0.0389,  0.0407,\n",
       "                       0.0389,  0.0359,  0.0485,  0.0370,  0.0414,  0.0423,  0.0395,  0.0450,\n",
       "                       0.0218,  0.0492,  0.0400,  0.0660, -0.0205,  0.0532,  0.0418,  0.0421,\n",
       "                       0.0006,  0.0650,  0.0418,  0.0501,  0.0761,  0.0801,  0.0388,  0.0487])),\n",
       "             ('decisions_q.2.bn2.running_mean',\n",
       "              tensor([ 0.4874, -0.1873,  0.0185,  0.0756, -0.0525,  0.0344,  0.1214, -0.1324,\n",
       "                       0.2155,  0.0272, -0.0139,  0.1476,  0.3603, -0.1388,  0.1995, -0.1654,\n",
       "                       0.0096,  0.0559, -0.2012, -0.1060,  0.1662,  0.0329,  0.3092,  0.2436,\n",
       "                       0.0211, -0.1290,  0.2194,  0.5097, -0.1919, -0.1884, -0.0603,  0.3877,\n",
       "                       0.4140,  0.0593,  0.0432, -0.1237, -0.1584, -0.0706,  0.0831, -0.0519,\n",
       "                       0.2723, -0.0945,  0.1311,  0.0663,  0.0525,  0.4505,  0.0397, -0.1293,\n",
       "                       0.0706, -0.1400, -0.0677,  0.2583,  0.0755,  0.2072, -0.1092, -0.0300,\n",
       "                       0.1243,  0.3457, -0.1877,  0.4626,  0.2664,  0.0835,  0.1580, -0.0225,\n",
       "                       0.0247, -0.0781,  0.0130,  0.3250,  0.3227, -0.1052,  0.1195, -0.1644,\n",
       "                      -0.1304,  0.2621,  0.1146,  0.3036, -0.0270,  0.1448,  0.1650,  0.1295,\n",
       "                      -0.1044, -0.1748,  0.2117,  0.2868, -0.0444,  0.2032,  0.3063,  0.1538,\n",
       "                      -0.0321, -0.1749, -0.0674,  0.0256,  0.0531,  0.0836,  0.2809,  0.0942,\n",
       "                       0.4163, -0.0332,  0.2635,  0.0235, -0.0181, -0.0615, -0.2417,  0.1927,\n",
       "                       0.2837,  0.2502, -0.0975,  0.0537,  0.0636, -0.1453,  0.1748, -0.0686,\n",
       "                       0.1884, -0.2793,  0.0154,  0.1909,  0.1462, -0.2318, -0.0229,  0.4381,\n",
       "                      -0.0686, -0.0765, -0.0757, -0.1056,  0.3211,  0.2526,  0.1277, -0.0356])),\n",
       "             ('decisions_q.2.bn2.running_var',\n",
       "              tensor([0.2930, 0.5208, 0.3226, 0.7628, 0.9350, 0.6479, 1.7034, 0.4514, 0.6052,\n",
       "                      0.5729, 0.8161, 0.5282, 0.4920, 0.3463, 0.4837, 0.6271, 0.5249, 0.3846,\n",
       "                      0.3835, 0.7642, 1.1172, 0.7457, 0.4262, 1.3869, 0.4346, 1.2098, 0.6244,\n",
       "                      0.7375, 1.5982, 0.6609, 0.6067, 0.3592, 0.3978, 0.7453, 0.4815, 0.8370,\n",
       "                      0.3150, 0.7816, 0.5208, 1.0797, 0.5452, 0.3928, 0.5877, 1.0564, 0.9741,\n",
       "                      1.0720, 0.5513, 0.8197, 0.6349, 0.3667, 0.7032, 0.4276, 1.4351, 0.7805,\n",
       "                      0.4826, 1.1134, 0.9509, 0.7261, 0.7934, 0.5922, 0.3890, 1.0453, 0.4293,\n",
       "                      1.2314, 1.3019, 0.8833, 0.6633, 1.3705, 0.7697, 1.0587, 1.1322, 0.6055,\n",
       "                      1.6942, 1.7569, 0.8857, 0.6731, 0.5730, 1.1555, 0.7858, 0.6166, 0.4887,\n",
       "                      0.9562, 0.7961, 0.1557, 1.0349, 1.3838, 0.6639, 0.7508, 1.2680, 0.9813,\n",
       "                      1.2402, 0.7951, 0.8752, 0.9728, 0.4759, 0.9049, 0.7669, 0.6962, 0.4916,\n",
       "                      0.2818, 1.0253, 0.9484, 0.9832, 0.5485, 0.4257, 0.7675, 0.6131, 0.5655,\n",
       "                      0.7183, 0.8275, 1.2242, 0.8486, 0.8216, 0.7346, 0.8559, 1.3968, 0.1412,\n",
       "                      1.3360, 1.0244, 1.2229, 1.1172, 0.4028, 0.8364, 1.1231, 0.8203, 0.4027,\n",
       "                      1.3067, 1.1341])),\n",
       "             ('decisions_q.2.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.2.dense3.weight',\n",
       "              tensor([[-0.0948,  0.0991,  0.0947,  0.1117,  0.0718, -0.1142,  0.1150,  0.1019,\n",
       "                       -0.0463, -0.0716,  0.0846,  0.0487, -0.0930,  0.1253, -0.1001,  0.1323,\n",
       "                       -0.1012,  0.0858,  0.0586,  0.1156, -0.0689, -0.0786, -0.0589,  0.0808,\n",
       "                       -0.1312, -0.0691, -0.0948, -0.0966, -0.0596, -0.0810,  0.0893, -0.0540,\n",
       "                       -0.0645, -0.0884, -0.0644,  0.1293,  0.0886,  0.0830, -0.0916,  0.0642,\n",
       "                       -0.0871, -0.0941, -0.0800, -0.1114,  0.1025, -0.1177,  0.0764,  0.0868,\n",
       "                        0.0756, -0.0567,  0.0834, -0.0629, -0.1122,  0.0672,  0.0781,  0.0993,\n",
       "                       -0.0675, -0.0728,  0.1017, -0.0640, -0.0477, -0.0538,  0.1146,  0.1166,\n",
       "                       -0.0639,  0.0739,  0.0513, -0.0785, -0.0823, -0.1100, -0.1017,  0.0583,\n",
       "                        0.1096,  0.0715, -0.0924, -0.0554,  0.1291,  0.1205, -0.0866, -0.1114,\n",
       "                        0.1171, -0.0790, -0.1289, -0.0766,  0.0494,  0.1224, -0.1279, -0.1198,\n",
       "                       -0.0881,  0.0927,  0.0922,  0.0552,  0.0548,  0.0540, -0.0614, -0.1304,\n",
       "                       -0.0608, -0.0722, -0.0532,  0.0368,  0.0772, -0.1009, -0.0943, -0.0760,\n",
       "                       -0.0854, -0.1015,  0.0812,  0.0870, -0.0763,  0.1102, -0.1166,  0.1094,\n",
       "                        0.0853,  0.1296, -0.1177,  0.0652, -0.0179, -0.0710,  0.1355,  0.1376,\n",
       "                        0.0608,  0.0517, -0.0952, -0.0912, -0.0478,  0.0494, -0.1218,  0.0855]])),\n",
       "             ('decisions_q.2.dense3.bias', tensor([0.0542])),\n",
       "             ('decoders.3.dense1.weight',\n",
       "              tensor([[ 0.1538,  0.1489, -0.0589,  ..., -0.1515,  0.1537, -0.0335],\n",
       "                      [-0.1758, -0.1180, -0.0397,  ...,  0.0763,  0.0905, -0.0491],\n",
       "                      [ 0.0676, -0.0492,  0.1592,  ...,  0.1134,  0.0822,  0.1360],\n",
       "                      ...,\n",
       "                      [ 0.1853, -0.1384,  0.0800,  ..., -0.0416,  0.1479,  0.0134],\n",
       "                      [ 0.0082, -0.0952,  0.0357,  ..., -0.0603, -0.0207, -0.1577],\n",
       "                      [-0.0732, -0.0302,  0.1144,  ...,  0.0936,  0.0003, -0.1791]])),\n",
       "             ('decoders.3.bn1.weight',\n",
       "              tensor([1.0210, 0.9921, 0.9900, 1.0148, 0.9955, 0.9880, 1.0092, 1.0229, 0.9931,\n",
       "                      0.9858, 0.9964, 0.9921, 0.9905, 1.0013, 1.0246, 1.0225, 1.0046, 0.9865,\n",
       "                      1.0179, 1.0056, 1.0191, 0.9914, 0.9848, 1.0235, 0.9877, 0.9896, 0.9859,\n",
       "                      0.9866, 0.9972, 0.9882, 0.9992, 0.9891, 1.0098, 1.0099, 0.9967, 0.9931,\n",
       "                      0.9933, 1.0012, 0.9939, 0.9916, 1.0024, 1.0118, 0.9932, 0.9865, 1.0031,\n",
       "                      0.9840, 0.9944, 0.9844, 1.0006, 0.9849, 0.9911, 1.0032, 0.9881, 1.0034,\n",
       "                      1.0020, 0.9910, 1.0129, 0.9924, 0.9987, 0.9982, 0.9795, 0.9917, 1.0140,\n",
       "                      0.9766, 0.9824, 1.0120, 0.9935, 1.0136, 0.9972, 0.9968, 0.9981, 1.0190,\n",
       "                      0.9898, 0.9885, 1.0026, 0.9852, 0.9856, 1.0020, 1.0042, 0.9946, 0.9983,\n",
       "                      0.9955, 1.0156, 0.9924, 1.0139, 1.0201, 1.0028, 1.0099, 1.0125, 0.9934,\n",
       "                      0.9827, 1.0073, 0.9858, 1.0029, 0.9985, 0.9929, 1.0008, 0.9912, 1.0067,\n",
       "                      0.9808, 0.9846, 0.9888, 0.9849, 0.9870, 0.9999, 0.9901, 0.9839, 1.0056,\n",
       "                      0.9933, 1.0011, 0.9883, 0.9831, 1.0001, 1.0081, 0.9919, 0.9902, 0.9976,\n",
       "                      1.0253, 0.9839, 1.0033, 0.9953, 0.9972, 1.0030, 0.9887, 1.0009, 0.9857,\n",
       "                      1.0146, 1.0078])),\n",
       "             ('decoders.3.bn1.bias',\n",
       "              tensor([-1.6631e-04, -4.6354e-03, -1.3290e-02,  5.7933e-04, -4.2485e-03,\n",
       "                      -8.1933e-03,  8.8537e-03, -1.2821e-03, -6.6210e-04, -1.0122e-02,\n",
       "                      -7.5679e-03,  1.0344e-02, -4.2023e-03,  2.0150e-02,  2.0666e-04,\n",
       "                      -6.6070e-03, -7.2478e-03, -5.4377e-03, -4.9635e-03, -6.9298e-03,\n",
       "                      -9.6819e-03, -5.2341e-03, -1.2476e-02, -1.9952e-03, -5.7609e-04,\n",
       "                      -9.0782e-03, -1.1755e-02, -1.3209e-02, -2.8737e-03, -1.9286e-02,\n",
       "                      -6.5876e-03, -1.4778e-02, -5.4022e-03,  4.8809e-03,  4.1718e-03,\n",
       "                       7.4449e-03, -7.1942e-03,  7.4001e-03, -5.1852e-03, -9.9528e-03,\n",
       "                       1.5312e-02,  6.5982e-03, -5.6317e-04, -1.2279e-02, -3.4132e-03,\n",
       "                      -1.2873e-02, -4.2640e-03,  9.9952e-04,  7.8245e-03, -3.4663e-03,\n",
       "                      -2.3028e-03,  1.1833e-02, -1.2943e-02,  9.9983e-03, -5.7875e-03,\n",
       "                      -1.1295e-02, -3.2991e-03, -9.5153e-03, -9.2485e-03, -9.9399e-03,\n",
       "                      -1.6986e-02, -5.8327e-03,  4.6138e-03, -2.0693e-02, -1.0460e-02,\n",
       "                      -4.9439e-04,  1.4394e-03, -4.3570e-03,  5.9118e-04, -4.5341e-03,\n",
       "                       5.2042e-04,  6.7942e-03, -2.0214e-03, -1.2600e-02,  1.9806e-02,\n",
       "                      -7.9704e-03, -1.6391e-02,  7.4508e-03,  1.3016e-03,  1.2570e-02,\n",
       "                       4.0927e-03, -2.4821e-03, -1.0252e-02,  5.4012e-03, -2.2046e-03,\n",
       "                       1.8588e-03, -2.8465e-03,  7.1661e-03,  6.6117e-03, -1.7713e-02,\n",
       "                      -2.2134e-02,  1.4380e-02, -1.2064e-02,  9.0289e-03,  6.9209e-03,\n",
       "                      -1.0708e-02,  7.9484e-03, -4.2937e-03, -2.4424e-03, -2.3250e-02,\n",
       "                      -5.3267e-04, -8.3929e-03, -1.3334e-02, -1.5530e-02,  9.3390e-03,\n",
       "                      -2.3688e-03, -1.1002e-02,  7.3199e-04, -9.9106e-03,  9.1385e-04,\n",
       "                      -6.8083e-03,  5.7414e-03,  2.0416e-02, -3.9008e-03, -2.5567e-03,\n",
       "                      -5.6025e-03,  4.1051e-04,  9.1510e-04, -1.4034e-02, -4.2614e-03,\n",
       "                      -6.5468e-03,  6.2291e-05, -8.5549e-03, -5.1750e-04, -8.6839e-03,\n",
       "                      -9.9529e-03,  8.0822e-03,  5.8340e-04])),\n",
       "             ('decoders.3.bn1.running_mean',\n",
       "              tensor([-0.3459,  0.2327, -0.0366, -0.2517,  0.0992,  0.1110,  0.1514, -0.2730,\n",
       "                      -0.1390,  0.0897, -0.2841,  0.2264,  0.0709,  0.3480, -0.4618, -0.4233,\n",
       "                      -0.2778,  0.0574, -0.2781, -0.1930, -0.3950,  0.1318, -0.1253, -0.3279,\n",
       "                       0.0949, -0.1858, -0.0098, -0.0337, -0.1625, -0.0136, -0.2340,  0.1149,\n",
       "                      -0.3639, -0.3616,  0.2913,  0.2627,  0.0487,  0.1322, -0.3006, -0.2532,\n",
       "                       0.0940, -0.2625, -0.0240,  0.0629, -0.0718, -0.1205,  0.0875,  0.0517,\n",
       "                      -0.0324,  0.1336,  0.0859, -0.0611, -0.0326,  0.2510, -0.3360,  0.0344,\n",
       "                      -0.1421, -0.0872, -0.2058, -0.3166, -0.0020, -0.3210, -0.1904, -0.0023,\n",
       "                       0.1979, -0.2380,  0.2485, -0.3225,  0.3779,  0.0277, -0.0370, -0.2372,\n",
       "                       0.1846, -0.1164, -0.0215, -0.0544,  0.0830,  0.0853,  0.0645,  0.2103,\n",
       "                       0.0056, -0.2511, -0.3963,  0.4105, -0.3532, -0.4019, -0.2900, -0.2532,\n",
       "                      -0.2785, -0.4088, -0.0639,  0.2135, -0.0724, -0.0118,  0.2388, -0.0257,\n",
       "                       0.0663,  0.1236, -0.2576,  0.0020, -0.0747,  0.0563, -0.0782, -0.2664,\n",
       "                       0.0720,  0.0398,  0.2354, -0.1944, -0.2623,  0.1030, -0.0729,  0.1297,\n",
       "                       0.3367, -0.1808,  0.0022,  0.0826, -0.2419, -0.3687,  0.0394, -0.1455,\n",
       "                       0.0328,  0.1826, -0.2487, -0.0353, -0.0816,  0.0139, -0.2546, -0.2884])),\n",
       "             ('decoders.3.bn1.running_var',\n",
       "              tensor([0.9979, 0.8030, 0.1131, 0.9312, 0.1482, 0.1985, 0.2073, 1.2368, 0.3363,\n",
       "                      0.1397, 0.6198, 0.4499, 0.0812, 0.4273, 1.0486, 1.2058, 0.8097, 0.2084,\n",
       "                      0.9611, 0.4828, 1.1706, 0.1208, 0.1257, 1.5271, 0.1753, 0.3254, 0.1808,\n",
       "                      0.2790, 0.1503, 0.2761, 0.2238, 0.6378, 0.8006, 0.6483, 0.6763, 0.9285,\n",
       "                      0.1517, 0.2735, 0.5387, 0.3882, 0.4538, 0.5085, 0.1782, 0.1945, 0.1657,\n",
       "                      0.2619, 0.2617, 0.3722, 0.3842, 0.2223, 0.1696, 0.1597, 0.1383, 0.3066,\n",
       "                      0.6475, 0.1525, 0.6945, 0.1549, 0.4454, 0.4961, 0.1802, 0.5803, 0.7426,\n",
       "                      0.1409, 0.2657, 0.5750, 0.3313, 0.9971, 0.2347, 0.1211, 0.2106, 0.3972,\n",
       "                      0.1438, 0.1900, 0.1129, 0.2039, 0.1371, 0.1077, 0.2283, 0.2679, 0.0759,\n",
       "                      0.1290, 1.0358, 0.6253, 0.8050, 0.7210, 0.4843, 0.3222, 1.0233, 1.0259,\n",
       "                      0.1338, 0.3122, 0.1987, 0.2025, 0.1771, 0.1174, 1.1461, 0.1472, 0.7666,\n",
       "                      0.1448, 0.1148, 0.1208, 0.1479, 0.2035, 0.3052, 0.1758, 0.1777, 0.5662,\n",
       "                      0.4849, 0.1840, 0.2050, 0.2128, 0.5662, 0.6655, 0.1272, 0.3623, 0.3654,\n",
       "                      1.0873, 0.0947, 0.4331, 0.1726, 0.7663, 0.8432, 0.1128, 0.3105, 0.1070,\n",
       "                      0.3250, 0.3975])),\n",
       "             ('decoders.3.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense2.weight',\n",
       "              tensor([[ 0.0506, -0.0235, -0.0495,  ..., -0.0329, -0.0391,  0.0618],\n",
       "                      [ 0.0631, -0.0726,  0.0134,  ..., -0.0648, -0.1042, -0.0932],\n",
       "                      [-0.0011, -0.0417, -0.0009,  ...,  0.0755, -0.0077,  0.0817],\n",
       "                      ...,\n",
       "                      [ 0.0162, -0.0135, -0.0234,  ...,  0.0761,  0.0420, -0.0851],\n",
       "                      [ 0.0313,  0.0073, -0.0376,  ...,  0.0322,  0.0884,  0.0315],\n",
       "                      [-0.0126, -0.0822,  0.0458,  ...,  0.0856,  0.0732, -0.0219]])),\n",
       "             ('decoders.3.bn2.weight',\n",
       "              tensor([0.9957, 0.9769, 1.0131, 1.0243, 0.9946, 1.0009, 0.9965, 0.9806, 0.9943,\n",
       "                      0.9819, 1.0018, 0.9884, 1.0179, 1.0084, 0.9905, 0.9931, 1.0009, 0.9917,\n",
       "                      1.0145, 0.9836, 0.9949, 0.9943, 1.0006, 0.9830, 0.9979, 0.9953, 0.9997,\n",
       "                      0.9914, 0.9998, 0.9891, 0.9986, 0.9946, 0.9845, 0.9911, 0.9909, 0.9917,\n",
       "                      1.0023, 1.0000, 1.0082, 0.9868, 0.9959, 1.0124, 0.9895, 1.0123, 0.9935,\n",
       "                      0.9902, 0.9986, 0.9965, 0.9886, 0.9863, 1.0336, 0.9912, 0.9796, 0.9792,\n",
       "                      0.9935, 0.9856, 0.9961, 0.9946, 0.9911, 1.0054, 1.0202, 0.9891, 0.9889,\n",
       "                      1.0075, 0.9973, 0.9891, 0.9959, 0.9985, 1.0086, 0.9932, 1.0199, 0.9884,\n",
       "                      0.9994, 1.0059, 0.9988, 0.9850, 0.9797, 1.0007, 0.9871, 0.9906, 1.0006,\n",
       "                      1.0048, 1.0181, 1.0289, 1.0236, 1.0005, 1.0002, 1.0013, 0.9933, 0.9901,\n",
       "                      1.0088, 1.0133, 0.9892, 1.0054, 0.9924, 1.0003, 0.9939, 0.9866, 0.9880,\n",
       "                      1.0001, 0.9915, 0.9968, 0.9975, 0.9834, 1.0123, 1.0077, 0.9814, 0.9984,\n",
       "                      0.9941, 1.0107, 0.9944, 0.9937, 0.9997, 0.9899, 0.9974, 1.0209, 1.0161,\n",
       "                      1.0219, 1.0023, 0.9822, 0.9870, 1.0180, 1.0131, 1.0093, 1.0092, 0.9952,\n",
       "                      0.9924, 1.0199, 0.9926, 0.9899, 0.9951, 1.0240, 0.9849, 0.9881, 0.9915,\n",
       "                      1.0080, 1.0051, 1.0010, 1.0089, 1.0183, 0.9882, 0.9928, 0.9854, 0.9930,\n",
       "                      1.0121, 1.0088, 1.0231, 1.0139, 0.9989, 0.9920, 0.9953, 0.9791, 0.9990,\n",
       "                      0.9900, 1.0049, 1.0059, 0.9959, 0.9810, 0.9982, 0.9981, 1.0101, 0.9923,\n",
       "                      0.9864, 1.0081, 0.9944, 0.9905, 0.9981, 0.9930, 0.9978, 1.0098, 0.9828,\n",
       "                      1.0074, 0.9979, 0.9915, 1.0053, 1.0017, 0.9876, 1.0152, 1.0010, 0.9911,\n",
       "                      1.0001, 0.9945, 1.0157, 0.9903, 1.0205, 1.0008, 0.9778, 1.0047, 1.0004,\n",
       "                      1.0185, 0.9786, 1.0119, 0.9942, 0.9990, 0.9990, 1.0155, 0.9878, 1.0037,\n",
       "                      0.9799, 1.0177, 0.9980, 0.9843, 1.0186, 1.0130, 1.0041, 1.0011, 0.9886,\n",
       "                      0.9897, 0.9839, 0.9809, 0.9973, 1.0086, 1.0124, 0.9975, 0.9858, 1.0009,\n",
       "                      0.9961, 0.9954, 0.9880, 0.9997, 0.9949, 0.9898, 0.9913, 1.0170, 0.9948,\n",
       "                      0.9955, 0.9882, 0.9975, 0.9870, 1.0186, 1.0159, 0.9842, 1.0054, 1.0219,\n",
       "                      0.9798, 0.9813, 0.9918, 1.0214, 0.9895, 0.9941, 0.9964, 0.9800, 0.9904,\n",
       "                      1.0143, 1.0027, 0.9899, 0.9921, 0.9900, 0.9887, 1.0103, 1.0204, 1.0067,\n",
       "                      0.9942, 0.9851, 1.0108, 0.9920])),\n",
       "             ('decoders.3.bn2.bias',\n",
       "              tensor([-2.5574e-03, -1.4156e-02, -5.9787e-03, -6.7769e-03,  8.3175e-03,\n",
       "                      -6.6071e-03, -5.8910e-03, -1.3551e-02, -2.3634e-03, -1.1503e-02,\n",
       "                       1.2130e-03, -1.0093e-02, -6.4189e-03,  2.1501e-02, -6.3631e-03,\n",
       "                      -6.7274e-03,  1.8312e-03,  1.4972e-02,  6.3740e-03,  1.1291e-02,\n",
       "                       1.3334e-02, -8.1705e-04, -7.5798e-03, -8.4616e-03,  1.2276e-02,\n",
       "                       2.4019e-03, -4.4159e-03, -1.5174e-02, -5.5839e-03, -3.0590e-04,\n",
       "                       3.2711e-03,  5.8323e-03, -1.3982e-02,  1.1198e-02, -7.6166e-03,\n",
       "                      -2.4412e-04,  8.3972e-03, -1.2458e-02, -2.1271e-03, -1.7055e-02,\n",
       "                       7.6317e-04, -4.2886e-04, -9.0267e-03, -4.0855e-03, -9.2570e-03,\n",
       "                      -1.0409e-02,  9.8672e-03,  5.9317e-03, -1.0083e-02, -1.6781e-02,\n",
       "                      -2.0504e-04,  9.0900e-03, -1.7769e-02, -2.1967e-02,  1.3728e-02,\n",
       "                      -9.1278e-03,  4.2571e-03, -8.4941e-03,  7.0973e-05, -5.4396e-03,\n",
       "                       3.5165e-04,  1.3162e-03, -1.3224e-02,  1.8304e-03, -9.1763e-04,\n",
       "                      -1.1728e-02,  2.9415e-03, -3.1951e-03, -5.8434e-03,  1.1153e-02,\n",
       "                       1.5874e-02, -1.2307e-02, -9.5150e-03, -8.1018e-03,  1.4383e-02,\n",
       "                      -3.4226e-03, -1.6438e-02,  1.9897e-03, -8.7725e-03, -1.1678e-02,\n",
       "                       1.8796e-02, -1.3539e-02,  9.9881e-04,  8.1314e-03, -4.4974e-03,\n",
       "                      -2.9017e-03,  1.5363e-02,  5.5088e-03,  2.3777e-03,  1.6662e-02,\n",
       "                       1.1800e-02,  1.4793e-02, -5.6616e-03, -1.6917e-02, -6.7222e-03,\n",
       "                       9.2308e-03, -5.6072e-03, -2.9914e-03, -6.9390e-03,  1.1521e-02,\n",
       "                      -4.4882e-03, -5.2209e-03,  1.3284e-02, -1.7889e-02, -5.8637e-03,\n",
       "                       1.4468e-02, -1.4831e-02,  4.7312e-03, -7.8661e-03,  4.9727e-03,\n",
       "                      -1.1984e-03, -2.3894e-03,  8.0368e-03, -2.1161e-02,  5.5150e-04,\n",
       "                      -6.3152e-03, -7.1242e-03, -1.5317e-03,  1.0948e-02, -1.5486e-02,\n",
       "                      -2.5188e-03,  1.4806e-03,  1.5781e-02, -2.4233e-03, -6.7003e-04,\n",
       "                      -5.9111e-03, -1.4800e-02,  2.9965e-03, -7.2793e-03, -1.3441e-03,\n",
       "                      -2.3487e-03,  5.7188e-03, -9.0886e-05, -4.8678e-03, -1.0701e-02,\n",
       "                       2.0312e-03,  2.0396e-02, -1.5695e-03,  9.5715e-03, -8.7362e-03,\n",
       "                      -1.4643e-02, -7.9902e-03, -9.5057e-03,  7.4173e-03,  3.2213e-03,\n",
       "                       5.5581e-03, -1.0729e-02,  1.3815e-02, -8.2631e-03, -4.2482e-03,\n",
       "                       6.0013e-03, -1.9630e-02,  1.2456e-03,  1.5282e-03, -1.2525e-02,\n",
       "                      -1.0764e-02, -8.3298e-03, -2.1303e-02, -3.8357e-03,  1.2816e-02,\n",
       "                      -1.1601e-03, -7.2392e-03, -1.4072e-02, -6.2921e-03, -7.0363e-03,\n",
       "                       7.4343e-04,  1.6773e-03, -2.9496e-03, -7.8301e-04,  6.6300e-04,\n",
       "                       6.0541e-04, -2.2597e-04,  1.2398e-02, -8.7328e-04, -5.1180e-04,\n",
       "                      -8.2807e-03, -1.3723e-03,  4.7190e-03,  1.1394e-02,  3.5233e-03,\n",
       "                      -5.5104e-03, -2.0074e-03, -1.0233e-02, -7.4750e-04,  2.3012e-03,\n",
       "                       2.7728e-03, -1.6928e-02,  6.9095e-03,  7.0714e-03, -5.9102e-06,\n",
       "                      -1.4726e-02,  1.4018e-02, -9.1667e-03,  3.1300e-03, -5.5777e-03,\n",
       "                      -1.2623e-02, -1.2737e-02, -1.0162e-03, -1.9546e-02, -6.2832e-03,\n",
       "                      -3.1662e-03, -1.4111e-02, -7.5138e-03, -1.0489e-02,  7.2462e-03,\n",
       "                      -1.0612e-03, -6.9512e-03, -5.4802e-03, -9.9499e-03, -2.3902e-02,\n",
       "                      -1.2340e-02, -2.7858e-04, -2.3092e-03, -3.8529e-03, -9.0111e-03,\n",
       "                      -5.7809e-03, -1.2328e-03, -6.9770e-04, -1.6730e-02,  2.8902e-03,\n",
       "                      -3.4720e-03, -1.4386e-02,  4.0309e-04, -5.9442e-03,  1.2000e-04,\n",
       "                      -2.9413e-03, -8.9670e-03,  4.7854e-03, -6.2540e-03, -1.1736e-02,\n",
       "                      -2.9933e-03, -3.7420e-03,  2.4180e-02,  4.0811e-03, -2.2969e-02,\n",
       "                      -2.0599e-02,  6.0175e-04,  7.8670e-03, -1.0111e-03, -5.5283e-03,\n",
       "                      -3.4033e-04, -1.0108e-02, -7.7287e-03,  5.2335e-03,  1.0987e-02,\n",
       "                      -8.1935e-03, -8.0775e-03, -1.3440e-02,  1.3441e-03, -6.0459e-03,\n",
       "                       2.4929e-03, -6.1200e-03,  8.4748e-03, -8.5531e-03, -2.9806e-03,\n",
       "                      -5.7849e-03])),\n",
       "             ('decoders.3.bn2.running_mean',\n",
       "              tensor([ 0.1240,  0.0489,  0.1517,  0.1893, -0.1224, -0.1035, -0.1670,  0.0697,\n",
       "                       0.0959,  0.0680,  0.0202,  0.1521,  0.3655, -0.3113, -0.0073,  0.0161,\n",
       "                      -0.2966, -0.0919,  0.0866, -0.2259, -0.1815, -0.1423, -0.2735, -0.0550,\n",
       "                      -0.2053, -0.3193,  0.1141,  0.0445,  0.0467, -0.0031,  0.1950, -0.2737,\n",
       "                      -0.1543, -0.1074,  0.0772,  0.3100,  0.3340, -0.0488,  0.2075,  0.0628,\n",
       "                      -0.4049,  0.3359,  0.0697,  0.2752,  0.1477,  0.1749,  0.0168,  0.0303,\n",
       "                       0.0737,  0.0485,  0.4402, -0.0988,  0.0405, -0.0356, -0.0753, -0.2488,\n",
       "                      -0.0078, -0.0342,  0.0422,  0.2045,  0.1951,  0.1627, -0.1587,  0.1083,\n",
       "                      -0.0406, -0.0451, -0.2090,  0.0623,  0.1708, -0.4025,  0.0756, -0.0607,\n",
       "                       0.1072,  0.0613, -0.4113, -0.0942,  0.0862,  0.1766,  0.2186, -0.1798,\n",
       "                      -0.0808,  0.0813, -0.1133,  0.1515,  0.1935,  0.3203, -0.3416, -0.1468,\n",
       "                      -0.2814, -0.3227, -0.3379,  0.0287, -0.0562,  0.1386, -0.3737,  0.2739,\n",
       "                       0.0952, -0.2245, -0.0291, -0.0301,  0.0050,  0.2945, -0.1081,  0.0978,\n",
       "                      -0.0629,  0.0779, -0.4053, -0.1423, -0.0333,  0.1939,  0.0431, -0.0291,\n",
       "                      -0.3491, -0.0574, -0.1007,  0.0221,  0.1703,  0.4328,  0.0668, -0.2482,\n",
       "                      -0.1681,  0.3491,  0.1274,  0.1758, -0.1128,  0.0220, -0.0154,  0.2516,\n",
       "                       0.0847, -0.0940, -0.0850,  0.2377, -0.0211, -0.1928,  0.0658,  0.2805,\n",
       "                      -0.3006, -0.0833, -0.3948,  0.1752,  0.1055,  0.1802, -0.0119, -0.1184,\n",
       "                       0.2602,  0.1780,  0.4108,  0.2153,  0.0604,  0.3691, -0.2516, -0.1474,\n",
       "                      -0.1628, -0.1378,  0.4918,  0.0218, -0.0104,  0.0349,  0.1603, -0.1854,\n",
       "                       0.1685,  0.1646,  0.1021,  0.4928,  0.2194,  0.0865,  0.1665,  0.0546,\n",
       "                      -0.1079,  0.2597,  0.0737,  0.3055, -0.2594,  0.0202,  0.1997,  0.4341,\n",
       "                      -0.1473,  0.1786, -0.2494, -0.0517,  0.1644,  0.0632,  0.1893,  0.0669,\n",
       "                       0.2594,  0.0628, -0.0827,  0.2439, -0.1650,  0.5255,  0.0475, -0.2098,\n",
       "                      -0.0412, -0.2537,  0.2643,  0.4043,  0.0053,  0.0150, -0.0119,  0.2743,\n",
       "                       0.0713, -0.0707,  0.2905,  0.2842, -0.5122, -0.1628,  0.0771, -0.0388,\n",
       "                      -0.2544, -0.1680,  0.3380, -0.0490, -0.0822,  0.1047,  0.0556,  0.3116,\n",
       "                      -0.2678, -0.1756,  0.0285,  0.4097,  0.1882, -0.0180, -0.0948,  0.4226,\n",
       "                       0.0265,  0.1655,  0.0815, -0.1456, -0.0415,  0.3148,  0.3562, -0.1896,\n",
       "                      -0.3291,  0.0722,  0.3255,  0.1289, -0.3196, -0.0016, -0.1177, -0.1153,\n",
       "                      -0.3310,  0.0062,  0.2679,  0.1508, -0.2030,  0.0473, -0.0742,  0.2498,\n",
       "                      -0.1733,  0.2847,  0.1060, -0.0506, -0.3057,  0.0788, -0.2566, -0.1609])),\n",
       "             ('decoders.3.bn2.running_var',\n",
       "              tensor([0.1606, 0.2064, 0.9485, 0.7989, 0.0754, 0.7366, 0.0844, 0.0917, 0.1519,\n",
       "                      0.0766, 0.3175, 0.0925, 0.2428, 0.0616, 0.2172, 0.2396, 0.3144, 0.4491,\n",
       "                      0.4741, 0.1092, 0.3998, 0.3090, 0.2465, 0.0897, 0.6293, 0.2202, 0.5443,\n",
       "                      0.3403, 0.2805, 0.0586, 0.3202, 0.0980, 0.1214, 0.2630, 0.1223, 0.2219,\n",
       "                      0.6526, 0.7829, 0.2531, 0.1412, 0.1289, 0.4378, 0.1330, 0.5236, 0.1644,\n",
       "                      0.2496, 0.2557, 0.5363, 0.2059, 0.1129, 0.3132, 0.4381, 0.1438, 0.0967,\n",
       "                      0.4281, 0.1771, 0.5612, 0.1268, 0.3670, 0.3254, 0.5593, 0.0943, 0.1566,\n",
       "                      0.5807, 0.6467, 0.3788, 0.9206, 0.5995, 0.2986, 0.2170, 1.1376, 0.1191,\n",
       "                      0.7514, 0.9385, 0.3105, 0.0989, 0.2752, 0.2928, 0.1765, 0.4237, 0.7484,\n",
       "                      0.3947, 0.9789, 0.4413, 0.7022, 0.3402, 0.4333, 0.0999, 0.1408, 0.1587,\n",
       "                      0.0914, 0.3023, 0.1586, 0.6364, 0.0824, 0.2569, 0.2850, 0.1342, 0.7783,\n",
       "                      0.5234, 0.3524, 0.0964, 0.5174, 0.1602, 0.5687, 0.8225, 0.1469, 0.0891,\n",
       "                      0.1456, 0.2942, 0.5134, 0.1182, 0.5759, 0.5975, 0.4155, 1.1486, 1.2741,\n",
       "                      0.9186, 1.0112, 0.4773, 0.2308, 0.4809, 0.7914, 0.2373, 0.7739, 0.6760,\n",
       "                      0.3381, 1.0633, 0.1940, 0.3370, 0.1644, 0.7469, 0.6170, 0.1004, 0.1839,\n",
       "                      0.3750, 0.6430, 0.4738, 0.1066, 0.5912, 0.0627, 0.2033, 0.2583, 0.0569,\n",
       "                      0.6851, 0.7964, 1.0899, 1.1426, 0.3940, 0.1791, 0.1536, 0.1761, 0.0661,\n",
       "                      0.3683, 0.3459, 0.9637, 0.4535, 0.1130, 0.1122, 0.4595, 0.4410, 0.2999,\n",
       "                      0.1105, 0.2958, 0.1639, 0.1401, 0.2897, 0.1239, 0.1961, 0.5520, 0.5609,\n",
       "                      0.2176, 0.3138, 0.2400, 0.5757, 0.2516, 0.1181, 0.6366, 0.3035, 0.3242,\n",
       "                      0.9220, 0.1981, 0.7606, 0.1297, 0.5819, 0.8038, 0.0887, 0.6728, 0.6278,\n",
       "                      0.5103, 0.2021, 0.0908, 0.2012, 0.1612, 0.4081, 0.7686, 0.0895, 0.3376,\n",
       "                      0.1077, 0.4643, 0.2502, 0.1112, 0.6181, 0.3444, 0.1387, 0.3055, 0.1117,\n",
       "                      0.1268, 0.2316, 0.2180, 0.8258, 1.0145, 0.7495, 0.1086, 0.2446, 0.3504,\n",
       "                      0.2052, 0.2517, 0.1110, 0.0745, 0.2179, 0.0554, 0.3109, 0.6972, 0.4541,\n",
       "                      0.2312, 0.1652, 0.1200, 0.1763, 0.5926, 0.5057, 0.2504, 0.5931, 1.0509,\n",
       "                      0.1765, 0.1435, 0.2644, 0.6178, 0.2451, 0.1480, 0.1443, 0.3785, 0.2116,\n",
       "                      0.6034, 0.0994, 0.2405, 0.3410, 0.2565, 0.1501, 0.7679, 0.7461, 0.6939,\n",
       "                      0.1092, 0.2253, 0.6495, 0.3513])),\n",
       "             ('decoders.3.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense3.weight',\n",
       "              tensor([[-0.0487,  0.0223,  0.0413,  ...,  0.0493,  0.0144, -0.0312],\n",
       "                      [-0.0408,  0.0511,  0.0330,  ...,  0.0017,  0.0389, -0.0206],\n",
       "                      [-0.0485,  0.0417,  0.0670,  ..., -0.0317,  0.0362,  0.0629],\n",
       "                      ...,\n",
       "                      [ 0.0162, -0.0514,  0.0294,  ...,  0.0179,  0.0236,  0.0331],\n",
       "                      [-0.0489, -0.0477,  0.0455,  ...,  0.0470, -0.0348,  0.0566],\n",
       "                      [-0.0264,  0.0137,  0.0227,  ..., -0.0478,  0.0139,  0.0005]])),\n",
       "             ('decoders.3.bn3.weight',\n",
       "              tensor([0.9988, 0.9962, 1.0027, 0.9963, 0.9910, 0.9888, 1.0002, 0.9957, 0.9939,\n",
       "                      0.9967, 1.0003, 0.9922, 0.9746, 0.9805, 1.0283, 0.9964, 0.9827, 0.9982,\n",
       "                      1.0205, 0.9962, 1.0020, 1.0061, 0.9904, 1.0137, 1.0163, 0.9980, 1.0052,\n",
       "                      1.0238, 0.9911, 1.0010, 1.0234, 0.9940, 1.0002, 0.9876, 0.9921, 0.9888,\n",
       "                      0.9887, 0.9828, 1.0199, 0.9918, 1.0192, 0.9730, 0.9989, 0.9945, 1.0222,\n",
       "                      0.9917, 1.0017, 0.9890, 0.9955, 1.0087, 0.9858, 0.9948, 0.9927, 1.0061,\n",
       "                      1.0154, 0.9952, 0.9918, 1.0246, 0.9912, 0.9938, 0.9874, 1.0036, 0.9952,\n",
       "                      0.9971, 1.0009, 0.9866, 0.9867, 1.0230, 1.0018, 0.9916, 1.0101, 0.9933,\n",
       "                      0.9973, 0.9987, 0.9953, 0.9921, 1.0179, 1.0128, 0.9906, 0.9884, 0.9915,\n",
       "                      0.9919, 0.9938, 0.9991, 1.0062, 0.9872, 0.9908, 1.0003, 0.9964, 0.9959,\n",
       "                      0.9941, 1.0255, 1.0077, 0.9901, 0.9862, 0.9960, 0.9855, 0.9922, 0.9864,\n",
       "                      1.0120, 1.0118, 1.0044, 1.0017, 1.0035, 0.9880, 1.0028, 0.9928, 0.9833,\n",
       "                      0.9969, 1.0072, 0.9936, 0.9807, 0.9969, 0.9838, 0.9905, 1.0057, 0.9911,\n",
       "                      1.0289, 0.9900, 0.9952, 0.9924, 0.9972, 0.9932, 1.0213, 1.0049, 1.0116,\n",
       "                      0.9884, 1.0186, 1.0125, 0.9982, 0.9929, 0.9961, 0.9926, 1.0020, 0.9980,\n",
       "                      0.9854, 1.0084, 0.9972, 0.9802, 0.9944, 0.9942, 0.9929, 0.9929, 1.0227,\n",
       "                      0.9978, 1.0143, 1.0012, 0.9845, 0.9856, 0.9841, 1.0068, 1.0013, 0.9950,\n",
       "                      0.9913, 1.0106, 0.9904, 0.9921, 1.0177, 0.9923, 0.9840, 0.9922, 0.9934,\n",
       "                      0.9976, 0.9857, 1.0013, 0.9874, 0.9869, 1.0224, 0.9853, 1.0165, 1.0004,\n",
       "                      0.9957, 0.9990, 0.9895, 1.0099, 0.9877, 0.9998, 1.0189, 0.9918, 0.9902,\n",
       "                      0.9901, 0.9889, 0.9899, 0.9861, 0.9946, 0.9930, 1.0066, 0.9815, 1.0081,\n",
       "                      0.9977, 1.0046, 1.0004, 0.9923, 0.9932, 0.9965, 1.0028, 1.0135, 1.0009,\n",
       "                      1.0077, 1.0081, 0.9919, 0.9835, 0.9817, 1.0260, 1.0233, 0.9946, 0.9991,\n",
       "                      0.9916, 1.0094, 1.0106, 0.9767, 1.0057, 0.9891, 0.9939, 0.9890, 0.9931,\n",
       "                      1.0207, 0.9877, 1.0008, 1.0031, 1.0035, 0.9933, 0.9871, 0.9906, 1.0181,\n",
       "                      1.0029, 0.9871, 1.0154, 0.9973, 1.0160, 0.9982, 0.9903, 0.9868, 0.9937,\n",
       "                      0.9909, 0.9933, 1.0127, 0.9895, 1.0017, 0.9937, 1.0202, 0.9922, 1.0258,\n",
       "                      0.9947, 1.0037, 1.0006, 0.9845, 0.9931, 0.9979, 1.0167, 1.0104, 1.0082,\n",
       "                      1.0073, 0.9846, 1.0011, 0.9954, 1.0030, 1.0043, 0.9918, 1.0153, 0.9985,\n",
       "                      1.0181, 0.9884, 0.9917, 0.9957, 1.0191, 1.0126, 1.0077, 0.9850, 0.9785,\n",
       "                      0.9917, 1.0023, 0.9887, 0.9964, 1.0028, 0.9965, 1.0076, 1.0063, 0.9964,\n",
       "                      1.0202, 1.0173, 0.9986, 1.0027, 0.9910, 0.9934, 0.9946, 0.9977, 1.0025,\n",
       "                      0.9971, 1.0096, 0.9937, 0.9954, 0.9937, 0.9843, 0.9992, 1.0087, 1.0242,\n",
       "                      1.0005, 0.9992, 1.0209, 0.9863, 1.0016, 0.9931, 0.9895, 0.9998, 0.9956,\n",
       "                      0.9989, 1.0121, 0.9919, 1.0174, 1.0053, 0.9934, 0.9866, 0.9981, 0.9909,\n",
       "                      1.0080, 0.9977, 0.9909, 0.9902, 0.9850, 0.9890, 0.9911, 1.0086, 0.9980,\n",
       "                      1.0052, 1.0178, 0.9823, 1.0228, 0.9961, 0.9958, 1.0056, 0.9922, 0.9846,\n",
       "                      1.0002, 1.0198, 0.9922, 0.9957, 0.9938, 0.9930, 1.0029, 0.9892, 1.0183,\n",
       "                      1.0073, 1.0048, 1.0007, 0.9866, 1.0018, 0.9921, 0.9930, 1.0017, 0.9826,\n",
       "                      1.0006, 1.0168, 0.9981, 0.9917, 0.9987, 1.0091, 0.9931, 0.9874, 0.9910,\n",
       "                      1.0072, 0.9938, 0.9945, 1.0061, 0.9965, 0.9876, 0.9948, 1.0093, 0.9905,\n",
       "                      1.0246, 1.0193, 0.9933, 1.0016, 1.0052, 0.9987, 1.0013, 0.9997, 1.0025,\n",
       "                      0.9895, 0.9940, 0.9837, 0.9844, 0.9932, 0.9979, 0.9865, 0.9975, 0.9937,\n",
       "                      0.9972, 1.0046, 0.9853, 0.9826, 1.0239, 0.9973, 0.9924, 1.0069, 0.9943,\n",
       "                      0.9936, 1.0184, 0.9981, 1.0047, 1.0198, 0.9991, 0.9953, 0.9888, 0.9927,\n",
       "                      1.0113, 0.9997, 1.0240, 1.0163, 1.0095, 0.9967, 0.9910, 0.9986, 0.9988,\n",
       "                      0.9972, 0.9943, 0.9980, 0.9873, 1.0010, 0.9916, 1.0085, 0.9983, 0.9900,\n",
       "                      1.0012, 1.0041, 0.9990, 1.0246, 0.9865, 1.0147, 0.9855, 1.0118, 0.9898,\n",
       "                      0.9903, 1.0137, 0.9909, 0.9980, 1.0225, 1.0026, 1.0025, 0.9893, 0.9814,\n",
       "                      1.0016, 0.9927, 1.0249, 0.9893, 0.9907, 1.0028, 0.9969, 0.9931, 1.0049,\n",
       "                      1.0038, 0.9990, 1.0261, 1.0131, 1.0218, 0.9996, 1.0121, 0.9940, 1.0004,\n",
       "                      0.9968, 1.0096, 1.0014, 0.9883, 1.0054, 0.9912, 1.0042, 1.0059, 0.9950,\n",
       "                      0.9711, 0.9914, 0.9967, 0.9951, 1.0005, 0.9947, 0.9800, 1.0068, 1.0134,\n",
       "                      1.0140, 0.9940, 0.9900, 0.9910, 0.9874, 0.9908, 0.9884, 1.0019, 1.0201,\n",
       "                      0.9995, 1.0019, 0.9906, 0.9894, 0.9857, 1.0183, 1.0165, 1.0075, 0.9954,\n",
       "                      1.0134, 1.0012, 0.9862, 1.0122, 1.0043, 0.9910, 0.9997, 1.0032, 0.9905,\n",
       "                      0.9890, 0.9983, 0.9919, 1.0018, 1.0239, 1.0140, 1.0095, 0.9953])),\n",
       "             ('decoders.3.bn3.bias',\n",
       "              tensor([-1.0466e-02, -9.0350e-03,  1.8816e-02, -1.8649e-03,  2.4662e-03,\n",
       "                       4.2287e-03,  2.0701e-02, -8.3036e-03, -1.7271e-02,  4.6751e-03,\n",
       "                       7.5355e-03, -8.8998e-03, -3.4397e-03, -5.6743e-03, -1.0107e-02,\n",
       "                      -2.1310e-02,  4.1048e-03,  5.8842e-03, -1.8549e-02,  8.3515e-03,\n",
       "                      -3.0478e-03,  6.6092e-03,  8.3669e-04, -1.0738e-02, -9.0037e-03,\n",
       "                       7.6583e-03,  1.8010e-02, -1.4028e-02,  7.6872e-03, -1.3442e-02,\n",
       "                      -1.9986e-02,  5.1870e-04,  5.4843e-03, -1.2500e-02,  1.9625e-02,\n",
       "                       3.2391e-03,  1.0090e-04, -4.7605e-03, -8.9560e-03,  1.1991e-02,\n",
       "                      -7.1974e-03, -1.7637e-02, -1.0191e-02, -6.7513e-03, -7.0078e-03,\n",
       "                      -1.0032e-02, -9.4618e-03, -1.9913e-03, -8.6658e-03, -1.1618e-02,\n",
       "                       1.5777e-03,  2.6863e-02,  6.4786e-03, -8.0568e-03, -1.5042e-02,\n",
       "                       1.0647e-02, -4.6962e-03, -1.5782e-02, -2.3089e-03,  2.4344e-03,\n",
       "                      -9.9046e-03,  3.6524e-03, -8.8380e-03,  7.0636e-03,  2.8637e-02,\n",
       "                       5.1029e-04,  1.3830e-02, -1.4447e-02, -1.3354e-02, -6.8859e-03,\n",
       "                      -1.8024e-02,  2.2604e-03, -1.3009e-02, -3.0060e-03,  5.8877e-06,\n",
       "                       4.8189e-03, -1.1301e-02, -1.3962e-02, -3.6777e-03, -1.0802e-02,\n",
       "                       1.5847e-02, -3.3479e-03, -1.0472e-02,  9.3647e-03, -2.0964e-03,\n",
       "                      -6.0961e-03, -1.1885e-02,  2.8380e-03,  1.3859e-02,  7.4377e-03,\n",
       "                       4.7309e-03, -1.2067e-02, -1.5883e-02, -2.4514e-02, -9.1417e-03,\n",
       "                      -3.6445e-03,  6.4062e-03, -3.9425e-03,  8.3946e-03, -1.3724e-02,\n",
       "                      -1.5171e-02, -1.5094e-02, -1.0250e-02,  1.2887e-02, -1.3972e-03,\n",
       "                       8.7402e-03, -9.4422e-03, -6.2117e-03,  1.2050e-02,  1.3954e-03,\n",
       "                      -8.6544e-03, -1.0908e-02,  1.0823e-02,  1.3973e-02, -1.1298e-02,\n",
       "                      -1.4643e-02, -1.1946e-03, -8.2723e-03,  3.5367e-03,  2.2601e-03,\n",
       "                       9.1228e-03,  2.7630e-02,  1.6578e-03, -1.6933e-02,  2.3320e-02,\n",
       "                      -1.1545e-02,  4.8641e-03, -1.1503e-02, -3.2682e-03, -1.9676e-02,\n",
       "                      -1.2109e-02,  4.1236e-04,  2.1443e-02, -5.3119e-03,  1.2507e-02,\n",
       "                      -1.9988e-02, -4.4167e-04,  8.9285e-03, -2.7215e-02,  1.0544e-02,\n",
       "                      -5.2164e-03,  2.4857e-03, -1.9959e-02, -1.4797e-02, -2.8816e-03,\n",
       "                       5.0490e-03,  2.6955e-02, -1.6648e-02,  1.2024e-02, -1.7012e-02,\n",
       "                      -9.9414e-03,  4.1977e-03,  2.4571e-02,  1.5084e-02, -1.5670e-02,\n",
       "                      -8.9110e-04,  7.6484e-04, -1.4236e-02,  2.0563e-03,  6.6693e-03,\n",
       "                      -1.1847e-02,  4.3909e-03,  1.4456e-02, -1.5153e-02,  9.7339e-03,\n",
       "                      -7.6235e-03,  1.8964e-03, -5.8109e-03, -6.9357e-03, -1.0874e-02,\n",
       "                       1.3479e-04, -4.9913e-03,  2.2938e-02,  1.1547e-03, -1.0961e-02,\n",
       "                       4.7839e-03,  1.7283e-03, -1.5655e-02,  4.0589e-03,  4.3128e-03,\n",
       "                      -9.3807e-03,  3.5238e-03, -5.0221e-03,  1.5113e-02,  2.2751e-03,\n",
       "                      -8.0545e-03, -1.1183e-02, -7.5361e-03,  4.1261e-03, -1.1539e-02,\n",
       "                      -6.9628e-03,  2.0158e-02, -9.6492e-03, -1.8979e-03,  1.0555e-02,\n",
       "                       3.3059e-02, -1.2695e-02,  6.3634e-03, -1.5917e-02,  1.6621e-02,\n",
       "                      -8.8010e-03, -7.6286e-03, -1.0631e-03, -7.9809e-03, -1.3711e-02,\n",
       "                      -3.7864e-03, -1.3227e-04,  5.7840e-03, -1.8993e-02, -9.2886e-03,\n",
       "                      -2.0022e-02,  2.2886e-02, -1.6345e-02, -1.7398e-03, -5.0188e-03,\n",
       "                      -1.7003e-03, -1.3202e-02, -7.2597e-03,  2.0228e-02, -5.4209e-03,\n",
       "                       4.8673e-03,  4.4068e-03, -2.9915e-03, -9.8816e-04, -8.0519e-03,\n",
       "                      -4.3391e-03, -7.0425e-03, -1.1369e-02,  1.8863e-03, -1.1602e-02,\n",
       "                       8.2423e-03, -2.6839e-03, -3.5336e-03, -3.9682e-03, -7.4895e-03,\n",
       "                      -7.9722e-03, -1.0481e-02, -2.5886e-03, -1.4520e-02, -2.9277e-03,\n",
       "                      -3.4958e-03,  2.0246e-02, -1.1644e-02,  2.5030e-03,  1.3212e-02,\n",
       "                       2.4965e-03, -1.3690e-04, -1.1120e-02,  1.1473e-03, -6.5109e-03,\n",
       "                      -1.8653e-02,  2.4428e-02, -1.1507e-02, -3.1104e-03,  1.9201e-02,\n",
       "                      -1.2740e-02,  2.1166e-02,  1.1459e-02, -2.8194e-03, -1.7935e-02,\n",
       "                      -3.7056e-03, -1.1814e-02, -7.7301e-03, -2.0269e-02,  3.5322e-02,\n",
       "                      -1.5392e-02, -5.5633e-03,  3.3439e-03, -1.1968e-02, -7.2813e-03,\n",
       "                      -4.0378e-03, -1.4006e-03, -1.6790e-02, -1.6984e-02, -7.5306e-03,\n",
       "                      -1.8036e-03, -2.3527e-02, -4.2458e-03,  8.1647e-03,  2.8689e-02,\n",
       "                      -1.5643e-02,  2.8070e-03,  5.7392e-03, -1.5344e-02,  2.2387e-02,\n",
       "                      -8.8887e-03,  1.6665e-03, -1.0163e-03, -1.8496e-03, -4.3908e-03,\n",
       "                      -3.7877e-03, -4.3155e-03,  3.1882e-04, -1.2754e-02, -1.8688e-03,\n",
       "                       7.0714e-04, -2.0971e-02,  9.0555e-03,  1.5520e-02, -8.2587e-03,\n",
       "                      -1.3960e-02,  2.2146e-03, -1.6392e-02,  1.9789e-04,  1.5696e-02,\n",
       "                      -3.0579e-03, -2.5584e-03, -9.0706e-03,  4.7687e-03,  3.9715e-03,\n",
       "                       3.9033e-02, -8.7159e-03, -4.1699e-03,  3.6662e-03,  1.3728e-03,\n",
       "                       1.6568e-02,  8.8816e-03, -1.2323e-02,  1.5226e-02, -6.5417e-03,\n",
       "                      -1.8181e-02,  1.0815e-02, -1.6794e-03, -1.0439e-02, -5.5988e-03,\n",
       "                      -5.4038e-03, -1.0260e-02, -1.1787e-02,  3.1312e-03,  1.7257e-03,\n",
       "                      -4.6914e-03, -1.4028e-02,  2.7523e-03,  3.4651e-03, -1.0384e-02,\n",
       "                       1.4908e-02, -1.1386e-02, -8.4759e-03,  7.4726e-03,  1.2861e-03,\n",
       "                       1.2962e-02, -9.0986e-03,  7.5231e-03, -1.9241e-02,  6.6728e-03,\n",
       "                       1.1945e-02, -8.2873e-03, -5.1394e-03,  5.1795e-03,  3.3900e-03,\n",
       "                      -9.1569e-03,  4.7905e-03, -1.8893e-02, -7.9622e-03,  1.1938e-03,\n",
       "                       1.9293e-02, -8.0623e-03,  1.0925e-02,  1.6644e-02, -2.5065e-03,\n",
       "                      -1.4148e-02,  8.1749e-04, -1.5732e-03,  1.0167e-03,  8.8666e-04,\n",
       "                      -5.2103e-03,  8.8355e-03, -9.2221e-03,  8.1512e-03, -1.4657e-02,\n",
       "                      -9.2086e-03, -3.9397e-05, -3.3885e-03, -1.4601e-02,  3.0922e-02,\n",
       "                       1.4778e-02,  1.0268e-02, -1.0653e-02,  4.3104e-03,  9.2984e-04,\n",
       "                      -1.7847e-02, -7.1665e-03, -4.2105e-03,  9.8136e-03,  3.3314e-03,\n",
       "                       1.9645e-02, -1.2074e-03, -2.5727e-03, -1.2688e-03,  2.1426e-02,\n",
       "                      -1.4825e-02,  5.7408e-03,  8.0424e-03, -1.7214e-03, -1.9245e-02,\n",
       "                       1.2228e-02, -5.3799e-03, -1.4244e-02, -7.4197e-03, -1.0935e-02,\n",
       "                      -1.2637e-02, -1.5937e-02, -8.8272e-03, -8.0056e-03,  2.1277e-02,\n",
       "                      -7.6185e-03, -2.3888e-03, -4.9488e-03, -1.3592e-02, -9.6094e-03,\n",
       "                       1.2178e-03, -1.0174e-02, -7.7864e-03, -6.4947e-03,  1.3844e-02,\n",
       "                       2.2631e-03,  2.2652e-02, -2.0548e-03,  1.8681e-02, -1.0441e-02,\n",
       "                       1.5305e-03, -4.4677e-03,  1.1450e-02,  2.4853e-02, -5.8735e-03,\n",
       "                       1.9241e-02, -6.6959e-03, -1.3433e-03, -8.1835e-03,  1.7135e-04,\n",
       "                      -1.2214e-02, -1.1054e-02, -1.1199e-02, -5.2478e-03,  1.6028e-02,\n",
       "                      -4.0629e-04, -1.0642e-02,  2.4763e-02,  1.9757e-02, -6.1428e-03,\n",
       "                      -1.4266e-03, -2.2173e-02,  5.4735e-03, -9.6670e-03, -1.1739e-02,\n",
       "                      -1.1344e-02, -8.4656e-03,  4.1869e-04,  3.0763e-03,  1.5935e-02,\n",
       "                       2.5592e-02, -8.0211e-03, -3.9259e-03, -6.8358e-03, -1.4482e-02,\n",
       "                      -5.0211e-03, -1.1677e-02,  1.0367e-02, -1.3930e-02,  7.9355e-04,\n",
       "                       6.0782e-04, -3.2229e-04, -6.1839e-03, -1.5244e-02, -1.8196e-02,\n",
       "                      -6.0814e-05, -9.8421e-03, -1.7697e-02, -1.6074e-02, -8.6542e-03,\n",
       "                       4.1013e-04, -8.5772e-03,  8.8334e-03,  2.9393e-03, -7.4671e-03,\n",
       "                      -1.5669e-02, -9.7146e-03, -3.3274e-03,  5.9939e-03, -5.4716e-03,\n",
       "                       2.8496e-02, -1.3602e-02, -1.4662e-02, -1.1161e-02,  3.1755e-02,\n",
       "                      -1.8684e-02, -1.0600e-02, -1.6263e-02,  1.1381e-02,  2.5783e-02,\n",
       "                      -4.2809e-03, -8.7915e-03, -8.9271e-03, -1.3691e-03,  2.1679e-02,\n",
       "                       1.5091e-02,  4.8523e-03,  3.6058e-03, -3.9409e-03,  1.6530e-02,\n",
       "                       1.2235e-02,  3.2475e-02, -1.7921e-02,  1.8176e-02, -2.2012e-03,\n",
       "                       4.9882e-03, -5.1345e-03,  2.3084e-02, -7.2114e-03, -1.7010e-03,\n",
       "                       5.6645e-03, -4.4214e-03])),\n",
       "             ('decoders.3.bn3.running_mean',\n",
       "              tensor([-1.3861e-01,  2.0617e-01,  1.2106e-01,  2.2107e-01,  7.7888e-02,\n",
       "                      -3.9821e-01, -1.1660e-02, -7.3172e-02,  3.2397e-01, -3.6695e-02,\n",
       "                       7.9978e-02, -2.9403e-01, -1.8750e-01, -3.4233e-01,  4.4006e-01,\n",
       "                       4.8436e-01, -1.0655e-01, -5.4729e-03,  2.4758e-01, -1.3686e-01,\n",
       "                       3.2382e-01,  2.9149e-01, -2.4422e-01,  3.1649e-01,  3.7665e-01,\n",
       "                      -1.9738e-01, -3.4518e-01,  3.9558e-01, -1.6683e-01, -1.8025e-01,\n",
       "                       3.9878e-01,  1.9775e-01, -1.7149e-01, -3.2253e-01, -5.7590e-01,\n",
       "                      -1.8597e-01, -3.6078e-01, -1.6461e-01,  5.7450e-01, -1.8261e-01,\n",
       "                       1.7319e-01,  2.0794e-01,  1.9831e-01,  3.4382e-02,  5.3091e-01,\n",
       "                      -2.8059e-02,  1.1333e-01, -1.2505e-01,  3.3020e-01,  2.9243e-01,\n",
       "                      -2.7067e-01, -4.1393e-01, -4.4525e-01,  3.2067e-01,  2.3824e-01,\n",
       "                       3.6882e-02, -2.2632e-01,  2.6373e-01, -2.9355e-01, -2.6010e-02,\n",
       "                      -2.2575e-01, -1.9741e-01, -7.2213e-02, -9.2845e-02, -4.4861e-01,\n",
       "                      -2.2682e-02, -2.3673e-01,  6.1104e-01,  3.1607e-01,  2.4173e-01,\n",
       "                       4.9487e-01, -2.8498e-01, -3.4954e-02, -1.8945e-01, -3.5287e-02,\n",
       "                      -1.6938e-01,  4.5878e-01,  3.4986e-01, -6.3323e-01, -7.9436e-02,\n",
       "                      -2.0658e-01, -1.1603e-01, -3.3774e-01,  6.5476e-02,  2.4149e-01,\n",
       "                       4.8310e-01,  5.7868e-02,  2.6620e-02, -2.5287e-01, -1.7205e-02,\n",
       "                      -1.4571e-01,  5.0230e-01,  3.6282e-01,  1.0244e-01,  1.2636e-01,\n",
       "                      -2.6038e-01, -8.9033e-03,  3.7471e-01, -1.6690e-01,  2.3378e-01,\n",
       "                       4.9054e-01,  4.6266e-01,  5.5481e-01,  3.1128e-03, -3.2008e-01,\n",
       "                       2.7185e-01,  5.0241e-02, -1.7414e-01, -4.5438e-01, -2.5475e-01,\n",
       "                      -3.3086e-01, -6.6178e-01,  2.1663e-02, -4.2511e-01,  3.2557e-02,\n",
       "                       2.1414e-01, -6.8354e-02,  4.8008e-01, -2.1533e-01, -1.1622e-01,\n",
       "                      -2.0923e-01, -3.3139e-01,  3.0215e-02,  3.3948e-01, -3.5656e-01,\n",
       "                       1.9384e-01, -2.7918e-01,  2.8519e-01,  3.5483e-01,  1.8685e-01,\n",
       "                       1.9563e-01, -3.5056e-01, -4.9045e-01,  5.6240e-01, -2.7077e-01,\n",
       "                       2.4005e-01,  3.4369e-01, -1.6056e-01,  2.0957e-01, -2.3370e-01,\n",
       "                       3.6100e-01, -2.6197e-01,  2.6506e-01,  4.4872e-01, -4.7762e-04,\n",
       "                       3.7268e-01, -4.0708e-01,  1.8841e-01, -5.9422e-02,  2.6932e-02,\n",
       "                       2.1659e-01, -2.9985e-01, -2.9842e-02, -2.7127e-01,  4.4665e-01,\n",
       "                       2.1045e-01, -2.1678e-01,  2.7421e-01, -2.3952e-01, -2.4629e-01,\n",
       "                       2.9449e-01, -5.1492e-01,  5.9265e-03, -5.0121e-01, -2.4114e-01,\n",
       "                       8.4736e-02, -2.2292e-01,  6.1772e-01, -2.6655e-02,  2.8544e-01,\n",
       "                      -1.1377e-01,  9.1567e-02, -3.0902e-01, -3.6650e-01,  2.9835e-01,\n",
       "                      -4.1308e-01, -1.9776e-01,  2.9475e-01, -1.1494e-01, -3.3040e-02,\n",
       "                      -1.5838e-01, -4.3249e-02, -2.0412e-01, -2.9774e-01, -3.1554e-01,\n",
       "                       1.7807e-01, -5.0834e-02, -2.1849e-01,  5.0416e-01,  8.5742e-02,\n",
       "                      -3.4429e-01, -1.2007e-01,  2.8597e-02,  3.7140e-02, -1.8799e-01,\n",
       "                       1.5675e-01,  4.6734e-01, -3.3532e-02,  4.7766e-02,  3.8713e-02,\n",
       "                       2.3744e-02, -1.9929e-02, -2.3712e-01,  5.2677e-01,  3.7230e-01,\n",
       "                       2.3912e-01,  6.8041e-02, -1.0523e-01,  3.1220e-01,  3.1602e-01,\n",
       "                      -1.2983e-01, -1.3099e-01,  3.2930e-02, -3.1281e-01, -2.3198e-03,\n",
       "                       1.0452e-01,  5.4767e-01,  8.1153e-02, -1.2165e-01, -1.0662e-01,\n",
       "                       1.3347e-01, -3.5560e-03, -3.5765e-01,  3.0618e-02,  3.7001e-01,\n",
       "                       2.6293e-02, -2.6591e-01,  4.9918e-01, -2.9597e-01,  2.6223e-01,\n",
       "                      -2.9273e-01, -5.1363e-02, -5.9863e-01,  3.4850e-01,  1.6267e-02,\n",
       "                       9.2730e-02,  5.3868e-01, -4.7535e-01,  4.9687e-01,  1.1262e-01,\n",
       "                       3.3738e-01, -3.7389e-01,  2.8927e-01, -2.8900e-01, -1.6157e-01,\n",
       "                      -4.4022e-02, -6.5799e-02, -1.9366e-01, -1.0695e-01,  3.8974e-01,\n",
       "                       1.0857e-01, -2.7187e-01,  2.0595e-02,  7.1689e-02, -2.6123e-01,\n",
       "                      -1.5331e-01, -2.6778e-01,  1.3479e-01, -8.5541e-02,  6.3670e-01,\n",
       "                      -2.1965e-01,  3.9071e-01, -3.0742e-01,  8.9980e-02, -3.8120e-01,\n",
       "                       5.7666e-01,  3.6313e-01,  3.4801e-01, -1.5404e-01, -3.8335e-01,\n",
       "                       1.7740e-01,  2.7854e-01,  1.6685e-01,  3.6813e-01,  3.3247e-01,\n",
       "                      -2.7624e-01,  3.9558e-01, -3.7438e-02,  3.6308e-01, -5.5698e-02,\n",
       "                       3.0167e-01, -2.9144e-01,  1.4394e-01,  3.5832e-01, -4.4345e-01,\n",
       "                      -4.6173e-02,  9.9778e-02, -1.1644e-01, -1.7375e-01,  3.8269e-01,\n",
       "                      -1.9959e-01, -8.0074e-03, -5.3714e-01,  2.0856e-01, -6.8840e-02,\n",
       "                      -2.3724e-01,  6.7419e-01,  1.2538e-02, -4.4238e-01,  5.2721e-01,\n",
       "                       7.0796e-02, -1.4564e-01,  2.6341e-01,  2.1513e-02,  1.8509e-01,\n",
       "                       1.3199e-01, -1.3750e-01,  4.1016e-01, -3.0336e-01,  6.3712e-02,\n",
       "                      -3.1276e-01, -2.2201e-01,  6.5298e-02,  8.2291e-03,  7.9306e-03,\n",
       "                       1.8417e-01, -4.1543e-02, -1.3859e-01, -1.9442e-01, -9.8720e-02,\n",
       "                      -2.4768e-01, -2.0076e-01,  5.5073e-01,  3.8069e-01,  3.7056e-02,\n",
       "                       3.8163e-01, -1.8795e-02,  3.0651e-01,  9.9350e-02,  2.4324e-01,\n",
       "                       3.1447e-01, -9.8491e-02, -5.8599e-01,  4.8559e-03,  2.7467e-01,\n",
       "                      -2.6903e-01,  5.3530e-02,  1.2677e-01, -1.2727e-01,  1.2546e-01,\n",
       "                      -3.8489e-01,  3.6530e-01,  2.4512e-01,  4.8093e-01, -6.5594e-02,\n",
       "                      -3.0282e-01,  3.6742e-01, -4.9992e-02, -4.1531e-01, -7.5435e-02,\n",
       "                      -4.2958e-01, -7.4423e-03,  4.6462e-01, -1.4281e-01, -3.1970e-01,\n",
       "                      -1.4976e-01,  2.0697e-01, -2.4954e-01, -5.0167e-01, -2.8058e-01,\n",
       "                       3.0893e-02, -7.8337e-02,  1.1301e-02,  2.5404e-01,  1.0596e-01,\n",
       "                      -4.6016e-01, -2.9219e-01,  5.1348e-01, -1.1161e-01,  2.9291e-01,\n",
       "                       2.8057e-01, -1.9400e-01,  2.7679e-01,  5.0333e-01, -4.1179e-01,\n",
       "                      -5.0898e-02,  4.7820e-02,  4.3952e-01, -2.1426e-01,  1.7648e-01,\n",
       "                       1.6418e-01,  3.4348e-02,  1.7638e-01, -2.0158e-01, -2.6743e-01,\n",
       "                       1.1371e-03, -3.0982e-01,  3.0060e-01, -1.1402e-01, -3.8917e-01,\n",
       "                      -1.2340e-02,  1.0329e-01, -3.9352e-01, -3.9465e-01,  3.7772e-01,\n",
       "                      -1.5646e-01,  1.2526e-02,  4.2877e-01, -1.5798e-01,  3.7221e-01,\n",
       "                       4.5504e-01,  3.7914e-01,  4.6849e-01,  6.0710e-02, -2.6901e-02,\n",
       "                       4.3310e-01, -1.4598e-01,  4.3629e-01,  3.2632e-01,  3.7464e-01,\n",
       "                       1.1615e-02, -2.6257e-01, -1.2278e-01, -8.5760e-03, -3.0921e-01,\n",
       "                       1.5507e-01, -5.4191e-01, -2.1523e-01, -3.5136e-01,  4.6342e-01,\n",
       "                       2.5047e-02, -1.3501e-01, -3.8293e-01, -1.8098e-01,  3.0925e-01,\n",
       "                      -3.0409e-01,  5.6601e-01, -3.6251e-01,  7.1475e-02,  7.6768e-02,\n",
       "                       1.4906e-01, -2.4240e-01, -9.5567e-02,  2.4029e-02, -2.1728e-01,\n",
       "                      -2.4456e-02,  4.4282e-01, -2.3747e-01, -3.5483e-01, -1.8712e-01,\n",
       "                      -4.3959e-01,  5.4977e-01, -4.1782e-01,  4.8099e-01,  1.1693e-01,\n",
       "                       6.3158e-02, -2.5042e-01,  2.3925e-01, -1.3937e-01, -2.3043e-01,\n",
       "                      -2.4369e-01, -2.8698e-01,  5.1950e-01,  1.0228e-01,  3.3060e-01,\n",
       "                      -4.0744e-01,  2.4194e-01, -1.6824e-01,  1.0042e-01, -1.6818e-01,\n",
       "                       1.8969e-01, -3.5744e-01, -2.6839e-01,  1.1601e-01, -1.6308e-01,\n",
       "                       1.5516e-01,  5.3673e-01,  4.0607e-01, -3.3697e-02,  7.7957e-02,\n",
       "                      -2.2991e-01,  2.8400e-01, -1.5670e-01, -1.9519e-01, -1.7352e-01,\n",
       "                       4.2545e-01,  1.1986e-01,  1.6709e-01, -1.2754e-02, -1.0671e-01,\n",
       "                      -2.3168e-01,  4.2053e-01,  2.6918e-01, -1.4429e-02, -2.0499e-01,\n",
       "                       4.8675e-01, -5.8090e-02,  3.7970e-01, -2.2724e-01, -3.4237e-01,\n",
       "                       1.6396e-01,  2.4837e-01,  3.9723e-01, -2.3134e-01, -1.8804e-01,\n",
       "                       2.8382e-01,  3.0854e-02, -2.5327e-01,  5.3547e-01,  1.9338e-01,\n",
       "                      -1.9528e-01, -3.8618e-01, -2.0579e-02, -1.7155e-01, -3.5395e-01,\n",
       "                       7.9252e-02,  4.3464e-01, -1.6019e-01,  3.3959e-01,  4.3712e-01,\n",
       "                      -4.0171e-02, -4.8750e-01])),\n",
       "             ('decoders.3.bn3.running_var',\n",
       "              tensor([1.0273, 0.6546, 1.5423, 1.0574, 0.4446, 0.3744, 0.7179, 0.3669, 0.3587,\n",
       "                      1.5011, 0.8675, 0.1905, 0.1911, 0.7473, 0.6741, 0.7709, 0.9808, 0.3110,\n",
       "                      1.0314, 0.5887, 0.7316, 1.0093, 0.6352, 0.9899, 2.3355, 0.8668, 0.8503,\n",
       "                      1.5193, 0.7910, 1.0346, 1.6762, 0.9551, 0.5692, 0.6300, 0.7180, 0.6184,\n",
       "                      0.5127, 0.7218, 2.3319, 0.4855, 0.8477, 0.1507, 0.8617, 0.3333, 3.1526,\n",
       "                      0.4294, 1.2078, 0.1506, 0.8810, 1.3188, 0.4542, 0.9434, 0.4075, 1.2711,\n",
       "                      1.5347, 1.1450, 0.1410, 1.4687, 0.9934, 0.3670, 0.1099, 0.4363, 0.6876,\n",
       "                      1.1529, 0.6630, 0.4872, 1.0605, 1.7312, 1.0774, 0.3742, 1.0821, 0.6829,\n",
       "                      0.2449, 1.5429, 0.8693, 0.2506, 1.4289, 0.9137, 0.4155, 0.2560, 0.5834,\n",
       "                      0.8307, 0.1365, 0.7541, 1.2250, 0.1972, 0.2874, 0.6876, 0.3376, 0.5463,\n",
       "                      1.0366, 1.9473, 1.2978, 0.5060, 0.3782, 1.3245, 0.3573, 0.8811, 0.8528,\n",
       "                      0.9166, 1.0042, 0.4384, 1.3129, 0.7556, 0.7448, 0.8850, 0.3136, 0.3953,\n",
       "                      0.5941, 0.4521, 0.2361, 0.2296, 0.5649, 1.1348, 0.2410, 2.0862, 0.2143,\n",
       "                      1.2180, 0.6440, 1.0833, 0.3826, 1.1154, 0.2857, 0.8773, 0.4765, 1.7512,\n",
       "                      0.3626, 2.4433, 1.7130, 0.8038, 0.5533, 0.2909, 0.8892, 0.5704, 0.3564,\n",
       "                      0.5863, 0.8238, 0.5084, 0.5475, 0.3906, 0.3265, 1.5835, 0.4083, 1.6707,\n",
       "                      0.4165, 0.6445, 1.6582, 0.3176, 1.1158, 0.1911, 0.7883, 0.5138, 0.6943,\n",
       "                      0.5083, 1.5533, 1.6186, 0.2751, 1.7410, 0.9462, 0.6284, 0.3984, 0.5599,\n",
       "                      0.5232, 0.3370, 0.5572, 0.5898, 0.5136, 2.6576, 0.3153, 1.3670, 0.3849,\n",
       "                      0.1818, 0.6385, 0.3321, 2.9827, 0.7707, 0.4030, 1.1689, 0.7240, 0.3893,\n",
       "                      0.3213, 0.8364, 0.1185, 0.9429, 0.6186, 0.2728, 1.5639, 0.2311, 0.8703,\n",
       "                      1.3837, 1.2922, 0.9452, 0.3006, 0.5088, 0.7438, 1.4162, 2.2590, 0.8980,\n",
       "                      1.4381, 0.2741, 0.2937, 0.9905, 0.8426, 1.9762, 1.4947, 0.4656, 0.3368,\n",
       "                      0.8959, 1.2222, 1.2312, 0.2125, 0.5158, 0.3237, 0.1833, 1.0612, 1.1163,\n",
       "                      1.0694, 0.4477, 0.3771, 0.8810, 0.3799, 0.3454, 0.2440, 1.4847, 2.1372,\n",
       "                      1.0671, 0.3961, 0.6417, 1.1824, 1.1809, 0.6461, 0.1775, 1.1652, 0.4888,\n",
       "                      0.9875, 0.5856, 0.9451, 0.3878, 1.2372, 0.4920, 0.8129, 0.5104, 1.5287,\n",
       "                      0.1306, 0.4574, 0.2424, 0.4836, 0.4977, 0.3355, 0.9237, 0.6689, 0.9017,\n",
       "                      0.9396, 0.3267, 1.6714, 0.3764, 0.8662, 1.1093, 0.8121, 0.7977, 0.5485,\n",
       "                      2.3763, 1.0429, 0.5775, 0.6684, 1.6660, 1.2545, 1.6166, 0.9136, 1.0405,\n",
       "                      0.4152, 1.0966, 0.3201, 0.7112, 1.3552, 0.3154, 0.7060, 2.2258, 1.0167,\n",
       "                      0.8628, 1.3868, 0.4784, 0.9272, 1.0137, 0.6863, 0.1865, 1.8675, 0.2929,\n",
       "                      0.6468, 1.7882, 0.1393, 0.5605, 0.4431, 0.5553, 0.2824, 0.5056, 1.8497,\n",
       "                      0.4979, 0.5691, 1.5267, 0.1010, 0.3487, 1.2032, 0.2847, 1.3384, 0.3123,\n",
       "                      0.1960, 1.8488, 0.2409, 1.6433, 0.8559, 0.3207, 0.5665, 1.0222, 1.4481,\n",
       "                      1.3324, 0.5950, 0.1657, 0.3067, 0.2275, 1.4703, 0.5502, 1.2060, 0.5171,\n",
       "                      1.7921, 2.2810, 0.4417, 2.5418, 0.2221, 0.4310, 1.6131, 0.3110, 1.3605,\n",
       "                      1.4481, 1.6365, 0.4242, 0.3747, 0.2821, 0.7937, 0.6058, 0.5143, 1.6809,\n",
       "                      0.7858, 0.8759, 0.5305, 0.4645, 0.8754, 0.5539, 0.7039, 0.7898, 0.2067,\n",
       "                      0.2904, 1.0517, 0.6212, 0.7632, 0.8678, 1.0436, 0.2715, 0.7628, 0.1732,\n",
       "                      1.4907, 0.4770, 0.9762, 0.8881, 0.8319, 0.5181, 0.5130, 1.1361, 0.4611,\n",
       "                      0.7057, 1.7108, 0.5757, 0.5468, 1.9037, 0.8288, 1.1606, 0.3187, 0.7913,\n",
       "                      0.8193, 0.6526, 0.3620, 0.4227, 0.4408, 0.4379, 0.5139, 1.0858, 0.6411,\n",
       "                      0.3408, 0.5744, 0.6738, 0.2262, 1.2129, 0.9819, 0.4713, 0.8910, 0.6446,\n",
       "                      0.2781, 1.9014, 0.7462, 1.1673, 1.1046, 1.0517, 0.5929, 0.4917, 0.7300,\n",
       "                      1.4439, 0.3948, 1.9390, 1.3868, 0.7897, 0.6218, 0.6125, 0.5731, 0.3672,\n",
       "                      0.6116, 1.7223, 1.3686, 1.6884, 0.3068, 0.2377, 0.4580, 0.2951, 0.4475,\n",
       "                      0.9350, 0.7477, 1.7990, 1.4839, 0.1641, 2.1195, 0.3915, 1.9858, 0.5254,\n",
       "                      0.2223, 1.0800, 0.4084, 0.6240, 1.9558, 0.9897, 1.1337, 0.4890, 0.7427,\n",
       "                      2.8345, 0.1955, 0.9628, 0.3184, 0.3207, 0.5445, 0.4461, 0.1514, 0.4741,\n",
       "                      0.5603, 0.2260, 0.8265, 1.4317, 1.2326, 0.3072, 1.2388, 0.4879, 0.9352,\n",
       "                      0.4705, 2.8022, 0.3817, 0.2316, 0.8450, 0.4699, 0.5174, 1.3078, 0.6204,\n",
       "                      0.2461, 0.3016, 0.7373, 0.7007, 0.7056, 0.3968, 0.2981, 1.0523, 1.6031,\n",
       "                      0.7386, 1.2617, 0.3395, 0.6453, 0.5408, 0.8924, 0.3457, 1.2918, 1.2572,\n",
       "                      1.1131, 1.0367, 0.9530, 0.6431, 0.7147, 2.1053, 1.8601, 0.5352, 1.3214,\n",
       "                      0.9091, 0.4702, 0.5213, 1.3088, 1.3064, 0.2274, 0.6891, 1.0218, 0.5621,\n",
       "                      1.5335, 0.4721, 0.1971, 1.7240, 1.2990, 1.6324, 0.5197, 0.1857])),\n",
       "             ('decoders.3.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense4.weight',\n",
       "              tensor([[ 0.0391,  0.0112, -0.0140,  ...,  0.0194, -0.0265,  0.0135],\n",
       "                      [ 0.0173,  0.0271,  0.0451,  ..., -0.0526,  0.0319,  0.0306],\n",
       "                      [-0.0152, -0.0467,  0.0177,  ..., -0.0405, -0.0265, -0.0043],\n",
       "                      ...,\n",
       "                      [-0.0010, -0.0079,  0.0155,  ..., -0.0431, -0.0397,  0.0100],\n",
       "                      [ 0.0026,  0.0267,  0.0146,  ..., -0.0300,  0.0118,  0.0424],\n",
       "                      [-0.0132,  0.0077,  0.0314,  ..., -0.0421, -0.0262,  0.0042]])),\n",
       "             ('decoders.3.bn4.weight',\n",
       "              tensor([1.0218, 1.0217, 1.0203, 1.0220, 1.0177, 1.0203, 1.0219, 1.0246, 1.0218,\n",
       "                      1.0219, 1.0203, 1.0190, 1.0215, 1.0190, 1.0214, 1.0221, 1.0151, 1.0221,\n",
       "                      1.0203, 1.0225, 1.0233, 1.0201, 1.0220, 1.0194, 1.0242, 1.0225, 1.0169,\n",
       "                      1.0232, 1.0227, 1.0205, 1.0209, 1.0244, 1.0219, 1.0211, 1.0180, 1.0225,\n",
       "                      1.0195, 1.0170, 1.0191, 1.0227, 1.0223, 1.0218, 1.0197, 1.0194, 1.0209,\n",
       "                      1.0217, 1.0211, 1.0219, 1.0202, 1.0250, 1.0209, 1.0200, 1.0217, 1.0200,\n",
       "                      1.0232, 1.0225, 1.0213, 1.0204, 1.0223, 1.0235, 1.0202, 1.0175, 1.0223,\n",
       "                      1.0250, 1.0223, 1.0174, 1.0205, 1.0216, 1.0208, 1.0208, 1.0194, 1.0214,\n",
       "                      1.0214, 1.0206, 1.0154, 1.0200, 1.0226, 1.0189, 1.0244, 1.0239, 1.0216,\n",
       "                      1.0222, 1.0191, 1.0222, 1.0233, 1.0227, 1.0189, 1.0211, 1.0216, 1.0209,\n",
       "                      1.0187, 1.0215, 1.0190, 1.0211, 1.0216, 1.0199, 1.0226, 1.0222, 1.0210,\n",
       "                      1.0192, 1.0188, 1.0199, 1.0190, 1.0179, 1.0229, 1.0194, 1.0203, 1.0184,\n",
       "                      1.0210, 1.0201, 1.0209, 1.0228, 1.0197, 1.0216, 1.0207, 1.0246, 1.0200,\n",
       "                      1.0208, 1.0196, 1.0169, 1.0188, 1.0203, 1.0200, 1.0189, 1.0200, 1.0212,\n",
       "                      1.0226, 1.0203, 1.0206, 1.0220, 1.0203, 1.0234, 1.0219, 1.0222, 1.0211,\n",
       "                      1.0216, 1.0180, 1.0216, 1.0212, 1.0191, 1.0190, 1.0200, 1.0217, 1.0207,\n",
       "                      1.0245, 1.0192, 1.0155, 1.0230, 1.0199, 1.0184, 1.0180, 1.0230, 1.0212,\n",
       "                      1.0204, 1.0218, 1.0192, 1.0213, 1.0212, 1.0225, 1.0249, 1.0213, 1.0220,\n",
       "                      1.0224, 1.0196, 1.0222, 1.0173, 1.0206, 1.0211, 1.0207, 1.0213, 1.0198,\n",
       "                      1.0204, 1.0182, 1.0165, 1.0222, 1.0212, 1.0232, 1.0193, 1.0205, 1.0204,\n",
       "                      1.0213, 1.0221, 1.0222, 1.0194, 1.0225, 1.0217, 1.0216, 1.0189, 1.0196,\n",
       "                      1.0239, 1.0219, 1.0220, 1.0208, 1.0160, 1.0214, 1.0201, 1.0204, 1.0238,\n",
       "                      1.0216, 1.0200, 1.0231, 1.0221, 1.0239, 1.0210, 1.0187, 1.0219, 1.0187,\n",
       "                      1.0202, 1.0190, 1.0213, 1.0208, 1.0204, 1.0240, 1.0211, 1.0228, 1.0191,\n",
       "                      1.0189, 1.0197, 1.0221, 1.0216, 1.0208, 1.0226, 1.0214, 1.0176, 1.0237,\n",
       "                      1.0195, 1.0216, 1.0217, 1.0204, 1.0225, 1.0216, 1.0198, 1.0154, 1.0187,\n",
       "                      1.0166, 1.0213, 1.0190, 1.0200, 1.0190, 1.0222, 1.0222, 1.0222, 1.0221,\n",
       "                      1.0194, 1.0226, 1.0211, 1.0220, 1.0204, 1.0217, 1.0198, 1.0211, 1.0255,\n",
       "                      1.0247, 1.0224, 1.0208, 1.0209, 1.0198, 1.0196, 1.0199, 1.0219, 1.0229,\n",
       "                      1.0196, 1.0225, 1.0215, 1.0200, 1.0220, 1.0215, 1.0232, 1.0215, 1.0221,\n",
       "                      1.0216, 1.0206, 1.0244, 1.0204, 1.0190, 1.0206, 1.0214, 1.0205, 1.0195,\n",
       "                      1.0232, 1.0194, 1.0211, 1.0218, 1.0238, 1.0224, 1.0214, 1.0201, 1.0197,\n",
       "                      1.0166, 1.0215, 1.0212, 1.0222, 1.0196, 1.0253, 1.0225, 1.0183, 1.0234,\n",
       "                      1.0210, 1.0225, 1.0200, 1.0221, 1.0217, 1.0220, 1.0224, 1.0216, 1.0213,\n",
       "                      1.0189, 1.0201, 1.0204, 1.0225, 1.0217, 1.0203, 1.0197, 1.0200, 1.0216,\n",
       "                      1.0217, 1.0204, 1.0176, 1.0233, 1.0213, 1.0210, 1.0204, 1.0219, 1.0194,\n",
       "                      1.0200, 1.0173, 1.0197, 1.0196, 1.0190, 1.0234, 1.0182, 1.0217, 1.0196,\n",
       "                      1.0197, 1.0207, 1.0205, 1.0209, 1.0210, 1.0212, 1.0214, 1.0177, 1.0211,\n",
       "                      1.0216, 1.0214, 1.0231, 1.0149, 1.0202, 1.0191, 1.0204, 1.0231, 1.0221,\n",
       "                      1.0223, 1.0217, 1.0212, 1.0222, 1.0183, 1.0194, 1.0199, 1.0210, 1.0187,\n",
       "                      1.0238, 1.0209, 1.0208, 1.0227, 1.0213, 1.0211, 1.0203, 1.0203, 1.0209,\n",
       "                      1.0179, 1.0221, 1.0233, 1.0229, 1.0219, 1.0208, 1.0222, 1.0203, 1.0185,\n",
       "                      1.0176, 1.0204, 1.0190, 1.0182, 1.0204, 1.0203, 1.0189, 1.0196, 1.0209,\n",
       "                      1.0210, 1.0210, 1.0244, 1.0231, 1.0222, 1.0171, 1.0208, 1.0211, 1.0223,\n",
       "                      1.0222, 1.0218, 1.0179, 1.0222, 1.0169, 1.0201, 1.0249, 1.0189, 1.0209,\n",
       "                      1.0196, 1.0206, 1.0234, 1.0207, 1.0216, 1.0233, 1.0220, 1.0225, 1.0215,\n",
       "                      1.0201, 1.0216, 1.0217, 1.0207, 1.0212, 1.0209, 1.0221, 1.0183, 1.0213,\n",
       "                      1.0213, 1.0188, 1.0214, 1.0218, 1.0206, 1.0227, 1.0250, 1.0207, 1.0183,\n",
       "                      1.0202, 1.0229, 1.0212, 1.0204, 1.0203, 1.0221, 1.0185, 1.0238, 1.0214,\n",
       "                      1.0228, 1.0233, 1.0170, 1.0228, 1.0232, 1.0194, 1.0215, 1.0212, 1.0199,\n",
       "                      1.0216, 1.0218, 1.0220, 1.0239, 1.0214, 1.0194, 1.0227, 1.0225, 1.0216,\n",
       "                      1.0196, 1.0215, 1.0216, 1.0177, 1.0197, 1.0218, 1.0235, 1.0218, 1.0184,\n",
       "                      1.0203, 1.0207, 1.0223, 1.0199, 1.0228, 1.0207, 1.0215, 1.0203, 1.0219,\n",
       "                      1.0218, 1.0183, 1.0214, 1.0190, 1.0153, 1.0210, 1.0215, 1.0204, 1.0218,\n",
       "                      1.0213, 1.0193, 1.0219, 1.0203, 1.0226, 1.0183, 1.0208, 1.0197, 1.0204,\n",
       "                      1.0203, 1.0190, 1.0220, 1.0211, 1.0188, 1.0184, 1.0206, 1.0220, 1.0202,\n",
       "                      1.0215, 1.0243, 1.0218, 1.0196, 1.0207, 1.0225, 1.0198, 1.0220])),\n",
       "             ('decoders.3.bn4.bias',\n",
       "              tensor([0.0258, 0.0312, 0.0275, 0.0262, 0.0272, 0.0271, 0.0256, 0.0287, 0.0287,\n",
       "                      0.0282, 0.0280, 0.0278, 0.0304, 0.0285, 0.0282, 0.0285, 0.0272, 0.0305,\n",
       "                      0.0314, 0.0305, 0.0287, 0.0277, 0.0285, 0.0280, 0.0287, 0.0256, 0.0284,\n",
       "                      0.0311, 0.0291, 0.0285, 0.0274, 0.0269, 0.0291, 0.0305, 0.0273, 0.0305,\n",
       "                      0.0268, 0.0271, 0.0280, 0.0255, 0.0257, 0.0301, 0.0277, 0.0269, 0.0292,\n",
       "                      0.0308, 0.0283, 0.0303, 0.0289, 0.0289, 0.0278, 0.0273, 0.0303, 0.0279,\n",
       "                      0.0263, 0.0284, 0.0283, 0.0302, 0.0283, 0.0266, 0.0284, 0.0281, 0.0299,\n",
       "                      0.0285, 0.0257, 0.0271, 0.0274, 0.0287, 0.0306, 0.0280, 0.0279, 0.0292,\n",
       "                      0.0305, 0.0287, 0.0275, 0.0270, 0.0308, 0.0279, 0.0302, 0.0260, 0.0289,\n",
       "                      0.0303, 0.0276, 0.0288, 0.0289, 0.0311, 0.0288, 0.0292, 0.0304, 0.0285,\n",
       "                      0.0283, 0.0287, 0.0297, 0.0286, 0.0291, 0.0293, 0.0306, 0.0292, 0.0301,\n",
       "                      0.0281, 0.0280, 0.0281, 0.0273, 0.0285, 0.0261, 0.0282, 0.0280, 0.0259,\n",
       "                      0.0302, 0.0290, 0.0285, 0.0260, 0.0287, 0.0302, 0.0277, 0.0270, 0.0273,\n",
       "                      0.0309, 0.0277, 0.0277, 0.0277, 0.0280, 0.0284, 0.0267, 0.0293, 0.0285,\n",
       "                      0.0284, 0.0307, 0.0282, 0.0304, 0.0277, 0.0263, 0.0302, 0.0291, 0.0280,\n",
       "                      0.0295, 0.0263, 0.0295, 0.0282, 0.0285, 0.0277, 0.0282, 0.0286, 0.0277,\n",
       "                      0.0289, 0.0270, 0.0255, 0.0260, 0.0284, 0.0272, 0.0277, 0.0308, 0.0259,\n",
       "                      0.0286, 0.0313, 0.0278, 0.0283, 0.0286, 0.0311, 0.0263, 0.0300, 0.0308,\n",
       "                      0.0308, 0.0273, 0.0303, 0.0279, 0.0306, 0.0303, 0.0291, 0.0281, 0.0280,\n",
       "                      0.0273, 0.0267, 0.0271, 0.0307, 0.0291, 0.0261, 0.0274, 0.0304, 0.0261,\n",
       "                      0.0284, 0.0308, 0.0281, 0.0285, 0.0289, 0.0279, 0.0286, 0.0283, 0.0288,\n",
       "                      0.0269, 0.0287, 0.0303, 0.0288, 0.0253, 0.0304, 0.0281, 0.0314, 0.0286,\n",
       "                      0.0279, 0.0254, 0.0303, 0.0280, 0.0266, 0.0281, 0.0273, 0.0284, 0.0281,\n",
       "                      0.0276, 0.0255, 0.0298, 0.0291, 0.0294, 0.0303, 0.0281, 0.0301, 0.0274,\n",
       "                      0.0262, 0.0279, 0.0308, 0.0302, 0.0283, 0.0290, 0.0287, 0.0283, 0.0268,\n",
       "                      0.0267, 0.0281, 0.0305, 0.0278, 0.0300, 0.0294, 0.0309, 0.0267, 0.0280,\n",
       "                      0.0270, 0.0285, 0.0287, 0.0282, 0.0277, 0.0281, 0.0303, 0.0279, 0.0286,\n",
       "                      0.0273, 0.0307, 0.0306, 0.0270, 0.0284, 0.0301, 0.0281, 0.0286, 0.0285,\n",
       "                      0.0298, 0.0286, 0.0279, 0.0297, 0.0281, 0.0266, 0.0281, 0.0282, 0.0306,\n",
       "                      0.0270, 0.0303, 0.0301, 0.0279, 0.0302, 0.0286, 0.0254, 0.0305, 0.0284,\n",
       "                      0.0279, 0.0282, 0.0266, 0.0311, 0.0275, 0.0282, 0.0280, 0.0305, 0.0283,\n",
       "                      0.0262, 0.0281, 0.0285, 0.0310, 0.0267, 0.0310, 0.0281, 0.0285, 0.0274,\n",
       "                      0.0287, 0.0284, 0.0280, 0.0257, 0.0301, 0.0304, 0.0306, 0.0284, 0.0264,\n",
       "                      0.0306, 0.0304, 0.0278, 0.0290, 0.0312, 0.0284, 0.0302, 0.0309, 0.0282,\n",
       "                      0.0283, 0.0264, 0.0281, 0.0308, 0.0305, 0.0284, 0.0283, 0.0281, 0.0285,\n",
       "                      0.0283, 0.0280, 0.0272, 0.0314, 0.0283, 0.0280, 0.0274, 0.0300, 0.0270,\n",
       "                      0.0283, 0.0272, 0.0276, 0.0297, 0.0282, 0.0305, 0.0297, 0.0284, 0.0276,\n",
       "                      0.0284, 0.0277, 0.0279, 0.0286, 0.0283, 0.0277, 0.0310, 0.0277, 0.0281,\n",
       "                      0.0289, 0.0282, 0.0262, 0.0277, 0.0273, 0.0270, 0.0306, 0.0262, 0.0278,\n",
       "                      0.0311, 0.0286, 0.0265, 0.0259, 0.0266, 0.0273, 0.0277, 0.0287, 0.0279,\n",
       "                      0.0270, 0.0302, 0.0277, 0.0306, 0.0287, 0.0298, 0.0279, 0.0260, 0.0282,\n",
       "                      0.0276, 0.0301, 0.0308, 0.0305, 0.0284, 0.0288, 0.0302, 0.0277, 0.0263,\n",
       "                      0.0279, 0.0283, 0.0272, 0.0273, 0.0273, 0.0280, 0.0276, 0.0277, 0.0301,\n",
       "                      0.0280, 0.0264, 0.0289, 0.0283, 0.0282, 0.0274, 0.0282, 0.0280, 0.0286,\n",
       "                      0.0287, 0.0285, 0.0281, 0.0291, 0.0276, 0.0277, 0.0269, 0.0277, 0.0284,\n",
       "                      0.0284, 0.0279, 0.0270, 0.0290, 0.0262, 0.0263, 0.0302, 0.0303, 0.0300,\n",
       "                      0.0279, 0.0280, 0.0302, 0.0284, 0.0265, 0.0287, 0.0266, 0.0279, 0.0280,\n",
       "                      0.0302, 0.0269, 0.0284, 0.0287, 0.0283, 0.0305, 0.0284, 0.0283, 0.0264,\n",
       "                      0.0281, 0.0306, 0.0280, 0.0301, 0.0280, 0.0282, 0.0279, 0.0259, 0.0287,\n",
       "                      0.0269, 0.0303, 0.0268, 0.0306, 0.0298, 0.0277, 0.0276, 0.0305, 0.0280,\n",
       "                      0.0291, 0.0281, 0.0288, 0.0295, 0.0262, 0.0289, 0.0300, 0.0305, 0.0280,\n",
       "                      0.0277, 0.0301, 0.0307, 0.0276, 0.0279, 0.0281, 0.0294, 0.0283, 0.0282,\n",
       "                      0.0273, 0.0274, 0.0306, 0.0275, 0.0299, 0.0281, 0.0285, 0.0281, 0.0284,\n",
       "                      0.0283, 0.0300, 0.0309, 0.0279, 0.0267, 0.0285, 0.0279, 0.0283, 0.0280,\n",
       "                      0.0307, 0.0280, 0.0297, 0.0298, 0.0287, 0.0296, 0.0306, 0.0286, 0.0281,\n",
       "                      0.0302, 0.0273, 0.0289, 0.0284, 0.0280, 0.0279, 0.0308, 0.0314, 0.0260,\n",
       "                      0.0285, 0.0286, 0.0258, 0.0277, 0.0244, 0.0307, 0.0278, 0.0294])),\n",
       "             ('decoders.3.bn4.running_mean',\n",
       "              tensor([-0.4715, -0.7810, -0.8710, -0.4768, -0.6419, -0.7555, -0.4547, -0.5129,\n",
       "                      -0.6367, -0.5947, -0.8368, -0.5941, -0.6628, -0.7380, -0.5669, -0.8105,\n",
       "                      -0.5658, -0.7263, -0.7057, -0.8866, -0.3484, -0.7157, -0.3657, -0.8166,\n",
       "                      -0.7280, -0.6879, -0.8038, -0.5287, -0.6046, -0.7318, -0.6162, -0.1121,\n",
       "                      -0.3145, -0.5901, -0.7493, -0.7905, -0.6880, -0.5113, -0.7123, -0.2446,\n",
       "                      -0.4679, -0.9562, -0.7731, -0.5420, -0.7334, -0.7625, -0.8923, -0.8297,\n",
       "                      -0.5314, -0.3512, -0.7402, -0.6352, -0.2489, -0.5840, -0.4226, -0.7514,\n",
       "                      -0.6480, -0.7902, -0.6774, -0.5188, -0.5124, -0.5265, -0.7205, -0.3434,\n",
       "                      -0.5583, -0.8050, -0.7327, -0.5674, -0.7315, -0.6571, -0.7761, -0.6838,\n",
       "                      -0.8280, -0.4221, -0.6669, -0.5162, -0.4182, -0.7336, -0.7083, -0.2278,\n",
       "                      -0.5604, -0.5206, -0.7033, -0.8796, -0.4580, -0.4777, -0.9032, -0.7088,\n",
       "                      -0.7112, -0.8739, -0.9346, -0.6505, -0.6907, -0.8084, -0.4849, -0.7335,\n",
       "                      -0.6827, -0.7121, -0.5252, -0.6190, -0.6648, -0.6624, -0.5244, -0.7195,\n",
       "                      -0.3938, -0.5901, -0.4513, -0.5944, -0.4900, -0.8323, -0.4760, -0.3527,\n",
       "                      -0.8209, -0.5743, -0.5423, -0.4000, -0.4806, -0.6608, -0.6076, -0.4987,\n",
       "                      -0.6879, -0.6556, -0.5485, -0.2995, -0.6245, -0.6830, -0.9455, -0.8325,\n",
       "                      -0.5297, -0.7502, -0.6955, -0.6938, -0.6634, -0.4495, -0.8997, -0.5147,\n",
       "                      -0.7977, -0.7583, -0.4866, -0.6729, -1.0416, -0.5811, -0.6818, -0.7113,\n",
       "                      -0.9120, -0.8941, -0.7146, -0.7405, -0.7310, -0.8051, -0.3694, -0.7904,\n",
       "                      -0.6315, -0.6567, -0.5809, -0.7743, -0.5109, -0.4682, -0.4613, -0.6527,\n",
       "                      -0.5476, -0.6798, -0.2482, -0.6533, -0.4574, -0.6432, -0.5895, -0.6366,\n",
       "                      -0.6540, -0.5385, -0.8719, -0.5646, -0.6928, -0.7374, -0.6684, -0.8679,\n",
       "                      -0.5172, -0.8953, -0.5478, -0.5923, -0.5954, -0.6250, -0.4155, -0.8504,\n",
       "                      -0.2678, -0.2738, -0.5716, -0.5973, -0.4782, -0.2082, -0.6303, -0.6683,\n",
       "                      -0.6567, -0.6491, -0.6490, -0.7312, -0.7319, -0.7501, -0.7727, -0.6005,\n",
       "                      -0.3152, -0.6902, -0.2938, -0.6108, -0.6521, -0.4477, -0.7744, -0.6429,\n",
       "                      -0.4183, -0.7960, -0.8912, -0.7506, -0.4612, -0.6390, -0.4636, -0.8354,\n",
       "                      -0.5838, -0.6226, -0.3927, -0.6475, -0.4184, -0.5231, -0.6296, -0.8048,\n",
       "                      -0.3640, -0.7749, -0.4530, -0.6427, -0.7938, -0.7886, -0.6151, -0.7071,\n",
       "                      -0.7980, -0.7382, -0.4817, -0.8674, -0.7013, -0.8413, -0.7363, -0.5030,\n",
       "                      -0.7228, -0.7950, -0.5807, -0.6326, -0.5699, -0.7949, -0.7975, -0.5489,\n",
       "                      -0.7852, -0.8834, -0.5721, -0.4681, -0.7128, -0.7740, -0.6758, -0.5904,\n",
       "                      -0.7871, -0.9504, -0.6461, -0.5172, -0.2839, -0.5261, -0.3669, -0.4514,\n",
       "                      -0.5135, -0.5014, -0.1111, -0.2490, -0.5116, -0.7728, -0.6244, -0.4131,\n",
       "                      -0.4551, -0.4700, -0.6212, -0.7966, -0.6496, -0.7286, -0.8054, -0.3998,\n",
       "                      -0.7224, -0.7586, -0.5610, -0.5547, -0.4954, -0.5421, -0.4520, -0.3370,\n",
       "                      -0.6688, -0.4050, -0.7895, -0.5359, -0.7092, -0.6904, -0.4391, -0.6216,\n",
       "                      -0.2696, -0.4952, -0.4661, -0.4572, -0.4995, -0.5191, -0.6389, -0.4432,\n",
       "                      -0.5475, -0.5026, -0.5923, -0.4399, -0.5693, -0.7652, -0.7822, -0.5141,\n",
       "                      -0.7459, -0.6545, -0.5701, -0.4054, -0.7945, -0.7041, -0.1534, -0.8025,\n",
       "                      -0.8902, -0.5372, -0.8971, -0.5105, -0.5670, -0.6837, -0.6732, -0.7473,\n",
       "                      -0.6880, -0.4571, -0.7672, -0.7145, -0.5120, -0.7981, -0.4371, -0.7121,\n",
       "                      -0.3812, -0.7277, -0.8215, -0.6863, -0.8890, -0.6425, -0.6225, -0.7995,\n",
       "                      -0.2844, -0.6639, -0.8016, -0.9571, -0.7962, -0.3997, -0.5788, -0.4238,\n",
       "                      -0.2582, -0.5993, -0.3174, -0.6478, -0.7244, -0.6780, -0.5832, -0.5712,\n",
       "                      -0.5975, -0.6008, -0.3024, -0.4606, -0.5775, -0.7464, -0.6287, -0.4260,\n",
       "                      -0.5662, -0.6163, -0.5180, -0.7502, -0.6981, -0.7071, -0.5222, -0.7385,\n",
       "                      -0.4277, -0.6668, -0.6131, -0.6843, -0.4117, -0.7497, -0.6329, -0.7351,\n",
       "                      -0.8351, -0.8409, -0.5667, -0.3721, -0.5293, -0.3581, -0.3771, -0.8484,\n",
       "                      -0.8346, -0.5961, -0.6824, -0.7970, -0.2834, -0.4247, -0.7437, -0.7310,\n",
       "                      -1.0171, -0.6566, -0.2677, -0.8194, -0.6866, -0.7195, -0.4869, -0.3288,\n",
       "                      -0.5080, -0.3035, -0.4164, -0.7413, -0.7147, -0.7692, -0.5672, -0.7338,\n",
       "                      -0.7115, -0.6395, -0.6567, -0.5476, -0.5546, -0.6810, -0.6987, -0.8765,\n",
       "                      -0.6577, -0.5009, -0.4789, -0.7600, -0.8258, -0.3282, -0.7968, -0.6210,\n",
       "                      -0.8348, -0.7656, -0.4553, -0.7115, -0.5168, -0.1763, -0.6872, -0.3781,\n",
       "                      -0.6081, -0.5527, -0.4359, -0.7968, -0.6424, -0.8873, -0.5912, -0.3827,\n",
       "                      -0.6624, -0.4249, -0.5840, -0.3044, -0.6997, -0.6790, -0.3086, -0.8016,\n",
       "                      -0.4269, -0.7860, -0.4731, -0.6915, -0.8232, -0.6748, -0.7763, -0.5674,\n",
       "                      -0.6418, -0.4982, -0.5326, -0.8379, -0.3884, -0.4738, -0.7456, -0.5944,\n",
       "                      -0.7057, -0.7101, -0.8164, -0.7801, -0.7582, -0.4973, -0.5140, -0.6904,\n",
       "                      -0.6616, -0.8423, -0.8703, -0.4920, -0.7326, -0.7734, -0.6598, -1.0167,\n",
       "                      -0.6054, -0.5146, -0.6684, -0.4695, -0.7045, -0.5022, -0.3901, -0.8010,\n",
       "                      -0.6491, -0.5879, -0.7807, -0.6702, -0.8496, -0.6396, -0.6742, -0.6627,\n",
       "                      -0.5584, -0.3552, -0.3022, -0.4860, -0.4608, -0.7046, -0.6143, -0.7498])),\n",
       "             ('decoders.3.bn4.running_var',\n",
       "              tensor([0.5887, 2.0324, 4.9040, 0.8163, 2.5340, 2.5929, 0.6682, 0.8124, 3.3445,\n",
       "                      4.1367, 2.2110, 2.5017, 2.5489, 1.6864, 3.5836, 2.9169, 0.9651, 2.6022,\n",
       "                      2.2278, 3.8401, 3.7933, 3.3893, 1.6651, 4.7878, 0.6569, 0.8854, 1.2625,\n",
       "                      1.9735, 3.8667, 2.7738, 4.8772, 3.5606, 3.8957, 4.6665, 2.2487, 2.4991,\n",
       "                      4.1587, 1.7255, 2.6778, 3.1830, 1.0736, 3.7300, 2.8196, 3.8330, 2.0690,\n",
       "                      2.6903, 2.1133, 4.2170, 2.8228, 0.9217, 4.7378, 2.6738, 3.7713, 2.0701,\n",
       "                      0.7501, 3.2242, 4.1435, 2.6169, 5.0622, 0.6480, 2.0850, 1.6840, 5.8316,\n",
       "                      0.6633, 0.7292, 1.8224, 5.4349, 2.7831, 1.5608, 3.3578, 3.0826, 2.6349,\n",
       "                      2.1582, 3.1997, 1.2613, 3.9026, 2.9750, 2.3561, 2.9747, 2.3459, 2.1058,\n",
       "                      2.7898, 1.8894, 2.4958, 0.8959, 2.6785, 1.7740, 2.3747, 2.2738, 2.4507,\n",
       "                      1.8674, 1.7665, 1.0990, 2.3487, 2.2585, 2.1698, 3.3735, 0.6869, 1.8257,\n",
       "                      2.8007, 2.0999, 1.8815, 3.1673, 1.7973, 0.8676, 2.3309, 3.9636, 3.1891,\n",
       "                      0.4002, 0.6767, 2.3970, 0.7320, 2.4179, 2.8370, 5.4452, 0.9726, 3.5689,\n",
       "                      2.2624, 2.5100, 1.4690, 2.5637, 2.5613, 2.3832, 3.5981, 2.1420, 3.2192,\n",
       "                      4.1271, 1.9765, 3.0403, 3.7109, 3.2312, 0.8260, 3.1190, 2.2861, 3.4060,\n",
       "                      0.5843, 2.1989, 4.9147, 3.6909, 2.5852, 2.3300, 2.7978, 3.3266, 5.3471,\n",
       "                      0.4545, 3.5675, 2.3962, 0.6953, 3.0112, 2.2619, 2.1475, 3.0302, 0.7572,\n",
       "                      3.5085, 1.6926, 2.1606, 3.0189, 3.3537, 3.4176, 0.9426, 3.3754, 2.3490,\n",
       "                      4.3286, 3.7397, 2.7902, 1.6369, 2.5472, 3.2675, 2.4935, 3.2112, 2.8079,\n",
       "                      4.8952, 1.7810, 1.6716, 2.0225, 2.6423, 1.3467, 2.6236, 2.5563, 0.6509,\n",
       "                      2.6765, 2.5817, 0.7509, 1.3074, 2.7141, 4.2488, 3.9281, 1.6426, 2.2129,\n",
       "                      2.2955, 3.5695, 2.5828, 2.8893, 4.3019, 2.6819, 1.9814, 1.7138, 0.4744,\n",
       "                      5.2686, 0.7888, 3.8804, 3.6401, 1.5336, 2.8256, 1.4027, 3.5954, 1.5638,\n",
       "                      4.5963, 0.6773, 3.5447, 1.7549, 1.2566, 3.9947, 4.5243, 3.6835, 3.2617,\n",
       "                      7.1702, 2.2774, 2.4629, 3.0535, 4.6322, 0.6761, 3.3217, 1.7712, 0.9153,\n",
       "                      3.9449, 4.1216, 4.3913, 2.0138, 5.3538, 2.7085, 1.3973, 1.1954, 2.3905,\n",
       "                      0.7479, 3.6289, 2.0996, 2.2751, 2.0941, 0.8016, 3.1181, 4.1658, 1.4311,\n",
       "                      3.5086, 3.2500, 1.8160, 0.5209, 2.8993, 3.1171, 2.0978, 2.4384, 0.5798,\n",
       "                      4.6699, 3.0643, 2.6800, 4.4780, 2.2489, 3.7592, 1.9444, 2.8628, 2.4632,\n",
       "                      4.8807, 3.0497, 3.5310, 2.8740, 1.7750, 3.8012, 3.2991, 2.6050, 3.3799,\n",
       "                      3.4966, 3.1399, 2.0368, 2.6140, 3.2035, 4.1931, 4.0794, 1.9466, 3.2215,\n",
       "                      0.7538, 2.3648, 2.5086, 3.1652, 0.6549, 2.9926, 3.8829, 2.9703, 3.4583,\n",
       "                      0.4936, 2.8317, 2.6147, 0.7788, 1.7991, 4.3742, 1.7966, 1.3487, 0.8772,\n",
       "                      1.9837, 4.7144, 4.5427, 2.4735, 2.5192, 4.4908, 3.5130, 2.6742, 3.3678,\n",
       "                      2.0887, 0.8175, 2.3149, 4.7144, 3.5749, 1.9834, 2.0462, 2.2511, 4.3246,\n",
       "                      5.3792, 4.5250, 2.0004, 3.0648, 2.3513, 2.9859, 3.3080, 2.9644, 0.6111,\n",
       "                      3.3463, 2.5153, 3.5360, 0.4089, 1.7835, 2.6685, 0.7930, 3.9260, 3.9891,\n",
       "                      2.6122, 4.6928, 3.2530, 2.8592, 3.5011, 4.4698, 1.9719, 2.5231, 3.7435,\n",
       "                      1.8094, 3.4956, 1.2914, 0.8117, 3.6811, 3.9433, 1.5091, 0.6887, 3.4026,\n",
       "                      3.7055, 3.9575, 0.5702, 1.0419, 3.5645, 3.6533, 4.1453, 2.7236, 2.0599,\n",
       "                      0.5980, 2.0794, 3.8028, 2.2584, 1.9771, 4.4167, 2.9898, 0.7766, 4.0337,\n",
       "                      1.9196, 3.2757, 2.3898, 4.0528, 3.8677, 2.4383, 3.5110, 5.1547, 4.9393,\n",
       "                      1.8025, 3.8879, 4.7188, 2.1839, 3.7870, 3.3599, 2.2004, 2.2220, 2.2748,\n",
       "                      3.4945, 0.6343, 0.8595, 0.9884, 4.9544, 1.9314, 4.3490, 4.3867, 4.3827,\n",
       "                      2.5339, 4.2566, 1.7355, 2.7362, 1.7563, 3.3930, 4.7484, 2.4632, 1.7740,\n",
       "                      2.4147, 4.0772, 0.8022, 2.4844, 1.1903, 2.0555, 5.1625, 2.9348, 3.8796,\n",
       "                      2.4503, 6.5665, 3.0693, 2.3992, 0.4655, 2.3062, 0.7596, 1.3028, 4.6138,\n",
       "                      4.6771, 1.7011, 4.0918, 2.8823, 1.8484, 3.2436, 2.6942, 3.7085, 3.1958,\n",
       "                      2.9942, 2.3989, 3.8556, 2.3654, 2.6700, 4.2637, 1.6076, 0.5965, 2.6406,\n",
       "                      1.1159, 4.1236, 1.8617, 4.0061, 3.7466, 2.3461, 4.3577, 3.1267, 2.9637,\n",
       "                      3.5263, 5.5695, 2.7128, 5.5817, 0.7433, 1.9665, 3.3712, 2.9256, 2.8814,\n",
       "                      3.2393, 3.3848, 1.6055, 1.6832, 3.6714, 3.0906, 2.5207, 5.6349, 1.9617,\n",
       "                      2.3029, 3.8403, 2.5998, 2.3988, 4.5952, 3.8866, 3.0810, 2.5742, 3.5178,\n",
       "                      4.1190, 1.5830, 1.5182, 2.1119, 0.6169, 3.1919, 3.5891, 1.9612, 3.7955,\n",
       "                      2.4203, 1.6704, 3.9520, 2.1795, 4.3047, 1.4727, 2.0004, 2.3906, 3.1208,\n",
       "                      1.9102, 2.5303, 2.4520, 2.1210, 2.9243, 1.7508, 2.0152, 2.8054, 0.6516,\n",
       "                      3.6895, 1.5018, 0.9527, 2.3132, 0.9412, 1.9646, 3.9331, 2.3557])),\n",
       "             ('decoders.3.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense5.weight',\n",
       "              tensor([[-0.0160,  0.0114, -0.0173,  ...,  0.0194, -0.0233, -0.0296],\n",
       "                      [-0.0370, -0.0514, -0.0389,  ...,  0.0112, -0.0485, -0.0332],\n",
       "                      [ 0.0003, -0.0470, -0.0164,  ..., -0.0444, -0.0237, -0.0152],\n",
       "                      ...,\n",
       "                      [-0.0042,  0.0043, -0.0191,  ..., -0.0190,  0.0007, -0.0231],\n",
       "                      [-0.0161,  0.0217, -0.0272,  ..., -0.0349, -0.0427,  0.0179],\n",
       "                      [-0.0561, -0.0266, -0.0291,  ..., -0.0486, -0.0223, -0.0298]])),\n",
       "             ('decoders.3.dense5.bias',\n",
       "              tensor([ 0.0100,  0.0032,  0.0078,  ..., -0.0052, -0.0112,  0.0046])),\n",
       "             ('decoders.4.dense1.weight',\n",
       "              tensor([[-0.1301, -0.1625,  0.1650,  ...,  0.1494,  0.1308, -0.1259],\n",
       "                      [-0.1348,  0.0026, -0.1320,  ...,  0.1251,  0.0486, -0.0367],\n",
       "                      [-0.1003, -0.1083,  0.1571,  ..., -0.0837, -0.0847, -0.1680],\n",
       "                      ...,\n",
       "                      [-0.0813, -0.0542, -0.0777,  ...,  0.0225,  0.1237, -0.0893],\n",
       "                      [-0.1276, -0.0137,  0.0923,  ..., -0.1121,  0.0343, -0.1033],\n",
       "                      [ 0.0936,  0.0996, -0.1125,  ...,  0.1235,  0.1585, -0.0217]])),\n",
       "             ('decoders.4.bn1.weight',\n",
       "              tensor([0.9924, 1.0126, 0.9930, 0.9922, 0.9932, 0.9827, 0.9986, 0.9885, 0.9865,\n",
       "                      1.0220, 1.0027, 1.0128, 0.9906, 0.9904, 1.0010, 1.0149, 1.0159, 1.0011,\n",
       "                      1.0052, 0.9944, 0.9990, 0.9949, 0.9835, 0.9929, 0.9859, 0.9890, 0.9886,\n",
       "                      0.9996, 0.9913, 0.9948, 1.0168, 0.9935, 1.0002, 0.9909, 0.9850, 1.0074,\n",
       "                      0.9946, 0.9927, 1.0164, 0.9888, 1.0103, 0.9889, 0.9818, 1.0166, 1.0001,\n",
       "                      1.0200, 0.9897, 1.0297, 0.9828, 1.0097, 0.9967, 1.0217, 1.0046, 0.9891,\n",
       "                      1.0208, 1.0062, 0.9913, 0.9919, 1.0110, 1.0000, 0.9987, 1.0076, 1.0010,\n",
       "                      0.9896, 1.0054, 0.9968, 0.9962, 0.9915, 0.9854, 0.9937, 0.9931, 1.0030,\n",
       "                      1.0135, 0.9989, 1.0032, 0.9830, 1.0159, 0.9958, 0.9689, 0.9917, 0.9871,\n",
       "                      1.0225, 0.9889, 1.0016, 1.0082, 0.9890, 0.9851, 1.0091, 0.9895, 1.0099,\n",
       "                      0.9819, 1.0074, 0.9997, 0.9939, 0.9971, 1.0032, 1.0094, 0.9994, 1.0019,\n",
       "                      1.0012, 1.0059, 0.9955, 1.0166, 1.0276, 0.9810, 0.9863, 1.0017, 0.9809,\n",
       "                      1.0109, 0.9857, 0.9955, 0.9951, 1.0065, 1.0229, 1.0117, 0.9906, 0.9923,\n",
       "                      0.9895, 0.9981, 0.9918, 0.9952, 1.0205, 0.9883, 0.9929, 0.9822, 0.9957,\n",
       "                      0.9977, 1.0223])),\n",
       "             ('decoders.4.bn1.bias',\n",
       "              tensor([ 1.5001e-02,  5.0551e-03, -9.4986e-04,  1.3293e-02,  2.8470e-03,\n",
       "                      -1.5988e-02, -9.5635e-04, -7.2529e-03, -9.5746e-03,  3.5124e-02,\n",
       "                       1.1589e-02,  3.1528e-03,  2.7828e-03, -1.1291e-02,  2.2242e-02,\n",
       "                       1.6208e-02,  1.9971e-02,  1.4721e-02,  5.3440e-03,  9.4276e-03,\n",
       "                      -6.8234e-04, -6.9397e-03, -2.3474e-03,  7.7302e-03, -1.2494e-02,\n",
       "                      -3.7479e-03, -1.0706e-02,  2.3729e-04,  6.0089e-03,  1.0348e-03,\n",
       "                       2.1136e-02,  1.6624e-02,  1.5140e-03, -5.8652e-03, -1.7817e-02,\n",
       "                       7.5436e-03,  3.5720e-03, -1.2679e-03,  3.2157e-02,  1.3646e-02,\n",
       "                       2.6749e-02, -7.9742e-03, -1.3304e-02,  9.5896e-03,  3.6951e-02,\n",
       "                       7.5342e-03, -1.3916e-02,  5.1618e-02,  1.9098e-04,  6.6832e-03,\n",
       "                       1.3259e-02, -3.6165e-03,  2.1043e-02, -8.5968e-04,  1.5960e-04,\n",
       "                       9.0047e-03, -1.9251e-03, -1.1625e-02,  1.8806e-02,  2.6540e-02,\n",
       "                       1.4002e-02,  2.9559e-02, -4.0451e-03, -1.7778e-02,  1.8596e-02,\n",
       "                       5.8392e-03,  1.1549e-03,  2.3335e-02, -1.2084e-02, -2.1540e-03,\n",
       "                      -4.4969e-03,  2.3820e-02,  1.5263e-02,  5.2966e-03,  1.8815e-03,\n",
       "                      -8.4912e-03,  6.8794e-03,  2.2510e-02, -1.4369e-02, -2.2140e-03,\n",
       "                      -9.3845e-03,  1.6415e-02,  1.3303e-03,  1.9906e-02,  2.4300e-02,\n",
       "                      -1.1487e-02, -4.8858e-03,  1.5207e-02, -9.9725e-04,  2.4076e-02,\n",
       "                      -9.7836e-03,  6.8722e-03,  3.8103e-03,  9.7013e-04,  8.5726e-03,\n",
       "                       2.6225e-02,  1.6097e-02,  5.6272e-03,  1.6141e-03,  1.1908e-02,\n",
       "                       3.2328e-02, -8.5181e-03,  1.1164e-02,  1.6105e-02,  3.9568e-03,\n",
       "                      -1.3533e-02,  1.3428e-02, -9.9001e-03,  1.3911e-02,  3.6566e-03,\n",
       "                       7.6307e-03, -2.2330e-03,  2.6244e-03,  3.3771e-02,  7.1361e-05,\n",
       "                      -4.9023e-03,  1.0483e-02, -8.1615e-03,  1.3096e-02,  5.9194e-03,\n",
       "                       4.1144e-03,  2.8804e-02, -8.3610e-03, -2.1987e-02, -1.7099e-02,\n",
       "                       1.5850e-02,  1.7659e-02,  1.3426e-02])),\n",
       "             ('decoders.4.bn1.running_mean',\n",
       "              tensor([-0.4137,  0.7112,  0.1714, -0.4833, -0.5430,  0.0444,  0.4751, -0.0637,\n",
       "                       0.3396, -0.3862,  0.4183,  0.7061, -0.1707,  0.0652, -0.4845,  0.6860,\n",
       "                       0.7393, -0.2947,  0.6056,  0.1452,  0.2470,  0.0251,  0.3291, -0.4480,\n",
       "                       0.0103, -0.1736,  0.0097,  0.5179, -0.1710,  0.5105,  0.6645, -0.2326,\n",
       "                       0.5068, -0.0616, -0.0045,  0.4404, -0.1465,  0.3414,  0.5353, -0.5956,\n",
       "                      -0.2639,  0.1797, -0.1550,  0.6671, -0.4618,  0.7136,  0.2031, -0.7165,\n",
       "                      -0.3351,  0.7333, -0.5429,  0.9747, -0.4161,  0.3340,  1.1352,  0.4997,\n",
       "                      -0.2744,  0.1560, -0.3157, -0.5009, -0.2167, -0.6159,  0.4701,  0.2024,\n",
       "                       0.4122,  0.3554,  0.1290, -0.4563, -0.0585,  0.2007,  0.3939, -0.3747,\n",
       "                       0.3999, -0.1062,  0.4074,  0.1448,  0.4453, -0.5063, -0.0381, -0.0199,\n",
       "                      -0.0259,  0.7143, -0.5907, -0.6026, -0.6157,  0.3813,  0.1577, -0.6204,\n",
       "                      -0.2991, -0.6793,  0.2211,  0.5340,  0.4791,  0.2496, -0.2907, -0.4124,\n",
       "                      -0.4509, -0.0918,  0.3613,  0.5618, -0.5557,  0.5708,  0.6565,  0.6257,\n",
       "                      -0.2491,  0.0107,  0.3296,  0.2382, -0.5240, -0.0535,  0.3554,  0.3881,\n",
       "                       0.4848,  0.7138,  0.5557,  0.2305, -0.2065,  0.1656, -0.1384, -0.4403,\n",
       "                       0.5578, -0.7561, -0.4226,  0.1470, -0.1618, -0.3830, -0.3255,  0.6119])),\n",
       "             ('decoders.4.bn1.running_var',\n",
       "              tensor([0.3311, 1.1485, 0.1974, 0.7768, 0.2286, 0.1614, 0.2744, 0.1688, 0.2268,\n",
       "                      0.3518, 0.4239, 1.2177, 0.1462, 0.1327, 0.6327, 0.6847, 0.7874, 0.1053,\n",
       "                      0.8272, 0.1372, 0.1837, 0.1562, 0.2555, 0.5868, 0.1679, 0.1351, 0.1641,\n",
       "                      0.3570, 0.1584, 0.4176, 0.7881, 0.4303, 0.4566, 0.1196, 0.1106, 0.4650,\n",
       "                      0.2366, 0.2969, 1.0054, 0.5641, 0.4440, 0.2561, 0.1135, 0.7852, 0.9094,\n",
       "                      1.0281, 0.2409, 0.4713, 0.2987, 0.8950, 0.4770, 1.7481, 0.4576, 0.1562,\n",
       "                      2.9680, 0.4162, 0.1144, 0.1935, 0.2913, 0.4501, 0.2704, 1.0522, 0.4913,\n",
       "                      0.1541, 0.3822, 0.3587, 0.1226, 0.3607, 0.1476, 0.4744, 0.3690, 0.3573,\n",
       "                      0.4869, 0.2057, 0.2835, 0.1194, 0.6645, 0.5292, 0.1010, 0.1058, 0.1633,\n",
       "                      1.1414, 0.7393, 0.5558, 0.4561, 0.4122, 0.1564, 0.4568, 0.2545, 1.0291,\n",
       "                      0.2711, 0.5225, 0.5042, 0.2770, 0.2159, 0.6557, 0.4183, 0.1969, 0.3890,\n",
       "                      0.4609, 0.7175, 0.5972, 0.9497, 0.9269, 0.2509, 0.1053, 0.1572, 0.1311,\n",
       "                      0.7877, 0.2032, 0.2861, 0.3081, 0.4402, 0.5929, 0.4887, 0.3350, 0.2352,\n",
       "                      0.1540, 0.1401, 1.0049, 0.5429, 1.4627, 0.4956, 0.1937, 0.1919, 0.3537,\n",
       "                      0.3335, 0.9626])),\n",
       "             ('decoders.4.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense2.weight',\n",
       "              tensor([[-0.0084, -0.0494, -0.0220,  ..., -0.0689, -0.0845,  0.0632],\n",
       "                      [-0.0590,  0.0829, -0.0002,  ..., -0.0308,  0.0072, -0.0535],\n",
       "                      [ 0.0078, -0.0970,  0.0457,  ...,  0.0206,  0.0186, -0.0474],\n",
       "                      ...,\n",
       "                      [-0.0444, -0.0732, -0.0649,  ..., -0.0634,  0.0682, -0.0757],\n",
       "                      [ 0.0321,  0.0630,  0.0506,  ..., -0.0774, -0.0708, -0.0896],\n",
       "                      [-0.0771,  0.0243,  0.0792,  ..., -0.0604,  0.0060,  0.0857]])),\n",
       "             ('decoders.4.bn2.weight',\n",
       "              tensor([1.0091, 0.9845, 0.9975, 1.0051, 0.9974, 0.9919, 0.9908, 0.9948, 0.9898,\n",
       "                      1.0054, 0.9793, 1.0008, 0.9830, 1.0043, 1.0069, 1.0027, 1.0167, 1.0083,\n",
       "                      1.0002, 1.0225, 1.0134, 0.9876, 0.9782, 0.9997, 0.9957, 0.9927, 0.9896,\n",
       "                      0.9958, 1.0105, 1.0097, 0.9959, 0.9954, 1.0071, 0.9936, 1.0004, 1.0031,\n",
       "                      0.9976, 1.0194, 1.0061, 0.9919, 0.9842, 0.9989, 0.9965, 0.9950, 0.9956,\n",
       "                      0.9943, 0.9970, 0.9953, 0.9984, 0.9941, 1.0006, 0.9932, 1.0190, 0.9939,\n",
       "                      0.9979, 1.0060, 0.9915, 0.9994, 1.0017, 1.0007, 0.9887, 1.0018, 0.9996,\n",
       "                      0.9886, 0.9996, 0.9921, 1.0101, 0.9853, 1.0253, 0.9982, 0.9856, 1.0141,\n",
       "                      0.9849, 0.9925, 0.9993, 1.0032, 0.9909, 1.0086, 1.0160, 1.0087, 1.0025,\n",
       "                      1.0026, 0.9987, 0.9818, 0.9872, 0.9934, 0.9946, 1.0186, 0.9946, 1.0129,\n",
       "                      0.9778, 1.0099, 1.0018, 0.9997, 0.9926, 1.0078, 0.9985, 1.0097, 0.9808,\n",
       "                      0.9783, 0.9980, 0.9984, 0.9862, 1.0030, 1.0129, 1.0191, 0.9887, 1.0091,\n",
       "                      1.0139, 1.0216, 1.0063, 0.9954, 1.0011, 0.9967, 1.0177, 0.9848, 0.9988,\n",
       "                      1.0196, 0.9992, 0.9856, 0.9869, 0.9996, 0.9976, 0.9820, 1.0119, 0.9882,\n",
       "                      0.9828, 0.9961, 1.0079, 0.9930, 0.9878, 0.9831, 0.9978, 0.9913, 0.9931,\n",
       "                      1.0064, 1.0147, 1.0170, 0.9906, 1.0079, 0.9903, 1.0093, 0.9953, 0.9982,\n",
       "                      1.0149, 1.0136, 0.9887, 0.9985, 1.0142, 0.9926, 0.9925, 1.0096, 1.0062,\n",
       "                      1.0088, 1.0088, 0.9839, 0.9907, 0.9852, 0.9914, 1.0017, 1.0026, 0.9933,\n",
       "                      0.9888, 0.9872, 0.9982, 0.9972, 0.9925, 1.0013, 0.9940, 1.0015, 1.0002,\n",
       "                      1.0032, 1.0226, 1.0198, 1.0054, 0.9897, 0.9781, 0.9920, 0.9893, 1.0084,\n",
       "                      0.9913, 0.9932, 0.9954, 0.9956, 0.9928, 1.0036, 1.0208, 0.9920, 0.9978,\n",
       "                      1.0021, 0.9917, 1.0089, 0.9931, 0.9959, 1.0099, 1.0011, 1.0013, 0.9909,\n",
       "                      0.9904, 1.0230, 0.9882, 0.9948, 0.9920, 0.9999, 0.9946, 0.9867, 0.9896,\n",
       "                      1.0173, 0.9940, 0.9979, 1.0134, 1.0063, 0.9948, 0.9902, 0.9966, 0.9942,\n",
       "                      1.0059, 0.9924, 1.0164, 0.9928, 0.9928, 1.0018, 0.9795, 1.0288, 1.0079,\n",
       "                      1.0073, 1.0021, 1.0209, 0.9905, 0.9894, 1.0037, 1.0093, 0.9897, 1.0144,\n",
       "                      1.0104, 0.9752, 1.0056, 0.9945, 0.9948, 0.9845, 0.9936, 1.0000, 1.0009,\n",
       "                      1.0011, 1.0202, 0.9863, 1.0015, 0.9895, 1.0145, 1.0138, 1.0177, 1.0216,\n",
       "                      0.9957, 1.0037, 0.9968, 0.9901])),\n",
       "             ('decoders.4.bn2.bias',\n",
       "              tensor([ 2.8752e-02, -1.7311e-02,  2.0343e-02,  1.1301e-02, -5.0704e-03,\n",
       "                       2.8820e-02,  1.8739e-02,  3.8339e-03, -9.6433e-03,  1.1667e-02,\n",
       "                      -2.4432e-02,  1.9573e-05, -1.8605e-02,  6.9483e-03,  1.1266e-02,\n",
       "                       5.8900e-03,  6.8317e-03,  1.7720e-02,  2.9414e-03,  6.7486e-03,\n",
       "                       2.4493e-02, -3.3799e-03, -1.6521e-02,  1.1785e-03, -4.9047e-03,\n",
       "                       6.5161e-03, -9.1930e-03,  1.1666e-02,  4.7229e-02,  1.0461e-02,\n",
       "                       1.7762e-02,  4.0447e-02,  3.2269e-02,  6.0915e-03,  6.4062e-03,\n",
       "                      -1.0664e-02,  1.4510e-03,  3.1356e-02,  1.9325e-02,  1.4918e-04,\n",
       "                      -1.4265e-02,  6.7011e-03,  3.9235e-03,  2.7037e-02,  4.0749e-03,\n",
       "                      -1.6903e-03,  2.4300e-03, -1.5739e-03,  7.5175e-04, -7.4269e-03,\n",
       "                       7.0934e-03,  2.8559e-03,  6.0402e-03, -1.1574e-03,  1.5914e-02,\n",
       "                       3.7451e-03,  1.0742e-02,  1.1972e-02,  1.1254e-02,  8.6602e-03,\n",
       "                      -6.4528e-03,  4.3886e-03,  9.6087e-03, -4.2226e-03, -2.6681e-02,\n",
       "                       1.9617e-02, -1.3157e-04, -5.7369e-03,  7.6042e-03, -2.7591e-03,\n",
       "                      -5.7405e-03,  8.2853e-03, -1.4277e-03,  1.8189e-02,  1.4691e-02,\n",
       "                       2.8913e-03,  7.0926e-03,  9.1523e-03,  8.4811e-03,  1.5745e-02,\n",
       "                       1.8626e-03,  8.8196e-03,  1.7284e-03, -1.2419e-02, -6.4319e-03,\n",
       "                       1.1070e-03,  1.3970e-03,  8.0599e-03,  7.8502e-04, -1.0322e-03,\n",
       "                      -3.4242e-03,  1.6244e-03,  2.7887e-03, -4.2853e-03, -2.9787e-03,\n",
       "                       2.6889e-02,  4.0137e-03,  5.7546e-02, -2.0935e-03,  9.4909e-03,\n",
       "                       1.8388e-02, -5.7608e-03, -1.3979e-02,  6.2021e-03,  4.9345e-02,\n",
       "                       4.3534e-02, -6.5987e-03,  1.0576e-02,  2.8853e-02, -1.5203e-03,\n",
       "                       2.2814e-02,  1.2397e-02, -1.4377e-03,  1.5422e-02,  1.8737e-02,\n",
       "                      -9.7457e-03, -6.4547e-03,  2.7373e-02,  5.6077e-03, -2.5962e-02,\n",
       "                      -1.0332e-02,  3.1678e-03,  2.0722e-02,  4.4097e-03, -1.2915e-04,\n",
       "                      -1.7714e-02, -5.5371e-03,  4.7641e-04,  3.5024e-02,  7.8048e-03,\n",
       "                       1.0580e-02, -1.1937e-02,  2.6853e-02, -1.7957e-03,  2.8168e-03,\n",
       "                       2.2479e-02,  9.1343e-03,  4.9369e-02, -2.6253e-03,  1.1909e-02,\n",
       "                      -2.9963e-03,  3.2995e-02,  1.9183e-02, -1.4195e-03,  2.3296e-02,\n",
       "                       1.3611e-03, -3.0333e-03,  8.0991e-03,  1.1179e-02,  7.8882e-03,\n",
       "                       5.6873e-03,  6.8218e-02,  5.9604e-04,  3.2167e-02,  4.2679e-02,\n",
       "                      -1.4312e-02, -1.0822e-02,  1.3372e-02,  1.5621e-02,  2.8413e-02,\n",
       "                       8.6551e-03, -7.6399e-03, -4.4255e-03,  2.9755e-03,  8.2082e-03,\n",
       "                      -1.9376e-03,  1.4186e-02,  9.7501e-03,  3.1954e-02, -2.3052e-03,\n",
       "                       3.2527e-02,  3.0335e-02,  1.5699e-02,  6.1250e-03, -7.2934e-03,\n",
       "                      -8.3197e-03, -2.1011e-02,  1.9096e-02, -6.8442e-03, -1.1987e-02,\n",
       "                       4.6972e-03,  3.1000e-02,  2.5098e-02,  1.3979e-02,  1.1064e-02,\n",
       "                       1.3369e-02,  1.1226e-02,  6.6102e-03,  2.7946e-02, -5.8059e-03,\n",
       "                       2.1309e-02,  1.5245e-02, -4.3103e-03, -7.3110e-03,  6.8232e-03,\n",
       "                      -6.7339e-03,  1.1357e-02,  1.1836e-03, -1.7609e-02,  2.9962e-02,\n",
       "                      -6.8817e-03,  6.6977e-03,  8.8089e-03,  3.8804e-02, -1.0141e-03,\n",
       "                      -1.0729e-02,  2.2343e-02,  1.5217e-03,  7.1688e-03,  1.7532e-02,\n",
       "                       6.2945e-03,  6.4366e-03,  3.9453e-03, -2.1479e-03,  1.1753e-02,\n",
       "                       1.3997e-02,  1.3019e-02, -8.1571e-03, -6.0796e-03, -6.3299e-03,\n",
       "                       5.2521e-03,  1.4974e-02, -1.7266e-02,  3.2494e-02,  4.2277e-03,\n",
       "                       4.2359e-03,  1.7826e-02,  1.1849e-02, -1.8077e-02, -1.7703e-03,\n",
       "                       1.3878e-02,  7.5174e-03, -3.4523e-03,  2.2384e-02, -8.4441e-03,\n",
       "                      -2.4571e-02,  9.5070e-03, -4.1777e-03,  8.3278e-03, -1.2003e-03,\n",
       "                       1.2734e-02,  3.5695e-03,  2.9773e-02, -3.8389e-03,  9.3018e-03,\n",
       "                      -8.1825e-03, -1.2482e-02,  6.9842e-03,  2.0743e-03,  1.0895e-03,\n",
       "                       6.6699e-03,  1.9873e-02,  9.3315e-03, -2.3736e-03,  2.6237e-03,\n",
       "                      -5.5366e-03])),\n",
       "             ('decoders.4.bn2.running_mean',\n",
       "              tensor([-2.9068e-01, -1.8419e-01, -1.2883e-01, -3.5109e-01,  2.9216e-01,\n",
       "                      -2.1034e-01, -3.9298e-01,  2.3970e-01,  3.2012e-03, -4.1450e-01,\n",
       "                       2.2897e-01, -2.2106e-01,  7.5052e-03, -5.0666e-02, -4.1225e-01,\n",
       "                      -1.2700e-01,  3.6799e-01, -1.6378e-01, -3.8228e-01,  1.7601e-01,\n",
       "                       8.0519e-02,  1.7633e-01, -1.1186e-01,  1.5832e-01, -2.2311e-01,\n",
       "                      -1.2232e-01,  9.2668e-02, -2.2832e-01, -4.6217e-02,  2.3663e-01,\n",
       "                       1.9578e-01, -2.0064e-01, -1.1626e-01, -1.2743e-01,  2.2261e-02,\n",
       "                       2.4265e-01, -1.7845e-01,  5.5340e-02,  7.1253e-02, -3.8345e-02,\n",
       "                      -1.6721e-01,  2.5754e-01,  1.3156e-01, -1.9727e-01,  1.7424e-01,\n",
       "                       1.3130e-01, -2.4749e-01,  1.1580e-01, -2.0588e-01,  1.3230e-01,\n",
       "                       3.3881e-02,  1.5137e-01, -1.2447e-02, -1.8974e-01, -3.2147e-01,\n",
       "                      -1.0206e-01, -1.1716e-01,  7.9721e-02, -1.9270e-01,  2.6743e-03,\n",
       "                       9.2150e-02,  9.4360e-03, -2.9569e-01,  4.9141e-02,  5.1644e-01,\n",
       "                      -2.6291e-01,  1.3517e-01, -2.0282e-02, -1.8010e-01, -1.1683e-01,\n",
       "                      -3.2185e-01,  1.2622e-01,  4.9415e-02,  1.6702e-02,  7.3901e-02,\n",
       "                      -7.8267e-03, -3.1934e-01,  4.1501e-02, -1.3613e-01,  2.5613e-01,\n",
       "                       1.7544e-01,  3.9253e-02, -2.9598e-01,  2.4585e-01, -6.6331e-02,\n",
       "                       8.2648e-02, -1.0739e-01,  2.0327e-01, -1.1372e-02,  4.1162e-02,\n",
       "                      -3.1650e-02, -1.0829e-02,  3.7282e-02,  4.5373e-01, -2.4328e-01,\n",
       "                      -1.6077e-01, -4.9839e-03, -1.8468e-01, -2.2556e-01, -9.9359e-02,\n",
       "                       1.1565e-01, -2.6252e-01, -2.0239e-01, -4.2598e-01, -1.8347e-01,\n",
       "                      -3.5207e-01,  8.4438e-03,  1.0336e-01, -6.8301e-02,  3.8917e-01,\n",
       "                       3.0883e-02, -1.6506e-01,  1.4152e-01, -7.0210e-02, -5.3864e-02,\n",
       "                      -3.5958e-02, -2.4318e-01,  9.7873e-02, -1.2670e-01,  2.8798e-01,\n",
       "                       2.6559e-01, -2.7337e-01,  1.2946e-01, -5.5935e-02,  1.9487e-01,\n",
       "                      -4.8579e-03, -1.2744e-01,  2.7292e-01,  1.8528e-01, -2.3591e-01,\n",
       "                      -2.7067e-01, -1.0445e-01, -4.2995e-01,  8.0467e-02, -1.9451e-01,\n",
       "                      -5.4813e-02, -1.4705e-01, -1.2331e-01, -5.2908e-02,  3.0014e-01,\n",
       "                       3.6667e-02, -2.8197e-01, -3.2558e-01,  1.5451e-01, -4.2269e-01,\n",
       "                       4.2310e-01,  1.7207e-01, -3.2115e-01,  3.8444e-03, -5.6950e-02,\n",
       "                       6.6524e-02, -5.6679e-01,  3.0941e-01, -4.8789e-01, -3.5059e-01,\n",
       "                      -2.2835e-01, -2.9405e-01, -7.0719e-02, -2.8896e-01, -4.4891e-01,\n",
       "                      -1.1742e-01, -3.7311e-02, -6.4861e-02, -7.0372e-02, -2.0940e-01,\n",
       "                       1.8273e-01, -5.6151e-01, -3.5261e-01, -2.8316e-01, -3.6411e-01,\n",
       "                      -2.5500e-01, -3.0799e-01, -4.3991e-01,  2.1513e-01,  2.4753e-01,\n",
       "                       8.8065e-02, -4.3873e-02,  9.4005e-02,  2.1650e-01,  5.2781e-01,\n",
       "                       1.0850e-01, -8.7431e-05, -2.6938e-01, -7.2186e-02,  7.5392e-02,\n",
       "                       2.9791e-02,  5.8081e-02, -2.3952e-01, -3.9619e-01,  1.4238e-01,\n",
       "                       1.0871e-02,  2.8339e-01, -3.4912e-02,  5.1747e-02, -2.1194e-01,\n",
       "                       1.0124e-01,  7.1182e-02,  8.3631e-02, -1.3610e-01,  1.4040e-01,\n",
       "                       2.4585e-02, -1.4707e-01, -1.6947e-02,  2.0283e-01, -7.6221e-02,\n",
       "                      -7.3251e-03, -2.2211e-01,  2.2178e-01, -4.1364e-02, -2.4368e-01,\n",
       "                       8.2098e-02,  2.9148e-01, -7.8308e-02,  5.1250e-03,  1.3669e-01,\n",
       "                      -2.0804e-02,  3.4478e-02,  4.4150e-02,  1.2494e-01, -1.5961e-01,\n",
       "                       1.6882e-01, -2.0607e-01,  4.5155e-02, -3.4632e-01,  5.6269e-01,\n",
       "                       1.6180e-01, -1.1691e-01,  3.1772e-01,  1.4612e-01, -1.6665e-01,\n",
       "                      -6.9415e-04,  3.3852e-01,  1.1844e-01,  2.0711e-01,  1.6443e-01,\n",
       "                      -1.2554e-01,  3.2496e-01, -3.5465e-01,  8.2323e-02,  8.9721e-02,\n",
       "                      -1.3592e-01, -1.0193e-01, -4.3639e-01,  1.1083e-01, -4.1076e-02,\n",
       "                       4.8515e-03,  1.8567e-01, -1.4900e-01,  2.3809e-01,  2.4749e-01,\n",
       "                       1.8519e-01, -5.5380e-01, -6.0636e-02, -2.4376e-01, -1.3216e-01,\n",
       "                      -1.5561e-01])),\n",
       "             ('decoders.4.bn2.running_var',\n",
       "              tensor([0.1906, 0.1325, 0.3081, 0.4290, 0.2297, 0.2724, 0.3290, 0.3607, 0.2919,\n",
       "                      0.0974, 0.3450, 0.4537, 0.1621, 0.2582, 0.1395, 0.0560, 2.4962, 0.6204,\n",
       "                      0.0869, 1.0801, 1.0579, 0.2318, 0.0763, 0.4097, 0.0857, 0.1544, 0.3111,\n",
       "                      0.2682, 0.4842, 0.5554, 0.5942, 0.2290, 0.8134, 0.4730, 1.3762, 0.2733,\n",
       "                      0.1677, 0.4415, 0.2265, 0.4618, 0.1215, 0.3062, 0.4291, 0.1529, 0.1920,\n",
       "                      0.2557, 0.0716, 0.1223, 0.4466, 0.2245, 0.4810, 0.3188, 0.9879, 0.1290,\n",
       "                      0.1894, 0.2700, 0.3767, 0.3641, 0.1594, 0.7708, 0.2920, 0.0745, 0.1373,\n",
       "                      0.2228, 0.2522, 0.3763, 0.4628, 0.2399, 1.0046, 0.1101, 0.0850, 1.3156,\n",
       "                      0.2566, 0.3264, 0.3171, 0.5304, 0.1459, 0.5316, 0.8720, 0.5595, 0.1504,\n",
       "                      0.1069, 0.2420, 0.1876, 0.3386, 0.0894, 0.1723, 1.5293, 0.1654, 1.1263,\n",
       "                      0.1257, 0.3869, 0.4330, 0.3225, 0.1081, 0.1831, 0.2862, 0.4165, 0.2870,\n",
       "                      0.2771, 0.4513, 0.1455, 0.0871, 0.1878, 0.3004, 0.0873, 0.0882, 0.8220,\n",
       "                      0.3877, 0.5089, 0.5901, 0.2946, 0.1034, 0.2143, 1.0723, 0.3118, 0.0978,\n",
       "                      1.4855, 0.1660, 0.1001, 0.3181, 0.1640, 0.2306, 0.2450, 1.3083, 0.3196,\n",
       "                      0.2537, 0.2089, 0.7162, 0.4100, 0.1491, 0.3836, 0.1546, 0.2304, 0.2144,\n",
       "                      0.7655, 0.5196, 0.2681, 0.0471, 0.2640, 0.3182, 0.2266, 0.6014, 0.2584,\n",
       "                      0.4476, 0.7784, 0.2676, 0.3161, 0.7074, 0.4416, 0.3347, 0.3167, 0.6215,\n",
       "                      0.1922, 0.1435, 0.0981, 0.0944, 0.3188, 0.1815, 0.2787, 0.2464, 0.5345,\n",
       "                      0.1257, 0.2036, 0.2215, 0.4861, 0.1316, 0.1417, 0.2912, 0.2262, 0.1294,\n",
       "                      0.3264, 0.5084, 1.4351, 0.2852, 0.0879, 0.0916, 0.1747, 0.1843, 0.8078,\n",
       "                      0.4364, 0.3427, 0.2182, 0.1526, 0.1237, 0.6802, 0.5606, 0.1463, 0.3035,\n",
       "                      0.3552, 0.5719, 0.2039, 0.0912, 0.1593, 0.1858, 0.2552, 0.5874, 0.3818,\n",
       "                      0.2108, 0.5343, 0.3694, 0.1138, 0.3663, 0.2354, 0.2592, 0.1149, 0.1086,\n",
       "                      1.0756, 0.3127, 0.1412, 0.4621, 0.2826, 0.4107, 0.2181, 0.2893, 0.4264,\n",
       "                      0.2554, 0.2009, 0.6988, 0.1806, 0.1711, 0.2643, 0.2163, 0.7371, 0.7713,\n",
       "                      0.8905, 0.1173, 0.5858, 0.1413, 0.5919, 0.5092, 0.1468, 0.4222, 0.8365,\n",
       "                      0.6300, 0.0656, 0.1609, 0.4003, 0.2550, 0.3030, 0.5180, 0.2093, 0.2178,\n",
       "                      0.6357, 1.0885, 0.1435, 0.6745, 0.1208, 1.5727, 1.3513, 1.5553, 0.4140,\n",
       "                      0.3329, 0.0653, 0.1745, 0.2082])),\n",
       "             ('decoders.4.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense3.weight',\n",
       "              tensor([[ 0.0481, -0.0489, -0.0039,  ...,  0.0558,  0.0334, -0.0204],\n",
       "                      [-0.0227,  0.0654, -0.0071,  ..., -0.0321, -0.0365,  0.0083],\n",
       "                      [ 0.0108,  0.0025,  0.0315,  ..., -0.0442,  0.0580,  0.0029],\n",
       "                      ...,\n",
       "                      [-0.0444,  0.0512,  0.0089,  ...,  0.0434, -0.0503, -0.0563],\n",
       "                      [ 0.0489,  0.0305, -0.0523,  ...,  0.0424,  0.0577,  0.0601],\n",
       "                      [-0.0481,  0.0003,  0.0031,  ...,  0.0064, -0.0327, -0.0682]])),\n",
       "             ('decoders.4.bn3.weight',\n",
       "              tensor([0.9962, 0.9952, 0.9892, 0.9949, 0.9950, 0.9991, 1.0025, 1.0134, 0.9938,\n",
       "                      1.0005, 1.0057, 1.0032, 1.0119, 0.9945, 0.9819, 0.9910, 1.0097, 0.9848,\n",
       "                      0.9996, 0.9950, 1.0041, 0.9944, 1.0046, 0.9997, 1.0092, 0.9985, 0.9835,\n",
       "                      1.0172, 0.9961, 0.9882, 0.9991, 1.0092, 0.9985, 1.0092, 1.0026, 1.0059,\n",
       "                      0.9797, 1.0107, 1.0130, 1.0028, 1.0048, 0.9900, 0.9921, 1.0108, 1.0027,\n",
       "                      0.9924, 1.0094, 0.9975, 0.9918, 1.0111, 0.9975, 0.9910, 0.9969, 0.9912,\n",
       "                      1.0136, 0.9942, 0.9943, 1.0066, 1.0011, 1.0080, 1.0178, 0.9943, 0.9769,\n",
       "                      1.0169, 1.0065, 0.9920, 1.0248, 1.0037, 1.0090, 0.9983, 1.0023, 1.0213,\n",
       "                      0.9925, 0.9976, 0.9950, 1.0037, 0.9897, 1.0089, 0.9991, 0.9989, 0.9866,\n",
       "                      0.9996, 1.0027, 0.9987, 1.0088, 0.9909, 0.9995, 0.9996, 1.0177, 1.0028,\n",
       "                      0.9960, 1.0003, 1.0054, 0.9977, 1.0175, 0.9857, 1.0150, 1.0000, 1.0036,\n",
       "                      1.0019, 0.9966, 0.9965, 1.0028, 1.0020, 0.9929, 0.9930, 0.9812, 0.9915,\n",
       "                      1.0059, 0.9859, 1.0208, 1.0027, 1.0008, 0.9990, 0.9948, 1.0033, 0.9962,\n",
       "                      0.9961, 1.0062, 0.9960, 0.9856, 1.0006, 1.0004, 0.9900, 1.0068, 1.0146,\n",
       "                      1.0043, 1.0074, 1.0032, 0.9905, 1.0024, 1.0204, 0.9890, 0.9906, 1.0139,\n",
       "                      1.0161, 0.9902, 0.9946, 0.9880, 0.9981, 1.0100, 1.0075, 0.9777, 1.0110,\n",
       "                      0.9892, 0.9928, 0.9902, 1.0018, 0.9957, 0.9901, 0.9940, 0.9924, 1.0181,\n",
       "                      1.0017, 0.9984, 0.9927, 0.9888, 0.9867, 1.0170, 1.0070, 1.0022, 0.9900,\n",
       "                      0.9975, 1.0189, 1.0026, 1.0055, 1.0163, 0.9907, 0.9979, 0.9960, 1.0111,\n",
       "                      0.9904, 1.0002, 0.9958, 0.9928, 0.9983, 0.9948, 0.9957, 1.0152, 1.0037,\n",
       "                      1.0008, 1.0082, 0.9893, 1.0045, 0.9985, 0.9955, 0.9984, 0.9986, 1.0130,\n",
       "                      0.9820, 0.9930, 0.9939, 0.9958, 1.0059, 0.9962, 1.0079, 1.0089, 1.0017,\n",
       "                      0.9909, 1.0048, 0.9912, 0.9995, 0.9906, 1.0182, 0.9965, 0.9934, 1.0195,\n",
       "                      1.0009, 1.0137, 0.9928, 0.9827, 1.0176, 0.9963, 1.0094, 1.0099, 1.0132,\n",
       "                      1.0072, 1.0195, 0.9989, 0.9886, 0.9939, 0.9979, 1.0026, 0.9897, 1.0210,\n",
       "                      0.9998, 1.0054, 1.0002, 0.9928, 0.9997, 0.9964, 0.9993, 1.0097, 0.9939,\n",
       "                      0.9953, 1.0098, 0.9943, 0.9931, 1.0070, 0.9865, 1.0053, 0.9962, 1.0040,\n",
       "                      0.9927, 0.9916, 1.0107, 0.9927, 0.9970, 0.9919, 1.0070, 1.0161, 1.0233,\n",
       "                      0.9882, 1.0034, 0.9849, 1.0126, 0.9942, 0.9930, 0.9965, 0.9891, 0.9879,\n",
       "                      1.0042, 0.9969, 1.0006, 1.0000, 0.9936, 1.0208, 1.0042, 1.0137, 0.9782,\n",
       "                      1.0065, 0.9924, 0.9991, 0.9963, 1.0038, 1.0083, 1.0137, 0.9906, 0.9977,\n",
       "                      0.9999, 0.9934, 1.0200, 1.0013, 0.9989, 0.9908, 0.9920, 1.0035, 0.9902,\n",
       "                      0.9886, 0.9960, 1.0050, 0.9901, 1.0039, 1.0037, 0.9922, 0.9912, 0.9919,\n",
       "                      0.9915, 0.9970, 1.0088, 0.9884, 1.0034, 1.0041, 1.0026, 0.9971, 1.0025,\n",
       "                      1.0003, 1.0061, 0.9931, 0.9836, 0.9843, 0.9981, 0.9931, 1.0006, 0.9955,\n",
       "                      1.0114, 0.9903, 0.9876, 0.9957, 1.0227, 0.9946, 1.0035, 0.9926, 0.9915,\n",
       "                      0.9952, 1.0216, 0.9919, 1.0069, 0.9998, 0.9815, 0.9971, 1.0113, 0.9998,\n",
       "                      0.9979, 0.9958, 0.9804, 0.9975, 1.0028, 1.0136, 0.9919, 0.9860, 1.0011,\n",
       "                      0.9974, 0.9858, 0.9934, 0.9962, 0.9941, 1.0216, 0.9991, 1.0001, 1.0008,\n",
       "                      1.0063, 0.9984, 0.9999, 1.0105, 1.0012, 1.0118, 0.9936, 0.9945, 0.9931,\n",
       "                      1.0024, 0.9924, 1.0070, 1.0015, 0.9869, 1.0189, 0.9916, 0.9870, 1.0138,\n",
       "                      1.0009, 1.0254, 1.0001, 0.9900, 0.9974, 0.9775, 1.0016, 0.9902, 1.0198,\n",
       "                      0.9904, 0.9942, 0.9944, 0.9907, 1.0010, 1.0068, 0.9970, 0.9823, 1.0016,\n",
       "                      0.9867, 0.9829, 1.0029, 1.0006, 0.9878, 1.0025, 1.0109, 0.9988, 0.9785,\n",
       "                      0.9996, 0.9978, 0.9947, 0.9915, 1.0127, 0.9919, 0.9875, 0.9859, 0.9877,\n",
       "                      1.0068, 0.9947, 0.9921, 0.9901, 1.0035, 1.0179, 1.0018, 0.9924, 0.9998,\n",
       "                      0.9963, 1.0015, 1.0132, 1.0177, 0.9871, 1.0065, 0.9971, 0.9977, 0.9973,\n",
       "                      1.0041, 0.9923, 1.0066, 1.0196, 1.0029, 0.9922, 0.9985, 0.9915, 1.0022,\n",
       "                      0.9975, 0.9986, 1.0037, 1.0042, 1.0190, 1.0190, 0.9936, 0.9955, 1.0141,\n",
       "                      1.0055, 1.0080, 0.9950, 0.9958, 0.9979, 1.0345, 0.9982, 1.0087, 0.9889,\n",
       "                      1.0022, 1.0115, 0.9951, 1.0053, 1.0017, 1.0072, 0.9818, 1.0040, 1.0117,\n",
       "                      0.9833, 1.0032, 0.9943, 1.0120, 1.0211, 0.9969, 0.9945, 0.9815, 1.0128,\n",
       "                      0.9991, 0.9947, 1.0203, 0.9909, 1.0006, 0.9997, 1.0011, 1.0045, 0.9874,\n",
       "                      0.9984, 1.0149, 1.0001, 0.9784, 1.0180, 1.0005, 0.9903, 1.0019, 1.0042,\n",
       "                      0.9976, 0.9949, 0.9856, 0.9926, 0.9877, 1.0033, 0.9949, 0.9857, 0.9880,\n",
       "                      0.9980, 1.0019, 0.9872, 0.9813, 0.9796, 1.0143, 0.9965, 0.9809, 1.0092,\n",
       "                      0.9896, 0.9871, 0.9880, 1.0264, 1.0004, 0.9920, 0.9999, 1.0208])),\n",
       "             ('decoders.4.bn3.bias',\n",
       "              tensor([ 3.0459e-03, -4.6738e-03, -1.0480e-03, -3.3533e-03,  2.3422e-02,\n",
       "                       2.3299e-02,  1.2609e-02,  6.8856e-02,  1.2196e-02,  3.1202e-02,\n",
       "                       2.5782e-03,  5.2010e-02,  7.1398e-03,  1.1568e-02, -8.0097e-03,\n",
       "                       7.6446e-04, -4.3090e-03, -9.0489e-03,  1.6173e-02,  2.2351e-02,\n",
       "                       1.6877e-02, -8.1865e-03, -8.4308e-05,  4.7423e-03,  9.5920e-03,\n",
       "                       2.3756e-02,  7.4303e-03, -3.5982e-03,  3.6755e-03,  1.0660e-02,\n",
       "                       8.9875e-03, -3.1179e-03,  2.1789e-02,  7.4313e-03,  1.7084e-03,\n",
       "                       6.6835e-02, -9.0434e-03, -1.6381e-03, -2.1935e-02,  1.3239e-02,\n",
       "                       3.0725e-02, -1.6485e-02, -4.4546e-03,  1.5325e-02,  3.7509e-02,\n",
       "                       3.6274e-02,  2.5799e-02,  1.6162e-02,  2.6674e-02, -3.8178e-03,\n",
       "                       1.2619e-02,  3.1428e-02,  1.5925e-02,  3.2061e-03,  2.3650e-03,\n",
       "                       8.8132e-03, -5.7079e-04, -2.1112e-03, -1.5844e-04, -8.9825e-03,\n",
       "                      -1.7523e-02,  3.8284e-02, -2.0534e-02, -6.6351e-03, -3.3038e-03,\n",
       "                      -4.8087e-03,  1.4501e-02,  1.3101e-02,  1.6779e-02,  1.6139e-02,\n",
       "                       3.0453e-02, -5.9051e-03, -7.1281e-03,  4.0884e-02, -6.4202e-03,\n",
       "                       9.7988e-03,  3.2382e-03,  3.6814e-02, -8.6945e-03,  4.1636e-02,\n",
       "                       2.2576e-03, -2.2434e-03,  1.9085e-02,  1.2775e-02,  4.2470e-03,\n",
       "                      -1.6794e-02,  1.3799e-02, -9.4781e-03,  2.4017e-02,  1.7457e-02,\n",
       "                       2.3134e-03,  1.6000e-02,  2.3001e-03,  7.2543e-03,  1.0602e-02,\n",
       "                      -8.2982e-03,  1.4280e-03, -1.3617e-02,  9.1314e-03,  1.2677e-02,\n",
       "                       5.8574e-03,  1.7491e-02,  1.3213e-02,  1.0813e-02, -8.3787e-03,\n",
       "                       1.3607e-02, -7.7650e-03,  3.1647e-03,  3.6883e-02, -1.9194e-05,\n",
       "                       2.8405e-03,  1.8774e-02,  9.2108e-03,  1.4593e-02,  1.4066e-03,\n",
       "                       5.3001e-03,  1.3474e-02,  2.8067e-02, -7.6800e-03, -5.6112e-03,\n",
       "                       3.2274e-02,  3.1360e-03,  1.8595e-02, -1.4438e-02,  1.3526e-02,\n",
       "                       7.9191e-03,  2.7647e-02,  2.1733e-03, -5.4995e-03, -3.0840e-03,\n",
       "                       1.9962e-02,  6.3142e-03, -1.1573e-02,  1.6467e-02, -1.4188e-02,\n",
       "                       5.7065e-02, -8.7979e-03, -1.1176e-02, -1.1302e-02, -1.3605e-03,\n",
       "                       9.4253e-03,  1.0744e-02, -1.0842e-02,  8.4929e-03, -1.7737e-04,\n",
       "                       7.5719e-03, -1.3572e-02,  2.5644e-02,  3.2832e-03, -1.6240e-02,\n",
       "                       4.3604e-03,  4.4216e-03,  4.2042e-02,  4.7321e-05,  1.2149e-02,\n",
       "                       6.0870e-03, -5.8974e-03,  6.2859e-03, -4.8138e-03,  6.5793e-03,\n",
       "                       2.8394e-02,  9.7876e-03,  5.9378e-03, -4.1170e-04, -3.2509e-03,\n",
       "                       1.2357e-02,  6.1908e-03, -2.5641e-04,  1.0858e-02,  2.7609e-02,\n",
       "                       2.3818e-02,  5.4844e-03,  1.2802e-02,  9.2825e-03,  1.4268e-02,\n",
       "                       1.7644e-02, -2.4599e-03,  1.4468e-02,  3.4587e-02,  9.4565e-03,\n",
       "                       5.6769e-03,  2.9648e-02, -7.7698e-03, -7.2624e-03,  3.7433e-02,\n",
       "                       1.0730e-02,  1.1728e-03, -5.3202e-03,  5.1100e-03, -5.7208e-03,\n",
       "                       7.5970e-03, -3.6306e-03,  1.3961e-02,  3.8512e-02, -1.9427e-02,\n",
       "                       1.9844e-02,  7.0097e-03,  1.4650e-03,  6.3111e-03,  1.3590e-02,\n",
       "                       2.3601e-02,  1.9788e-03, -1.1318e-02,  2.2821e-02,  1.0943e-02,\n",
       "                      -5.2929e-03,  9.1744e-03,  1.8985e-03,  1.5907e-02, -1.7406e-02,\n",
       "                      -7.4235e-03, -6.9487e-03,  1.0793e-02,  7.9502e-03, -5.7605e-03,\n",
       "                       6.3244e-03,  1.8889e-02, -7.1468e-03,  2.4106e-02, -1.0191e-02,\n",
       "                       8.8338e-03,  1.3081e-02,  7.6558e-03,  1.7156e-02, -9.3001e-03,\n",
       "                       3.6477e-03,  1.4905e-02,  2.2425e-02,  7.5545e-03, -6.9577e-03,\n",
       "                       1.7453e-02,  4.4186e-04, -1.6412e-03,  1.9235e-02,  1.9769e-03,\n",
       "                      -7.0971e-03, -4.2454e-03,  1.2205e-02,  2.4991e-02, -7.5393e-03,\n",
       "                       3.0928e-03,  5.9338e-03, -8.4035e-03,  1.1958e-02,  3.4227e-03,\n",
       "                       2.3861e-03, -3.1536e-04,  1.2127e-02, -3.0021e-04,  3.0504e-02,\n",
       "                       3.1297e-02,  7.9094e-03, -8.2177e-03,  1.8188e-02,  7.6687e-03,\n",
       "                       3.9276e-02, -1.0842e-03,  1.0910e-02,  4.6011e-03, -8.9269e-03,\n",
       "                       5.3029e-03,  2.3832e-02,  2.9807e-02,  5.0663e-03,  1.1130e-03,\n",
       "                       1.2404e-02, -1.1494e-02,  1.9679e-02,  2.4182e-03, -2.3287e-02,\n",
       "                       4.1641e-03,  4.1608e-03,  1.2469e-02,  2.2797e-02,  1.2461e-02,\n",
       "                      -2.9242e-03,  3.3876e-02,  2.5638e-02,  7.5008e-03,  7.4726e-03,\n",
       "                       6.7939e-03, -7.9946e-03,  3.2129e-03, -1.0664e-02,  1.1917e-02,\n",
       "                       2.0930e-02,  3.7631e-03,  6.9257e-03,  9.9196e-03, -8.1318e-03,\n",
       "                       2.4179e-03,  1.0274e-02,  3.6881e-02, -4.3004e-03,  1.8127e-02,\n",
       "                       1.2506e-02,  1.5561e-02, -6.3079e-03, -1.1630e-02,  9.2345e-03,\n",
       "                      -4.3860e-03,  5.3199e-04,  4.1793e-02,  1.6607e-02,  1.8352e-02,\n",
       "                       3.4393e-02, -7.2775e-03,  1.9208e-03,  4.0793e-03, -1.6852e-02,\n",
       "                      -1.0979e-02, -1.0350e-03, -1.5379e-03,  2.3323e-03,  1.0593e-02,\n",
       "                       2.2240e-02, -4.7108e-03, -1.4436e-02,  5.4606e-03,  7.0419e-03,\n",
       "                       2.2443e-02, -1.1583e-02,  4.6255e-03,  2.4043e-02,  1.0184e-02,\n",
       "                       1.6837e-02,  2.9749e-02,  1.8087e-02, -8.5799e-03, -1.2555e-02,\n",
       "                       2.6940e-02,  2.5713e-03,  2.2610e-02,  4.5426e-03,  7.4677e-03,\n",
       "                      -1.0902e-02,  3.9773e-02,  6.4572e-04,  3.2653e-02, -1.6989e-02,\n",
       "                      -6.2284e-03,  5.4664e-03,  1.2467e-02, -4.1227e-03, -2.1286e-03,\n",
       "                       2.2851e-02,  4.1560e-03,  3.5520e-03,  1.9242e-03,  8.4935e-03,\n",
       "                       2.7214e-02,  1.8909e-02,  1.7360e-02, -1.6835e-02,  2.4247e-02,\n",
       "                      -4.4687e-03,  2.5545e-02, -3.8209e-03,  2.6071e-02,  1.7820e-02,\n",
       "                       1.7588e-02,  2.2660e-02, -9.5411e-04,  7.8607e-03, -4.3714e-03,\n",
       "                       2.0784e-02,  1.5192e-02, -4.9110e-03,  2.2089e-02,  1.3581e-02,\n",
       "                      -2.0006e-04,  3.8066e-03,  8.3880e-03,  2.4073e-02, -1.3626e-02,\n",
       "                      -9.7414e-03, -2.7881e-03,  2.3619e-03, -1.4696e-02, -4.1236e-04,\n",
       "                      -2.3023e-03,  1.9605e-02, -5.4426e-04,  1.0128e-02,  2.8029e-02,\n",
       "                      -2.4844e-03,  4.8142e-03,  1.1705e-02, -1.2764e-02, -3.9032e-03,\n",
       "                       4.6391e-03, -8.2017e-03,  3.0775e-02,  3.6346e-02,  2.1046e-02,\n",
       "                      -9.7178e-03,  1.4489e-02,  3.7448e-03, -1.9309e-04,  1.9329e-02,\n",
       "                      -3.0191e-03,  1.3910e-02,  8.2291e-03, -5.2823e-03,  1.6102e-02,\n",
       "                       7.3345e-03, -7.7246e-04, -6.4704e-03, -3.1468e-03,  3.0314e-03,\n",
       "                      -2.9536e-03,  9.0020e-03,  1.2134e-02, -1.6729e-03,  3.6208e-03,\n",
       "                       1.2715e-02,  3.8646e-02,  3.5793e-02, -1.0298e-02, -4.9872e-04,\n",
       "                      -2.6865e-03,  5.8305e-04, -1.4539e-02, -2.1606e-03, -2.1326e-03,\n",
       "                       1.9812e-02,  1.4878e-02, -2.8210e-03, -5.2076e-03,  8.7903e-03,\n",
       "                       1.0576e-02,  4.5140e-03,  1.2363e-02,  6.7572e-03,  3.9479e-02,\n",
       "                       1.9837e-02, -9.5392e-03,  1.7217e-02, -5.6406e-04,  1.1070e-02,\n",
       "                       4.8991e-03,  1.3039e-02,  1.6870e-02, -2.2205e-03,  1.3356e-02,\n",
       "                       1.1783e-02,  4.3389e-02,  4.4673e-03,  6.1510e-03,  4.6970e-04,\n",
       "                      -1.1260e-03, -4.9672e-03,  5.6068e-03, -1.4191e-02,  5.2315e-03,\n",
       "                      -3.1630e-03, -1.0981e-02,  3.5036e-03,  1.5640e-04, -1.0114e-03,\n",
       "                       1.5414e-02,  1.7044e-02, -8.7282e-03,  2.2060e-02,  6.7855e-03,\n",
       "                      -1.7340e-03, -6.9711e-04, -3.6601e-03, -9.6420e-04, -7.0818e-03,\n",
       "                       1.0213e-02,  1.2428e-02, -5.4983e-03,  8.4480e-03,  1.6897e-02,\n",
       "                       8.9597e-03, -1.8708e-02, -8.2510e-03,  4.0151e-02,  9.8590e-03,\n",
       "                      -1.0593e-02, -2.6320e-03,  6.8309e-03, -3.3272e-03,  2.5522e-02,\n",
       "                       2.0965e-02,  1.4668e-02,  2.4538e-03, -5.4289e-03,  2.3784e-02,\n",
       "                      -7.6331e-03,  4.1841e-02,  2.4930e-02,  4.1666e-03,  1.0406e-02,\n",
       "                      -4.5664e-03,  2.3727e-02,  4.1057e-03, -1.2896e-02, -7.8769e-03,\n",
       "                       5.2212e-02, -2.6518e-03, -6.6591e-03, -1.9815e-03,  9.4604e-03,\n",
       "                       1.7383e-02, -3.3078e-03, -6.1529e-03,  1.9805e-02, -4.4295e-03,\n",
       "                       2.3859e-03, -3.6353e-03])),\n",
       "             ('decoders.4.bn3.running_mean',\n",
       "              tensor([ 4.1539e-01, -1.9582e-01, -4.3974e-02, -2.5809e-01, -2.1578e-01,\n",
       "                      -5.7551e-01, -7.0482e-02, -3.4895e-01,  1.7242e-01, -1.4993e-01,\n",
       "                       3.2019e-01, -6.2739e-02,  5.4147e-01, -4.4803e-01, -3.3921e-01,\n",
       "                       6.5456e-02,  3.1863e-01,  1.0327e-01, -4.8574e-01, -4.8736e-01,\n",
       "                      -1.6125e-01,  2.4664e-01, -3.2930e-01, -2.2115e-01,  5.1053e-02,\n",
       "                      -2.3149e-01, -2.2925e-01,  3.1951e-01, -4.5225e-01, -3.9429e-01,\n",
       "                      -3.8746e-01,  5.6440e-01, -2.0023e-01,  5.1911e-01, -1.2211e-01,\n",
       "                      -5.7089e-01, -1.5477e-01,  2.0792e-01,  4.6050e-01,  1.2112e-01,\n",
       "                       7.7456e-02, -3.4256e-01, -6.0160e-03,  3.5130e-01, -1.6977e-01,\n",
       "                      -9.6038e-02, -4.9660e-01, -3.4398e-01,  9.4550e-02,  2.1136e-01,\n",
       "                      -3.5483e-01, -2.8952e-01,  6.7344e-02,  9.8372e-02,  2.0867e-01,\n",
       "                       3.1780e-02, -2.7520e-02,  3.6859e-01, -4.8476e-01,  1.9614e-01,\n",
       "                       3.4919e-01, -3.9561e-01,  2.1328e-01,  3.9920e-01,  8.2677e-02,\n",
       "                      -2.4874e-01,  4.0109e-01, -4.3945e-01,  1.4803e-01, -4.2147e-01,\n",
       "                      -1.8295e-01,  3.7892e-01, -2.6868e-01, -3.8674e-01,  3.8144e-02,\n",
       "                       4.6338e-01,  1.2785e-01, -4.2221e-01, -4.2312e-01, -1.8497e-01,\n",
       "                       2.9069e-02,  1.1966e-02, -1.7221e-01, -8.5968e-02,  9.8958e-02,\n",
       "                      -1.8205e-01,  1.9924e-01,  5.9490e-01, -2.9295e-01, -3.8315e-01,\n",
       "                      -3.3017e-01, -4.3651e-03,  6.4536e-01, -3.8497e-02,  4.2154e-02,\n",
       "                      -1.8838e-01,  2.8351e-01,  9.7602e-02,  1.1989e-01, -1.3968e-01,\n",
       "                      -2.9710e-01, -3.0327e-01, -1.9903e-01, -7.7716e-02, -3.3876e-01,\n",
       "                      -3.0565e-01, -6.9728e-02, -3.6941e-02, -2.1967e-01, -2.8235e-01,\n",
       "                       4.2246e-01,  1.4760e-01, -4.0510e-01,  1.5828e-01,  1.2182e-02,\n",
       "                      -3.4104e-01, -2.4567e-01, -3.6762e-01,  4.4931e-01,  3.3407e-01,\n",
       "                      -4.7892e-01, -1.6603e-01, -1.9445e-01,  7.6852e-02, -6.3705e-02,\n",
       "                      -9.6289e-02, -6.1039e-02,  7.9787e-02,  1.4776e-01, -2.5723e-01,\n",
       "                      -1.4253e-01,  1.5170e-01,  5.1765e-01, -3.8651e-01,  2.0180e-01,\n",
       "                      -4.7821e-01, -1.0397e-01,  1.8010e-01,  1.7752e-01,  7.6572e-02,\n",
       "                       1.9779e-01, -1.8268e-02,  9.2864e-02,  6.1406e-02, -1.0954e-01,\n",
       "                      -1.7958e-01, -3.7858e-02, -3.9977e-01, -1.6944e-01, -2.2043e-01,\n",
       "                      -3.1051e-01, -2.4575e-01, -8.0040e-02,  4.5905e-01,  1.6400e-01,\n",
       "                      -2.2004e-01,  1.1328e-01, -2.5469e-01,  2.7095e-01, -2.5511e-01,\n",
       "                      -5.1664e-01, -1.7488e-01, -3.1980e-01,  4.3278e-01,  1.0180e-01,\n",
       "                       1.7518e-01,  5.9222e-01,  1.9853e-03,  8.9087e-03, -3.3922e-01,\n",
       "                       1.6952e-01, -1.1967e-02,  1.7139e-02, -4.1340e-01, -1.7105e-01,\n",
       "                      -4.3189e-01, -2.2166e-01, -2.4586e-01, -1.1003e-01, -2.6568e-01,\n",
       "                       7.4244e-03, -1.4320e-01, -2.2987e-01,  7.4726e-02, -3.5630e-01,\n",
       "                      -2.9593e-01, -3.4711e-01,  2.3527e-01,  1.4743e-01, -2.2373e-01,\n",
       "                      -7.3357e-03, -2.7822e-02, -3.3673e-02, -2.5628e-01, -3.4270e-02,\n",
       "                       4.2182e-03, -2.1857e-04, -9.2244e-02,  5.0324e-02, -1.4605e-01,\n",
       "                      -2.4959e-01,  1.5868e-01, -1.1322e-01, -2.3657e-01, -6.3298e-02,\n",
       "                       2.7911e-01, -5.4583e-01, -2.3506e-01,  1.3570e-01,  1.3504e-01,\n",
       "                      -4.0296e-01,  3.7191e-01,  1.5529e-01,  3.8813e-01,  2.0931e-01,\n",
       "                       2.8812e-01,  1.6865e-01,  2.2750e-01, -9.4822e-02,  3.4774e-01,\n",
       "                       2.0744e-01,  2.2648e-01, -4.1150e-01, -3.5631e-02,  4.4124e-01,\n",
       "                       2.2761e-01,  2.7064e-02, -4.3667e-01, -1.1268e-01,  1.8564e-01,\n",
       "                      -5.0726e-01, -1.9636e-01,  2.1038e-02, -1.2613e-01, -3.3714e-01,\n",
       "                       2.5635e-01, -4.5562e-01, -3.3292e-01, -2.6494e-02, -1.8382e-02,\n",
       "                       2.0422e-01, -3.0750e-01,  4.5698e-01, -2.5734e-01,  1.9265e-01,\n",
       "                       2.0427e-01, -3.1146e-01,  2.8290e-02, -8.3032e-02, -1.2067e-01,\n",
       "                      -4.5807e-01,  4.5283e-01, -1.0894e-01,  1.3670e-02, -4.1032e-01,\n",
       "                      -1.1125e-01,  4.6861e-02, -2.7542e-01,  9.2869e-03, -2.6295e-01,\n",
       "                      -4.4656e-01, -8.8499e-02, -1.8482e-01, -4.2190e-02,  1.0821e-01,\n",
       "                       3.0666e-02,  4.9519e-01, -4.9868e-01,  5.1035e-01,  2.9287e-01,\n",
       "                      -2.3578e-01,  1.8957e-01, -1.5634e-01,  2.4740e-01,  1.2525e-01,\n",
       "                       4.1051e-01, -3.3898e-01, -3.1386e-01, -2.2125e-01, -1.4826e-01,\n",
       "                      -3.3843e-04,  1.5985e-01, -3.6605e-01,  4.5083e-01,  2.2100e-02,\n",
       "                      -2.7235e-01,  1.6279e-01,  2.4556e-02,  3.8130e-02,  2.8250e-01,\n",
       "                      -4.2511e-01, -4.0800e-01, -2.8708e-01, -1.4115e-01,  1.9052e-01,\n",
       "                       3.2557e-02,  2.1831e-02, -3.9110e-01,  2.9312e-01, -6.7535e-02,\n",
       "                       8.6926e-02, -3.6488e-01, -5.9051e-01,  7.5017e-02, -1.0823e-01,\n",
       "                      -4.6998e-02,  1.2726e-01, -1.6765e-01, -2.4846e-01,  1.3026e-01,\n",
       "                      -3.6715e-02,  2.0993e-01,  2.9011e-01, -1.2433e-01, -3.4865e-01,\n",
       "                       8.9756e-02, -5.6355e-02, -1.5604e-01,  5.4086e-02,  2.0113e-01,\n",
       "                      -1.8113e-01,  2.9151e-01, -8.9250e-02, -2.1587e-01, -1.4663e-01,\n",
       "                       2.3788e-01, -5.3593e-01, -4.2348e-01,  2.0269e-01, -7.0521e-02,\n",
       "                      -3.9511e-01,  1.9490e-01, -4.2418e-01,  1.5772e-01, -2.9876e-01,\n",
       "                      -3.8101e-01, -4.0979e-01, -2.1355e-01,  1.4008e-02,  5.3304e-02,\n",
       "                       2.8817e-02,  1.5460e-01, -2.4300e-01,  4.9410e-02,  3.5554e-01,\n",
       "                      -2.2183e-01, -1.2986e-01,  2.6742e-01,  1.4309e-01, -2.2942e-01,\n",
       "                      -4.3653e-01,  8.2382e-02, -8.9214e-02,  4.8051e-01, -1.8150e-01,\n",
       "                      -2.7270e-01,  2.1178e-01,  9.4619e-02, -2.2594e-01, -9.4845e-02,\n",
       "                      -3.7383e-01, -2.9621e-02, -7.1312e-02,  4.6078e-03, -1.1948e-01,\n",
       "                       3.0978e-01, -1.7059e-01, -2.4607e-01, -4.3888e-01,  3.4077e-01,\n",
       "                       5.2938e-01, -2.1032e-01, -1.5893e-02, -9.2207e-02,  1.6846e-02,\n",
       "                       3.2982e-01, -1.4046e-01,  1.7813e-01,  9.9824e-02, -1.1648e-01,\n",
       "                      -1.2900e-01, -1.8534e-01, -3.3377e-01,  1.2581e-01, -3.0779e-01,\n",
       "                      -4.4351e-01,  1.7019e-02, -4.1875e-01, -1.5893e-01,  2.3166e-01,\n",
       "                      -1.5692e-01,  2.8755e-01, -7.5654e-02, -3.0198e-01,  2.5668e-01,\n",
       "                       2.4524e-01, -2.3030e-01,  4.9555e-02,  1.8000e-01,  6.0762e-02,\n",
       "                       1.0325e-01, -1.0333e-02, -3.5948e-01, -1.3795e-01, -1.4061e-01,\n",
       "                       3.3053e-01, -2.2800e-01, -9.9419e-02,  1.6132e-01, -1.6466e-01,\n",
       "                       4.6284e-01,  2.6012e-02, -5.9552e-02, -1.5536e-01, -2.9300e-01,\n",
       "                      -6.8864e-03, -2.7805e-01, -1.4842e-01,  2.4575e-01, -2.2593e-01,\n",
       "                      -1.6009e-01, -6.6067e-02,  2.0626e-01, -2.7474e-01, -5.4811e-02,\n",
       "                      -1.9561e-01,  3.1681e-01, -2.5653e-01, -3.0111e-01, -2.7935e-01,\n",
       "                      -1.9936e-01, -3.8301e-01, -1.1482e-01, -2.1152e-01,  6.2051e-02,\n",
       "                      -1.8568e-01,  2.9861e-01, -3.3940e-01,  3.1784e-01, -3.7058e-01,\n",
       "                      -8.7283e-02,  3.1213e-02,  1.7693e-01,  2.8315e-01, -4.8254e-02,\n",
       "                      -3.0120e-01, -6.2845e-01, -5.1398e-01, -5.5868e-02, -6.1524e-02,\n",
       "                      -4.1186e-01,  3.8375e-01, -3.5843e-02,  5.8348e-01, -1.5260e-01,\n",
       "                       4.6814e-02, -4.2158e-01, -6.8347e-02,  3.3012e-01, -3.3708e-01,\n",
       "                      -2.3740e-01, -1.6327e-01,  1.3263e-01,  2.2401e-01, -3.3711e-01,\n",
       "                      -2.6141e-01, -2.8397e-01,  1.9977e-01, -3.5171e-01,  3.2535e-02,\n",
       "                       1.8476e-01,  4.6588e-02, -1.7382e-01, -9.8675e-02, -9.7324e-02,\n",
       "                       1.3744e-01,  1.3549e-01,  1.0157e-01, -2.5321e-03, -1.5554e-01,\n",
       "                      -2.3103e-01,  2.8416e-01,  3.1032e-01,  1.3730e-01,  1.8847e-01,\n",
       "                      -2.2638e-02, -2.4340e-01, -4.1537e-01,  1.2307e-01, -3.6057e-01,\n",
       "                      -2.3629e-01, -6.2251e-02, -6.4978e-02, -2.9742e-01, -2.8883e-01,\n",
       "                       8.2190e-02, -5.1688e-01,  2.3228e-01,  1.9057e-01, -3.4411e-01,\n",
       "                      -4.2208e-01, -2.2471e-01,  6.2823e-02,  3.1649e-01, -3.7941e-01,\n",
       "                      -1.1081e-01, -3.6473e-02,  2.8614e-01, -8.9963e-02, -1.4794e-01,\n",
       "                       3.0925e-01,  3.7847e-01])),\n",
       "             ('decoders.4.bn3.running_var',\n",
       "              tensor([0.1958, 0.1727, 0.3803, 0.1802, 0.5511, 0.4997, 0.9544, 0.3548, 0.6505,\n",
       "                      0.8254, 1.1816, 0.3496, 1.1885, 0.2788, 0.3834, 0.4506, 0.6896, 0.2403,\n",
       "                      1.1870, 0.8786, 1.0751, 0.4371, 0.2390, 0.4553, 1.2569, 0.5614, 0.6701,\n",
       "                      0.8205, 0.1481, 0.7730, 0.2491, 0.7768, 0.7305, 0.7309, 0.3066, 0.6980,\n",
       "                      0.7819, 1.0142, 0.5180, 0.8151, 0.6855, 0.4850, 0.6662, 0.8593, 0.8822,\n",
       "                      0.2836, 0.2447, 1.4884, 1.2587, 0.9198, 0.3211, 0.5861, 0.4671, 0.1813,\n",
       "                      1.2403, 0.7785, 0.2847, 0.3213, 0.4180, 1.3536, 0.6243, 0.8369, 0.4612,\n",
       "                      0.6824, 0.5088, 0.5180, 0.6800, 0.3526, 1.4957, 0.2774, 0.3646, 0.6049,\n",
       "                      0.1853, 0.7005, 0.1760, 1.2310, 0.5739, 0.5153, 0.2053, 0.2566, 0.8383,\n",
       "                      0.3097, 0.4973, 0.4982, 1.8005, 0.2889, 2.0869, 0.5442, 0.5243, 0.6565,\n",
       "                      0.2399, 0.5497, 0.4113, 0.4447, 0.7229, 0.2933, 1.0328, 0.5410, 0.6806,\n",
       "                      0.4184, 0.2938, 0.3539, 0.7165, 0.3482, 0.1905, 0.3405, 0.5701, 0.6451,\n",
       "                      0.9217, 0.6640, 2.3781, 1.9775, 0.2965, 0.6248, 1.0801, 0.2546, 0.3156,\n",
       "                      0.2491, 0.9546, 0.5157, 0.5472, 0.2165, 1.2193, 0.4324, 1.1783, 1.9473,\n",
       "                      1.1253, 1.2990, 1.1917, 0.2102, 0.6842, 1.6148, 0.5632, 0.3186, 0.8067,\n",
       "                      0.4684, 0.1940, 0.4486, 0.3616, 0.5291, 1.3703, 1.6413, 0.3808, 1.2687,\n",
       "                      0.2713, 0.5667, 0.1170, 0.4774, 0.3941, 0.1543, 0.2656, 0.1423, 1.6635,\n",
       "                      0.2070, 0.9941, 0.3299, 0.4020, 1.8349, 0.7900, 0.2384, 0.3423, 0.3967,\n",
       "                      0.1551, 1.9661, 0.4840, 1.1307, 1.7866, 0.2829, 0.8790, 0.3554, 0.7433,\n",
       "                      0.3352, 1.2454, 0.3888, 0.9689, 0.5198, 0.1341, 0.1973, 0.7324, 0.3252,\n",
       "                      0.5517, 0.5230, 0.1422, 0.9281, 0.3456, 0.6262, 0.2136, 0.4458, 1.6564,\n",
       "                      0.3616, 0.6907, 0.2394, 0.7058, 0.7368, 0.5842, 0.6925, 0.9155, 0.2939,\n",
       "                      0.5917, 0.3183, 0.5512, 1.0315, 0.5239, 0.5994, 1.0263, 0.1524, 0.2131,\n",
       "                      0.2995, 1.2002, 1.0476, 0.2334, 1.7636, 0.9851, 0.4394, 0.8515, 1.7801,\n",
       "                      1.0019, 0.7005, 1.0530, 0.3732, 0.8215, 0.3914, 0.2509, 0.5707, 0.7171,\n",
       "                      1.3761, 0.9022, 0.5996, 0.2521, 0.8375, 0.8573, 0.4402, 1.5028, 0.5562,\n",
       "                      0.2653, 0.6077, 0.1733, 0.9374, 1.0220, 0.4292, 2.2102, 0.9928, 1.2229,\n",
       "                      0.7114, 0.3585, 1.0578, 0.3088, 0.8236, 0.7793, 1.0656, 0.4728, 3.4076,\n",
       "                      0.1690, 0.5982, 0.4027, 1.1485, 0.3864, 0.8124, 1.0947, 0.2092, 0.2250,\n",
       "                      0.6590, 1.0588, 0.2840, 0.7933, 0.9288, 0.7575, 0.3534, 0.4274, 0.4259,\n",
       "                      0.2369, 1.6926, 1.3633, 1.3196, 0.5242, 1.1674, 0.2653, 0.6401, 0.3297,\n",
       "                      0.3222, 0.8481, 0.6842, 0.3421, 0.7827, 0.8743, 0.5433, 1.5418, 0.4086,\n",
       "                      0.5765, 0.5546, 0.2473, 0.9990, 1.3256, 1.1391, 1.0897, 0.3280, 0.7453,\n",
       "                      0.4141, 0.6429, 0.8163, 0.3135, 0.8176, 0.6305, 0.3771, 0.6510, 0.9535,\n",
       "                      0.6406, 1.2077, 0.1809, 0.2411, 0.2168, 0.6283, 0.5001, 0.4759, 0.3751,\n",
       "                      2.4472, 0.1829, 0.1633, 0.6390, 1.8100, 1.2833, 0.4090, 1.2456, 0.3420,\n",
       "                      0.2073, 2.0220, 0.7309, 0.3233, 1.2354, 0.2664, 0.2449, 1.9567, 0.5442,\n",
       "                      1.7637, 0.2294, 0.3281, 0.4661, 0.5569, 0.4419, 0.1707, 0.5331, 1.0804,\n",
       "                      0.2801, 1.7049, 0.3192, 0.6772, 0.2254, 2.0828, 0.4916, 0.4075, 0.3277,\n",
       "                      1.1783, 0.7194, 0.4445, 0.3052, 0.4136, 1.0176, 0.4651, 1.0220, 0.6739,\n",
       "                      0.9029, 0.2345, 0.8253, 0.9950, 0.3260, 2.2940, 0.9694, 0.3173, 0.3027,\n",
       "                      0.9424, 1.1109, 0.1947, 0.6939, 1.3116, 0.5037, 0.4464, 0.1625, 2.2801,\n",
       "                      0.2484, 1.0187, 0.2691, 0.4847, 0.1091, 0.9383, 0.5419, 0.4963, 0.7834,\n",
       "                      0.5277, 0.1141, 0.3602, 0.5524, 0.5529, 0.7838, 0.6959, 1.9662, 0.3434,\n",
       "                      0.5909, 0.3960, 0.5988, 0.8135, 1.5702, 0.6842, 0.4101, 1.1621, 0.3376,\n",
       "                      1.0613, 0.1496, 0.4150, 0.8604, 0.7276, 0.8546, 1.6448, 0.3316, 0.2581,\n",
       "                      0.2871, 0.9897, 0.7575, 1.2540, 0.3938, 0.8871, 0.2601, 0.7724, 0.2798,\n",
       "                      0.2565, 0.2065, 0.5028, 1.5566, 0.4598, 0.5721, 0.3963, 0.3755, 0.1744,\n",
       "                      0.5204, 0.2445, 1.2709, 0.4621, 0.9061, 0.1414, 0.5773, 0.2742, 1.2217,\n",
       "                      0.6743, 1.5049, 0.6238, 0.4380, 0.4807, 0.4476, 0.1607, 1.3261, 0.3280,\n",
       "                      0.2586, 1.4485, 0.5380, 0.8381, 0.2870, 1.3217, 0.2033, 0.5757, 1.2850,\n",
       "                      0.2489, 0.3911, 1.5038, 1.0533, 1.6291, 0.0840, 0.2008, 0.1926, 0.7340,\n",
       "                      0.6187, 0.9304, 1.6873, 0.7067, 0.1388, 0.3447, 0.4852, 1.3494, 0.4822,\n",
       "                      0.2191, 1.1381, 0.3681, 0.5453, 1.2874, 1.6458, 1.0798, 1.8989, 0.5689,\n",
       "                      0.5490, 0.1215, 0.3376, 0.7996, 0.3531, 1.3913, 0.4225, 0.8734, 0.3028,\n",
       "                      2.0628, 0.5516, 0.3633, 0.4285, 0.2305, 0.5123, 0.2592, 0.5161, 2.3656,\n",
       "                      0.1754, 0.6605, 0.3883, 1.2663, 0.4860, 0.3546, 0.3927, 2.1772])),\n",
       "             ('decoders.4.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense4.weight',\n",
       "              tensor([[-0.0074,  0.0073, -0.0221,  ...,  0.0445,  0.0348, -0.0441],\n",
       "                      [ 0.0109,  0.0331,  0.0366,  ..., -0.0263, -0.0372, -0.0167],\n",
       "                      [-0.0538,  0.0302, -0.0109,  ..., -0.0218, -0.0301,  0.0314],\n",
       "                      ...,\n",
       "                      [ 0.0236, -0.0285,  0.0341,  ..., -0.0186,  0.0386, -0.0259],\n",
       "                      [-0.0446,  0.0074,  0.0156,  ..., -0.0156,  0.0281, -0.0510],\n",
       "                      [ 0.0244,  0.0241, -0.0107,  ..., -0.0345,  0.0094, -0.0127]])),\n",
       "             ('decoders.4.bn4.weight',\n",
       "              tensor([1.0274, 1.0351, 1.0358, 1.0350, 1.0288, 1.0383, 1.0317, 1.0322, 1.0311,\n",
       "                      1.0343, 1.0292, 1.0298, 1.0298, 1.0299, 1.0316, 1.0324, 1.0324, 1.0285,\n",
       "                      1.0338, 1.0291, 1.0332, 1.0315, 1.0312, 1.0288, 1.0341, 1.0286, 1.0313,\n",
       "                      1.0324, 1.0318, 1.0324, 1.0302, 1.0335, 1.0317, 1.0311, 1.0333, 1.0351,\n",
       "                      1.0324, 1.0312, 1.0311, 1.0320, 1.0297, 1.0313, 1.0304, 1.0307, 1.0268,\n",
       "                      1.0319, 1.0329, 1.0309, 1.0314, 1.0304, 1.0294, 1.0316, 1.0292, 1.0305,\n",
       "                      1.0306, 1.0279, 1.0318, 1.0309, 1.0299, 1.0295, 1.0243, 1.0334, 1.0314,\n",
       "                      1.0338, 1.0363, 1.0304, 1.0292, 1.0309, 1.0321, 1.0325, 1.0321, 1.0324,\n",
       "                      1.0297, 1.0344, 1.0312, 1.0314, 1.0318, 1.0288, 1.0289, 1.0312, 1.0369,\n",
       "                      1.0288, 1.0307, 1.0314, 1.0320, 1.0339, 1.0294, 1.0354, 1.0304, 1.0345,\n",
       "                      1.0295, 1.0325, 1.0311, 1.0307, 1.0337, 1.0277, 1.0294, 1.0302, 1.0304,\n",
       "                      1.0316, 1.0310, 1.0345, 1.0340, 1.0318, 1.0292, 1.0316, 1.0259, 1.0315,\n",
       "                      1.0297, 1.0319, 1.0314, 1.0324, 1.0308, 1.0292, 1.0363, 1.0294, 1.0302,\n",
       "                      1.0318, 1.0307, 1.0307, 1.0311, 1.0305, 1.0300, 1.0284, 1.0306, 1.0309,\n",
       "                      1.0311, 1.0307, 1.0349, 1.0311, 1.0326, 1.0293, 1.0283, 1.0317, 1.0279,\n",
       "                      1.0307, 1.0311, 1.0322, 1.0275, 1.0288, 1.0318, 1.0320, 1.0314, 1.0296,\n",
       "                      1.0308, 1.0347, 1.0294, 1.0307, 1.0286, 1.0335, 1.0352, 1.0306, 1.0323,\n",
       "                      1.0348, 1.0287, 1.0320, 1.0320, 1.0307, 1.0291, 1.0302, 1.0295, 1.0322,\n",
       "                      1.0279, 1.0332, 1.0297, 1.0313, 1.0288, 1.0307, 1.0348, 1.0302, 1.0326,\n",
       "                      1.0315, 1.0331, 1.0300, 1.0270, 1.0313, 1.0299, 1.0301, 1.0328, 1.0329,\n",
       "                      1.0316, 1.0295, 1.0345, 1.0325, 1.0327, 1.0316, 1.0299, 1.0310, 1.0356,\n",
       "                      1.0314, 1.0320, 1.0317, 1.0301, 1.0323, 1.0269, 1.0340, 1.0297, 1.0305,\n",
       "                      1.0318, 1.0301, 1.0299, 1.0355, 1.0293, 1.0305, 1.0324, 1.0313, 1.0302,\n",
       "                      1.0328, 1.0370, 1.0304, 1.0324, 1.0314, 1.0314, 1.0318, 1.0298, 1.0301,\n",
       "                      1.0313, 1.0363, 1.0308, 1.0310, 1.0292, 1.0304, 1.0315, 1.0319, 1.0300,\n",
       "                      1.0304, 1.0322, 1.0303, 1.0305, 1.0314, 1.0298, 1.0291, 1.0293, 1.0337,\n",
       "                      1.0316, 1.0293, 1.0313, 1.0323, 1.0315, 1.0340, 1.0288, 1.0327, 1.0324,\n",
       "                      1.0303, 1.0325, 1.0306, 1.0358, 1.0306, 1.0289, 1.0353, 1.0295, 1.0302,\n",
       "                      1.0299, 1.0302, 1.0300, 1.0311, 1.0347, 1.0310, 1.0276, 1.0324, 1.0293,\n",
       "                      1.0302, 1.0355, 1.0304, 1.0318, 1.0307, 1.0331, 1.0321, 1.0298, 1.0322,\n",
       "                      1.0308, 1.0347, 1.0309, 1.0362, 1.0293, 1.0333, 1.0340, 1.0333, 1.0341,\n",
       "                      1.0312, 1.0303, 1.0356, 1.0288, 1.0327, 1.0329, 1.0320, 1.0307, 1.0300,\n",
       "                      1.0342, 1.0347, 1.0309, 1.0296, 1.0290, 1.0311, 1.0296, 1.0299, 1.0302,\n",
       "                      1.0287, 1.0336, 1.0303, 1.0297, 1.0318, 1.0310, 1.0298, 1.0314, 1.0356,\n",
       "                      1.0276, 1.0319, 1.0316, 1.0335, 1.0307, 1.0333, 1.0333, 1.0291, 1.0322,\n",
       "                      1.0312, 1.0345, 1.0359, 1.0287, 1.0302, 1.0327, 1.0310, 1.0350, 1.0340,\n",
       "                      1.0307, 1.0331, 1.0295, 1.0328, 1.0340, 1.0340, 1.0304, 1.0302, 1.0310,\n",
       "                      1.0319, 1.0308, 1.0284, 1.0307, 1.0311, 1.0346, 1.0300, 1.0324, 1.0368,\n",
       "                      1.0316, 1.0340, 1.0334, 1.0346, 1.0307, 1.0328, 1.0335, 1.0296, 1.0349,\n",
       "                      1.0292, 1.0306, 1.0330, 1.0298, 1.0328, 1.0308, 1.0360, 1.0327, 1.0321,\n",
       "                      1.0288, 1.0281, 1.0302, 1.0330, 1.0340, 1.0337, 1.0324, 1.0333, 1.0306,\n",
       "                      1.0347, 1.0336, 1.0326, 1.0323, 1.0286, 1.0299, 1.0319, 1.0303, 1.0304,\n",
       "                      1.0372, 1.0301, 1.0316, 1.0330, 1.0320, 1.0315, 1.0312, 1.0307, 1.0321,\n",
       "                      1.0320, 1.0315, 1.0333, 1.0305, 1.0299, 1.0343, 1.0310, 1.0272, 1.0317,\n",
       "                      1.0298, 1.0347, 1.0343, 1.0325, 1.0322, 1.0309, 1.0305, 1.0290, 1.0303,\n",
       "                      1.0323, 1.0316, 1.0349, 1.0319, 1.0314, 1.0289, 1.0319, 1.0309, 1.0266,\n",
       "                      1.0288, 1.0303, 1.0312, 1.0284, 1.0373, 1.0325, 1.0351, 1.0360, 1.0335,\n",
       "                      1.0288, 1.0361, 1.0297, 1.0350, 1.0318, 1.0309, 1.0302, 1.0310, 1.0316,\n",
       "                      1.0353, 1.0312, 1.0332, 1.0321, 1.0315, 1.0316, 1.0320, 1.0310, 1.0336,\n",
       "                      1.0337, 1.0341, 1.0306, 1.0313, 1.0278, 1.0280, 1.0304, 1.0294, 1.0287,\n",
       "                      1.0311, 1.0338, 1.0319, 1.0331, 1.0330, 1.0313, 1.0298, 1.0351, 1.0298,\n",
       "                      1.0325, 1.0301, 1.0301, 1.0313, 1.0324, 1.0313, 1.0341, 1.0342, 1.0316,\n",
       "                      1.0325, 1.0320, 1.0297, 1.0314, 1.0338, 1.0275, 1.0318, 1.0356, 1.0337,\n",
       "                      1.0378, 1.0312, 1.0320, 1.0291, 1.0319, 1.0312, 1.0317, 1.0329, 1.0300,\n",
       "                      1.0293, 1.0306, 1.0328, 1.0313, 1.0302, 1.0299, 1.0341, 1.0341, 1.0325,\n",
       "                      1.0275, 1.0314, 1.0341, 1.0310, 1.0348, 1.0311, 1.0288, 1.0321, 1.0284,\n",
       "                      1.0308, 1.0300, 1.0316, 1.0274, 1.0316, 1.0294, 1.0361, 1.0309])),\n",
       "             ('decoders.4.bn4.bias',\n",
       "              tensor([0.0375, 0.0379, 0.0364, 0.0372, 0.0375, 0.0385, 0.0412, 0.0389, 0.0390,\n",
       "                      0.0352, 0.0373, 0.0385, 0.0389, 0.0382, 0.0408, 0.0351, 0.0391, 0.0378,\n",
       "                      0.0358, 0.0379, 0.0345, 0.0392, 0.0388, 0.0380, 0.0354, 0.0376, 0.0381,\n",
       "                      0.0385, 0.0395, 0.0404, 0.0379, 0.0385, 0.0391, 0.0388, 0.0362, 0.0354,\n",
       "                      0.0404, 0.0406, 0.0387, 0.0386, 0.0398, 0.0378, 0.0403, 0.0408, 0.0392,\n",
       "                      0.0381, 0.0413, 0.0401, 0.0377, 0.0384, 0.0401, 0.0394, 0.0380, 0.0382,\n",
       "                      0.0374, 0.0383, 0.0387, 0.0380, 0.0381, 0.0385, 0.0369, 0.0370, 0.0387,\n",
       "                      0.0404, 0.0389, 0.0376, 0.0379, 0.0398, 0.0386, 0.0399, 0.0412, 0.0375,\n",
       "                      0.0374, 0.0381, 0.0397, 0.0402, 0.0386, 0.0378, 0.0380, 0.0384, 0.0389,\n",
       "                      0.0374, 0.0388, 0.0386, 0.0387, 0.0365, 0.0389, 0.0387, 0.0377, 0.0358,\n",
       "                      0.0372, 0.0411, 0.0375, 0.0381, 0.0360, 0.0388, 0.0385, 0.0374, 0.0384,\n",
       "                      0.0390, 0.0390, 0.0391, 0.0378, 0.0367, 0.0380, 0.0401, 0.0378, 0.0384,\n",
       "                      0.0398, 0.0387, 0.0384, 0.0411, 0.0406, 0.0373, 0.0376, 0.0390, 0.0368,\n",
       "                      0.0392, 0.0385, 0.0398, 0.0387, 0.0385, 0.0386, 0.0376, 0.0376, 0.0375,\n",
       "                      0.0391, 0.0381, 0.0384, 0.0413, 0.0357, 0.0382, 0.0385, 0.0408, 0.0370,\n",
       "                      0.0383, 0.0383, 0.0362, 0.0381, 0.0388, 0.0400, 0.0397, 0.0390, 0.0381,\n",
       "                      0.0385, 0.0363, 0.0390, 0.0374, 0.0387, 0.0408, 0.0390, 0.0397, 0.0405,\n",
       "                      0.0363, 0.0382, 0.0406, 0.0408, 0.0387, 0.0393, 0.0380, 0.0379, 0.0404,\n",
       "                      0.0368, 0.0410, 0.0379, 0.0382, 0.0359, 0.0390, 0.0379, 0.0383, 0.0390,\n",
       "                      0.0388, 0.0391, 0.0383, 0.0375, 0.0391, 0.0376, 0.0382, 0.0385, 0.0384,\n",
       "                      0.0386, 0.0373, 0.0362, 0.0407, 0.0408, 0.0400, 0.0382, 0.0397, 0.0386,\n",
       "                      0.0403, 0.0381, 0.0365, 0.0385, 0.0396, 0.0368, 0.0362, 0.0384, 0.0402,\n",
       "                      0.0384, 0.0392, 0.0378, 0.0364, 0.0393, 0.0385, 0.0405, 0.0414, 0.0389,\n",
       "                      0.0403, 0.0386, 0.0386, 0.0365, 0.0405, 0.0385, 0.0406, 0.0384, 0.0383,\n",
       "                      0.0408, 0.0377, 0.0384, 0.0379, 0.0366, 0.0394, 0.0402, 0.0383, 0.0383,\n",
       "                      0.0384, 0.0383, 0.0397, 0.0396, 0.0389, 0.0384, 0.0380, 0.0380, 0.0382,\n",
       "                      0.0385, 0.0379, 0.0376, 0.0382, 0.0397, 0.0364, 0.0379, 0.0389, 0.0382,\n",
       "                      0.0381, 0.0371, 0.0380, 0.0357, 0.0385, 0.0378, 0.0363, 0.0382, 0.0392,\n",
       "                      0.0384, 0.0379, 0.0384, 0.0377, 0.0353, 0.0380, 0.0369, 0.0404, 0.0377,\n",
       "                      0.0384, 0.0358, 0.0385, 0.0408, 0.0384, 0.0408, 0.0385, 0.0402, 0.0387,\n",
       "                      0.0340, 0.0363, 0.0385, 0.0388, 0.0395, 0.0349, 0.0354, 0.0349, 0.0374,\n",
       "                      0.0403, 0.0393, 0.0371, 0.0384, 0.0356, 0.0359, 0.0387, 0.0374, 0.0379,\n",
       "                      0.0352, 0.0383, 0.0385, 0.0377, 0.0381, 0.0390, 0.0382, 0.0382, 0.0378,\n",
       "                      0.0381, 0.0348, 0.0382, 0.0387, 0.0403, 0.0382, 0.0390, 0.0387, 0.0370,\n",
       "                      0.0380, 0.0380, 0.0391, 0.0369, 0.0379, 0.0365, 0.0360, 0.0387, 0.0404,\n",
       "                      0.0401, 0.0360, 0.0382, 0.0386, 0.0380, 0.0348, 0.0404, 0.0357, 0.0346,\n",
       "                      0.0383, 0.0404, 0.0378, 0.0357, 0.0357, 0.0359, 0.0379, 0.0382, 0.0389,\n",
       "                      0.0381, 0.0380, 0.0372, 0.0384, 0.0384, 0.0400, 0.0374, 0.0412, 0.0394,\n",
       "                      0.0396, 0.0366, 0.0356, 0.0356, 0.0380, 0.0405, 0.0391, 0.0375, 0.0380,\n",
       "                      0.0378, 0.0376, 0.0409, 0.0385, 0.0413, 0.0388, 0.0385, 0.0409, 0.0390,\n",
       "                      0.0386, 0.0383, 0.0384, 0.0402, 0.0352, 0.0362, 0.0404, 0.0412, 0.0376,\n",
       "                      0.0365, 0.0403, 0.0345, 0.0383, 0.0368, 0.0382, 0.0407, 0.0399, 0.0395,\n",
       "                      0.0375, 0.0385, 0.0392, 0.0350, 0.0396, 0.0338, 0.0405, 0.0374, 0.0393,\n",
       "                      0.0400, 0.0399, 0.0392, 0.0390, 0.0378, 0.0354, 0.0379, 0.0386, 0.0404,\n",
       "                      0.0380, 0.0352, 0.0361, 0.0349, 0.0392, 0.0387, 0.0415, 0.0384, 0.0384,\n",
       "                      0.0404, 0.0387, 0.0372, 0.0388, 0.0386, 0.0375, 0.0408, 0.0400, 0.0375,\n",
       "                      0.0388, 0.0384, 0.0403, 0.0377, 0.0377, 0.0365, 0.0378, 0.0370, 0.0405,\n",
       "                      0.0392, 0.0387, 0.0384, 0.0373, 0.0386, 0.0404, 0.0375, 0.0390, 0.0398,\n",
       "                      0.0380, 0.0379, 0.0412, 0.0386, 0.0363, 0.0380, 0.0400, 0.0377, 0.0408,\n",
       "                      0.0379, 0.0363, 0.0383, 0.0382, 0.0385, 0.0379, 0.0380, 0.0387, 0.0378,\n",
       "                      0.0379, 0.0375, 0.0401, 0.0350, 0.0361, 0.0380, 0.0378, 0.0389, 0.0374,\n",
       "                      0.0404, 0.0381, 0.0381, 0.0382, 0.0406, 0.0383, 0.0369, 0.0349, 0.0387,\n",
       "                      0.0406, 0.0383, 0.0378, 0.0381, 0.0412, 0.0371, 0.0383, 0.0357, 0.0355,\n",
       "                      0.0380, 0.0375, 0.0378, 0.0375, 0.0400, 0.0405, 0.0381, 0.0386, 0.0399,\n",
       "                      0.0401, 0.0376, 0.0406, 0.0404, 0.0382, 0.0381, 0.0387, 0.0368, 0.0383,\n",
       "                      0.0379, 0.0351, 0.0362, 0.0399, 0.0403, 0.0387, 0.0399, 0.0364, 0.0379,\n",
       "                      0.0385, 0.0391, 0.0371, 0.0380, 0.0406, 0.0371, 0.0384, 0.0399])),\n",
       "             ('decoders.4.bn4.running_mean',\n",
       "              tensor([-0.7943, -0.3789, -0.3364, -0.3756, -0.7705, -0.2888, -0.6543, -0.5195,\n",
       "                      -0.6329, -0.5359, -0.6421, -0.7057, -0.6017, -0.6973, -0.5783, -0.4017,\n",
       "                      -0.6601, -0.6706, -0.2726, -0.6075, -0.3037, -0.7124, -0.6864, -0.7062,\n",
       "                      -0.2658, -0.5364, -0.5363, -0.5567, -0.1974, -0.3827, -0.3943, -0.3825,\n",
       "                      -0.5819, -0.3503, -0.3587, -0.2970, -0.5791, -0.7887, -0.7202, -0.4775,\n",
       "                      -0.4998, -0.7036, -0.5986, -0.5683, -0.7546, -0.7698, -0.6501, -0.6325,\n",
       "                      -0.7214, -0.4887, -0.4060, -0.4424, -0.5061, -0.4298, -0.7522, -0.5912,\n",
       "                      -0.5340, -0.7601, -0.8298, -0.6628, -0.7993, -0.1772, -0.4806, -0.6686,\n",
       "                      -0.1773, -0.5654, -0.5700, -0.2350, -0.4000, -0.5118, -0.4978, -0.5655,\n",
       "                      -0.8375, -0.4195, -0.5473, -0.6718, -0.6548, -0.7577, -0.7350, -0.7012,\n",
       "                      -0.2759, -0.2746, -0.4914, -0.4700, -0.3916, -0.5742, -0.4570, -0.5025,\n",
       "                      -0.8123, -0.2468, -0.8794, -0.7691, -0.3567, -0.6184, -0.4118, -0.6751,\n",
       "                      -0.5622, -0.4810, -0.5738, -0.3056, -0.7911, -0.2172, -0.2032, -0.4087,\n",
       "                      -0.2640, -0.3994, -0.5630, -0.5157, -0.6630, -0.7762, -0.6190, -0.6666,\n",
       "                      -0.5445, -0.5954, -0.3541, -0.5915, -0.4039, -0.4247, -0.5477, -0.5029,\n",
       "                      -0.6484, -0.6387, -0.5757, -0.6144, -0.5188, -0.6608, -0.5388, -0.7498,\n",
       "                      -0.5136, -0.5444, -0.3940, -0.8080, -0.6062, -0.5202, -0.7228, -0.7942,\n",
       "                      -0.5532, -0.3866, -0.7367, -0.4831, -0.7091, -0.4448, -0.5469, -0.7064,\n",
       "                      -0.5884, -0.3066, -0.7442, -0.5739, -0.4154, -0.4992, -0.2094, -0.6802,\n",
       "                      -0.2896, -0.1389, -0.6997, -0.7459, -0.4611, -0.4867, -0.7854, -0.7519,\n",
       "                      -0.7202, -0.7200, -0.6542, -0.6039, -0.4951, -0.6857, -0.3670, -0.7513,\n",
       "                      -0.0476, -0.4116, -0.1590, -0.4239, -0.5177, -1.0159, -0.4666, -0.4819,\n",
       "                      -0.9761, -0.4642, -0.0939, -0.3087, -0.5777, -0.4880, -0.2200, -0.7212,\n",
       "                      -0.5993, -0.4139, -0.6608, -0.4624, -0.5977, -0.4267, -0.7278, -0.2862,\n",
       "                      -0.5262, -0.3313, -0.4283, -0.0547, -0.6314, -0.7544, -0.7836, -0.7134,\n",
       "                      -0.6243, -0.3753, -0.7438, -0.5386, -0.4331, -0.4798, -0.8131, -0.5982,\n",
       "                      -0.6022, -0.4816, -0.4855, -0.3220, -0.4468, -0.5895, -0.5147, -0.5709,\n",
       "                      -0.7264, -0.1170, -0.3754, -0.8171, -0.6733, -0.6624, -0.8430, -0.6469,\n",
       "                      -0.6595, -0.1890, -0.7290, -0.5425, -0.6721, -0.6700, -0.5087, -0.6121,\n",
       "                      -0.6928, -0.5660, -0.4118, -0.8143, -0.7792, -0.4338, -0.5187, -0.0937,\n",
       "                      -0.7568, -0.6016, -0.3197, -0.6721, -0.2141, -0.4983, -0.6856, -0.6875,\n",
       "                      -0.5107, -0.4517, -0.4589, -0.4993, -0.6593, -0.5697, -0.5501, -0.6832,\n",
       "                      -0.6499, -0.4991, -0.5589, -0.6574, -0.6631, -0.5332, -0.5904, -0.7227,\n",
       "                      -0.4593, -0.4540, -0.4867, -0.5568, -0.4064, -0.7846, -0.3581, -0.2261,\n",
       "                      -0.2823, -0.0803, -0.6655, -0.4545, -0.4152, -0.6372, -0.3988, -0.7123,\n",
       "                      -0.3570, -0.2211, -0.5749, -0.3876, -0.1843, -0.6567, -0.6466, -0.6786,\n",
       "                      -0.3404, -0.1558, -0.6251, -0.5625, -0.4674, -0.7623, -0.7344, -0.8053,\n",
       "                      -0.6785, -0.7049, -0.4868, -0.5003, -0.6105, -0.2724, -0.5825, -0.6190,\n",
       "                      -0.3729, -0.1844, -0.6269, -0.6903, -0.5995, -0.2471, -0.6259, -0.2165,\n",
       "                      -0.3460, -0.6816, -0.8641, -0.7067, -0.3389, -0.2344, -0.7485, -0.6672,\n",
       "                      -0.5250, -0.3697, -0.3416, -0.1722, -0.2554, -0.3308, -0.6694, -0.2137,\n",
       "                      -0.4209, -0.5333, -0.6683, -0.3893, -0.3999, -0.6222, -0.7348, -0.8469,\n",
       "                      -0.4717, -0.6101, -0.7480, -0.8453, -0.4825, -0.4769, -0.7052, -0.1041,\n",
       "                      -0.4972, -0.3163, -0.7343, -0.4875, -0.4181, -0.7459, -0.3352, -0.5523,\n",
       "                      -0.5208, -0.0256, -0.5206, -0.6104, -0.4277, -0.5684, -0.5899, -0.7736,\n",
       "                      -0.7516, -0.4451, -0.7524, -0.7049, -0.3151, -0.5363, -0.5818, -0.5352,\n",
       "                      -0.2581, -0.4218, -0.5261, -0.2507, -0.3980, -0.6106, -0.5083, -0.3682,\n",
       "                      -0.3450, -0.6802, -0.3003, -0.5887, -0.8372, -0.6738, -0.5240, -0.3733,\n",
       "                      -0.5541, -0.5465, -0.5188, -0.5193, -0.6097, -0.3224, -0.3959, -0.4897,\n",
       "                      -0.3169, -0.6304, -0.7852, -0.3484, -0.5759, -0.1666, -0.1639, -0.4858,\n",
       "                      -0.6167, -0.5908, -0.8064, -0.6807, -0.5631, -0.4469, -0.3288, -0.3715,\n",
       "                      -0.6224, -0.6160, -0.5634, -0.5536, -0.5866, -0.7353, -0.6034, -0.5554,\n",
       "                      -0.7570, -0.8165, -0.4493, -0.4608, -0.5366, -0.5092, -0.6165, -0.7878,\n",
       "                      -0.4718, -0.5145, -0.2823, -0.3497, -0.6892, -0.8698, -0.5921, -0.3992,\n",
       "                      -0.3034, -0.3671, -0.6033, -0.5095, -0.4942, -0.5141, -0.4203, -0.7689,\n",
       "                      -0.3516, -0.6334, -0.2977, -0.7595, -0.7137, -0.7186, -0.8171, -0.6312,\n",
       "                      -0.6413, -0.5547, -0.5127, -0.2878, -0.6877, -0.5382, -0.3474, -0.3681,\n",
       "                      -0.7278, -0.5071, -0.6786, -0.5658, -0.6886, -0.8372, -0.7936, -0.6092,\n",
       "                      -0.2171, -0.1931, -0.6095, -0.7790, -0.4947, -0.8892, -0.6131, -0.7925,\n",
       "                      -0.6531, -0.7076, -0.3852, -0.2176, -0.2444, -0.2022, -0.6175, -0.4141,\n",
       "                      -0.7760, -0.4935, -0.5355, -0.4272, -0.4573, -0.4737, -0.8919, -0.6157,\n",
       "                      -0.1447, -0.6308, -0.4636, -0.6203, -0.4489, -0.3721, -0.6214, -0.5307,\n",
       "                      -0.3623, -0.5955, -0.5713, -0.6204, -0.7491, -0.4453, -0.2529, -0.5662,\n",
       "                      -0.6495, -0.6760, -0.4708, -0.6875, -0.5496, -0.6770, -0.2804, -0.5192])),\n",
       "             ('decoders.4.bn4.running_var',\n",
       "              tensor([1.8523, 0.3130, 0.4178, 0.2945, 2.8041, 0.3675, 2.2665, 3.8993, 3.3286,\n",
       "                      0.3729, 2.9174, 2.4047, 2.3513, 3.5473, 2.6956, 0.4258, 3.4788, 2.5339,\n",
       "                      0.4434, 1.6091, 1.6864, 3.7353, 3.3922, 3.0452, 0.4166, 2.5990, 3.2524,\n",
       "                      5.1564, 0.4348, 3.8599, 3.8345, 0.3805, 2.2981, 2.9698, 0.4793, 0.6305,\n",
       "                      3.1453, 3.2566, 4.1557, 2.9617, 2.0587, 3.2845, 2.7173, 1.9730, 1.5735,\n",
       "                      4.2567, 2.5426, 2.8086, 3.6803, 0.3057, 2.5167, 0.2810, 2.4965, 3.1541,\n",
       "                      5.2521, 1.9706, 3.6144, 3.6482, 4.1805, 3.0166, 1.6676, 0.4466, 3.0477,\n",
       "                      2.9339, 0.4021, 4.3591, 3.4762, 0.4620, 4.2603, 3.1562, 2.7186, 0.3397,\n",
       "                      3.3261, 0.3529, 4.6161, 2.3978, 3.6833, 3.2860, 4.0580, 2.7702, 0.4680,\n",
       "                      2.8061, 2.5337, 3.8767, 3.1944, 0.2595, 3.9137, 0.3459, 3.6923, 0.5339,\n",
       "                      5.2101, 2.4608, 4.5188, 3.6735, 0.3946, 1.6460, 3.6002, 3.4322, 3.4028,\n",
       "                      2.6362, 3.9932, 0.4151, 0.4252, 0.3860, 2.8205, 2.2603, 2.4035, 3.3694,\n",
       "                      1.8890, 3.3654, 4.3438, 2.2836, 2.0641, 3.0704, 0.2750, 1.8992, 0.4849,\n",
       "                      0.2602, 2.8765, 3.5117, 2.1402, 2.3442, 2.7158, 3.4976, 4.8077, 3.0797,\n",
       "                      2.6982, 2.5295, 0.3182, 2.4190, 0.2971, 2.5421, 2.3439, 2.6525, 2.9863,\n",
       "                      2.7435, 3.5874, 0.3278, 2.1532, 3.4827, 3.0819, 2.4412, 3.1285, 1.9265,\n",
       "                      3.7369, 0.4082, 2.7326, 4.5219, 2.2799, 3.6295, 0.5056, 2.2014, 3.1723,\n",
       "                      0.8126, 2.3787, 4.8766, 2.0956, 3.2681, 3.0983, 3.2222, 3.6950, 5.0782,\n",
       "                      3.3950, 4.6006, 4.5578, 6.5880, 0.3421, 2.9170, 0.5140, 2.2572, 0.5296,\n",
       "                      3.1621, 4.1652, 3.5669, 2.0560, 2.5902, 4.0933, 3.0887, 0.6873, 2.9571,\n",
       "                      2.4280, 3.0609, 0.5139, 2.1454, 2.1920, 2.6898, 3.3400, 4.1291, 0.2338,\n",
       "                      0.3337, 3.6541, 0.2765, 4.1933, 0.4366, 3.3385, 0.3955, 2.4352, 2.4736,\n",
       "                      3.0324, 4.1990, 4.0040, 0.5207, 3.2193, 4.3289, 2.9613, 2.0904, 2.5723,\n",
       "                      3.5779, 0.4374, 2.1660, 0.3912, 2.7420, 2.8743, 3.2092, 2.5314, 3.2196,\n",
       "                      2.7402, 0.4497, 2.8586, 4.1973, 5.5667, 2.8203, 2.4026, 4.8388, 3.3951,\n",
       "                      2.7997, 4.1590, 2.2536, 3.5872, 2.3862, 4.3255, 2.6014, 3.5105, 0.2933,\n",
       "                      3.5188, 3.1880, 5.3997, 2.9689, 2.9802, 0.5324, 2.6603, 4.5942, 4.6649,\n",
       "                      3.9763, 0.4392, 3.0787, 0.4330, 2.5968, 2.8931, 0.4042, 2.7841, 2.7955,\n",
       "                      3.2617, 3.9716, 1.9042, 4.2268, 0.3560, 3.4812, 3.0619, 4.0023, 3.3919,\n",
       "                      3.3229, 0.2192, 3.0973, 4.0026, 2.3101, 2.6002, 3.7910, 3.3373, 3.5896,\n",
       "                      0.4048, 0.5412, 3.1587, 0.4992, 2.3683, 0.3698, 0.3410, 0.2926, 0.3860,\n",
       "                      2.3479, 0.4566, 0.4008, 3.0305, 0.3839, 0.3241, 2.4285, 3.7895, 4.4082,\n",
       "                      0.4897, 0.6215, 2.6012, 4.8128, 2.4330, 3.0781, 4.1083, 2.7473, 3.9671,\n",
       "                      2.2893, 0.4185, 3.8537, 2.8303, 3.4078, 3.1736, 2.7622, 3.8714, 0.4729,\n",
       "                      3.0478, 4.4170, 3.1079, 0.5199, 4.5376, 0.5545, 0.3101, 2.7970, 3.8464,\n",
       "                      3.6250, 0.4074, 0.4983, 3.3976, 2.3478, 0.3165, 2.0555, 0.4803, 0.5246,\n",
       "                      2.6558, 3.5131, 2.6402, 0.3719, 0.3820, 0.2981, 4.1682, 2.4879, 2.5874,\n",
       "                      4.7776, 4.4697, 3.3692, 2.2648, 3.5790, 3.9202, 4.4045, 2.7348, 0.4243,\n",
       "                      3.6319, 0.4939, 0.4596, 0.3782, 3.5855, 2.8300, 0.4265, 4.4240, 0.4407,\n",
       "                      2.6971, 0.2873, 2.5948, 2.3187, 3.3010, 3.4195, 0.2864, 2.8632, 2.3419,\n",
       "                      3.1076, 2.8091, 3.5583, 4.9406, 0.3920, 0.2854, 2.7306, 3.3464, 0.4222,\n",
       "                      0.2647, 1.9202, 0.5241, 3.4978, 2.8599, 2.9043, 3.6832, 2.6608, 2.9251,\n",
       "                      0.4735, 3.0975, 2.4890, 0.2558, 4.3035, 0.3453, 2.6850, 6.7053, 3.6256,\n",
       "                      2.8113, 3.8839, 3.0907, 2.9099, 4.1589, 0.3523, 3.7613, 1.8251, 3.1109,\n",
       "                      4.1262, 0.4875, 0.5287, 0.3223, 3.2353, 2.3430, 1.4934, 2.5812, 3.6937,\n",
       "                      2.4316, 0.3348, 0.3992, 3.9036, 3.3089, 2.8199, 2.0376, 3.9154, 2.1783,\n",
       "                      2.5647, 2.9806, 3.7545, 4.0818, 0.4061, 0.3742, 0.2637, 0.3801, 2.3670,\n",
       "                      3.0041, 0.3008, 2.3177, 0.3497, 3.2956, 2.9758, 3.9110, 3.2432, 3.3794,\n",
       "                      0.5035, 4.3477, 2.8710, 3.6223, 0.3669, 3.7878, 5.2101, 5.6629, 2.5744,\n",
       "                      0.2798, 0.3473, 3.5547, 3.1787, 3.1770, 2.4246, 3.4873, 0.4742, 2.6919,\n",
       "                      5.0082, 0.2743, 2.5535, 0.1544, 0.3922, 4.3469, 3.1917, 0.5009, 3.1746,\n",
       "                      4.1433, 3.3546, 3.6987, 3.6268, 2.4222, 3.5866, 0.4738, 0.3484, 3.4410,\n",
       "                      3.3520, 3.9497, 3.4794, 2.9185, 2.7510, 2.6217, 4.7448, 0.5152, 0.5904,\n",
       "                      0.3409, 3.3615, 0.4284, 3.3132, 3.1864, 2.4184, 4.3036, 2.8169, 1.5394,\n",
       "                      3.1092, 3.0387, 3.3194, 2.7684, 3.4388, 3.5652, 0.3655, 0.4732, 3.7289,\n",
       "                      3.1285, 0.4819, 0.3203, 2.3880, 2.4792, 4.0277, 1.7422, 0.5254, 0.3563,\n",
       "                      3.3640, 2.4555, 0.3990, 2.3402, 2.4049, 3.3583, 0.3480, 2.1646])),\n",
       "             ('decoders.4.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense5.weight',\n",
       "              tensor([[-0.0395, -0.0231,  0.0250,  ..., -0.0029, -0.0194, -0.0279],\n",
       "                      [-0.0434, -0.0308, -0.0553,  ...,  0.0008, -0.0243, -0.0155],\n",
       "                      [-0.0559, -0.0458,  0.0029,  ..., -0.0230, -0.0421, -0.0280],\n",
       "                      ...,\n",
       "                      [ 0.0193, -0.0468, -0.0048,  ..., -0.0592, -0.0385, -0.0558],\n",
       "                      [-0.0424, -0.0541,  0.0051,  ..., -0.0394, -0.0190, -0.0508],\n",
       "                      [-0.0228, -0.0595,  0.0045,  ..., -0.0477, -0.0413, -0.0255]])),\n",
       "             ('decoders.4.dense5.bias',\n",
       "              tensor([-0.0479, -0.0414, -0.0298,  ..., -0.0293,  0.0095, -0.0338])),\n",
       "             ('decoders.5.dense1.weight',\n",
       "              tensor([[-0.1533,  0.1208,  0.0475,  ..., -0.0736, -0.1077,  0.0465],\n",
       "                      [-0.0173,  0.0888,  0.0287,  ...,  0.1399, -0.1546,  0.1783],\n",
       "                      [ 0.1457,  0.1502, -0.0993,  ..., -0.0611,  0.0894, -0.0598],\n",
       "                      ...,\n",
       "                      [-0.0860, -0.0687, -0.1267,  ..., -0.1399,  0.0314,  0.0515],\n",
       "                      [ 0.0733,  0.0143, -0.1765,  ...,  0.0131, -0.1518,  0.0996],\n",
       "                      [ 0.0371, -0.0069, -0.1620,  ..., -0.1757,  0.1452,  0.0888]])),\n",
       "             ('decoders.5.bn1.weight',\n",
       "              tensor([0.9945, 0.9920, 0.9845, 1.0158, 1.0195, 0.9938, 0.9972, 1.0099, 1.0139,\n",
       "                      0.9948, 1.0074, 1.0185, 0.9956, 0.9899, 0.9884, 0.9892, 0.9961, 1.0190,\n",
       "                      0.9893, 1.0180, 1.0192, 0.9905, 0.9859, 0.9968, 0.9825, 1.0165, 0.9914,\n",
       "                      0.9946, 1.0042, 0.9947, 0.9847, 0.9852, 1.0010, 1.0058, 0.9949, 1.0172,\n",
       "                      1.0023, 1.0013, 0.9964, 0.9946, 0.9898, 0.9817, 0.9878, 0.9932, 0.9925,\n",
       "                      0.9968, 0.9826, 0.9962, 1.0170, 0.9836, 0.9909, 1.0220, 0.9874, 1.0068,\n",
       "                      1.0140, 0.9814, 1.0165, 1.0220, 0.9843, 0.9746, 0.9889, 0.9817, 1.0271,\n",
       "                      1.0035, 0.9972, 0.9802, 1.0172, 1.0132, 0.9776, 0.9835, 0.9972, 0.9931,\n",
       "                      1.0122, 1.0077, 0.9746, 0.9885, 0.9882, 1.0047, 1.0177, 1.0037, 0.9843,\n",
       "                      0.9995, 1.0078, 0.9937, 1.0074, 1.0062, 0.9887, 0.9896, 0.9944, 0.9850,\n",
       "                      0.9966, 1.0067, 0.9953, 0.9978, 0.9825, 1.0006, 1.0252, 0.9791, 1.0176,\n",
       "                      0.9832, 1.0085, 1.0031, 0.9890, 1.0119, 0.9818, 1.0183, 1.0175, 0.9862,\n",
       "                      0.9888, 0.9913, 0.9919, 0.9917, 0.9828, 0.9851, 0.9865, 1.0029, 0.9918,\n",
       "                      1.0227, 0.9866, 0.9883, 1.0018, 0.9954, 1.0026, 0.9973, 0.9997, 1.0146,\n",
       "                      1.0110, 1.0057])),\n",
       "             ('decoders.5.bn1.bias',\n",
       "              tensor([-3.2145e-03, -6.3824e-03,  9.9711e-03, -1.2895e-02,  8.7022e-04,\n",
       "                       1.2507e-02,  4.5185e-03,  5.9639e-03, -4.9827e-03,  7.8440e-03,\n",
       "                      -1.2419e-02, -1.6569e-03,  3.0471e-03,  1.4430e-02, -1.1976e-02,\n",
       "                      -5.7233e-03, -8.6924e-04, -2.9981e-03, -1.4168e-02, -3.1238e-03,\n",
       "                      -1.3170e-02, -9.9700e-03, -7.7526e-03, -4.6120e-03, -1.2733e-02,\n",
       "                       5.5967e-03, -5.8528e-03, -8.9686e-03, -8.5875e-03, -6.7768e-03,\n",
       "                      -3.6751e-03, -1.4710e-02, -6.6527e-03,  1.1980e-02, -5.8025e-03,\n",
       "                      -5.9002e-03,  1.3293e-02, -6.0366e-03, -1.3353e-02, -8.0186e-04,\n",
       "                      -9.7131e-03, -1.9988e-02,  1.6402e-03, -3.0566e-03, -2.1433e-02,\n",
       "                       5.3510e-04, -1.3484e-02, -1.4693e-02,  2.8515e-03, -1.3703e-02,\n",
       "                      -1.6049e-02, -5.6189e-03, -1.4004e-02,  5.2873e-03, -8.4060e-03,\n",
       "                      -1.0302e-02, -1.3046e-02, -1.3281e-02, -1.4560e-02, -2.8652e-02,\n",
       "                       6.5888e-04, -2.3286e-02, -1.1889e-02, -6.9148e-03, -1.2811e-02,\n",
       "                      -1.8193e-02, -8.7710e-03,  2.3878e-02, -1.9424e-02, -1.0073e-02,\n",
       "                       7.4748e-03, -1.2835e-02, -1.1648e-02,  3.2982e-03, -1.7617e-02,\n",
       "                      -1.0790e-02, -1.4168e-02,  1.6414e-02, -3.2543e-03, -1.4903e-03,\n",
       "                       1.3456e-03,  1.0543e-02,  2.2109e-02,  4.4591e-03,  1.1664e-02,\n",
       "                       1.9921e-03, -4.2291e-03, -1.8113e-02,  8.0066e-03, -8.6232e-03,\n",
       "                      -4.5082e-03,  1.8566e-03, -8.0670e-03, -1.9373e-03, -1.5590e-02,\n",
       "                      -4.8714e-03, -6.7187e-03, -1.0976e-02,  1.9172e-03, -1.2837e-02,\n",
       "                      -7.4297e-03,  4.3329e-03, -1.8562e-03, -1.9877e-05, -1.2017e-02,\n",
       "                      -4.8674e-03,  3.3302e-03, -1.0253e-02, -1.0232e-03, -2.0552e-02,\n",
       "                      -2.6938e-03, -3.9813e-03, -1.6000e-02, -9.1906e-03, -1.4720e-02,\n",
       "                       6.8040e-03, -9.3011e-03, -1.1141e-02,  8.5989e-03, -1.1888e-02,\n",
       "                       4.5244e-03, -1.0979e-02, -1.4252e-03, -5.5583e-03,  1.0308e-02,\n",
       "                      -1.0501e-02, -1.5677e-03,  2.2160e-04])),\n",
       "             ('decoders.5.bn1.running_mean',\n",
       "              tensor([-0.0922, -0.2031, -0.0190, -0.2695,  0.0176, -0.0544,  0.2916, -0.1541,\n",
       "                      -0.3597, -0.0115, -0.1982, -0.1328, -0.0224,  0.1729, -0.0743, -0.0325,\n",
       "                      -0.1471, -0.3349, -0.2012, -0.2876, -0.3242,  0.2499, -0.0408,  0.2117,\n",
       "                       0.1389, -0.2136,  0.2014, -0.1787, -0.3195,  0.2003, -0.0770, -0.0452,\n",
       "                      -0.1761,  0.1174, -0.1505, -0.2205,  0.2274, -0.2603,  0.0151, -0.0662,\n",
       "                      -0.0026, -0.0444,  0.1216,  0.0219, -0.0999,  0.1618, -0.0950, -0.0618,\n",
       "                      -0.2135, -0.1049, -0.1505, -0.4295, -0.0534, -0.1240, -0.0706, -0.2329,\n",
       "                      -0.1921, -0.2608, -0.1586, -0.0101,  0.1363, -0.1797, -0.3205, -0.1202,\n",
       "                      -0.0403, -0.0743, -0.2678,  0.0417,  0.0503,  0.2599,  0.1006,  0.1635,\n",
       "                      -0.2710, -0.0318,  0.1136, -0.2211,  0.2293,  0.1855, -0.2604, -0.0175,\n",
       "                       0.1224,  0.2920,  0.0547,  0.1590, -0.0437, -0.1036, -0.0282,  0.0364,\n",
       "                       0.1323, -0.0472, -0.0901,  0.0308,  0.1341, -0.1611, -0.0161, -0.1738,\n",
       "                      -0.1788, -0.0380, -0.0827, -0.0556, -0.2189, -0.1600,  0.0144, -0.2361,\n",
       "                      -0.0717, -0.2429, -0.0286, -0.0830,  0.0146,  0.0636,  0.0651, -0.0960,\n",
       "                       0.1124,  0.1025,  0.0482,  0.0143, -0.0803, -0.1476,  0.1403,  0.1372,\n",
       "                       0.0233, -0.0676, -0.0141, -0.0523, -0.1345, -0.3623, -0.1692,  0.1579])),\n",
       "             ('decoders.5.bn1.running_var',\n",
       "              tensor([0.1429, 0.1938, 0.6680, 2.2419, 0.3163, 0.5251, 0.9689, 0.4492, 1.2297,\n",
       "                      0.5248, 0.5913, 0.7893, 0.2837, 0.6375, 0.1397, 0.0739, 0.3669, 1.2146,\n",
       "                      0.5895, 1.9928, 1.7698, 0.8742, 0.2571, 0.0968, 0.1989, 0.8726, 0.3919,\n",
       "                      0.4810, 1.1406, 0.3023, 0.1502, 0.1273, 0.4063, 0.6526, 0.3394, 0.9864,\n",
       "                      1.1230, 1.1647, 0.9334, 0.1676, 0.3466, 0.2659, 0.1219, 0.4690, 1.2174,\n",
       "                      0.5949, 0.4136, 0.2037, 1.5422, 0.1241, 0.8612, 2.1324, 0.1826, 0.8473,\n",
       "                      0.4575, 0.1665, 1.8338, 1.3287, 0.4358, 0.1259, 0.3226, 0.2710, 1.8445,\n",
       "                      0.4252, 0.4509, 0.3062, 1.3549, 0.4146, 0.1254, 0.5825, 0.5998, 0.5092,\n",
       "                      1.1229, 0.5505, 0.1746, 0.2484, 0.3623, 0.7032, 0.9056, 0.4324, 0.1175,\n",
       "                      1.5559, 0.5166, 0.8916, 0.2707, 0.3009, 0.1999, 0.6983, 0.2885, 0.2424,\n",
       "                      0.4852, 0.5650, 0.2205, 0.3683, 0.2553, 0.7904, 1.4698, 0.2862, 0.7123,\n",
       "                      0.1654, 0.6031, 0.3167, 0.2158, 1.0725, 0.1285, 1.4181, 0.8540, 0.1461,\n",
       "                      0.2609, 0.3174, 0.1785, 0.1312, 0.1415, 0.2034, 0.1951, 0.1070, 0.4272,\n",
       "                      1.8248, 1.1711, 0.3041, 0.1628, 0.6182, 0.2392, 0.2266, 0.1582, 2.1244,\n",
       "                      1.4610, 0.1433])),\n",
       "             ('decoders.5.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense2.weight',\n",
       "              tensor([[-0.0448,  0.0407, -0.0026,  ..., -0.1001, -0.0159,  0.0943],\n",
       "                      [-0.0118, -0.0270,  0.0728,  ...,  0.0946,  0.0802, -0.0867],\n",
       "                      [-0.0759, -0.0176,  0.0378,  ...,  0.0025,  0.0587,  0.0416],\n",
       "                      ...,\n",
       "                      [-0.0022,  0.0843, -0.0041,  ...,  0.0566,  0.0789,  0.0143],\n",
       "                      [-0.0898, -0.0142,  0.0443,  ..., -0.0169, -0.0514,  0.0919],\n",
       "                      [ 0.0954,  0.0582,  0.0267,  ...,  0.0017,  0.0705, -0.0221]])),\n",
       "             ('decoders.5.bn2.weight',\n",
       "              tensor([0.9886, 1.0186, 1.0253, 0.9876, 0.9995, 1.0219, 1.0014, 0.9939, 1.0065,\n",
       "                      0.9970, 0.9818, 0.9841, 0.9990, 0.9987, 0.9790, 1.0069, 1.0079, 1.0211,\n",
       "                      1.0226, 1.0106, 0.9845, 0.9976, 1.0037, 1.0104, 1.0128, 0.9901, 0.9884,\n",
       "                      0.9938, 1.0037, 1.0016, 1.0167, 1.0122, 0.9928, 1.0148, 0.9806, 0.9891,\n",
       "                      0.9890, 1.0008, 1.0159, 1.0023, 0.9863, 0.9858, 1.0164, 1.0127, 0.9927,\n",
       "                      1.0165, 1.0056, 1.0293, 0.9829, 0.9951, 0.9970, 0.9766, 1.0004, 1.0103,\n",
       "                      0.9865, 1.0201, 0.9813, 0.9955, 0.9919, 0.9926, 0.9930, 0.9998, 0.9834,\n",
       "                      0.9839, 0.9958, 0.9864, 0.9946, 1.0113, 1.0019, 0.9844, 0.9956, 1.0145,\n",
       "                      1.0002, 0.9888, 0.9860, 1.0230, 0.9873, 0.9945, 0.9968, 1.0020, 0.9971,\n",
       "                      0.9845, 0.9923, 1.0220, 0.9995, 0.9904, 0.9943, 0.9748, 1.0030, 1.0026,\n",
       "                      0.9948, 1.0185, 0.9963, 1.0038, 1.0082, 0.9753, 0.9897, 0.9880, 0.9945,\n",
       "                      1.0176, 0.9884, 0.9837, 0.9904, 0.9979, 0.9993, 0.9914, 0.9951, 0.9915,\n",
       "                      0.9878, 0.9928, 0.9916, 0.9933, 0.9873, 1.0059, 1.0028, 0.9980, 1.0070,\n",
       "                      0.9958, 0.9825, 0.9915, 0.9910, 1.0178, 0.9804, 0.9810, 0.9949, 1.0112,\n",
       "                      1.0126, 0.9923, 0.9940, 0.9881, 0.9982, 1.0179, 0.9902, 0.9953, 0.9747,\n",
       "                      1.0002, 0.9925, 1.0104, 0.9979, 1.0159, 1.0086, 0.9800, 0.9856, 0.9898,\n",
       "                      0.9984, 0.9906, 1.0078, 0.9931, 1.0079, 0.9994, 0.9952, 1.0188, 0.9899,\n",
       "                      1.0164, 0.9859, 1.0148, 0.9915, 0.9849, 1.0258, 0.9984, 1.0010, 0.9841,\n",
       "                      1.0045, 1.0064, 1.0081, 1.0013, 0.9967, 0.9870, 0.9762, 1.0148, 0.9826,\n",
       "                      1.0180, 0.9819, 0.9972, 1.0008, 1.0111, 0.9848, 1.0248, 1.0076, 1.0036,\n",
       "                      1.0136, 0.9936, 0.9695, 0.9801, 0.9869, 0.9923, 0.9796, 0.9926, 1.0093,\n",
       "                      0.9887, 0.9863, 1.0130, 1.0071, 1.0044, 0.9904, 1.0203, 1.0030, 0.9993,\n",
       "                      1.0158, 0.9958, 0.9954, 0.9975, 0.9914, 0.9929, 0.9973, 1.0065, 0.9978,\n",
       "                      0.9960, 0.9921, 0.9966, 1.0134, 0.9938, 1.0232, 0.9936, 0.9890, 1.0164,\n",
       "                      0.9929, 0.9813, 0.9947, 0.9939, 0.9858, 1.0037, 0.9946, 0.9830, 0.9745,\n",
       "                      1.0001, 1.0000, 0.9868, 0.9931, 1.0089, 0.9886, 0.9997, 0.9945, 1.0028,\n",
       "                      0.9853, 0.9973, 1.0141, 0.9876, 1.0086, 1.0000, 1.0063, 1.0164, 1.0121,\n",
       "                      0.9986, 0.9836, 1.0114, 1.0095, 1.0125, 0.9911, 0.9962, 1.0032, 1.0244,\n",
       "                      0.9913, 0.9981, 0.9822, 0.9784])),\n",
       "             ('decoders.5.bn2.bias',\n",
       "              tensor([ 7.3975e-05, -8.1900e-03,  9.8405e-03, -1.2717e-02,  3.1376e-03,\n",
       "                       8.8391e-03,  1.7974e-02,  1.1427e-02,  2.4379e-02, -7.2337e-03,\n",
       "                      -1.2030e-02, -1.4492e-02, -5.2090e-03,  9.5829e-03, -2.3075e-02,\n",
       "                      -3.4441e-03, -2.9175e-03, -2.8246e-03, -7.2585e-03, -3.2448e-04,\n",
       "                      -1.5716e-02,  1.5468e-03,  5.9203e-03,  6.4050e-04, -2.2401e-03,\n",
       "                      -1.6002e-03,  4.9870e-03, -2.4121e-03,  1.8873e-02,  1.6482e-02,\n",
       "                      -4.0642e-04, -2.2852e-03, -5.9075e-03, -1.3986e-02, -1.3528e-02,\n",
       "                      -1.0519e-02, -1.1937e-02,  6.2145e-03, -1.0404e-03, -6.0266e-03,\n",
       "                      -1.2809e-03, -3.1823e-03,  3.8235e-03,  5.6539e-04, -5.3692e-03,\n",
       "                      -4.6521e-03, -1.2533e-02,  4.0586e-03, -1.0904e-02, -6.7809e-03,\n",
       "                      -7.8180e-03, -2.1677e-02, -1.9260e-03, -7.4941e-03, -1.5699e-02,\n",
       "                      -3.3941e-03, -9.4210e-03, -5.1016e-03,  2.0575e-02, -1.9534e-02,\n",
       "                       1.6956e-02,  4.9689e-04, -9.4896e-03, -1.7361e-02, -1.1379e-02,\n",
       "                      -1.6403e-02, -3.2868e-03, -1.8165e-03, -3.2652e-03, -1.0726e-02,\n",
       "                      -2.9497e-03, -6.6468e-03,  1.0943e-03, -9.5137e-03, -1.2301e-02,\n",
       "                       5.2351e-03, -1.3365e-02,  1.6289e-02,  1.0097e-03, -1.1778e-02,\n",
       "                       3.3173e-03, -1.6977e-02,  1.4786e-02, -5.2516e-03, -3.3432e-03,\n",
       "                      -7.4117e-03,  1.5468e-02, -2.1115e-02, -1.0413e-02, -1.0865e-02,\n",
       "                       2.1201e-03, -4.8092e-03,  1.5655e-02, -6.3165e-03, -7.1832e-03,\n",
       "                      -1.0269e-02, -1.7932e-02, -1.0192e-02, -1.3051e-03, -5.9903e-04,\n",
       "                      -1.0707e-02, -1.9190e-02, -8.1199e-03,  9.4303e-03,  2.1503e-03,\n",
       "                       6.8002e-03, -8.5884e-03, -6.8251e-03, -1.6806e-03, -1.5315e-02,\n",
       "                      -9.1429e-03,  3.3456e-03, -8.2463e-03,  1.9182e-02,  1.7843e-02,\n",
       "                       3.2671e-03,  7.0321e-03, -1.2989e-03, -2.0083e-02, -1.2657e-02,\n",
       "                      -9.9193e-03, -9.3309e-03, -1.4037e-02, -2.3031e-02,  1.6317e-02,\n",
       "                      -6.8555e-03,  2.9315e-03, -2.4722e-03,  7.0148e-03, -1.5834e-02,\n",
       "                      -8.0563e-03, -8.1887e-04, -1.7586e-02, -5.1964e-03, -2.4025e-02,\n",
       "                      -8.0959e-03, -3.2946e-03,  6.3255e-04,  1.4729e-02,  1.0103e-02,\n",
       "                      -3.7040e-03, -1.6186e-02, -1.6209e-02, -1.5547e-02, -1.4237e-02,\n",
       "                      -6.7245e-03, -5.6223e-03,  7.6013e-03,  2.0425e-03, -3.4348e-03,\n",
       "                      -6.9340e-03, -8.1772e-04,  7.1043e-03,  7.1126e-03, -6.2073e-03,\n",
       "                      -5.6404e-03, -5.7917e-03, -1.3265e-03, -2.0141e-03, -1.4543e-03,\n",
       "                       1.8299e-02, -1.0471e-02,  1.4570e-02, -1.5120e-02, -6.4661e-03,\n",
       "                      -4.2887e-04,  1.3942e-02, -1.8056e-03, -1.7261e-02, -6.8218e-03,\n",
       "                      -1.2398e-02, -1.9378e-02, -1.1714e-02, -1.1489e-02, -9.4385e-03,\n",
       "                      -1.0893e-02, -1.7059e-02, -9.8924e-03, -1.1616e-03,  3.3960e-03,\n",
       "                      -1.1078e-02, -3.7584e-03, -2.3854e-02, -2.5930e-02, -5.2651e-03,\n",
       "                       1.5827e-02, -6.8678e-03,  1.0914e-03,  8.3187e-03,  1.8786e-02,\n",
       "                      -1.4382e-02, -8.0758e-03,  5.5212e-04,  2.9382e-03,  1.8606e-03,\n",
       "                       6.4162e-03,  6.1351e-03, -4.3085e-03, -1.0740e-02,  8.3318e-03,\n",
       "                      -1.1168e-02,  1.8283e-02, -1.0481e-02,  4.0319e-03, -1.1443e-02,\n",
       "                       9.9878e-03, -4.3442e-03,  8.9887e-03,  5.0609e-03,  8.2505e-03,\n",
       "                      -7.3840e-03,  1.9308e-03, -6.6236e-03, -9.3756e-03, -3.5150e-03,\n",
       "                      -5.5993e-03,  1.5537e-02, -8.0115e-03,  1.3648e-02,  1.2418e-03,\n",
       "                      -1.8173e-03,  4.7174e-03,  9.4408e-03, -1.3565e-02, -1.6974e-02,\n",
       "                      -1.4007e-02, -1.0053e-02, -1.0024e-02, -5.3267e-03, -4.1506e-03,\n",
       "                      -4.9662e-03, -3.3579e-03,  1.6694e-02, -4.4220e-03, -1.3536e-02,\n",
       "                       1.2440e-02,  3.9755e-03, -7.5852e-03, -1.0102e-02, -6.4406e-03,\n",
       "                      -5.3640e-03, -7.0281e-03, -1.2115e-02, -5.2437e-03, -1.4204e-02,\n",
       "                      -5.3641e-03,  2.6754e-03, -6.8526e-03, -1.1054e-02,  6.8431e-03,\n",
       "                      -3.6856e-03,  1.5598e-02, -6.7860e-04, -6.2346e-03, -1.6632e-02,\n",
       "                      -1.6811e-02])),\n",
       "             ('decoders.5.bn2.running_mean',\n",
       "              tensor([-3.0081e-01,  3.1843e-01,  2.0861e-01,  6.2312e-02, -8.4021e-02,\n",
       "                       3.4801e-01, -3.9435e-01, -1.3741e-01, -1.4246e-01, -2.8926e-02,\n",
       "                       2.9529e-01, -2.2126e-01, -1.8608e-02, -3.8921e-01,  2.2189e-01,\n",
       "                      -1.6659e-02,  3.8743e-01,  1.3456e-01,  4.9503e-01,  1.4538e-01,\n",
       "                       3.1234e-01,  3.6254e-01, -5.8642e-02,  2.1455e-01, -1.0675e-01,\n",
       "                      -2.1933e-01, -1.0499e-01, -1.6496e-01, -1.6030e-01, -2.9451e-01,\n",
       "                       4.1613e-01,  2.6766e-01, -7.6336e-02,  3.1308e-01,  1.9796e-01,\n",
       "                      -6.6282e-02, -1.2176e-01, -1.9465e-01,  1.8807e-01,  7.7674e-02,\n",
       "                      -1.2035e-01, -8.7863e-02,  1.5013e-01,  2.5520e-01,  2.9968e-01,\n",
       "                       6.7746e-02,  2.3787e-01,  6.9992e-01, -3.0214e-01, -1.0027e-01,\n",
       "                       1.4442e-01, -6.2483e-02, -1.3320e-01,  2.3042e-01, -1.4244e-01,\n",
       "                       3.2583e-01, -3.7858e-01,  1.3323e-01, -3.5786e-01,  3.1722e-01,\n",
       "                      -3.9950e-01, -1.4915e-01, -7.5831e-02, -4.0884e-02,  3.6550e-01,\n",
       "                      -3.3903e-02, -1.2918e-01,  5.5929e-01,  4.5885e-01, -8.7978e-02,\n",
       "                      -1.1356e-01,  3.6788e-01, -1.9650e-01, -1.6221e-01, -2.8037e-01,\n",
       "                       4.8353e-01,  2.3463e-04, -1.6286e-01, -3.4633e-01,  1.0499e-01,\n",
       "                       3.0244e-01,  1.4247e-01,  1.2365e-01,  3.4549e-01,  2.9755e-01,\n",
       "                      -2.1817e-01, -1.4305e-01, -2.4466e-01, -2.7125e-01,  1.3105e-01,\n",
       "                      -1.6121e-01,  3.2828e-01, -3.7139e-01,  4.1500e-02,  2.1424e-01,\n",
       "                      -1.8033e-02,  2.6949e-01, -2.0911e-01,  1.2832e-01,  1.7505e-02,\n",
       "                      -1.4148e-01,  2.9600e-01, -2.8452e-01, -1.4332e-01,  3.0102e-01,\n",
       "                      -3.1318e-01, -1.4948e-01, -1.1332e-01, -3.8207e-02,  2.7961e-01,\n",
       "                       8.4573e-02, -3.6858e-01,  2.1156e-01, -3.2872e-01, -4.8472e-01,\n",
       "                      -9.2577e-02, -3.0750e-01, -1.1246e-01,  2.1267e-01, -1.6704e-01,\n",
       "                       1.3178e-01,  3.2632e-01,  5.0695e-02, -1.0105e-01, -6.2373e-01,\n",
       "                      -7.3467e-04,  3.4745e-01, -1.4394e-02, -3.4442e-03,  2.8081e-02,\n",
       "                      -4.2233e-02,  2.0590e-01,  2.7992e-01, -8.2205e-02,  2.5679e-01,\n",
       "                      -1.0388e-02, -3.5928e-01,  1.7039e-01, -2.2039e-01,  2.7605e-01,\n",
       "                       1.2823e-01,  1.1205e-01, -7.9366e-02,  2.0229e-02,  2.7095e-03,\n",
       "                       2.2487e-02,  2.7954e-01, -3.7645e-01,  9.3960e-03,  1.9418e-01,\n",
       "                       1.4925e-01,  1.0280e-01, -1.0729e-02,  1.3588e-01,  7.0632e-02,\n",
       "                       1.2801e-01, -3.0618e-01, -5.7583e-02,  3.1733e-01,  1.2672e-01,\n",
       "                      -5.0231e-01, -4.3574e-02, -2.0808e-01,  2.6852e-01,  2.9193e-01,\n",
       "                       3.1567e-01, -1.7391e-01, -9.9305e-02,  1.2032e-01,  2.7944e-01,\n",
       "                      -7.3569e-02,  2.5228e-01, -9.6675e-02,  2.9083e-01,  3.7265e-01,\n",
       "                       3.7810e-01, -1.8358e-01,  2.7219e-01,  2.6168e-01, -7.4281e-02,\n",
       "                       1.0882e-01,  5.7108e-02, -2.7433e-01,  1.9140e-02,  1.8821e-01,\n",
       "                      -1.9519e-01,  2.5382e-01,  8.6956e-03, -1.0593e-01, -1.3996e-01,\n",
       "                       1.5850e-01,  1.8937e-01,  2.8292e-01, -3.0607e-01, -3.4307e-02,\n",
       "                       5.4138e-01, -2.7153e-01, -3.6711e-01,  4.5814e-01, -1.0041e-01,\n",
       "                      -8.6641e-02, -2.6971e-01,  1.7520e-01, -2.0945e-01, -2.1356e-01,\n",
       "                       5.0080e-02, -4.2214e-02, -1.9937e-01, -4.2416e-01, -2.0711e-01,\n",
       "                       2.5796e-01, -3.6618e-01,  5.1807e-01,  9.5864e-03,  9.1792e-02,\n",
       "                       3.4429e-01, -2.3481e-01, -3.5964e-01, -3.0453e-01, -1.5196e-01,\n",
       "                       3.9978e-01,  2.7600e-01, -2.4824e-01, -5.4761e-02, -6.7564e-03,\n",
       "                       4.4574e-01,  1.4890e-01, -2.2024e-02, -1.8984e-01,  1.3885e-01,\n",
       "                      -2.0281e-01,  2.3751e-01, -2.8509e-01,  3.7003e-01,  1.7892e-01,\n",
       "                      -3.6537e-01,  3.0413e-01, -8.2976e-02,  3.1643e-01,  3.9963e-02,\n",
       "                       1.0069e-01, -2.0680e-02,  2.7627e-01,  9.5027e-02,  4.1650e-01,\n",
       "                       2.0828e-01,  2.6951e-01,  1.7169e-01,  3.1246e-02, -3.6599e-01,\n",
       "                      -3.4176e-02,  2.2388e-01,  1.1427e-01,  1.0711e-01, -1.0188e-01,\n",
       "                       1.3140e-02])),\n",
       "             ('decoders.5.bn2.running_var',\n",
       "              tensor([0.0910, 1.3553, 0.4746, 0.5345, 0.2075, 0.4816, 0.1322, 0.3923, 0.3802,\n",
       "                      0.4570, 0.1781, 0.3993, 0.0832, 1.0459, 0.1266, 0.6651, 0.3412, 0.8045,\n",
       "                      0.4553, 0.1517, 0.9050, 0.1008, 0.1344, 0.5176, 0.8016, 0.1392, 0.1571,\n",
       "                      0.0647, 0.4049, 0.0825, 0.2727, 0.2559, 0.3643, 0.5316, 0.0635, 0.1118,\n",
       "                      0.0923, 0.0970, 0.7249, 0.3567, 0.1963, 0.0843, 0.6805, 0.7702, 0.0751,\n",
       "                      1.0044, 1.1204, 0.3658, 0.1561, 0.7751, 0.2074, 0.0927, 0.8050, 0.3094,\n",
       "                      0.0651, 0.2468, 0.4872, 0.4034, 0.3414, 0.2162, 0.0877, 0.2480, 0.1309,\n",
       "                      0.0882, 0.1330, 0.0606, 0.2086, 0.6966, 0.1445, 0.2515, 0.5463, 0.2347,\n",
       "                      0.1686, 0.3732, 0.4607, 1.3447, 0.3412, 0.4397, 0.0903, 0.4711, 0.4117,\n",
       "                      0.1567, 0.6558, 0.9064, 0.2653, 0.1550, 0.6049, 0.1268, 0.6660, 0.7006,\n",
       "                      0.4944, 0.9433, 0.0813, 1.4036, 0.9174, 0.0891, 0.3359, 0.2684, 0.3060,\n",
       "                      0.5606, 0.3499, 0.2704, 0.1788, 0.1493, 0.2894, 0.0673, 0.1431, 0.2260,\n",
       "                      0.3141, 0.1484, 0.3786, 0.1053, 0.1190, 0.1529, 0.0726, 0.0693, 0.0828,\n",
       "                      0.1500, 0.2329, 0.5873, 0.1648, 0.3797, 0.2168, 0.1802, 0.1824, 0.3441,\n",
       "                      0.5518, 0.1492, 0.7597, 0.0653, 0.1118, 0.8616, 0.2996, 0.4679, 0.1577,\n",
       "                      1.0869, 0.1444, 0.4026, 0.2198, 0.3818, 0.7777, 0.1317, 0.0875, 0.1793,\n",
       "                      0.3668, 0.5311, 0.1883, 0.0861, 0.3717, 0.4659, 0.4422, 0.9950, 0.0761,\n",
       "                      0.5048, 0.1013, 0.3636, 0.3720, 0.1581, 0.4724, 0.2497, 0.5069, 0.2844,\n",
       "                      0.0804, 0.7776, 0.2389, 0.2706, 0.7366, 0.1135, 0.1501, 0.6028, 0.4775,\n",
       "                      0.8495, 0.2280, 0.2353, 0.6121, 0.8652, 0.2656, 0.3179, 0.6803, 0.2619,\n",
       "                      1.0973, 0.3617, 0.1044, 0.3201, 0.1388, 0.3457, 0.0834, 0.1629, 0.2291,\n",
       "                      0.9041, 0.0786, 1.0072, 0.2236, 0.3670, 0.1211, 0.5523, 0.0776, 0.0757,\n",
       "                      0.4547, 0.1653, 0.1482, 0.1519, 0.3626, 0.5308, 1.2149, 0.9236, 0.1716,\n",
       "                      0.0911, 0.1288, 0.4900, 0.6237, 0.1444, 0.4517, 0.4640, 0.3395, 0.5520,\n",
       "                      0.1366, 0.1494, 0.1628, 0.0882, 0.5972, 0.5005, 0.0597, 0.4264, 0.3209,\n",
       "                      0.2402, 0.5969, 0.0585, 0.2564, 0.4336, 0.2959, 0.4631, 0.2794, 0.2208,\n",
       "                      0.0497, 0.0695, 0.2848, 0.3058, 0.1930, 0.6980, 0.4858, 0.8977, 0.7567,\n",
       "                      0.1485, 0.4603, 1.0111, 0.3563, 0.5386, 0.2558, 1.4948, 0.6602, 1.3510,\n",
       "                      0.2916, 0.1699, 0.2099, 0.0987])),\n",
       "             ('decoders.5.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense3.weight',\n",
       "              tensor([[-0.0273, -0.0393,  0.0074,  ...,  0.0433,  0.0031, -0.0243],\n",
       "                      [-0.0506, -0.0341, -0.0192,  ..., -0.0179, -0.0630, -0.0544],\n",
       "                      [ 0.0036, -0.0196,  0.0298,  ...,  0.0281,  0.0393,  0.0329],\n",
       "                      ...,\n",
       "                      [-0.0659,  0.0614, -0.0199,  ..., -0.0631, -0.0629, -0.0118],\n",
       "                      [ 0.0133, -0.0216, -0.0014,  ..., -0.0304, -0.0002, -0.0010],\n",
       "                      [-0.0268,  0.0672, -0.0106,  ..., -0.0183,  0.0456, -0.0257]])),\n",
       "             ('decoders.5.bn3.weight',\n",
       "              tensor([1.0097, 1.0166, 0.9984, 0.9943, 1.0156, 1.0047, 0.9956, 0.9992, 0.9967,\n",
       "                      0.9906, 0.9952, 1.0144, 1.0138, 0.9977, 0.9918, 0.9920, 1.0102, 1.0111,\n",
       "                      0.9963, 0.9854, 0.9881, 0.9933, 0.9912, 0.9940, 1.0001, 1.0020, 0.9995,\n",
       "                      0.9969, 0.9949, 0.9928, 0.9966, 0.9847, 0.9903, 0.9818, 1.0003, 1.0114,\n",
       "                      1.0218, 0.9959, 1.0032, 0.9977, 0.9953, 0.9888, 0.9951, 1.0069, 0.9931,\n",
       "                      1.0128, 0.9901, 1.0099, 0.9922, 0.9972, 1.0146, 0.9992, 1.0158, 0.9974,\n",
       "                      1.0031, 0.9993, 1.0230, 0.9992, 0.9840, 0.9938, 1.0033, 0.9998, 0.9855,\n",
       "                      1.0115, 0.9936, 1.0101, 0.9844, 0.9877, 0.9973, 1.0116, 0.9971, 0.9935,\n",
       "                      0.9884, 0.9906, 0.9942, 1.0259, 0.9869, 1.0017, 0.9916, 0.9961, 0.9948,\n",
       "                      0.9845, 1.0147, 0.9959, 1.0084, 0.9983, 0.9864, 0.9889, 1.0150, 0.9937,\n",
       "                      0.9948, 0.9853, 1.0011, 0.9904, 0.9911, 0.9930, 1.0012, 0.9937, 0.9821,\n",
       "                      0.9872, 1.0057, 0.9925, 0.9905, 1.0032, 0.9955, 1.0015, 0.9875, 0.9945,\n",
       "                      1.0156, 0.9930, 1.0032, 0.9984, 0.9827, 0.9871, 0.9838, 0.9902, 1.0061,\n",
       "                      1.0259, 1.0058, 0.9882, 1.0012, 0.9926, 0.9912, 1.0156, 1.0005, 1.0161,\n",
       "                      0.9946, 1.0223, 1.0120, 0.9895, 0.9938, 0.9968, 0.9744, 1.0244, 1.0007,\n",
       "                      1.0198, 0.9874, 0.9948, 0.9821, 1.0022, 1.0005, 0.9884, 1.0225, 0.9935,\n",
       "                      1.0010, 1.0139, 0.9826, 0.9869, 1.0179, 1.0199, 1.0126, 1.0077, 1.0177,\n",
       "                      1.0193, 1.0020, 0.9973, 0.9951, 1.0042, 0.9948, 1.0069, 0.9881, 1.0179,\n",
       "                      0.9960, 0.9918, 0.9944, 1.0005, 0.9931, 0.9827, 0.9904, 1.0043, 1.0069,\n",
       "                      1.0065, 1.0227, 0.9856, 0.9988, 0.9988, 0.9925, 0.9753, 1.0210, 0.9891,\n",
       "                      0.9823, 1.0120, 0.9905, 0.9927, 1.0162, 1.0072, 1.0021, 1.0251, 0.9903,\n",
       "                      0.9987, 1.0013, 0.9978, 0.9934, 1.0058, 1.0144, 0.9862, 1.0068, 0.9967,\n",
       "                      0.9967, 1.0040, 1.0164, 0.9972, 0.9822, 0.9958, 1.0209, 0.9890, 0.9950,\n",
       "                      0.9966, 1.0234, 1.0092, 0.9968, 0.9883, 1.0149, 0.9962, 1.0004, 1.0018,\n",
       "                      0.9961, 0.9912, 1.0066, 1.0220, 1.0175, 0.9799, 1.0153, 1.0079, 0.9966,\n",
       "                      0.9842, 0.9971, 0.9893, 1.0062, 0.9908, 1.0176, 1.0131, 0.9973, 0.9944,\n",
       "                      0.9862, 0.9883, 0.9894, 0.9938, 0.9980, 1.0209, 1.0023, 1.0191, 1.0005,\n",
       "                      0.9818, 0.9879, 0.9879, 0.9876, 0.9913, 1.0056, 0.9973, 0.9857, 0.9918,\n",
       "                      0.9950, 0.9932, 0.9837, 0.9916, 0.9917, 0.9772, 0.9980, 1.0035, 1.0202,\n",
       "                      1.0110, 0.9924, 0.9877, 1.0000, 0.9920, 0.9954, 0.9909, 0.9877, 0.9955,\n",
       "                      0.9925, 0.9912, 0.9965, 0.9979, 0.9974, 1.0114, 0.9993, 0.9980, 0.9903,\n",
       "                      0.9991, 0.9900, 1.0004, 1.0190, 0.9939, 0.9937, 0.9991, 1.0023, 0.9948,\n",
       "                      0.9845, 0.9868, 1.0125, 0.9946, 1.0175, 1.0108, 0.9975, 0.9775, 0.9951,\n",
       "                      1.0158, 0.9983, 1.0141, 1.0152, 1.0015, 0.9788, 1.0198, 0.9979, 0.9822,\n",
       "                      0.9984, 0.9866, 1.0002, 0.9988, 1.0192, 0.9980, 1.0127, 1.0043, 1.0160,\n",
       "                      1.0157, 0.9952, 0.9784, 0.9945, 0.9950, 0.9951, 1.0101, 0.9895, 1.0170,\n",
       "                      0.9976, 0.9970, 1.0096, 0.9830, 0.9934, 0.9986, 1.0143, 0.9834, 0.9872,\n",
       "                      1.0143, 0.9924, 1.0248, 0.9834, 1.0188, 0.9938, 1.0239, 1.0161, 1.0034,\n",
       "                      0.9932, 0.9741, 0.9981, 0.9906, 1.0132, 0.9939, 0.9954, 0.9942, 0.9893,\n",
       "                      0.9964, 0.9826, 0.9995, 0.9975, 0.9918, 0.9940, 0.9975, 0.9926, 0.9948,\n",
       "                      0.9948, 0.9921, 1.0187, 0.9805, 0.9844, 0.9909, 0.9832, 1.0177, 0.9987,\n",
       "                      1.0047, 0.9897, 0.9943, 0.9870, 0.9949, 0.9965, 1.0067, 0.9826, 1.0161,\n",
       "                      0.9911, 1.0242, 1.0116, 0.9915, 0.9902, 1.0037, 0.9957, 1.0015, 0.9845,\n",
       "                      1.0134, 0.9951, 0.9880, 0.9889, 1.0154, 0.9923, 0.9896, 0.9780, 0.9980,\n",
       "                      0.9837, 0.9904, 1.0132, 0.9889, 1.0222, 0.9830, 0.9876, 1.0158, 1.0138,\n",
       "                      0.9946, 1.0220, 0.9965, 1.0165, 1.0050, 0.9895, 0.9862, 1.0102, 1.0038,\n",
       "                      1.0029, 0.9906, 0.9874, 0.9870, 0.9899, 0.9766, 0.9901, 0.9952, 0.9908,\n",
       "                      1.0025, 0.9947, 0.9897, 0.9959, 0.9926, 1.0065, 0.9945, 0.9912, 1.0218,\n",
       "                      0.9934, 0.9957, 0.9974, 0.9957, 1.0111, 0.9962, 1.0141, 0.9892, 1.0073,\n",
       "                      1.0160, 0.9887, 0.9959, 1.0098, 0.9880, 0.9963, 1.0198, 0.9963, 0.9935,\n",
       "                      0.9854, 1.0024, 0.9970, 0.9979, 0.9985, 0.9950, 1.0182, 0.9930, 0.9961,\n",
       "                      0.9872, 0.9983, 1.0222, 1.0031, 0.9960, 1.0151, 1.0199, 0.9905, 0.9921,\n",
       "                      1.0134, 0.9930, 0.9937, 0.9907, 0.9923, 0.9932, 0.9884, 0.9971, 0.9875,\n",
       "                      1.0099, 1.0119, 0.9800, 1.0260, 1.0063, 0.9986, 0.9797, 1.0192, 0.9931,\n",
       "                      0.9901, 0.9887, 1.0025, 1.0259, 0.9969, 0.9965, 0.9936, 1.0160, 1.0003,\n",
       "                      1.0035, 1.0223, 0.9978, 1.0140, 0.9851, 0.9943, 0.9924, 0.9969, 0.9980,\n",
       "                      0.9866, 0.9952, 1.0000, 1.0111, 0.9999, 1.0089, 0.9856, 1.0199])),\n",
       "             ('decoders.5.bn3.bias',\n",
       "              tensor([-4.9351e-03, -1.0585e-02,  1.9452e-02, -6.0874e-03, -7.2928e-03,\n",
       "                      -7.8147e-03, -2.1239e-03,  1.4701e-02, -1.4035e-02,  4.2094e-03,\n",
       "                      -6.3642e-03, -1.3018e-02, -1.0568e-02,  3.6697e-02, -5.8940e-03,\n",
       "                       6.1561e-03, -5.8276e-03, -5.9228e-03,  1.7864e-02, -5.1960e-03,\n",
       "                       1.9313e-02,  6.2918e-03,  4.1155e-03,  2.6008e-02,  3.5150e-02,\n",
       "                      -6.6603e-03, -1.5007e-03,  3.4786e-03,  1.2625e-02,  9.2754e-03,\n",
       "                       6.5670e-03, -1.7769e-02,  1.5364e-02, -1.3137e-02,  1.2388e-02,\n",
       "                      -8.1988e-03, -2.7783e-03,  1.9125e-02,  2.7168e-03,  6.4227e-03,\n",
       "                      -8.1254e-03, -6.4110e-03,  2.0605e-04, -1.4178e-02, -9.5744e-03,\n",
       "                      -1.7961e-02,  1.1854e-02, -1.3073e-02, -5.8405e-03, -1.0529e-02,\n",
       "                      -1.1132e-02,  1.9476e-02, -5.8535e-03,  1.2449e-02, -1.4598e-02,\n",
       "                       1.4259e-02, -4.4504e-03, -1.0592e-03, -7.9458e-03,  2.0408e-02,\n",
       "                      -1.2500e-02, -1.7968e-03, -8.1518e-03, -2.0811e-02, -8.6155e-03,\n",
       "                      -1.4114e-02, -1.7849e-02, -1.2965e-03, -4.1088e-03,  3.3453e-02,\n",
       "                       5.3811e-05,  7.8497e-03, -5.9454e-03,  1.5754e-02, -1.6115e-02,\n",
       "                      -7.7580e-03,  5.6713e-03,  7.8580e-03, -2.2103e-03,  3.8003e-03,\n",
       "                       8.7799e-03,  7.0815e-03, -8.4457e-03, -8.6079e-04, -1.4583e-02,\n",
       "                       1.8067e-03, -9.8733e-03, -9.9569e-03, -1.3495e-02,  8.2873e-03,\n",
       "                       3.7191e-03, -4.9044e-03, -8.1903e-03, -7.7218e-03, -8.5553e-03,\n",
       "                       5.5222e-03, -1.0342e-02,  2.2733e-02, -1.2952e-02, -8.0250e-03,\n",
       "                      -1.3528e-02, -6.8802e-03,  4.0629e-03, -1.3167e-03, -9.1742e-03,\n",
       "                      -1.6080e-02, -2.1013e-03,  2.3662e-03, -1.6778e-02,  1.9999e-02,\n",
       "                      -4.1241e-03, -2.4582e-03, -1.8743e-02,  1.8386e-02, -5.4659e-03,\n",
       "                      -1.1783e-02, -2.3474e-02, -1.3769e-02,  2.8423e-02,  6.1824e-03,\n",
       "                       5.9611e-03,  8.1533e-03,  4.9915e-04, -1.2583e-02,  3.4876e-05,\n",
       "                      -9.3495e-04,  2.1757e-03, -6.3510e-03, -9.0950e-03,  1.7240e-02,\n",
       "                       1.0028e-03,  1.9654e-03, -2.1261e-02, -5.8355e-03, -8.2265e-03,\n",
       "                      -6.5424e-03,  4.3130e-03,  3.2044e-03, -2.9347e-03,  8.6147e-03,\n",
       "                       1.6736e-03, -8.7220e-03, -1.1617e-02,  2.2236e-02,  2.1345e-03,\n",
       "                      -1.8260e-02,  3.6413e-03,  1.9978e-02, -1.0688e-02, -1.5309e-02,\n",
       "                      -1.8542e-02, -1.0362e-02, -1.0389e-02, -1.6570e-02,  6.4423e-03,\n",
       "                       1.1257e-02, -9.1319e-03,  2.6456e-02,  4.6529e-03, -8.1649e-03,\n",
       "                      -6.3718e-03, -9.5070e-03,  1.1946e-02, -9.2971e-03,  7.9232e-03,\n",
       "                       1.3973e-02,  2.2055e-05, -1.4854e-03,  1.3498e-02,  1.9036e-02,\n",
       "                      -8.6897e-03,  7.6394e-04, -2.2103e-03,  1.2356e-02, -8.7980e-03,\n",
       "                       1.7007e-03,  5.6595e-03, -2.4086e-02, -8.4154e-03, -2.0945e-02,\n",
       "                      -1.0913e-03,  2.7048e-03,  1.5012e-02, -1.1889e-02, -1.3335e-02,\n",
       "                       3.5392e-03,  6.1738e-03, -1.1434e-02,  1.5513e-02,  4.8329e-03,\n",
       "                       5.5991e-03, -2.9044e-03, -7.3242e-04,  3.1165e-02, -7.5661e-03,\n",
       "                      -1.3928e-02, -1.6563e-02, -5.7094e-03,  2.6132e-02, -2.3881e-02,\n",
       "                      -1.1290e-02,  1.0587e-02,  4.1434e-03,  5.7809e-04, -1.3469e-02,\n",
       "                      -9.9473e-03, -4.4632e-03, -1.0166e-02, -9.7045e-03, -9.1809e-03,\n",
       "                       1.1553e-02,  2.9150e-03, -7.1979e-03,  3.9618e-02, -3.7854e-03,\n",
       "                      -2.0520e-02, -1.6624e-03,  6.3955e-03, -9.2737e-03, -7.9241e-03,\n",
       "                      -4.4859e-03,  7.1322e-03, -5.0359e-03, -4.1293e-03,  3.0870e-02,\n",
       "                      -1.4680e-04,  1.7786e-02,  1.1349e-02,  5.1402e-03, -6.3616e-03,\n",
       "                      -3.7716e-03, -3.6127e-03,  1.5718e-02, -1.9657e-03,  7.5959e-04,\n",
       "                      -9.4085e-03, -5.7210e-04,  1.2274e-03,  1.7722e-02, -2.5355e-03,\n",
       "                       2.4570e-02, -3.5952e-03,  3.8877e-03, -1.7420e-02,  8.1555e-04,\n",
       "                       1.1095e-02, -3.2991e-03,  2.9026e-02,  3.6655e-03, -8.7474e-03,\n",
       "                      -8.2894e-03,  1.4612e-03,  1.2820e-02, -1.4630e-02,  1.6922e-02,\n",
       "                      -6.5416e-03, -7.2854e-03, -1.0158e-02,  1.1701e-02, -1.0419e-03,\n",
       "                      -5.8984e-03, -3.4636e-03, -1.3711e-02, -1.6420e-03,  8.9527e-03,\n",
       "                       2.1443e-02,  1.7941e-02, -6.9366e-03,  4.9396e-03, -3.8294e-03,\n",
       "                       3.1849e-03, -6.1071e-03,  1.2413e-02,  1.0748e-02,  2.9951e-02,\n",
       "                      -1.4888e-02, -1.9325e-02,  9.6624e-03,  5.3171e-03,  5.6648e-03,\n",
       "                       1.8170e-02,  1.0822e-02, -1.2798e-02,  1.0796e-03,  7.1823e-03,\n",
       "                       1.9889e-02,  3.1584e-03,  2.5668e-02,  4.9426e-03, -1.0422e-03,\n",
       "                       2.8756e-02,  1.1505e-02, -3.7300e-03, -1.4625e-02, -5.3437e-03,\n",
       "                      -2.1906e-02, -1.0409e-02, -2.3317e-03,  2.2050e-02, -1.8736e-02,\n",
       "                      -2.1686e-02, -1.7830e-02, -1.1675e-02, -1.6403e-02,  2.3761e-02,\n",
       "                      -9.0855e-03,  1.0358e-03, -5.9162e-03,  2.2290e-02,  1.4631e-02,\n",
       "                      -1.3156e-02,  8.2855e-03, -7.7629e-03,  2.1838e-03,  2.5874e-03,\n",
       "                      -1.2252e-02,  1.8112e-02, -1.5552e-02,  2.5642e-03,  1.4178e-02,\n",
       "                       2.5384e-03, -6.7112e-03, -8.4907e-03, -1.2082e-02,  1.1468e-02,\n",
       "                      -1.0671e-02, -1.2155e-02, -1.2398e-02,  1.0652e-02,  2.7191e-03,\n",
       "                      -1.0112e-02, -9.3664e-03, -8.2183e-03, -1.0612e-02, -5.8562e-04,\n",
       "                      -6.8340e-03, -1.3318e-02, -1.7117e-02,  2.1445e-02, -1.1949e-02,\n",
       "                       3.2833e-03,  2.2881e-03, -7.1740e-03, -2.1153e-02,  1.3562e-02,\n",
       "                      -1.2798e-02, -4.2422e-03,  2.7220e-03,  8.1155e-03,  5.2049e-03,\n",
       "                      -3.6526e-03,  9.8582e-03, -3.9992e-03,  2.9454e-02, -3.3132e-03,\n",
       "                       8.5936e-04,  7.5658e-03,  3.8529e-02, -5.0134e-03, -1.0490e-02,\n",
       "                      -4.8040e-03,  2.2925e-02, -1.4529e-02, -2.7924e-03, -1.2343e-02,\n",
       "                       7.7404e-03, -1.5693e-02, -3.2910e-03, -4.3496e-03, -1.8870e-03,\n",
       "                       6.9422e-03,  9.2457e-03, -6.7832e-03,  1.9831e-02, -4.9044e-03,\n",
       "                       2.3815e-03, -2.3725e-02, -1.0372e-02, -9.2347e-03, -4.4493e-03,\n",
       "                      -1.2633e-02, -5.9003e-03,  1.1462e-02, -6.4415e-03,  8.0096e-03,\n",
       "                      -2.9623e-03, -1.2085e-02, -1.0133e-02,  1.1077e-02, -3.3450e-03,\n",
       "                       5.8446e-03, -1.3658e-02,  2.0428e-02, -1.2028e-02, -6.1376e-03,\n",
       "                       1.7631e-02, -9.1314e-03, -1.3080e-02,  3.3549e-02, -7.4808e-03,\n",
       "                       3.2030e-03, -1.0449e-02, -7.3171e-03, -1.0224e-02, -9.0115e-03,\n",
       "                      -8.3864e-03, -7.3759e-03,  2.1929e-02, -3.3549e-03, -1.5136e-02,\n",
       "                      -7.0245e-03,  9.2100e-04, -1.2055e-02, -9.3523e-03, -1.9102e-03,\n",
       "                       1.2034e-02, -1.7526e-02,  2.3452e-03, -6.0065e-03, -1.7734e-02,\n",
       "                       1.6248e-02, -6.4657e-03, -8.5445e-03,  5.3232e-03, -4.3490e-03,\n",
       "                      -3.1446e-03,  3.2853e-03, -8.9412e-03, -9.2900e-03, -2.0291e-02,\n",
       "                       6.1418e-03, -8.9314e-03, -8.2963e-03,  9.0182e-03,  6.8404e-03,\n",
       "                       1.1447e-02,  2.9326e-02, -3.1101e-03, -9.4860e-03,  9.8845e-03,\n",
       "                      -9.3334e-03, -1.3693e-02,  1.1540e-02,  3.8096e-03, -1.5482e-02,\n",
       "                      -2.9873e-03,  1.5866e-03, -9.5255e-03,  1.9139e-02,  1.7173e-02,\n",
       "                      -8.2443e-03,  3.2926e-02,  1.7670e-02, -3.6727e-04,  2.6080e-02,\n",
       "                      -9.8420e-03, -2.0105e-03, -9.2013e-03, -5.6437e-04, -1.2384e-02,\n",
       "                      -4.9893e-03, -1.0237e-02,  2.7594e-03, -3.2666e-03, -1.5250e-02,\n",
       "                      -1.3809e-02,  1.6954e-02, -6.6260e-03, -5.3552e-03,  1.2184e-02,\n",
       "                       1.0694e-02,  1.1246e-02, -2.1349e-03,  8.6417e-03, -1.1762e-02,\n",
       "                      -2.9667e-03, -1.3927e-02, -1.4347e-02, -1.4327e-02,  1.1959e-02,\n",
       "                      -1.9107e-02, -2.5218e-03, -8.0843e-03, -2.4596e-02, -8.7176e-03,\n",
       "                      -9.7868e-04,  1.5311e-02, -1.0318e-02, -1.8849e-02,  1.7137e-03,\n",
       "                       8.3412e-03, -1.9871e-03,  5.1356e-03, -6.3466e-03,  1.0835e-02,\n",
       "                       2.9649e-02, -1.3608e-03,  6.2000e-03, -5.5660e-03, -1.1746e-02,\n",
       "                      -5.1732e-03,  9.9809e-03, -9.1734e-03,  2.9907e-02, -2.7314e-04,\n",
       "                      -2.0198e-03,  1.6429e-02, -1.1189e-02, -5.0021e-03,  2.3721e-02,\n",
       "                       3.0595e-03, -2.4742e-03])),\n",
       "             ('decoders.5.bn3.running_mean',\n",
       "              tensor([ 4.8300e-01,  3.1502e-01, -2.3490e-01, -4.1286e-01,  2.5943e-01,\n",
       "                       1.5540e-01,  4.6337e-02,  3.0853e-01,  1.6538e-01, -1.5295e-01,\n",
       "                       2.7786e-01,  2.9253e-01,  3.6708e-01, -1.7885e-01,  1.4821e-02,\n",
       "                      -3.9253e-01,  3.1180e-01, -5.3285e-02, -1.5113e-01, -4.2749e-01,\n",
       "                      -3.0194e-01, -5.6010e-01,  3.2012e-01, -1.9732e-01, -2.7022e-01,\n",
       "                       1.2778e-01,  6.8438e-01, -2.4426e-01, -2.9181e-01, -3.4623e-01,\n",
       "                      -1.1765e-01, -1.5168e-01, -1.7987e-01, -6.9651e-02, -2.0727e-01,\n",
       "                       8.0189e-02,  4.3403e-01, -1.8608e-01, -1.7908e-01, -2.3815e-01,\n",
       "                      -3.2501e-02, -3.1576e-02,  1.6941e-01,  2.7362e-01, -8.2445e-02,\n",
       "                       4.1044e-01, -1.9211e-01,  6.0317e-01,  1.4742e-01, -1.3741e-01,\n",
       "                       4.4336e-01, -2.1572e-01,  4.6068e-01, -2.2383e-02,  3.8369e-01,\n",
       "                      -1.0118e-01,  3.5760e-01, -1.5003e-01, -3.4512e-01, -1.7880e-01,\n",
       "                       1.4987e-01, -1.1871e-01, -4.6356e-02,  6.8168e-01,  1.8237e-01,\n",
       "                       4.5957e-01,  3.4271e-02, -4.2538e-02, -4.3642e-02, -2.9074e-01,\n",
       "                       1.5870e-01,  3.4720e-03, -2.2544e-01, -2.3121e-01,  1.0692e-01,\n",
       "                       4.4461e-01, -1.2674e-01,  3.3784e-01,  6.5526e-02, -4.0861e-01,\n",
       "                      -4.1753e-02, -2.8330e-01,  4.8545e-01,  5.5302e-02,  3.4317e-01,\n",
       "                      -7.2672e-03,  4.1400e-03,  3.4392e-01,  3.7179e-01, -3.1578e-01,\n",
       "                       2.0188e-01, -2.6923e-02,  2.6953e-01,  1.6702e-01, -3.4902e-02,\n",
       "                       2.9966e-01,  9.4992e-02, -2.3752e-01,  1.1326e-01,  7.2224e-02,\n",
       "                       4.6708e-01,  8.8736e-02, -2.7485e-01,  4.2071e-01,  3.8266e-01,\n",
       "                       4.9211e-01,  2.0106e-01,  1.5397e-02,  1.2253e-01, -8.4101e-02,\n",
       "                       2.5479e-02,  2.2005e-01,  9.5730e-02, -2.3970e-01, -3.2180e-01,\n",
       "                       1.2252e-01,  1.6300e-01,  4.3224e-01, -3.0569e-01, -1.5055e-01,\n",
       "                       2.1781e-01, -2.0605e-01, -2.5771e-02,  4.7158e-01,  1.4858e-02,\n",
       "                       1.1681e-01, -1.0217e-02,  3.7049e-01,  3.2078e-01, -3.8014e-01,\n",
       "                       2.8955e-02, -8.4616e-02, -3.2079e-01,  6.4995e-01, -8.7655e-02,\n",
       "                       6.1040e-01, -1.9950e-01, -4.4422e-01, -3.3390e-01, -1.4327e-01,\n",
       "                       6.3640e-01,  1.9243e-01,  3.6220e-01, -2.2825e-01, -1.4628e-01,\n",
       "                       5.1496e-01, -5.1833e-02, -1.1631e-01,  3.0480e-01,  3.0394e-01,\n",
       "                       4.5126e-01,  3.1269e-01,  2.6578e-01,  4.2908e-01,  2.2244e-01,\n",
       "                      -1.4306e-01, -1.1412e-01, -2.1772e-01, -2.9296e-01,  2.6459e-01,\n",
       "                       2.0374e-01,  8.7040e-02, -1.8849e-01,  1.7227e-01, -3.2327e-01,\n",
       "                       3.8713e-02,  7.5855e-02, -2.8882e-01, -2.7174e-01,  3.9384e-02,\n",
       "                       1.7461e-01, -1.4695e-01,  5.0770e-01, -4.4014e-01,  1.3440e-01,\n",
       "                       9.5442e-02, -2.5890e-01,  1.1849e-02,  2.3611e-01,  4.8474e-01,\n",
       "                      -2.1566e-01,  4.7708e-01, -1.7039e-01,  2.2819e-01,  6.0404e-01,\n",
       "                       5.0065e-01,  2.6590e-01,  6.3082e-01, -4.3153e-01,  1.4622e-01,\n",
       "                      -2.0157e-01,  1.2319e-01, -7.7195e-02, -2.0380e-01,  2.8402e-01,\n",
       "                       4.5157e-02,  4.0961e-01, -2.9056e-01,  2.4982e-01,  2.4526e-01,\n",
       "                       3.3298e-01, -5.7247e-01,  1.4267e-01, -3.7081e-01,  2.4951e-01,\n",
       "                       1.3724e-01,  5.6350e-02, -2.3574e-01,  4.0373e-01,  3.8480e-01,\n",
       "                      -2.9580e-01, -9.2668e-02,  2.8372e-01, -1.6766e-01,  3.5804e-01,\n",
       "                       4.4967e-01,  2.8012e-01, -8.7822e-02,  3.9093e-01,  5.8023e-01,\n",
       "                       2.6292e-01, -4.0532e-01,  4.1599e-01,  3.0521e-02, -4.3541e-01,\n",
       "                      -3.4935e-01, -1.1718e-01, -3.6732e-01,  2.7246e-01,  4.2593e-02,\n",
       "                       3.7359e-01,  3.0269e-01, -4.0439e-01,  3.0892e-01, -5.0472e-01,\n",
       "                      -3.3280e-04, -3.4637e-01,  1.8915e-01,  2.3817e-03,  2.2760e-01,\n",
       "                       6.5687e-02,  4.7504e-01, -1.4697e-01,  9.8738e-02, -6.7902e-02,\n",
       "                      -2.6360e-01, -2.0248e-01, -8.3914e-02,  5.4824e-01,  1.5206e-01,\n",
       "                      -2.3681e-01, -1.2976e-01, -3.7407e-01,  4.1656e-01, -4.6619e-01,\n",
       "                      -2.7058e-01,  2.2656e-01, -2.9493e-01, -2.9630e-01, -2.7851e-01,\n",
       "                       2.8897e-01,  5.9128e-01,  3.3935e-01,  1.7620e-01,  1.5963e-01,\n",
       "                      -3.5027e-01, -1.4695e-01, -1.2391e-01, -4.3398e-01, -8.5641e-02,\n",
       "                      -3.0122e-01, -1.4413e-01, -5.7072e-02, -3.7911e-01, -2.5549e-01,\n",
       "                       4.2332e-01,  8.1933e-02, -1.5071e-01, -1.9420e-01, -1.0973e-01,\n",
       "                      -4.5878e-01, -3.0310e-02,  2.4688e-01, -1.0476e-01, -1.0622e-01,\n",
       "                      -3.3095e-01, -2.2524e-01, -1.6120e-01, -5.4161e-01, -3.1076e-01,\n",
       "                       1.7853e-01, -2.1089e-01,  3.1448e-01,  1.2261e-01, -2.5708e-01,\n",
       "                      -3.0969e-01,  2.5413e-01,  3.2019e-01,  2.1408e-02,  5.9511e-01,\n",
       "                       4.5069e-01,  2.9410e-01, -7.4241e-03,  4.7420e-01, -3.4947e-01,\n",
       "                      -1.4729e-01,  1.8249e-01,  1.5393e-01, -1.7790e-01, -4.4045e-01,\n",
       "                       4.6198e-01,  7.4265e-02,  3.3600e-01,  2.1652e-01,  5.5194e-01,\n",
       "                       4.6793e-01, -1.4425e-02, -4.9041e-01, -3.6293e-02, -1.8983e-01,\n",
       "                      -9.3739e-03,  3.1038e-01,  8.6272e-02,  2.4303e-02, -4.0160e-01,\n",
       "                       4.8388e-01,  2.6850e-01, -4.4401e-01, -1.1016e-01,  1.1122e-01,\n",
       "                       2.6278e-01, -2.8362e-01,  4.3912e-02,  2.6142e-01, -2.0374e-01,\n",
       "                       4.7974e-01,  2.4709e-03,  3.6645e-01, -3.5750e-01,  5.8706e-01,\n",
       "                       6.1115e-02, -2.4229e-01, -1.4393e-01, -4.5708e-01, -2.5385e-01,\n",
       "                       1.8030e-01,  6.0678e-01, -1.2178e-01, -2.0852e-01, -8.7906e-02,\n",
       "                      -2.5566e-01, -1.3003e-01, -1.5356e-01, -2.2342e-01,  1.5956e-01,\n",
       "                      -1.4185e-02,  8.4472e-02, -2.1279e-01,  2.3759e-01, -2.1064e-01,\n",
       "                      -1.9347e-01, -7.9491e-02,  3.9900e-01, -4.3226e-01, -3.5633e-01,\n",
       "                      -2.0021e-01, -8.8792e-02,  3.0310e-01, -8.4792e-02,  5.2479e-01,\n",
       "                       8.1396e-02, -4.4736e-01,  1.9329e-02, -3.6115e-01,  2.3491e-01,\n",
       "                       4.0254e-01,  1.7889e-01,  3.2030e-01, -5.5072e-02,  3.8724e-01,\n",
       "                       3.1635e-01,  2.3927e-01, -2.3504e-01,  4.2323e-01,  2.4200e-01,\n",
       "                       3.0898e-01,  2.7952e-01,  1.1553e-01, -2.4877e-01, -2.8655e-01,\n",
       "                      -1.5798e-01,  4.6003e-01, -4.3491e-01,  2.8066e-02, -4.3701e-01,\n",
       "                      -3.5009e-01, -3.0157e-01,  2.1265e-01, -1.7539e-01,  7.9126e-02,\n",
       "                       5.7753e-01,  9.4322e-03,  1.8314e-01,  2.3408e-01, -1.4890e-02,\n",
       "                      -3.5712e-02,  2.9637e-01, -3.7603e-01,  3.0999e-01,  4.7063e-01,\n",
       "                       1.1829e-01,  8.4529e-02,  3.5944e-01,  7.6053e-02, -9.0909e-02,\n",
       "                      -2.1020e-01, -3.5607e-02, -2.8234e-01,  1.2105e-01, -4.0461e-01,\n",
       "                      -5.1326e-01,  1.3814e-01,  3.5462e-02, -1.7737e-01, -1.9161e-01,\n",
       "                       3.7480e-02, -1.0001e-01,  8.8701e-02,  3.2281e-01,  2.8707e-01,\n",
       "                      -3.8526e-01,  4.9840e-01,  2.2281e-02, -2.7794e-01, -2.7530e-01,\n",
       "                      -2.7381e-01, -1.9773e-01, -5.7910e-02,  2.0908e-01, -1.4898e-01,\n",
       "                       3.1143e-01,  3.3058e-01, -2.5819e-01,  1.8925e-01,  2.3142e-01,\n",
       "                       1.2339e-01,  1.0222e-01,  4.4222e-01, -3.8214e-01, -5.6025e-01,\n",
       "                       1.4588e-01, -3.9294e-01,  2.3861e-01, -1.2545e-01, -3.3203e-01,\n",
       "                       2.3176e-01,  3.1128e-01,  6.5002e-01,  2.5508e-01, -5.9162e-03,\n",
       "                       4.0193e-01,  3.7780e-01, -1.7883e-01, -4.7674e-02,  8.1999e-01,\n",
       "                       5.0363e-01, -3.2608e-01, -1.2638e-01,  8.1659e-01, -3.1908e-01,\n",
       "                      -4.2323e-01, -3.7464e-01, -9.6624e-03, -2.4977e-02,  2.8193e-01,\n",
       "                       5.6263e-02, -8.9361e-02,  5.3853e-01,  6.4898e-02, -3.9814e-01,\n",
       "                       4.9304e-01,  1.7522e-01,  3.7772e-02,  2.0788e-01,  9.2383e-02,\n",
       "                      -9.1432e-02, -1.3596e-01, -1.8882e-02,  3.8493e-01,  3.3529e-01,\n",
       "                       1.4446e-01, -1.2526e-01, -4.3966e-01,  5.3022e-01, -1.4772e-01,\n",
       "                      -2.4135e-01,  4.8098e-01, -1.1252e-01,  3.3196e-01,  1.6675e-01,\n",
       "                      -1.6672e-01, -2.5651e-01, -7.2544e-02, -1.9905e-01,  1.7542e-02,\n",
       "                      -2.6421e-01,  5.8455e-02,  3.0495e-01, -2.2917e-01, -1.7479e-01,\n",
       "                      -2.7783e-01,  3.5442e-01])),\n",
       "             ('decoders.5.bn3.running_var',\n",
       "              tensor([2.1779, 1.2892, 0.8349, 0.2054, 1.9022, 1.7907, 1.0662, 0.8378, 1.0287,\n",
       "                      0.8035, 1.3313, 1.3373, 0.7722, 0.6216, 0.7090, 0.4903, 1.1229, 0.9672,\n",
       "                      0.6048, 1.0101, 1.1232, 0.4515, 1.0514, 0.8340, 0.8659, 1.6589, 0.4742,\n",
       "                      0.1683, 0.5552, 0.2414, 0.1175, 0.1437, 0.6762, 0.1445, 1.9106, 1.0970,\n",
       "                      0.4282, 1.1898, 0.2650, 0.8130, 0.4230, 0.4378, 0.2374, 1.0883, 0.4167,\n",
       "                      1.0679, 0.6914, 1.1150, 0.8513, 0.4891, 0.9771, 0.8554, 1.7060, 0.5009,\n",
       "                      0.7860, 0.5796, 0.9504, 0.7284, 0.6653, 0.8859, 0.9201, 0.9826, 0.3558,\n",
       "                      0.6986, 0.4277, 1.4805, 0.2797, 0.2736, 0.2480, 1.0547, 1.2594, 0.8508,\n",
       "                      0.4607, 0.5833, 0.2062, 1.2454, 0.2595, 0.7928, 0.4687, 0.5471, 0.3726,\n",
       "                      0.4529, 1.2881, 0.7388, 1.3343, 0.6211, 0.6494, 0.3545, 1.2401, 0.4693,\n",
       "                      0.3112, 0.4231, 1.2402, 0.5621, 0.7464, 0.5844, 2.2055, 0.5607, 0.9865,\n",
       "                      0.6146, 1.5775, 0.7495, 0.4043, 2.3907, 1.0266, 0.9185, 0.7614, 0.4083,\n",
       "                      0.9813, 1.1517, 1.4908, 0.6619, 0.2581, 0.7875, 0.4687, 0.4812, 0.7415,\n",
       "                      1.2134, 1.0601, 1.0501, 1.0012, 0.5949, 0.9870, 0.8661, 0.3916, 1.1219,\n",
       "                      0.4595, 1.0371, 1.0013, 0.3232, 0.9525, 0.4592, 0.8130, 1.2548, 0.8761,\n",
       "                      2.6353, 0.5871, 0.2442, 0.4125, 0.8815, 0.8265, 1.0044, 0.8350, 0.6180,\n",
       "                      0.4945, 0.6792, 0.5104, 0.3234, 1.3608, 1.2367, 1.0245, 1.5535, 0.7962,\n",
       "                      1.5250, 1.0053, 0.4230, 0.5063, 0.8732, 0.4743, 1.7685, 0.4174, 1.3836,\n",
       "                      0.1793, 0.5637, 0.3420, 0.5604, 1.1034, 0.2869, 0.5713, 0.7149, 0.9437,\n",
       "                      0.5720, 1.9694, 0.4823, 1.0729, 0.9150, 1.3223, 0.1777, 1.2140, 0.9582,\n",
       "                      0.7888, 0.9048, 0.9782, 0.6540, 1.7354, 2.0439, 0.7406, 1.7877, 0.4425,\n",
       "                      0.5104, 0.3917, 0.7932, 0.3663, 0.7610, 1.3415, 0.5909, 1.7006, 0.1910,\n",
       "                      0.9133, 0.9204, 2.1463, 0.5481, 0.2958, 0.5716, 0.8582, 0.6149, 0.3257,\n",
       "                      0.6117, 1.0842, 1.2068, 1.0529, 0.3185, 1.8249, 1.0959, 1.6836, 1.2929,\n",
       "                      0.9528, 1.2091, 0.6502, 1.2738, 0.9166, 0.5524, 2.9521, 1.0925, 0.7728,\n",
       "                      0.3306, 1.4565, 0.5256, 0.9741, 0.3935, 1.8650, 2.1557, 0.4948, 0.6880,\n",
       "                      0.2176, 0.6304, 0.6198, 0.5601, 1.1848, 2.1130, 0.9475, 1.6468, 0.7641,\n",
       "                      0.2875, 0.8089, 0.3453, 0.1307, 0.7109, 1.1892, 0.8288, 0.8311, 0.1974,\n",
       "                      0.7126, 0.8577, 0.7165, 0.3222, 0.8113, 0.5185, 0.6682, 1.7532, 1.7505,\n",
       "                      1.2441, 0.6844, 0.7863, 0.3942, 0.6071, 0.3119, 0.6872, 0.5049, 0.2887,\n",
       "                      0.7388, 0.2689, 0.3725, 0.6550, 1.0550, 0.9552, 0.7907, 0.2924, 0.4101,\n",
       "                      0.5654, 0.9262, 0.6127, 1.2921, 0.5593, 0.8190, 0.4451, 0.4108, 1.1198,\n",
       "                      0.3875, 0.2249, 0.5328, 0.3032, 1.9321, 1.0086, 0.1775, 0.3970, 0.7066,\n",
       "                      1.3790, 0.6897, 0.8582, 0.5913, 0.7856, 0.4096, 0.7956, 1.0489, 0.7190,\n",
       "                      0.2892, 0.2227, 0.7257, 0.6038, 0.9674, 0.7862, 1.0953, 1.2454, 1.7376,\n",
       "                      1.7419, 0.6458, 0.1969, 0.8179, 0.6342, 0.8647, 1.8802, 0.3543, 1.4913,\n",
       "                      0.3126, 1.0073, 1.2572, 0.5427, 0.6138, 1.0564, 1.2283, 0.7689, 0.3957,\n",
       "                      1.2171, 0.1613, 1.2355, 0.3148, 1.0418, 0.6170, 1.0644, 1.1822, 0.5411,\n",
       "                      0.1875, 0.5716, 0.4552, 0.3670, 0.6617, 0.4799, 1.3865, 1.1413, 0.2816,\n",
       "                      0.4315, 0.6876, 0.6453, 1.1539, 0.4148, 0.3202, 0.6362, 0.4722, 0.9651,\n",
       "                      0.9025, 0.8750, 1.1195, 0.6272, 0.3438, 0.8236, 0.3063, 1.6861, 0.9780,\n",
       "                      0.9141, 0.7217, 0.6109, 0.6335, 1.1033, 1.4030, 1.6644, 0.1598, 0.9839,\n",
       "                      0.2160, 1.3856, 1.1404, 0.3198, 0.7477, 1.0598, 0.3937, 0.6950, 0.1935,\n",
       "                      1.1286, 0.8950, 0.4960, 0.6333, 1.0154, 0.7061, 0.4993, 0.6742, 0.5948,\n",
       "                      0.6337, 0.4942, 0.6089, 0.3782, 1.1964, 0.2291, 0.4465, 2.1441, 1.5693,\n",
       "                      1.2237, 0.6345, 0.3925, 1.4309, 1.1439, 0.5567, 0.5743, 1.9887, 1.0108,\n",
       "                      0.4208, 0.4436, 0.6673, 0.5003, 0.5449, 0.3799, 0.6046, 1.0416, 0.2017,\n",
       "                      0.4452, 0.6341, 0.1650, 0.4273, 0.4051, 1.6625, 0.5194, 0.4680, 1.8130,\n",
       "                      0.4781, 0.2045, 0.2872, 0.2759, 0.4607, 0.7248, 1.2848, 0.6564, 1.0599,\n",
       "                      1.5904, 0.8504, 0.6114, 1.0631, 1.1316, 0.3958, 0.8560, 0.7044, 0.3894,\n",
       "                      0.3467, 0.7605, 1.5796, 0.4718, 0.6242, 1.0830, 1.9271, 0.2193, 1.2342,\n",
       "                      0.3334, 1.5619, 1.4704, 0.5669, 0.6468, 2.1155, 1.7585, 0.5422, 0.3067,\n",
       "                      1.9998, 0.4425, 1.6463, 0.5363, 0.8917, 0.6209, 0.2752, 0.8491, 0.6167,\n",
       "                      0.7259, 0.8462, 0.6707, 0.8677, 1.4489, 0.3856, 0.2627, 1.5820, 0.4703,\n",
       "                      0.5519, 0.3156, 0.5828, 1.2202, 1.0161, 0.7721, 1.8435, 2.4184, 0.5958,\n",
       "                      0.5291, 1.7940, 1.2718, 2.2567, 0.2449, 0.3541, 0.2197, 0.4946, 0.8295,\n",
       "                      0.8633, 0.7246, 0.7190, 1.5767, 0.0864, 1.0496, 0.4250, 1.4274])),\n",
       "             ('decoders.5.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense4.weight',\n",
       "              tensor([[-0.0311, -0.0214,  0.0205,  ...,  0.0236,  0.0238, -0.0562],\n",
       "                      [ 0.0245,  0.0218,  0.0186,  ...,  0.0240,  0.0360, -0.0566],\n",
       "                      [-0.0429,  0.0191, -0.0450,  ..., -0.0546,  0.0092, -0.0325],\n",
       "                      ...,\n",
       "                      [-0.0565, -0.0299,  0.0304,  ...,  0.0180,  0.0081, -0.0613],\n",
       "                      [ 0.0010, -0.0174,  0.0030,  ..., -0.0153,  0.0248, -0.0503],\n",
       "                      [ 0.0018,  0.0278, -0.0151,  ..., -0.0436,  0.0378,  0.0158]])),\n",
       "             ('decoders.5.bn4.weight',\n",
       "              tensor([1.0204, 1.0236, 1.0189, 1.0232, 1.0222, 1.0222, 1.0329, 1.0331, 1.0225,\n",
       "                      1.0222, 1.0214, 1.0230, 1.0232, 1.0232, 1.0220, 1.0242, 1.0235, 1.0247,\n",
       "                      1.0254, 1.0231, 1.0274, 1.0232, 1.0330, 1.0222, 1.0235, 1.0228, 1.0214,\n",
       "                      1.0229, 1.0240, 1.0243, 1.0238, 1.0218, 1.0231, 1.0237, 1.0212, 1.0238,\n",
       "                      1.0223, 1.0225, 1.0221, 1.0219, 1.0235, 1.0209, 1.0217, 1.0238, 1.0227,\n",
       "                      1.0357, 1.0229, 1.0214, 1.0229, 1.0226, 1.0199, 1.0232, 1.0219, 1.0353,\n",
       "                      1.0215, 1.0319, 1.0220, 1.0210, 1.0233, 1.0207, 1.0232, 1.0218, 1.0227,\n",
       "                      1.0332, 1.0230, 1.0225, 1.0232, 1.0218, 1.0224, 1.0216, 1.0221, 1.0241,\n",
       "                      1.0230, 1.0223, 1.0201, 1.0232, 1.0330, 1.0239, 1.0232, 1.0225, 1.0230,\n",
       "                      1.0222, 1.0245, 1.0224, 1.0221, 1.0212, 1.0249, 1.0251, 1.0157, 1.0255,\n",
       "                      1.0240, 1.0256, 1.0228, 1.0213, 1.0224, 1.0221, 1.0229, 1.0225, 1.0234,\n",
       "                      1.0367, 1.0237, 1.0230, 1.0347, 1.0245, 1.0238, 1.0260, 1.0222, 1.0357,\n",
       "                      1.0221, 1.0253, 1.0215, 1.0240, 1.0220, 1.0219, 1.0216, 1.0239, 1.0268,\n",
       "                      1.0228, 1.0234, 1.0225, 1.0230, 1.0219, 1.0216, 1.0235, 1.0243, 1.0222,\n",
       "                      1.0229, 1.0155, 1.0243, 1.0230, 1.0370, 1.0222, 1.0252, 1.0220, 1.0239,\n",
       "                      1.0250, 1.0270, 1.0232, 1.0241, 1.0337, 1.0227, 1.0244, 1.0225, 1.0371,\n",
       "                      1.0231, 1.0248, 1.0349, 1.0307, 1.0227, 1.0372, 1.0217, 1.0224, 1.0250,\n",
       "                      1.0205, 1.0346, 1.0364, 1.0201, 1.0263, 1.0328, 1.0239, 1.0230, 1.0212,\n",
       "                      1.0228, 1.0229, 1.0224, 1.0225, 1.0330, 1.0311, 1.0249, 1.0315, 1.0237,\n",
       "                      1.0225, 1.0220, 1.0218, 1.0198, 1.0228, 1.0215, 1.0227, 1.0227, 1.0234,\n",
       "                      1.0244, 1.0237, 1.0224, 1.0153, 1.0226, 1.0230, 1.0349, 1.0335, 1.0242,\n",
       "                      1.0221, 1.0210, 1.0367, 1.0234, 1.0323, 1.0230, 1.0229, 1.0215, 1.0213,\n",
       "                      1.0248, 1.0238, 1.0233, 1.0239, 1.0232, 1.0218, 1.0220, 1.0317, 1.0230,\n",
       "                      1.0182, 1.0213, 1.0336, 1.0328, 1.0313, 1.0227, 1.0225, 1.0238, 1.0232,\n",
       "                      1.0358, 1.0230, 1.0251, 1.0241, 1.0351, 1.0225, 1.0244, 1.0189, 1.0234,\n",
       "                      1.0239, 1.0241, 1.0231, 1.0245, 1.0223, 1.0227, 1.0231, 1.0251, 1.0233,\n",
       "                      1.0249, 1.0232, 1.0238, 1.0239, 1.0224, 1.0223, 1.0232, 1.0225, 1.0222,\n",
       "                      1.0325, 1.0234, 1.0185, 1.0218, 1.0321, 1.0248, 1.0251, 1.0238, 1.0256,\n",
       "                      1.0230, 1.0214, 1.0218, 1.0221, 1.0227, 1.0182, 1.0207, 1.0326, 1.0207,\n",
       "                      1.0220, 1.0214, 1.0324, 1.0303, 1.0227, 1.0238, 1.0323, 1.0221, 1.0246,\n",
       "                      1.0221, 1.0225, 1.0315, 1.0221, 1.0232, 1.0333, 1.0238, 1.0216, 1.0300,\n",
       "                      1.0242, 1.0286, 1.0248, 1.0368, 1.0230, 1.0233, 1.0195, 1.0224, 1.0216,\n",
       "                      1.0171, 1.0361, 1.0255, 1.0348, 1.0231, 1.0298, 1.0359, 1.0224, 1.0261,\n",
       "                      1.0234, 1.0221, 1.0220, 1.0225, 1.0224, 1.0219, 1.0240, 1.0203, 1.0173,\n",
       "                      1.0265, 1.0366, 1.0230, 1.0227, 1.0240, 1.0228, 1.0230, 1.0231, 1.0171,\n",
       "                      1.0195, 1.0357, 1.0340, 1.0185, 1.0258, 1.0327, 1.0319, 1.0246, 1.0236,\n",
       "                      1.0240, 1.0215, 1.0227, 1.0223, 1.0200, 1.0337, 1.0230, 1.0206, 1.0219,\n",
       "                      1.0227, 1.0220, 1.0248, 1.0228, 1.0254, 1.0230, 1.0215, 1.0205, 1.0220,\n",
       "                      1.0226, 1.0224, 1.0238, 1.0232, 1.0241, 1.0219, 1.0241, 1.0250, 1.0216,\n",
       "                      1.0221, 1.0237, 1.0222, 1.0208, 1.0222, 1.0207, 1.0165, 1.0227, 1.0257,\n",
       "                      1.0231, 1.0221, 1.0318, 1.0225, 1.0341, 1.0225, 1.0228, 1.0189, 1.0236,\n",
       "                      1.0247, 1.0224, 1.0259, 1.0229, 1.0231, 1.0222, 1.0233, 1.0217, 1.0229,\n",
       "                      1.0244, 1.0252, 1.0246, 1.0233, 1.0331, 1.0233, 1.0229, 1.0212, 1.0226,\n",
       "                      1.0349, 1.0307, 1.0224, 1.0233, 1.0252, 1.0232, 1.0214, 1.0235, 1.0228,\n",
       "                      1.0340, 1.0211, 1.0246, 1.0248, 1.0229, 1.0243, 1.0229, 1.0223, 1.0223,\n",
       "                      1.0231, 1.0218, 1.0222, 1.0226, 1.0244, 1.0237, 1.0237, 1.0246, 1.0355,\n",
       "                      1.0237, 1.0225, 1.0227, 1.0231, 1.0231, 1.0323, 1.0218, 1.0242, 1.0219,\n",
       "                      1.0230, 1.0234, 1.0246, 1.0230, 1.0210, 1.0241, 1.0234, 1.0202, 1.0357,\n",
       "                      1.0219, 1.0242, 1.0224, 1.0367, 1.0202, 1.0292, 1.0233, 1.0233, 1.0231,\n",
       "                      1.0343, 1.0171, 1.0348, 1.0201, 1.0229, 1.0211, 1.0228, 1.0226, 1.0240,\n",
       "                      1.0252, 1.0224, 1.0234, 1.0234, 1.0233, 1.0260, 1.0245, 1.0207, 1.0228,\n",
       "                      1.0215, 1.0217, 1.0224, 1.0323, 1.0246, 1.0216, 1.0223, 1.0221, 1.0239,\n",
       "                      1.0228, 1.0229, 1.0218, 1.0190, 1.0226, 1.0228, 1.0209, 1.0175, 1.0349,\n",
       "                      1.0247, 1.0226, 1.0214, 1.0328, 1.0229, 1.0221, 1.0226, 1.0222, 1.0248,\n",
       "                      1.0209, 1.0220, 1.0360, 1.0231, 1.0220, 1.0223, 1.0213, 1.0228, 1.0366,\n",
       "                      1.0229, 1.0218, 1.0237, 1.0339, 1.0238, 1.0222, 1.0215, 1.0333, 1.0308,\n",
       "                      1.0241, 1.0227, 1.0248, 1.0223, 1.0337, 1.0234, 1.0245, 1.0204])),\n",
       "             ('decoders.5.bn4.bias',\n",
       "              tensor([0.0314, 0.0343, 0.0321, 0.0330, 0.0325, 0.0326, 0.0312, 0.0309, 0.0318,\n",
       "                      0.0317, 0.0312, 0.0340, 0.0338, 0.0333, 0.0324, 0.0322, 0.0317, 0.0342,\n",
       "                      0.0350, 0.0334, 0.0352, 0.0330, 0.0308, 0.0322, 0.0321, 0.0318, 0.0327,\n",
       "                      0.0333, 0.0329, 0.0326, 0.0334, 0.0315, 0.0339, 0.0321, 0.0318, 0.0324,\n",
       "                      0.0334, 0.0313, 0.0315, 0.0313, 0.0338, 0.0306, 0.0317, 0.0320, 0.0338,\n",
       "                      0.0339, 0.0332, 0.0331, 0.0316, 0.0321, 0.0329, 0.0319, 0.0313, 0.0315,\n",
       "                      0.0333, 0.0301, 0.0319, 0.0313, 0.0333, 0.0332, 0.0319, 0.0315, 0.0315,\n",
       "                      0.0331, 0.0318, 0.0312, 0.0355, 0.0321, 0.0323, 0.0347, 0.0317, 0.0336,\n",
       "                      0.0347, 0.0311, 0.0322, 0.0336, 0.0315, 0.0323, 0.0338, 0.0332, 0.0324,\n",
       "                      0.0319, 0.0338, 0.0327, 0.0319, 0.0325, 0.0345, 0.0324, 0.0315, 0.0322,\n",
       "                      0.0334, 0.0333, 0.0345, 0.0311, 0.0325, 0.0322, 0.0322, 0.0320, 0.0338,\n",
       "                      0.0321, 0.0320, 0.0314, 0.0340, 0.0344, 0.0329, 0.0342, 0.0329, 0.0336,\n",
       "                      0.0319, 0.0345, 0.0312, 0.0339, 0.0311, 0.0310, 0.0323, 0.0336, 0.0361,\n",
       "                      0.0322, 0.0339, 0.0312, 0.0323, 0.0343, 0.0318, 0.0338, 0.0321, 0.0329,\n",
       "                      0.0339, 0.0309, 0.0322, 0.0330, 0.0318, 0.0329, 0.0346, 0.0340, 0.0334,\n",
       "                      0.0355, 0.0340, 0.0318, 0.0331, 0.0323, 0.0318, 0.0344, 0.0317, 0.0330,\n",
       "                      0.0330, 0.0340, 0.0314, 0.0307, 0.0314, 0.0339, 0.0317, 0.0318, 0.0337,\n",
       "                      0.0340, 0.0333, 0.0320, 0.0307, 0.0332, 0.0312, 0.0327, 0.0321, 0.0307,\n",
       "                      0.0336, 0.0321, 0.0321, 0.0314, 0.0306, 0.0301, 0.0345, 0.0300, 0.0334,\n",
       "                      0.0328, 0.0317, 0.0318, 0.0302, 0.0317, 0.0313, 0.0322, 0.0317, 0.0323,\n",
       "                      0.0322, 0.0316, 0.0319, 0.0313, 0.0325, 0.0333, 0.0332, 0.0327, 0.0319,\n",
       "                      0.0317, 0.0307, 0.0309, 0.0318, 0.0308, 0.0340, 0.0316, 0.0313, 0.0312,\n",
       "                      0.0334, 0.0345, 0.0324, 0.0337, 0.0317, 0.0315, 0.0321, 0.0312, 0.0334,\n",
       "                      0.0328, 0.0341, 0.0320, 0.0311, 0.0299, 0.0316, 0.0340, 0.0331, 0.0322,\n",
       "                      0.0347, 0.0324, 0.0339, 0.0328, 0.0338, 0.0337, 0.0331, 0.0318, 0.0337,\n",
       "                      0.0323, 0.0326, 0.0319, 0.0330, 0.0321, 0.0317, 0.0339, 0.0321, 0.0339,\n",
       "                      0.0330, 0.0323, 0.0311, 0.0318, 0.0311, 0.0316, 0.0318, 0.0337, 0.0325,\n",
       "                      0.0304, 0.0320, 0.0312, 0.0335, 0.0311, 0.0338, 0.0337, 0.0319, 0.0329,\n",
       "                      0.0322, 0.0315, 0.0319, 0.0318, 0.0312, 0.0320, 0.0328, 0.0325, 0.0318,\n",
       "                      0.0322, 0.0314, 0.0330, 0.0303, 0.0320, 0.0325, 0.0310, 0.0307, 0.0341,\n",
       "                      0.0318, 0.0361, 0.0321, 0.0311, 0.0338, 0.0330, 0.0324, 0.0337, 0.0308,\n",
       "                      0.0320, 0.0340, 0.0323, 0.0339, 0.0315, 0.0337, 0.0306, 0.0324, 0.0341,\n",
       "                      0.0314, 0.0319, 0.0345, 0.0322, 0.0343, 0.0314, 0.0334, 0.0326, 0.0352,\n",
       "                      0.0335, 0.0343, 0.0316, 0.0326, 0.0316, 0.0320, 0.0347, 0.0309, 0.0315,\n",
       "                      0.0329, 0.0324, 0.0319, 0.0312, 0.0335, 0.0316, 0.0316, 0.0337, 0.0316,\n",
       "                      0.0319, 0.0323, 0.0306, 0.0325, 0.0346, 0.0319, 0.0302, 0.0341, 0.0317,\n",
       "                      0.0342, 0.0323, 0.0320, 0.0321, 0.0321, 0.0319, 0.0336, 0.0306, 0.0318,\n",
       "                      0.0315, 0.0326, 0.0337, 0.0320, 0.0348, 0.0329, 0.0315, 0.0344, 0.0321,\n",
       "                      0.0336, 0.0316, 0.0326, 0.0326, 0.0352, 0.0324, 0.0321, 0.0342, 0.0314,\n",
       "                      0.0319, 0.0332, 0.0313, 0.0323, 0.0312, 0.0327, 0.0308, 0.0319, 0.0347,\n",
       "                      0.0341, 0.0331, 0.0303, 0.0343, 0.0308, 0.0318, 0.0327, 0.0331, 0.0343,\n",
       "                      0.0324, 0.0320, 0.0328, 0.0330, 0.0337, 0.0324, 0.0317, 0.0312, 0.0342,\n",
       "                      0.0344, 0.0337, 0.0329, 0.0318, 0.0321, 0.0336, 0.0326, 0.0308, 0.0336,\n",
       "                      0.0310, 0.0296, 0.0319, 0.0338, 0.0338, 0.0318, 0.0318, 0.0327, 0.0321,\n",
       "                      0.0312, 0.0314, 0.0324, 0.0340, 0.0333, 0.0344, 0.0327, 0.0309, 0.0315,\n",
       "                      0.0337, 0.0319, 0.0321, 0.0316, 0.0335, 0.0331, 0.0340, 0.0341, 0.0327,\n",
       "                      0.0327, 0.0317, 0.0318, 0.0318, 0.0343, 0.0305, 0.0321, 0.0344, 0.0319,\n",
       "                      0.0315, 0.0321, 0.0326, 0.0317, 0.0309, 0.0325, 0.0322, 0.0323, 0.0315,\n",
       "                      0.0320, 0.0327, 0.0314, 0.0317, 0.0316, 0.0329, 0.0319, 0.0331, 0.0316,\n",
       "                      0.0328, 0.0319, 0.0311, 0.0323, 0.0317, 0.0310, 0.0320, 0.0317, 0.0326,\n",
       "                      0.0352, 0.0318, 0.0325, 0.0311, 0.0321, 0.0336, 0.0321, 0.0342, 0.0325,\n",
       "                      0.0313, 0.0314, 0.0338, 0.0305, 0.0342, 0.0341, 0.0313, 0.0313, 0.0320,\n",
       "                      0.0318, 0.0319, 0.0312, 0.0319, 0.0339, 0.0316, 0.0322, 0.0318, 0.0311,\n",
       "                      0.0321, 0.0324, 0.0322, 0.0316, 0.0319, 0.0320, 0.0316, 0.0320, 0.0330,\n",
       "                      0.0320, 0.0319, 0.0317, 0.0323, 0.0320, 0.0318, 0.0316, 0.0315, 0.0317,\n",
       "                      0.0335, 0.0311, 0.0321, 0.0315, 0.0341, 0.0342, 0.0327, 0.0315, 0.0309,\n",
       "                      0.0336, 0.0317, 0.0330, 0.0317, 0.0313, 0.0319, 0.0331, 0.0320])),\n",
       "             ('decoders.5.bn4.running_mean',\n",
       "              tensor([-0.7681, -0.6304, -0.7212, -0.4715, -0.5909, -0.7722, -0.6142, -0.2659,\n",
       "                      -0.6920, -0.6838, -0.9014, -1.0281, -0.7527, -0.5307, -0.5656, -0.2824,\n",
       "                      -0.8582, -0.6656, -0.5824, -0.6776, -0.2274, -0.6791, -0.3745, -0.6124,\n",
       "                      -0.6994, -1.0624, -0.6758, -0.7601, -0.5637, -0.7747, -0.7796, -0.7106,\n",
       "                      -0.7188, -0.5681, -0.7302, -0.3867, -0.6870, -0.7553, -1.1595, -0.7623,\n",
       "                      -0.7091, -0.7549, -0.3730, -0.3565, -0.7274,  0.1078, -0.7373, -0.6938,\n",
       "                      -0.7559, -1.0821, -1.0626, -0.8000, -0.8925, -0.5289, -1.1323, -0.4871,\n",
       "                      -1.0429, -0.8700, -0.5933, -0.7160, -0.5232, -0.7624, -0.5698, -0.3952,\n",
       "                      -0.6915, -0.8225, -0.8546, -0.7715, -0.9547, -0.8434, -0.7123, -0.6451,\n",
       "                      -1.0923, -0.5721, -0.6380, -0.6369, -0.2095, -0.2921, -0.6871, -0.7991,\n",
       "                      -0.9782, -0.9137, -0.7773, -0.6180, -0.6645, -0.8063, -0.6035, -0.4013,\n",
       "                      -1.1245, -0.2748, -0.9179, -0.5186, -0.7338, -0.6631, -0.7279, -1.0140,\n",
       "                      -0.8300, -0.7002, -0.7673, -0.1898, -0.8189, -0.4553, -0.3960, -0.7234,\n",
       "                      -0.4574, -0.1711, -0.9142, -0.3894, -0.7555, -0.5520, -0.8682, -0.7448,\n",
       "                      -0.7523, -0.7019, -0.8628, -0.6140, -0.5533, -0.6925, -0.4374, -0.4964,\n",
       "                      -0.5249, -0.7217, -0.8719, -0.4531, -0.9756, -0.4923, -0.8523, -1.1119,\n",
       "                      -0.1895, -0.5971, -0.7184, -0.7712, -0.7482, -0.6619, -0.4618, -0.6575,\n",
       "                      -0.5747, -0.6683, -0.7903, -0.5329, -0.8618, -0.7510, -0.7563, -0.5391,\n",
       "                      -0.5943, -0.6891, -0.1175, -0.6181, -0.6855, -0.4609, -0.4652, -0.6040,\n",
       "                      -0.6492, -0.7962, -0.2735, -0.2302, -0.7273, -0.4723, -0.6264, -0.7320,\n",
       "                      -0.9204, -1.0483, -0.7394, -0.8153, -0.8143, -0.2283, -0.2592, -0.6249,\n",
       "                      -0.6457, -0.7834, -0.4945, -0.6046, -0.7195, -0.9537, -1.0816, -0.7281,\n",
       "                      -0.5245, -0.6281, -0.8595, -0.5969, -0.8853, -0.5404, -0.8995, -0.7502,\n",
       "                      -0.7159, -0.8533, -0.3248, -0.2380, -0.6266, -0.5949, -0.8423, -0.6920,\n",
       "                      -0.6974, -0.4781, -0.6611, -0.5348, -0.9555, -0.9093, -0.6502, -0.5354,\n",
       "                      -0.7068, -0.6279, -0.9354, -0.6836, -0.6590, -0.6619, -0.5254, -0.6100,\n",
       "                      -1.0380, -0.7199, -0.3220, -0.6659, -1.0138, -0.7838, -0.6894, -0.8337,\n",
       "                      -0.5098, -0.5559, -0.4743, -0.4723, -0.2288, -0.6269, -0.4436, -0.9703,\n",
       "                      -0.8315, -0.5536, -0.8600, -0.6797, -0.6546, -0.8673, -0.8333, -0.4121,\n",
       "                      -0.1680, -0.5239, -0.6871, -0.7225, -0.7326, -0.4513, -0.9453, -0.8192,\n",
       "                      -0.4919, -0.7625, -0.6909, -0.6100, -0.7453, -0.7733, -0.9552, -0.3266,\n",
       "                      -0.7517, -0.8488, -0.6937, -0.6921, -0.6911, -0.7563, -0.4386, -0.8538,\n",
       "                      -0.6758, -0.3384, -0.6739, -0.2358, -0.8485, -0.6753, -0.7855, -0.5703,\n",
       "                      -0.4179, -1.0232, -0.9237, -0.5190, -1.0720, -0.4188, -0.6308, -0.6421,\n",
       "                      -0.5263, -0.6570, -0.9389, -0.5315, -0.5386, -0.8469, -0.4779, -0.5426,\n",
       "                      -0.2984, -0.2963, -0.2608, -0.8468, -0.7756, -0.9235, -0.7629, -0.7499,\n",
       "                      -1.1027, -0.2876, -0.5938, -0.5966, -0.8493, -0.5376, -0.5413, -0.5993,\n",
       "                      -0.8040, -0.5758, -0.6826, -0.9979, -0.8173, -1.0620, -0.9667, -0.7260,\n",
       "                      -0.7445, -1.1764, -0.7122, -0.4136, -1.0329, -0.8315, -0.8321, -0.8668,\n",
       "                      -0.8978, -0.6513, -0.9369, -0.9249, -0.5586, -0.4167, -0.8764, -0.4817,\n",
       "                      -0.5933, -0.7121, -0.8052, -0.9618, -0.8031, -0.6691, -1.0570, -0.7844,\n",
       "                      -0.8185, -0.4876, -0.6669, -0.8687, -0.6714, -0.9456, -0.7198, -0.5855,\n",
       "                      -0.6892, -0.4984, -0.9852, -0.6047, -0.9339, -0.7572, -0.7749, -0.7764,\n",
       "                      -0.7571, -0.5926, -0.5967, -0.6915, -1.0123, -0.4367, -1.0426, -0.4827,\n",
       "                      -0.5539, -0.9304, -0.6566, -0.8392, -0.8534, -1.0493, -0.6183, -0.3202,\n",
       "                      -0.8430, -1.0107, -0.6565, -0.7294, -0.5389, -0.6849, -0.4431, -0.9283,\n",
       "                      -0.8054, -0.6205, -0.8870, -0.3221, -1.0118, -0.3716, -0.5100, -0.5935,\n",
       "                      -0.6970, -0.7075, -0.4045, -0.2647, -0.3985, -0.8161, -0.4576, -0.7606,\n",
       "                      -0.6814, -0.8908, -0.6903, -0.5725, -0.8007, -0.5338, -0.5753, -0.5010,\n",
       "                      -0.4919, -0.9386, -0.7538, -0.8663, -0.5690, -0.7468, -0.7782, -0.3254,\n",
       "                      -0.6315, -0.7290, -0.3655, -0.5969, -1.0335, -0.7313, -0.8779, -0.6683,\n",
       "                      -0.8158, -0.6673, -0.7499, -0.7612, -0.8851, -0.5936, -0.6841, -0.4751,\n",
       "                      -0.9258, -0.7521, -0.6719, -0.4480, -0.7254, -0.4396, -0.8485, -0.7108,\n",
       "                      -0.9175, -0.5342, -0.7038, -0.9215, -0.7611, -0.8410, -0.5862, -0.2408,\n",
       "                      -0.8280, -0.7676, -0.5883, -0.4163, -0.9113, -0.3701, -0.7887, -0.8805,\n",
       "                      -0.5533, -0.4706, -0.8867, -0.8735, -0.8567, -0.5468, -0.6900, -0.9085,\n",
       "                      -0.8576, -0.5101, -0.6515, -0.7950, -0.7337, -0.5215, -0.4020, -0.5399,\n",
       "                      -0.4890, -0.8499, -0.5877, -0.7779, -0.6577, -0.7588, -0.6651, -0.4725,\n",
       "                      -0.9465, -0.4778, -0.6578, -0.3203, -0.8729, -0.7038, -0.4727, -0.7831,\n",
       "                      -0.6995, -1.0948, -0.8876, -0.9303, -0.3696, -0.3276, -0.9455, -0.7938,\n",
       "                      -0.5164, -0.9601, -0.8863, -0.5813, -0.7613, -0.4910, -0.8944, -0.8688,\n",
       "                      -0.4799, -0.7903, -0.5116, -0.8526, -0.8438, -0.8276, -0.1222, -0.8538,\n",
       "                      -0.9817, -0.5435, -0.3856, -0.8229, -0.3493, -0.6424, -0.6841, -0.3772,\n",
       "                      -0.7514, -0.7057, -0.9126, -0.5698, -0.4112, -0.5295, -0.8142, -0.8058])),\n",
       "             ('decoders.5.bn4.running_var',\n",
       "              tensor([2.4083, 3.2674, 1.2879, 5.5941, 3.0228, 2.3940, 0.6013, 1.0573, 3.5461,\n",
       "                      5.0660, 3.6418, 3.0066, 3.1707, 4.4026, 2.0023, 4.5346, 6.7303, 3.0471,\n",
       "                      3.1807, 2.4093, 3.9049, 3.3960, 1.3395, 2.8882, 4.0967, 5.2742, 2.4787,\n",
       "                      3.4971, 2.5724, 3.7169, 2.1505, 3.8363, 4.2520, 3.8034, 2.4352, 5.2591,\n",
       "                      4.6200, 6.1651, 4.3315, 5.5922, 4.9998, 7.5725, 3.8007, 7.9375, 3.2819,\n",
       "                      0.8505, 4.1156, 2.1917, 4.3359, 2.5731, 1.3454, 4.1174, 3.5639, 1.5051,\n",
       "                      1.7154, 0.7084, 2.7347, 4.5025, 2.7355, 1.3059, 4.8464, 3.7729, 4.6352,\n",
       "                      0.8494, 4.6955, 4.7710, 0.9874, 3.1173, 2.4455, 1.7680, 4.4160, 3.8164,\n",
       "                      2.2811, 5.6905, 2.2470, 4.2050, 2.4087, 3.7405, 3.3381, 7.7568, 2.3537,\n",
       "                      2.3315, 6.1529, 3.4149, 3.1469, 1.8111, 2.7524, 3.6613, 1.0858, 2.7417,\n",
       "                      2.4773, 3.5170, 2.4220, 5.2613, 3.8195, 2.9922, 4.5700, 2.7629, 1.6123,\n",
       "                      1.8929, 3.6896, 6.3001, 0.8409, 3.3394, 3.8139, 3.9174, 1.5927, 0.7480,\n",
       "                      3.5937, 3.6490, 5.8819, 4.0367, 3.4370, 4.5657, 2.5102, 7.2091, 2.9349,\n",
       "                      3.0809, 1.6543, 5.4894, 3.4794, 1.4275, 5.4316, 4.7650, 4.1599, 1.9645,\n",
       "                      4.8982, 1.4341, 3.8767, 3.9797, 0.4519, 4.4917, 3.2299, 1.0388, 4.9260,\n",
       "                      1.5499, 1.5885, 4.8111, 2.8517, 0.6584, 3.4823, 2.9395, 5.9022, 0.6945,\n",
       "                      3.7229, 2.2314, 2.1462, 0.8549, 5.2384, 1.3272, 4.0331, 4.5218, 3.0102,\n",
       "                      1.8583, 0.5245, 1.9274, 4.5631, 4.7651, 0.3079, 2.9428, 3.6160, 4.2390,\n",
       "                      2.6138, 4.1182, 5.5854, 3.8610, 2.0759, 0.9796, 2.9651, 0.4944, 5.7744,\n",
       "                      2.4316, 4.0258, 4.9396, 4.3733, 3.7215, 4.2113, 3.1056, 6.2329, 4.4894,\n",
       "                      5.1574, 5.0071, 5.5866, 0.8850, 2.9741, 5.5834, 0.3572, 2.0283, 3.3947,\n",
       "                      3.4704, 5.9040, 0.9375, 4.8362, 0.6645, 2.0783, 7.3664, 6.4958, 3.9064,\n",
       "                      2.7949, 3.2682, 5.4184, 5.1559, 5.8785, 4.1139, 3.9177, 0.7696, 2.3962,\n",
       "                      1.0384, 2.2115, 0.6453, 0.7076, 0.8329, 3.6456, 1.9628, 3.1418, 4.5132,\n",
       "                      0.4115, 4.1768, 4.4519, 3.9458, 3.0257, 1.4947, 3.2058, 1.3655, 4.1352,\n",
       "                      3.4105, 4.5888, 3.3150, 1.9294, 4.0421, 6.0221, 3.2912, 4.2873, 4.7720,\n",
       "                      3.4656, 3.0590, 8.2182, 4.4124, 6.4919, 3.9676, 5.5203, 5.1562, 3.4146,\n",
       "                      0.8346, 4.4209, 2.3305, 2.4899, 0.8488, 5.5537, 1.7388, 4.6757, 3.9809,\n",
       "                      4.5584, 4.9674, 2.6232, 4.7558, 5.0128, 1.2062, 2.2482, 0.7095, 3.1713,\n",
       "                      2.3571, 4.5236, 0.6485, 0.6402, 3.8079, 3.0503, 0.8216, 6.8033, 3.4044,\n",
       "                      3.8080, 1.8482, 0.5449, 7.0092, 1.5784, 0.5482, 5.7341, 2.6435, 0.7831,\n",
       "                      4.0010, 3.1418, 5.6034, 1.8706, 5.0983, 3.0142, 4.2100, 3.1216, 1.8255,\n",
       "                      1.4043, 2.2610, 3.7400, 0.9591, 4.3895, 0.8906, 1.9388, 2.4783, 1.5522,\n",
       "                      3.2200, 2.3497, 5.1347, 1.6659, 4.3208, 1.8821, 1.6936, 2.7439, 1.4729,\n",
       "                      5.6261, 0.9408, 3.1011, 7.1450, 3.4328, 6.4996, 6.3311, 3.0277, 1.0650,\n",
       "                      1.7758, 0.6302, 1.2459, 1.2973, 1.5363, 0.6243, 2.1484, 3.6919, 7.0684,\n",
       "                      2.9535, 3.3390, 4.2143, 2.8005, 1.8156, 0.7702, 2.1887, 5.9005, 3.2514,\n",
       "                      5.4945, 2.2440, 3.8744, 5.9169, 4.0190, 3.1756, 2.9989, 2.6420, 3.1059,\n",
       "                      2.2281, 5.4333, 2.8785, 3.2172, 2.7643, 3.1294, 4.0642, 5.1206, 3.5090,\n",
       "                      4.3961, 3.0115, 5.9440, 1.9283, 4.1815, 2.1835, 1.4314, 3.4040, 2.5957,\n",
       "                      2.6853, 5.1235, 0.7751, 2.2768, 1.4816, 4.6942, 2.8516, 0.8998, 3.3343,\n",
       "                      4.6592, 3.3794, 5.6437, 1.3156, 2.1070, 5.0763, 7.6396, 5.2843, 2.2395,\n",
       "                      3.2096, 6.3119, 2.6331, 4.6839, 0.6528, 5.0714, 3.5581, 4.1165, 3.1359,\n",
       "                      0.6871, 0.5570, 5.6502, 3.5575, 1.7096, 5.4676, 1.8800, 2.4769, 4.1370,\n",
       "                      0.6875, 2.9181, 4.6547, 2.5038, 1.9937, 2.9104, 2.1367, 5.6294, 4.4348,\n",
       "                      2.4529, 3.4773, 4.9291, 4.4389, 3.3580, 2.1686, 1.2246, 3.2229, 0.6858,\n",
       "                      3.4384, 4.8847, 3.6186, 3.1970, 1.8362, 0.8665, 2.4701, 1.7848, 4.7461,\n",
       "                      6.8829, 4.4657, 3.2407, 3.9232, 3.9043, 5.0451, 4.5044, 1.4879, 1.3901,\n",
       "                      3.5334, 4.1773, 6.4060, 2.3294, 2.6451, 0.8763, 4.9015, 3.0607, 3.9015,\n",
       "                      0.7255, 0.9973, 0.8929, 1.9283, 3.2329, 3.9223, 4.7599, 3.9288, 2.6871,\n",
       "                      3.1667, 4.8176, 3.7107, 5.9818, 4.7062, 2.3127, 6.5029, 1.3959, 2.7819,\n",
       "                      3.9042, 3.0533, 3.2759, 1.6547, 2.4185, 0.9166, 6.5005, 6.8757, 5.3783,\n",
       "                      3.3165, 5.3681, 5.1587, 1.9619, 3.7308, 5.5301, 3.2581, 1.4869, 0.6746,\n",
       "                      5.9806, 2.6170, 2.8998, 0.6369, 4.0114, 3.4190, 4.8675, 2.3960, 2.5909,\n",
       "                      2.1951, 3.0333, 0.8429, 2.8128, 4.3407, 4.3649, 2.3173, 6.8269, 1.9255,\n",
       "                      4.6326, 3.7234, 4.1625, 2.6587, 4.0651, 2.3690, 3.3869, 0.5461, 0.8049,\n",
       "                      2.7820, 4.4526, 2.6279, 6.0258, 0.5703, 4.4455, 1.8234, 2.8839])),\n",
       "             ('decoders.5.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense5.weight',\n",
       "              tensor([[-0.0356,  0.0112, -0.0081,  ...,  0.0094,  0.0218,  0.0049],\n",
       "                      [-0.0107, -0.0632, -0.0236,  ..., -0.0125, -0.0134, -0.0459],\n",
       "                      [-0.0086, -0.0408, -0.0487,  ..., -0.0059, -0.0295, -0.0055],\n",
       "                      ...,\n",
       "                      [-0.0133,  0.0256, -0.0492,  ...,  0.0052,  0.0032, -0.0249],\n",
       "                      [-0.0491,  0.0165,  0.0112,  ..., -0.0191, -0.0322, -0.0345],\n",
       "                      [-0.0349, -0.0165, -0.0521,  ..., -0.0602, -0.0315, -0.0232]])),\n",
       "             ('decoders.5.dense5.bias',\n",
       "              tensor([-0.0497, -0.0313, -0.0637,  ...,  0.0227, -0.0592, -0.0443])),\n",
       "             ('decoders.6.dense1.weight',\n",
       "              tensor([[ 0.0583, -0.0452,  0.0130,  ..., -0.0016,  0.1166,  0.1514],\n",
       "                      [ 0.0470,  0.1267, -0.1485,  ..., -0.0614,  0.1166, -0.0440],\n",
       "                      [-0.1470,  0.0824, -0.0279,  ..., -0.0856,  0.0424, -0.0442],\n",
       "                      ...,\n",
       "                      [ 0.1282, -0.1477,  0.1661,  ...,  0.1375, -0.1008,  0.0502],\n",
       "                      [ 0.1197, -0.1610, -0.0614,  ...,  0.1209,  0.1298, -0.0817],\n",
       "                      [ 0.0187,  0.0672, -0.0529,  ..., -0.1890,  0.0550, -0.1368]])),\n",
       "             ('decoders.6.bn1.weight',\n",
       "              tensor([0.9938, 1.0160, 1.0199, 0.9982, 0.9949, 1.0175, 0.9954, 0.9787, 1.0067,\n",
       "                      1.0144, 0.9873, 0.9948, 0.9961, 1.0148, 0.9916, 0.9945, 0.9954, 0.9939,\n",
       "                      0.9961, 1.0065, 0.9922, 1.0184, 0.9976, 1.0145, 0.9943, 1.0032, 0.9831,\n",
       "                      0.9809, 1.0185, 1.0016, 1.0094, 0.9927, 0.9842, 1.0024, 1.0155, 0.9935,\n",
       "                      0.9979, 1.0078, 1.0029, 0.9908, 1.0106, 0.9875, 0.9922, 0.9949, 0.9901,\n",
       "                      0.9927, 0.9947, 0.9962, 0.9955, 0.9950, 0.9990, 1.0193, 1.0029, 0.9921,\n",
       "                      0.9973, 1.0060, 1.0028, 1.0043, 0.9850, 0.9840, 0.9914, 1.0118, 1.0220,\n",
       "                      0.9936, 1.0019, 1.0009, 0.9832, 1.0151, 0.9945, 0.9936, 0.9936, 0.9979,\n",
       "                      0.9806, 0.9934, 1.0068, 0.9716, 0.9948, 1.0071, 1.0157, 0.9988, 1.0065,\n",
       "                      0.9986, 0.9972, 0.9833, 1.0134, 0.9917, 0.9885, 0.9877, 0.9915, 0.9849,\n",
       "                      0.9979, 0.9884, 0.9914, 0.9932, 1.0284, 0.9924, 0.9819, 1.0178, 0.9908,\n",
       "                      0.9985, 1.0051, 0.9995, 1.0029, 0.9824, 1.0054, 1.0019, 1.0001, 0.9852,\n",
       "                      0.9966, 0.9905, 0.9930, 0.9976, 0.9816, 0.9948, 0.9934, 1.0114, 0.9839,\n",
       "                      0.9861, 0.9942, 0.9877, 1.0021, 0.9829, 0.9891, 1.0064, 0.9951, 0.9951,\n",
       "                      0.9970, 1.0116])),\n",
       "             ('decoders.6.bn1.bias',\n",
       "              tensor([-7.7230e-03,  2.6010e-02,  1.2807e-02,  1.3412e-02,  1.9391e-02,\n",
       "                       1.4413e-02,  1.3475e-02, -1.7366e-02,  6.3416e-03,  7.5319e-03,\n",
       "                      -6.9815e-03,  5.5409e-03, -7.7775e-03, -2.9692e-04, -7.4944e-04,\n",
       "                      -4.5310e-03, -3.3179e-03, -7.4555e-04,  1.6190e-02,  2.0756e-02,\n",
       "                       2.0308e-02,  2.7537e-03,  1.4455e-02,  2.1399e-03, -1.4952e-03,\n",
       "                       1.4835e-02, -1.1350e-02,  7.9249e-03,  2.4194e-03,  2.0878e-02,\n",
       "                       6.0820e-03, -3.9914e-03, -4.1487e-03,  1.1901e-02,  1.1770e-03,\n",
       "                       5.6446e-03,  3.4826e-03,  9.0836e-03,  1.2204e-02,  5.4777e-03,\n",
       "                       3.4809e-03, -2.4938e-03, -6.3221e-03,  2.8196e-03,  2.5660e-03,\n",
       "                      -1.7545e-03,  2.4133e-03,  1.0345e-02, -5.4066e-03, -1.9158e-03,\n",
       "                       1.9230e-02,  5.4735e-03,  1.1251e-02, -9.8005e-03,  1.1522e-02,\n",
       "                       1.1886e-02,  1.7368e-02, -5.8074e-03, -1.0501e-02, -2.0012e-02,\n",
       "                       7.6382e-04,  2.2616e-02,  2.0314e-03, -7.8937e-03,  1.7404e-02,\n",
       "                       4.7778e-03, -1.9887e-03,  3.6784e-03,  2.0649e-02, -6.7821e-03,\n",
       "                      -1.0686e-02,  1.2250e-02, -1.3785e-02, -1.2980e-03,  1.5154e-02,\n",
       "                      -2.0642e-02, -1.0856e-02,  8.5907e-03,  4.1716e-03,  6.6490e-03,\n",
       "                       4.1848e-03, -9.4156e-04,  1.5654e-02, -3.9813e-03,  1.9932e-02,\n",
       "                      -1.3648e-02, -7.1719e-03, -1.3915e-03, -9.3055e-03, -5.0996e-03,\n",
       "                       1.7735e-02,  2.3098e-03, -1.2231e-02,  7.9091e-03,  9.5196e-03,\n",
       "                       2.1891e-03, -1.8174e-02,  2.7356e-03, -8.1704e-03,  9.6793e-05,\n",
       "                       1.0642e-02,  7.0724e-03,  6.6398e-04, -1.8673e-02,  1.1793e-02,\n",
       "                       1.6252e-02,  1.6947e-02, -1.2677e-02, -1.0586e-02, -9.0439e-03,\n",
       "                       6.3021e-03,  1.5161e-02, -8.3701e-03,  5.7332e-03, -9.9884e-03,\n",
       "                       6.6687e-03, -1.1635e-02, -7.9203e-03, -5.1009e-03, -4.6184e-03,\n",
       "                       1.0287e-02, -1.4920e-02,  9.6205e-04, -2.2448e-03,  8.7300e-03,\n",
       "                       5.2537e-03,  1.4812e-02,  3.0215e-02])),\n",
       "             ('decoders.6.bn1.running_mean',\n",
       "              tensor([ 0.1508, -0.4265,  0.8252, -0.1457, -0.7552,  0.3196, -0.3173, -0.1690,\n",
       "                       0.2690,  0.5256, -0.2125, -0.0466,  0.1431,  0.6414, -0.2040,  0.1170,\n",
       "                       0.1357, -0.0064, -0.2529, -0.3497, -0.3672,  0.4887, -0.3063,  0.5595,\n",
       "                       0.2047, -0.4592, -0.0579,  0.2312,  0.7619, -0.1719,  0.3348,  0.2219,\n",
       "                       0.0583, -0.1581,  0.5875, -0.0968, -0.0719,  0.3842,  0.0804, -0.6484,\n",
       "                       0.4108, -0.3723,  0.2693, -0.2117, -0.1852, -0.2129, -0.0963, -0.2683,\n",
       "                      -0.0163,  0.1934, -0.4165,  0.5060, -0.3468,  0.2760,  0.0194, -0.3113,\n",
       "                      -0.3505,  0.5487,  0.1071,  0.2627, -0.3731,  0.2650,  0.3916, -0.0089,\n",
       "                      -0.2801,  0.4582, -0.4302,  0.5405, -0.3664,  0.3488,  0.1528, -0.3026,\n",
       "                       0.2217, -0.1832, -0.4701,  0.0066,  0.3317,  0.3400,  0.6577, -0.0974,\n",
       "                       0.3831,  0.1599, -0.2361,  0.1275, -0.2784,  0.0850,  0.0980, -0.3613,\n",
       "                       0.0869, -0.1996, -0.2764, -0.4684,  0.1118, -0.4259,  0.5365, -0.3382,\n",
       "                      -0.0513,  0.5477,  0.4161,  0.3828,  0.3780, -0.3147, -0.1110,  0.0446,\n",
       "                      -0.4109, -0.3644,  0.2667, -0.0888,  0.3444, -0.1273,  0.3570, -0.1048,\n",
       "                      -0.2023, -0.2025, -0.1553,  0.5243, -0.0390,  0.0334, -0.1640, -0.1112,\n",
       "                       0.1675,  0.1399, -0.1830,  0.3255, -0.2758,  0.0674, -0.1829,  0.1769])),\n",
       "             ('decoders.6.bn1.running_var',\n",
       "              tensor([0.0704, 0.6683, 3.3388, 0.3330, 0.9825, 0.9796, 0.6804, 0.0953, 0.5312,\n",
       "                      1.1721, 0.1210, 0.0777, 0.3207, 2.7244, 0.2071, 0.4172, 0.3610, 0.1362,\n",
       "                      0.4419, 0.2898, 0.4642, 1.5708, 0.3095, 2.0602, 0.2885, 0.7742, 0.1370,\n",
       "                      0.3230, 2.4768, 0.1772, 0.4760, 0.5130, 0.2126, 0.2600, 1.8529, 0.4370,\n",
       "                      0.1676, 0.7817, 0.2241, 0.9487, 1.3698, 0.5302, 0.5181, 0.3089, 0.2893,\n",
       "                      0.1379, 0.1250, 0.2729, 0.1104, 0.1600, 0.6320, 1.2111, 0.4645, 0.8977,\n",
       "                      0.1305, 0.2046, 0.9112, 0.9817, 0.1376, 0.2149, 0.6817, 0.1991, 0.8600,\n",
       "                      0.1066, 0.1727, 0.5503, 0.7490, 0.9970, 0.2424, 0.7219, 0.1846, 0.7663,\n",
       "                      0.2652, 0.1370, 0.8962, 0.1071, 0.2581, 0.7021, 1.7468, 0.0941, 0.7519,\n",
       "                      0.2043, 0.2738, 0.2744, 0.8124, 0.2323, 0.1443, 0.3410, 0.2895, 0.2960,\n",
       "                      0.7717, 1.1826, 0.3037, 0.2933, 0.5897, 0.1617, 0.1233, 0.9357, 0.6117,\n",
       "                      0.6539, 0.7852, 0.5743, 0.1666, 0.1357, 0.6788, 0.1187, 0.4981, 0.1491,\n",
       "                      0.2656, 0.2890, 0.3147, 0.1675, 0.1459, 0.3102, 0.1197, 1.1439, 0.3041,\n",
       "                      0.2440, 0.2308, 0.2250, 0.2755, 0.1427, 0.2068, 0.5515, 0.4871, 0.2454,\n",
       "                      0.1092, 0.3134])),\n",
       "             ('decoders.6.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense2.weight',\n",
       "              tensor([[-0.0038, -0.0469, -0.0427,  ..., -0.0340,  0.0690,  0.0088],\n",
       "                      [-0.0245, -0.0048,  0.0702,  ..., -0.0349,  0.0013,  0.0626],\n",
       "                      [-0.0620, -0.0843,  0.0326,  ..., -0.0098, -0.0737, -0.0018],\n",
       "                      ...,\n",
       "                      [-0.0699, -0.0094,  0.0812,  ...,  0.0161,  0.0153,  0.0761],\n",
       "                      [ 0.0341,  0.0091, -0.0556,  ..., -0.0534, -0.0051, -0.0834],\n",
       "                      [ 0.0370, -0.0825,  0.0573,  ...,  0.0138, -0.0623,  0.0665]])),\n",
       "             ('decoders.6.bn2.weight',\n",
       "              tensor([0.9992, 0.9888, 0.9822, 0.9873, 0.9924, 1.0052, 0.9905, 0.9994, 0.9908,\n",
       "                      1.0096, 1.0115, 0.9942, 0.9993, 0.9970, 0.9936, 0.9951, 0.9903, 1.0024,\n",
       "                      0.9829, 1.0080, 1.0077, 0.9947, 0.9964, 1.0110, 1.0077, 0.9901, 0.9869,\n",
       "                      1.0045, 0.9995, 1.0023, 1.0092, 1.0030, 0.9946, 0.9950, 1.0008, 0.9967,\n",
       "                      1.0052, 1.0124, 0.9831, 0.9884, 0.9924, 0.9907, 1.0095, 0.9923, 0.9882,\n",
       "                      0.9993, 1.0023, 0.9975, 0.9929, 1.0246, 1.0037, 1.0006, 0.9944, 1.0111,\n",
       "                      0.9858, 0.9904, 1.0023, 1.0010, 0.9934, 0.9835, 0.9884, 0.9995, 1.0112,\n",
       "                      0.9999, 0.9990, 0.9994, 0.9781, 0.9929, 0.9956, 0.9994, 1.0002, 1.0187,\n",
       "                      0.9822, 0.9888, 1.0185, 1.0017, 1.0121, 0.9872, 1.0085, 0.9943, 1.0089,\n",
       "                      1.0253, 1.0002, 1.0253, 0.9968, 0.9916, 0.9915, 0.9880, 1.0050, 0.9974,\n",
       "                      0.9880, 1.0209, 0.9974, 0.9964, 1.0008, 1.0135, 0.9938, 0.9947, 0.9890,\n",
       "                      0.9863, 0.9969, 1.0195, 1.0028, 1.0016, 1.0055, 1.0102, 1.0002, 0.9867,\n",
       "                      1.0057, 0.9849, 1.0034, 1.0087, 1.0094, 0.9828, 0.9973, 0.9884, 1.0252,\n",
       "                      1.0002, 1.0127, 1.0187, 0.9976, 0.9881, 0.9939, 0.9974, 0.9897, 1.0109,\n",
       "                      1.0151, 0.9914, 1.0049, 0.9939, 1.0005, 0.9797, 0.9938, 0.9904, 0.9937,\n",
       "                      0.9868, 0.9965, 1.0101, 0.9921, 1.0030, 1.0140, 0.9935, 0.9944, 0.9917,\n",
       "                      0.9881, 0.9816, 0.9907, 1.0022, 1.0089, 1.0145, 1.0180, 1.0090, 1.0080,\n",
       "                      0.9996, 1.0204, 1.0015, 1.0104, 1.0100, 0.9857, 0.9974, 1.0035, 1.0014,\n",
       "                      0.9957, 0.9954, 0.9839, 0.9966, 1.0266, 0.9986, 0.9920, 0.9941, 0.9913,\n",
       "                      1.0157, 1.0013, 0.9942, 0.9905, 0.9947, 0.9985, 1.0111, 0.9897, 0.9940,\n",
       "                      1.0187, 0.9900, 1.0007, 1.0085, 0.9810, 1.0104, 1.0241, 0.9977, 0.9910,\n",
       "                      0.9967, 0.9834, 1.0041, 1.0009, 1.0038, 0.9906, 1.0026, 1.0008, 0.9938,\n",
       "                      0.9912, 0.9789, 1.0066, 1.0075, 0.9972, 0.9922, 1.0199, 0.9917, 1.0131,\n",
       "                      0.9969, 1.0034, 1.0011, 1.0029, 0.9972, 0.9986, 1.0033, 0.9867, 1.0222,\n",
       "                      0.9960, 1.0014, 1.0076, 0.9930, 1.0059, 1.0058, 1.0040, 1.0183, 1.0196,\n",
       "                      0.9915, 0.9860, 0.9914, 0.9891, 0.9921, 1.0003, 0.9943, 0.9907, 0.9875,\n",
       "                      0.9962, 1.0003, 1.0059, 0.9823, 0.9978, 0.9886, 0.9928, 0.9928, 0.9850,\n",
       "                      0.9971, 1.0124, 0.9961, 1.0082, 0.9970, 1.0184, 0.9998, 1.0279, 1.0034,\n",
       "                      0.9876, 0.9996, 0.9934, 0.9984])),\n",
       "             ('decoders.6.bn2.bias',\n",
       "              tensor([ 4.9045e-04,  2.6075e-03, -1.9007e-02, -1.1577e-02,  5.8879e-03,\n",
       "                       2.4920e-02, -8.4926e-04, -1.5225e-03, -5.0313e-03,  9.0354e-03,\n",
       "                       1.0380e-02,  1.7752e-02, -2.9230e-03,  4.0352e-03, -3.0487e-03,\n",
       "                       3.5403e-03,  1.1650e-02,  1.9282e-03, -1.2766e-02, -1.3008e-03,\n",
       "                       1.9744e-02,  4.1454e-02, -4.0422e-03, -3.6311e-03,  3.2395e-03,\n",
       "                       1.2054e-02, -4.7012e-03,  7.3517e-03,  2.3435e-03,  4.9872e-03,\n",
       "                       4.7818e-03,  1.5213e-02, -5.8586e-03, -1.4951e-03,  8.1907e-03,\n",
       "                       2.1650e-02,  3.4167e-03,  5.9566e-03, -9.9596e-03,  6.6746e-03,\n",
       "                       2.1988e-03,  1.2169e-02,  8.7659e-03,  1.3624e-02, -7.8237e-03,\n",
       "                       1.5723e-02,  1.4144e-03,  1.4557e-02, -7.7826e-03,  5.7415e-03,\n",
       "                       1.8289e-03,  7.4813e-04,  1.6238e-02,  2.9385e-02, -3.9650e-03,\n",
       "                      -3.0874e-03,  1.6989e-02,  1.1331e-02, -9.9007e-03, -4.1854e-03,\n",
       "                      -9.9545e-03, -4.8610e-03,  2.9371e-04,  2.0819e-02,  1.9726e-02,\n",
       "                      -1.2609e-03, -9.6010e-03,  7.8774e-03, -5.3334e-03,  7.6798e-03,\n",
       "                       2.4654e-03,  2.1437e-02, -2.4589e-03, -1.3702e-03,  1.7042e-02,\n",
       "                       1.8649e-02, -5.3326e-03,  1.0363e-02,  2.4495e-02,  1.8425e-03,\n",
       "                       6.5083e-05,  6.2503e-03, -6.8272e-04,  2.0055e-02,  1.0339e-02,\n",
       "                      -7.0468e-05,  4.6621e-03, -4.5006e-03,  1.2665e-02, -6.3276e-04,\n",
       "                       4.8090e-03,  1.3596e-02, -9.4983e-03,  6.7957e-03,  1.8619e-02,\n",
       "                       4.5729e-03,  1.0200e-03, -8.7466e-03, -3.4408e-03,  2.7823e-03,\n",
       "                       2.4885e-02,  1.0473e-02,  7.3907e-03,  1.4515e-03,  1.3315e-03,\n",
       "                       6.6383e-03,  1.0881e-02, -4.5255e-03,  6.0730e-03, -4.7401e-03,\n",
       "                      -2.4664e-03,  5.7939e-03,  1.0861e-02, -1.7032e-02, -5.4013e-04,\n",
       "                      -8.6486e-03,  1.2342e-02, -3.5624e-03,  1.8687e-02,  3.4587e-02,\n",
       "                       1.3421e-03,  9.2153e-04,  1.6226e-02,  6.0292e-03, -1.7040e-02,\n",
       "                       2.9716e-04,  8.8476e-03, -2.2110e-02,  2.1286e-02, -5.1439e-03,\n",
       "                       1.6105e-02, -2.0111e-03,  1.2877e-02, -4.3262e-03, -5.1263e-03,\n",
       "                      -1.0895e-02,  3.1861e-03,  4.5218e-03, -5.0619e-03,  2.7892e-02,\n",
       "                       8.4267e-04, -8.6658e-03, -4.0765e-03, -3.1975e-03,  1.4847e-03,\n",
       "                      -1.6112e-02,  1.6908e-02, -1.5622e-03,  2.9600e-02,  2.1215e-03,\n",
       "                       1.7209e-02,  8.3244e-03,  9.7048e-03,  2.6463e-03,  6.8376e-03,\n",
       "                       2.7565e-02,  3.1668e-02,  1.7174e-02, -1.5970e-03,  8.7901e-03,\n",
       "                      -1.6261e-02,  2.0707e-02, -7.2164e-03, -3.8554e-03, -2.5513e-02,\n",
       "                      -2.6546e-03,  5.6906e-03,  2.4907e-02, -1.9166e-02,  6.1318e-03,\n",
       "                      -8.8688e-03,  1.6558e-02,  5.0024e-03, -4.5775e-03, -7.9125e-03,\n",
       "                       5.0542e-03,  8.8688e-03,  4.2534e-03, -1.2242e-02,  9.2078e-03,\n",
       "                       2.2198e-03, -6.9268e-03,  1.2610e-02,  2.0200e-02, -9.2403e-03,\n",
       "                       1.6141e-02,  1.4039e-02,  1.9661e-02,  1.1123e-03, -3.2962e-03,\n",
       "                       5.9239e-04, -2.2411e-03,  5.8942e-03,  1.4772e-03, -4.4101e-03,\n",
       "                       1.5538e-03,  1.9933e-02, -8.6514e-03,  5.9315e-03, -1.6089e-02,\n",
       "                       2.6501e-03,  2.1792e-02, -5.0200e-03, -1.0070e-02,  5.5633e-03,\n",
       "                      -1.8477e-02,  6.1237e-03,  2.1118e-02, -1.3710e-03, -6.0817e-04,\n",
       "                       9.6079e-03,  4.0326e-03,  5.5894e-03,  9.4780e-03, -5.9923e-03,\n",
       "                       5.4971e-03,  3.4425e-03,  1.1009e-03,  7.0280e-04, -9.8216e-05,\n",
       "                       8.6325e-03,  3.4507e-02,  1.0876e-02,  1.0548e-02,  1.6613e-02,\n",
       "                      -3.1591e-03, -1.2286e-02, -5.8608e-03, -8.5765e-04, -1.1446e-03,\n",
       "                      -6.4135e-03, -2.2904e-03,  9.0139e-03,  2.0730e-03,  1.3483e-03,\n",
       "                      -2.2361e-04,  1.2757e-02, -2.5936e-03,  9.0874e-03,  6.8181e-03,\n",
       "                       7.4882e-03, -5.5083e-03, -4.8025e-04, -2.4889e-03,  8.5988e-03,\n",
       "                       7.4767e-03,  1.1248e-02,  1.1119e-03,  1.0191e-02, -1.5685e-03,\n",
       "                       1.4807e-02,  2.1080e-02, -1.4875e-02, -1.0908e-03,  1.0355e-02,\n",
       "                       2.1553e-02])),\n",
       "             ('decoders.6.bn2.running_mean',\n",
       "              tensor([-0.1922, -0.0519, -0.0995, -0.3092, -0.3360, -0.2955, -0.1573, -0.1981,\n",
       "                      -0.1670,  0.1188,  0.0405, -0.1794, -0.0809,  0.1737, -0.3201,  0.1701,\n",
       "                       0.1386, -0.5783,  0.2611,  0.1619, -0.2858, -0.0671,  0.0852,  0.3904,\n",
       "                      -0.0991, -0.2914, -0.2889,  0.0743,  0.1372, -0.4312,  0.3418, -0.1514,\n",
       "                      -0.1747, -0.5453,  0.1286, -0.2024,  0.2231, -0.0957,  0.1278,  0.0540,\n",
       "                      -0.1853,  0.0118,  0.0852, -0.1662,  0.2198, -0.0948, -0.1545,  0.2221,\n",
       "                      -0.2543,  0.1735, -0.1851,  0.1173, -0.1930, -0.1346,  0.0969, -0.2704,\n",
       "                       0.0824, -0.1264,  0.2625,  0.0894,  0.0346,  0.2498,  0.2113, -0.2344,\n",
       "                       0.0041, -0.2935,  0.1483, -0.1178,  0.1116, -0.1930, -0.0426,  0.2924,\n",
       "                       0.1688, -0.0907,  0.1780, -0.2245, -0.0761, -0.0515, -0.0464, -0.0450,\n",
       "                       0.2165,  0.4255,  0.0086,  0.1485,  0.0526, -0.1668,  0.0851, -0.0971,\n",
       "                       0.3235, -0.1552,  0.0869,  0.0210,  0.1634, -0.3494,  0.0415, -0.0995,\n",
       "                      -0.1470, -0.0342,  0.1059,  0.1561, -0.3940,  0.1817, -0.2565, -0.1180,\n",
       "                      -0.2162,  0.1795,  0.0960,  0.0566,  0.2406,  0.0342,  0.1180, -0.2899,\n",
       "                      -0.2625,  0.1815, -0.1772, -0.4011, -0.0601,  0.1131, -0.5151, -0.0963,\n",
       "                      -0.3390, -0.1621, -0.2486,  0.3555,  0.0251, -0.1156, -0.1244,  0.0356,\n",
       "                      -0.0256, -0.1255, -0.1325,  0.0251, -0.3504, -0.3393,  0.0390, -0.0915,\n",
       "                      -0.1739, -0.0054, -0.0566,  0.0186,  0.0063, -0.1308,  0.2127, -0.0377,\n",
       "                       0.2529,  0.0326,  0.0439, -0.0134, -0.1974,  0.2353, -0.0616, -0.2442,\n",
       "                      -0.2408, -0.0603,  0.0674, -0.0417, -0.1871,  0.2388, -0.0859, -0.1934,\n",
       "                       0.5432, -0.0399, -0.0135, -0.2266,  0.2035, -0.1333,  0.4672, -0.0870,\n",
       "                       0.1605, -0.0157,  0.3347,  0.1029, -0.1773, -0.0785, -0.1143, -0.0858,\n",
       "                      -0.0610,  0.2419,  0.1784, -0.1211,  0.3711,  0.2997, -0.1259, -0.2768,\n",
       "                      -0.1245, -0.0821,  0.3589, -0.3152, -0.2954, -0.1019,  0.0966,  0.4261,\n",
       "                      -0.2146,  0.0581,  0.0308, -0.2747, -0.4100, -0.0838,  0.0996, -0.2193,\n",
       "                       0.2080, -0.1950, -0.1051, -0.0873,  0.3228,  0.4894, -0.0043,  0.1478,\n",
       "                       0.1385, -0.2735,  0.0596,  0.0031,  0.0051, -0.3939, -0.2996,  0.0212,\n",
       "                       0.1760,  0.0431,  0.3600,  0.1848,  0.2752, -0.2458, -0.3659, -0.2873,\n",
       "                       0.0860,  0.0730,  0.2744,  0.0784, -0.3235, -0.3498, -0.1352,  0.2671,\n",
       "                      -0.0776,  0.0743,  0.1794, -0.2498, -0.1889,  0.1314, -0.1843,  0.0619,\n",
       "                      -0.2382, -0.2598,  0.0360, -0.2206, -0.5425, -0.1755, -0.1605,  0.0849,\n",
       "                       0.1774,  0.2009,  0.2967, -0.4011, -0.0412, -0.2316, -0.0594, -0.3527])),\n",
       "             ('decoders.6.bn2.running_var',\n",
       "              tensor([0.1137, 0.2611, 0.1506, 0.0939, 0.1202, 0.2585, 0.3058, 0.5787, 0.5640,\n",
       "                      0.7395, 0.8043, 0.4881, 0.3148, 0.3278, 0.1448, 0.3009, 1.1484, 0.2752,\n",
       "                      0.7270, 0.6572, 0.2013, 0.2603, 0.0903, 0.2962, 0.5336, 0.1799, 0.0583,\n",
       "                      0.3289, 0.4764, 0.1083, 1.1879, 0.0958, 0.1098, 0.0971, 0.2964, 0.2665,\n",
       "                      0.4070, 1.7880, 0.3134, 0.2162, 0.0809, 0.2150, 0.2331, 0.1820, 0.3261,\n",
       "                      0.1113, 0.5746, 0.4785, 0.0700, 0.3035, 0.0782, 0.9026, 0.1685, 0.3898,\n",
       "                      0.1311, 0.1182, 0.2646, 0.1280, 0.2093, 0.1515, 0.1502, 0.1499, 0.4353,\n",
       "                      0.3110, 0.8299, 0.1285, 0.1615, 0.3343, 0.2124, 1.0971, 0.1951, 0.4728,\n",
       "                      0.1080, 0.0939, 0.6715, 0.7037, 1.0665, 0.1293, 0.9786, 0.1250, 0.3679,\n",
       "                      0.8763, 0.2611, 0.4674, 0.2153, 0.1136, 0.2921, 0.1062, 0.3097, 0.9115,\n",
       "                      0.1390, 0.5945, 0.2826, 0.2253, 1.3104, 0.8111, 0.2212, 0.2721, 0.2365,\n",
       "                      0.2685, 0.7815, 0.8850, 0.0933, 0.2179, 0.1426, 0.3851, 0.6360, 0.1791,\n",
       "                      0.3819, 0.6837, 0.7379, 0.5926, 0.0925, 0.5193, 0.1482, 0.1065, 0.9284,\n",
       "                      0.2312, 0.2404, 0.7387, 0.0781, 0.0881, 0.1452, 0.4120, 0.1163, 0.6768,\n",
       "                      0.8256, 0.2279, 0.7195, 0.3469, 0.3647, 0.0995, 0.1801, 0.0945, 0.5727,\n",
       "                      0.1776, 0.2105, 0.3163, 0.2348, 0.2700, 1.2365, 0.2703, 0.7925, 0.1727,\n",
       "                      0.3961, 0.1763, 0.2873, 0.7274, 0.1166, 0.4701, 0.9419, 0.9165, 0.3823,\n",
       "                      0.4520, 0.5480, 0.1477, 0.2450, 0.2831, 0.0936, 0.1137, 0.2461, 0.2912,\n",
       "                      0.1965, 0.6442, 0.2338, 0.2085, 0.2688, 0.4632, 0.1121, 0.0755, 0.1764,\n",
       "                      0.4442, 0.0799, 0.1523, 0.1528, 0.0535, 0.1039, 1.0154, 0.1844, 0.0941,\n",
       "                      0.5787, 0.1781, 0.4985, 0.0998, 0.2598, 0.5897, 0.2130, 0.1323, 0.0954,\n",
       "                      0.1744, 0.2558, 0.4759, 0.1952, 1.6684, 0.1225, 0.2110, 0.1384, 0.6444,\n",
       "                      0.2963, 0.0680, 0.6848, 0.2099, 0.0769, 0.1323, 1.3751, 0.1560, 1.4221,\n",
       "                      0.3246, 0.5157, 0.1984, 0.8424, 0.4710, 0.3897, 0.3477, 0.1729, 1.1747,\n",
       "                      0.9002, 0.3998, 0.4640, 0.1658, 0.8100, 0.1820, 0.1134, 0.8013, 1.0979,\n",
       "                      0.4614, 0.3879, 0.1235, 0.1531, 0.1014, 0.1057, 0.2665, 0.4013, 0.0558,\n",
       "                      0.1042, 0.4555, 0.4195, 0.6084, 0.0839, 0.2420, 0.4228, 0.2961, 0.2266,\n",
       "                      0.0851, 0.7348, 0.2079, 0.5742, 0.2707, 0.5507, 0.3979, 0.4453, 0.0877,\n",
       "                      0.2436, 0.6749, 0.8986, 0.2285])),\n",
       "             ('decoders.6.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense3.weight',\n",
       "              tensor([[ 0.0160,  0.0168, -0.0098,  ...,  0.0127, -0.0543,  0.0105],\n",
       "                      [ 0.0101, -0.0139, -0.0578,  ...,  0.0556, -0.0687, -0.0615],\n",
       "                      [-0.0132,  0.0388, -0.0340,  ..., -0.0426,  0.0498, -0.0309],\n",
       "                      ...,\n",
       "                      [-0.0132, -0.0049, -0.0059,  ..., -0.0279, -0.0017,  0.0292],\n",
       "                      [-0.0519, -0.0740,  0.0377,  ..., -0.0391, -0.0473,  0.0137],\n",
       "                      [-0.0594, -0.0324, -0.0321,  ...,  0.0162, -0.0297, -0.0016]])),\n",
       "             ('decoders.6.bn3.weight',\n",
       "              tensor([0.9896, 1.0094, 0.9924, 0.9954, 0.9895, 0.9920, 0.9990, 0.9883, 1.0031,\n",
       "                      1.0220, 0.9916, 1.0159, 1.0130, 0.9949, 0.9994, 0.9966, 0.9856, 0.9889,\n",
       "                      1.0024, 0.9904, 0.9934, 0.9768, 0.9945, 0.9910, 0.9932, 0.9865, 1.0009,\n",
       "                      1.0050, 1.0005, 1.0058, 0.9987, 1.0196, 1.0082, 1.0016, 0.9912, 0.9934,\n",
       "                      1.0122, 0.9938, 1.0026, 0.9914, 1.0001, 0.9972, 1.0060, 0.9885, 0.9899,\n",
       "                      0.9916, 1.0059, 0.9903, 0.9926, 1.0085, 0.9926, 1.0230, 0.9845, 1.0075,\n",
       "                      0.9802, 1.0010, 0.9879, 0.9886, 0.9842, 0.9909, 0.9969, 1.0013, 0.9999,\n",
       "                      0.9933, 0.9850, 1.0056, 0.9952, 0.9905, 1.0232, 0.9914, 0.9974, 0.9893,\n",
       "                      1.0203, 1.0022, 0.9818, 0.9968, 1.0070, 0.9945, 1.0129, 0.9964, 0.9858,\n",
       "                      0.9858, 1.0023, 0.9922, 1.0177, 1.0163, 0.9912, 1.0149, 0.9854, 1.0174,\n",
       "                      0.9919, 0.9860, 0.9918, 0.9923, 1.0082, 1.0254, 0.9889, 1.0109, 0.9865,\n",
       "                      1.0063, 1.0262, 0.9887, 1.0104, 0.9941, 0.9954, 1.0173, 1.0010, 0.9841,\n",
       "                      0.9977, 1.0130, 0.9947, 0.9955, 1.0093, 0.9956, 0.9930, 1.0105, 0.9986,\n",
       "                      0.9921, 0.9943, 0.9963, 0.9945, 0.9970, 1.0260, 0.9969, 0.9956, 1.0005,\n",
       "                      1.0143, 0.9916, 0.9870, 0.9941, 0.9963, 0.9855, 0.9825, 1.0243, 1.0067,\n",
       "                      0.9891, 1.0234, 0.9944, 0.9910, 1.0037, 0.9890, 0.9969, 0.9861, 0.9835,\n",
       "                      0.9964, 0.9924, 0.9933, 0.9959, 1.0081, 1.0168, 1.0253, 0.9914, 0.9867,\n",
       "                      1.0183, 1.0049, 1.0185, 0.9973, 1.0240, 1.0193, 0.9868, 1.0057, 1.0186,\n",
       "                      0.9940, 0.9909, 1.0133, 0.9936, 0.9942, 0.9959, 0.9903, 0.9990, 0.9917,\n",
       "                      1.0072, 0.9927, 0.9924, 1.0007, 1.0097, 1.0259, 0.9937, 0.9957, 1.0218,\n",
       "                      0.9972, 0.9928, 0.9932, 1.0153, 0.9861, 1.0216, 1.0052, 0.9928, 0.9906,\n",
       "                      0.9950, 1.0085, 0.9926, 0.9948, 0.9983, 1.0080, 0.9959, 1.0232, 1.0204,\n",
       "                      0.9851, 0.9871, 0.9888, 1.0209, 1.0050, 0.9933, 1.0015, 1.0189, 1.0274,\n",
       "                      1.0022, 0.9967, 1.0218, 0.9970, 0.9960, 1.0052, 1.0031, 0.9955, 0.9948,\n",
       "                      1.0134, 0.9897, 1.0003, 0.9959, 0.9975, 1.0004, 1.0008, 0.9898, 1.0219,\n",
       "                      0.9868, 1.0005, 1.0232, 1.0009, 0.9861, 1.0108, 1.0152, 0.9966, 1.0092,\n",
       "                      0.9827, 1.0044, 0.9926, 0.9843, 0.9934, 1.0162, 1.0086, 0.9947, 0.9975,\n",
       "                      1.0026, 1.0048, 0.9869, 1.0035, 1.0177, 0.9900, 0.9921, 0.9985, 0.9957,\n",
       "                      0.9866, 1.0005, 0.9979, 0.9852, 0.9899, 1.0253, 0.9980, 0.9852, 0.9942,\n",
       "                      0.9959, 0.9882, 0.9946, 1.0150, 0.9976, 1.0119, 1.0189, 0.9942, 0.9916,\n",
       "                      0.9993, 0.9976, 0.9954, 0.9947, 0.9913, 1.0028, 0.9955, 0.9819, 0.9823,\n",
       "                      0.9930, 0.9876, 0.9953, 1.0061, 1.0005, 0.9944, 0.9934, 1.0161, 1.0275,\n",
       "                      1.0084, 0.9947, 1.0058, 0.9925, 0.9903, 0.9894, 0.9820, 1.0157, 0.9826,\n",
       "                      0.9907, 0.9805, 0.9897, 0.9912, 0.9957, 0.9982, 1.0198, 0.9958, 0.9955,\n",
       "                      0.9824, 1.0163, 1.0141, 0.9866, 0.9900, 0.9929, 0.9858, 1.0017, 0.9979,\n",
       "                      1.0173, 0.9927, 0.9838, 1.0017, 1.0152, 0.9897, 1.0002, 0.9965, 1.0235,\n",
       "                      1.0176, 1.0006, 1.0080, 0.9940, 0.9863, 1.0173, 0.9971, 1.0018, 1.0071,\n",
       "                      1.0037, 0.9892, 0.9914, 1.0259, 0.9888, 1.0196, 0.9840, 0.9949, 1.0056,\n",
       "                      0.9872, 0.9934, 0.9894, 1.0017, 0.9912, 0.9960, 1.0094, 0.9894, 0.9852,\n",
       "                      0.9956, 0.9911, 1.0004, 0.9967, 0.9897, 1.0013, 1.0192, 1.0160, 1.0006,\n",
       "                      1.0042, 0.9928, 0.9965, 0.9990, 0.9890, 1.0024, 0.9837, 0.9877, 0.9941,\n",
       "                      1.0057, 0.9986, 1.0135, 0.9886, 0.9955, 0.9990, 0.9832, 0.9983, 0.9922,\n",
       "                      0.9939, 0.9928, 0.9933, 1.0187, 1.0299, 1.0014, 0.9838, 0.9956, 0.9977,\n",
       "                      0.9874, 0.9824, 1.0005, 1.0115, 1.0113, 0.9916, 1.0200, 1.0092, 0.9918,\n",
       "                      1.0001, 1.0248, 1.0142, 0.9883, 1.0064, 1.0124, 0.9887, 1.0244, 0.9918,\n",
       "                      0.9918, 1.0077, 1.0094, 0.9913, 0.9988, 0.9891, 0.9897, 0.9859, 0.9948,\n",
       "                      1.0137, 1.0043, 1.0137, 1.0076, 0.9905, 1.0164, 0.9791, 1.0069, 1.0284,\n",
       "                      1.0205, 0.9898, 0.9853, 0.9897, 0.9958, 1.0065, 0.9943, 0.9918, 0.9917,\n",
       "                      0.9995, 1.0165, 1.0276, 1.0193, 0.9969, 0.9987, 0.9986, 0.9959, 0.9921,\n",
       "                      0.9821, 1.0116, 0.9931, 0.9915, 0.9917, 0.9950, 0.9945, 0.9954, 0.9988,\n",
       "                      0.9896, 0.9931, 0.9857, 0.9860, 0.9901, 0.9967, 0.9953, 0.9847, 0.9919,\n",
       "                      0.9845, 0.9952, 1.0060, 0.9946, 1.0046, 0.9942, 0.9876, 0.9897, 0.9866,\n",
       "                      0.9912, 0.9813, 1.0085, 0.9774, 1.0098, 0.9965, 1.0255, 1.0020, 1.0227,\n",
       "                      0.9953, 1.0098, 1.0163, 0.9827, 0.9850, 1.0095, 0.9923, 0.9921, 0.9715,\n",
       "                      0.9948, 0.9862, 0.9936, 0.9934, 1.0032, 1.0190, 0.9997, 1.0245, 0.9894,\n",
       "                      1.0203, 0.9820, 0.9827, 0.9995, 1.0242, 0.9897, 1.0232, 0.9957, 0.9827,\n",
       "                      0.9972, 0.9932, 0.9978, 0.9987, 1.0096, 0.9808, 0.9848, 1.0247])),\n",
       "             ('decoders.6.bn3.bias',\n",
       "              tensor([-2.8187e-03,  6.2836e-03, -1.1542e-02, -8.9495e-04, -8.3388e-03,\n",
       "                       1.3811e-02,  1.1015e-02, -1.5034e-02, -7.7784e-03,  5.9825e-03,\n",
       "                       6.1571e-06, -2.0681e-02,  3.4834e-03,  3.2743e-03,  2.3859e-02,\n",
       "                      -3.0355e-03, -2.0108e-02,  8.8365e-04,  1.1618e-02,  1.1349e-02,\n",
       "                       1.2167e-02, -7.9871e-03,  2.2648e-02,  1.3183e-02,  4.2886e-03,\n",
       "                      -6.7275e-03,  3.2410e-02,  2.0902e-02, -4.8045e-03,  1.4745e-02,\n",
       "                      -4.0011e-03,  4.8746e-04,  2.7578e-03,  1.6823e-02, -1.8654e-03,\n",
       "                      -2.2142e-03,  6.3272e-04,  2.8362e-02,  2.2278e-02,  1.8579e-02,\n",
       "                       2.0582e-03, -1.0920e-03,  2.1190e-02, -2.1043e-03, -1.6337e-02,\n",
       "                       1.4944e-02,  2.2219e-02,  8.0174e-03,  1.0307e-02,  1.0098e-03,\n",
       "                       5.5723e-04,  1.8080e-02, -4.0068e-03, -9.2971e-03, -5.2817e-03,\n",
       "                      -1.1750e-02, -3.0684e-03,  1.2087e-03,  9.3589e-03, -8.3445e-03,\n",
       "                      -1.7055e-02,  3.3409e-02,  6.6268e-03,  1.5791e-02,  6.6410e-03,\n",
       "                       1.1336e-02,  2.4455e-02,  1.0022e-02,  6.8155e-04,  1.5719e-02,\n",
       "                      -2.2999e-03, -1.3796e-02,  7.2308e-03, -6.3442e-03,  1.5003e-02,\n",
       "                       1.9996e-02,  1.4505e-02,  2.2322e-04,  1.9560e-03,  1.5447e-02,\n",
       "                      -1.4252e-02, -5.5661e-03,  1.5010e-02,  4.3705e-03, -1.9822e-03,\n",
       "                       2.0581e-03, -2.2384e-03,  4.5410e-02,  2.1513e-04,  1.2297e-02,\n",
       "                       1.4909e-02, -2.2382e-04,  2.9479e-03,  3.0247e-04,  3.9811e-03,\n",
       "                      -1.2176e-03, -2.1936e-05,  1.4819e-02, -3.5093e-03,  1.0777e-02,\n",
       "                       2.8719e-03,  1.5346e-03,  3.7821e-02,  1.5510e-02,  1.6708e-02,\n",
       "                       1.0506e-02, -9.5128e-03, -8.1046e-04, -1.2951e-03,  2.5398e-02,\n",
       "                      -4.6289e-03,  5.1794e-03,  4.5881e-02,  3.2314e-03, -1.0748e-02,\n",
       "                       3.2053e-02,  4.0609e-02, -2.9729e-03, -4.8719e-03,  2.8826e-03,\n",
       "                       2.2231e-02,  9.6315e-03,  8.3994e-03,  1.5527e-02,  9.8533e-03,\n",
       "                       3.6014e-03,  2.5155e-04, -1.8910e-03, -3.1635e-04,  1.6718e-02,\n",
       "                       1.9426e-02, -1.0525e-02, -4.6338e-03,  2.7525e-03,  1.4563e-02,\n",
       "                       1.9483e-02,  3.0898e-02,  3.3911e-04,  2.1873e-02,  1.9016e-02,\n",
       "                       8.4712e-03,  1.0303e-02,  3.5493e-03,  1.5528e-02,  3.0886e-02,\n",
       "                       5.9261e-03, -5.5392e-03,  1.5546e-02,  1.6250e-03, -4.4807e-03,\n",
       "                       4.0185e-03,  8.9378e-03,  1.2062e-02, -4.7990e-04,  1.9219e-03,\n",
       "                       2.2121e-02,  4.1378e-02,  7.9495e-03,  8.0411e-03, -5.6704e-03,\n",
       "                       1.9361e-02,  9.2632e-03,  2.7846e-02,  4.3196e-03,  2.0402e-03,\n",
       "                       1.5536e-02,  2.0002e-02,  3.0171e-02, -1.4862e-02,  3.5048e-03,\n",
       "                       1.3942e-02,  1.4543e-02,  6.6059e-03,  2.2655e-02, -6.1898e-05,\n",
       "                       9.5354e-03, -6.6003e-03,  4.6488e-03,  2.1324e-03,  6.6623e-03,\n",
       "                      -1.3026e-02,  8.3558e-03, -1.0288e-03,  1.5305e-03, -2.4519e-03,\n",
       "                       1.6965e-03,  3.4980e-02,  1.0151e-03, -1.0278e-03,  4.7027e-04,\n",
       "                       9.3341e-03,  3.8880e-03,  2.8758e-02,  3.8408e-03,  4.3822e-03,\n",
       "                       1.1878e-02, -8.1878e-03,  1.1364e-02,  8.3608e-03,  2.2648e-02,\n",
       "                      -4.0138e-03,  1.9662e-02, -6.6414e-03, -5.9583e-03,  1.3055e-03,\n",
       "                      -3.1627e-03, -5.6524e-03,  8.9131e-03,  1.8818e-02,  5.9191e-03,\n",
       "                       2.9324e-02,  1.4588e-02,  2.4361e-02,  1.6768e-02,  2.1287e-02,\n",
       "                       3.3251e-02,  1.2546e-02, -7.5034e-03,  1.6396e-02, -3.6850e-04,\n",
       "                       2.0061e-02,  3.8994e-03, -1.3370e-02,  1.1851e-02,  3.9548e-03,\n",
       "                       1.0980e-02,  1.7876e-02, -2.2133e-03,  2.1254e-02,  1.8835e-02,\n",
       "                       2.3455e-02, -5.2262e-03,  2.9698e-03,  5.7737e-03, -7.8737e-03,\n",
       "                      -2.1148e-03, -8.0261e-03,  9.1274e-03, -1.5060e-02,  1.7696e-03,\n",
       "                       5.0971e-02, -5.6532e-03,  4.5699e-03,  4.9882e-02,  7.0913e-03,\n",
       "                       5.4807e-03,  3.3971e-03, -8.9290e-03,  5.3236e-03, -4.5018e-05,\n",
       "                       7.3108e-03,  1.7473e-02, -9.1123e-03,  3.3057e-03, -7.7555e-03,\n",
       "                       6.5032e-04,  2.0545e-02, -3.0785e-03,  1.2896e-02, -1.7845e-02,\n",
       "                       1.2681e-02,  5.6035e-02, -4.0051e-03,  3.3985e-04, -8.9899e-03,\n",
       "                       1.7056e-02,  1.7629e-03, -2.7055e-03,  2.9893e-03,  5.8779e-03,\n",
       "                      -3.8111e-03,  4.9759e-03, -2.6062e-03,  1.4998e-02,  5.3196e-03,\n",
       "                       2.5501e-02, -5.3559e-03, -5.0633e-03, -1.5505e-03, -1.4258e-03,\n",
       "                       9.2925e-03,  1.4642e-02, -1.1661e-03,  1.4791e-02, -9.7176e-03,\n",
       "                       8.3594e-03, -2.9249e-03,  3.1809e-03, -9.8077e-04,  2.8621e-02,\n",
       "                       1.4589e-02, -1.0165e-02, -1.0125e-02,  1.9430e-05,  1.0073e-03,\n",
       "                       6.1979e-04,  1.8197e-02, -1.1396e-02, -1.6989e-02, -1.2116e-02,\n",
       "                      -1.4731e-02,  8.0385e-03,  7.1565e-03,  3.7010e-02, -2.9470e-03,\n",
       "                       2.0870e-02,  1.8846e-03,  4.0225e-02,  7.5961e-03, -1.5564e-02,\n",
       "                       1.8465e-02, -7.6296e-03,  2.0008e-03,  1.5139e-03, -1.7441e-03,\n",
       "                       1.0798e-02,  1.5155e-02, -1.6315e-02,  1.6540e-02, -1.0586e-02,\n",
       "                      -6.4115e-03,  6.4543e-03,  5.0011e-03, -8.2444e-03,  4.2759e-02,\n",
       "                       2.5743e-02,  1.2078e-02,  6.4839e-03,  5.1920e-05, -5.6445e-03,\n",
       "                       1.8339e-02,  2.6195e-02, -6.7154e-03,  2.4477e-03,  8.3364e-03,\n",
       "                       7.9257e-03, -2.2403e-03, -5.1047e-03,  2.8224e-02,  8.0261e-03,\n",
       "                       3.0521e-02, -1.3713e-02, -7.3173e-03,  8.5889e-03,  1.7354e-03,\n",
       "                       4.6178e-03,  8.6782e-03,  1.0952e-02, -5.3219e-03,  6.3212e-03,\n",
       "                       1.4321e-03, -1.4992e-03, -7.9248e-04,  9.9809e-03,  1.6623e-02,\n",
       "                      -9.1917e-03, -1.8126e-03,  1.1433e-02,  1.3297e-02,  2.7250e-02,\n",
       "                       2.1556e-03,  1.3084e-02,  6.4036e-03,  2.9844e-03,  2.7091e-03,\n",
       "                       5.7106e-03, -6.8328e-03, -1.0021e-03,  8.4075e-03, -7.9180e-03,\n",
       "                       2.6163e-03, -5.3666e-03,  8.3279e-03,  3.3501e-03,  2.6150e-02,\n",
       "                       3.9070e-03,  8.6068e-06,  6.6533e-03, -5.2019e-06,  2.8786e-03,\n",
       "                      -9.7516e-03, -1.0313e-03, -5.3096e-03,  3.1627e-02, -2.0914e-02,\n",
       "                      -5.1217e-03,  1.7887e-02,  5.0254e-03, -1.4105e-02,  1.6339e-02,\n",
       "                      -2.6878e-03, -1.0449e-02,  5.2045e-03, -4.7038e-03,  6.6811e-03,\n",
       "                       2.1716e-03, -6.3693e-03, -2.9563e-03,  1.5636e-02, -5.1446e-03,\n",
       "                      -3.6892e-03,  6.5012e-03,  1.7296e-03,  6.6058e-04,  2.0825e-02,\n",
       "                       3.4340e-02,  1.7682e-03, -6.7921e-03,  2.4206e-02, -1.1685e-02,\n",
       "                      -1.4905e-03, -1.2735e-02, -8.7535e-03,  2.5039e-02, -2.2615e-03,\n",
       "                       3.1286e-02,  7.1540e-04,  2.3540e-02,  1.6079e-02, -2.4694e-03,\n",
       "                      -9.1501e-03,  9.6998e-04, -2.5352e-04,  4.7471e-03,  6.9679e-03,\n",
       "                      -9.2330e-03,  1.1252e-03,  8.7238e-03, -7.5681e-03,  1.3824e-02,\n",
       "                       2.2294e-02, -5.9490e-03,  3.2152e-02,  6.7222e-03,  6.8653e-03,\n",
       "                       9.5948e-05,  7.4629e-03,  5.0587e-03, -1.4436e-02,  1.8621e-02,\n",
       "                       1.0421e-02,  1.6136e-02,  2.5275e-02,  4.2406e-03, -1.5591e-02,\n",
       "                       1.1839e-02, -6.2057e-03,  6.5202e-03,  1.6564e-02,  2.3631e-02,\n",
       "                      -3.9218e-03,  6.8741e-03, -6.3750e-04,  1.4166e-02, -1.7519e-02,\n",
       "                       7.2216e-03,  9.9499e-03, -5.4060e-03,  1.3101e-02,  4.7887e-03,\n",
       "                       1.4852e-02, -1.3169e-03, -1.4793e-02, -1.5273e-02,  3.6589e-03,\n",
       "                       1.4315e-02,  1.5283e-02, -2.9263e-03,  4.4912e-03, -4.6440e-03,\n",
       "                       6.5631e-03,  2.4207e-02,  2.3295e-03,  2.4031e-02, -1.7228e-03,\n",
       "                       2.9227e-02,  3.7584e-03,  4.9837e-03,  7.2396e-03,  5.4653e-03,\n",
       "                       6.5565e-03,  2.1022e-02, -8.5707e-03,  1.4231e-03,  1.0963e-02,\n",
       "                      -2.8574e-02,  4.5159e-04,  1.2596e-03,  6.0403e-03, -2.4535e-03,\n",
       "                       1.2635e-02,  7.1098e-03, -1.9751e-03, -3.5246e-03,  2.2309e-02,\n",
       "                       2.2769e-02, -2.5530e-02,  6.9769e-03,  7.5386e-03,  1.7727e-02,\n",
       "                      -3.2056e-03,  1.7947e-02,  2.2262e-02, -5.1427e-03,  1.3604e-02,\n",
       "                      -9.6841e-03,  2.8489e-02, -1.3608e-02,  1.7617e-02, -4.3044e-03,\n",
       "                       7.1253e-03,  2.5433e-03])),\n",
       "             ('decoders.6.bn3.running_mean',\n",
       "              tensor([-0.2692,  0.4008,  0.0048, -0.3089, -0.4239,  0.0861, -0.3663,  0.4177,\n",
       "                      -0.2915,  0.2091, -0.2050,  0.3632,  0.4165,  0.1259, -0.2406,  0.1970,\n",
       "                       0.1759,  0.2457,  0.0945, -0.1762, -0.0641, -0.1620, -0.1947, -0.1434,\n",
       "                       0.0823, -0.0691, -0.1381, -0.2259,  0.2796, -0.0800, -0.3374,  0.1473,\n",
       "                       0.4017,  0.1157, -0.0447, -0.2325,  0.2048, -0.2105, -0.1966, -0.0601,\n",
       "                       0.3056,  0.2181,  0.1447, -0.3817, -0.0441, -0.3560, -0.5911,  0.4270,\n",
       "                      -0.1880,  0.2762, -0.0389,  0.4278, -0.4147,  0.3480, -0.3638,  0.2244,\n",
       "                      -0.2862,  0.0691, -0.4999, -0.1846, -0.2495, -0.1839, -0.1579, -0.2344,\n",
       "                      -0.2637, -0.0614, -0.0988, -0.1599,  0.2778, -0.0733, -0.0421,  0.1555,\n",
       "                       0.0493,  0.2050, -0.1253, -0.2071,  0.0275, -0.4005,  0.1711, -0.1982,\n",
       "                      -0.2568, -0.0758, -0.3037, -0.2808, -0.0105,  0.0117, -0.3515, -0.1894,\n",
       "                      -0.0407,  0.4243, -0.5456, -0.2895, -0.0849, -0.1776,  0.0461,  0.3759,\n",
       "                      -0.1137,  0.2688, -0.1867,  0.0346,  0.3619, -0.2189, -0.3651, -0.2447,\n",
       "                      -0.5403,  0.2032, -0.1197,  0.2263, -0.2542, -0.0593,  0.3099, -0.2717,\n",
       "                      -0.4131, -0.1024,  0.2782, -0.0715, -0.1529, -0.3585, -0.2141, -0.0280,\n",
       "                      -0.0538, -0.0790,  0.1903, -0.6620, -0.3409, -0.2242,  0.1888,  0.1782,\n",
       "                      -0.2285, -0.4504, -0.2423,  0.0056, -0.3742,  0.4970, -0.2853, -0.0827,\n",
       "                      -0.0442,  0.0300, -0.2961, -0.1052, -0.1901,  0.0140, -0.3161,  0.0107,\n",
       "                      -0.0501, -0.0038, -0.1373, -0.0608, -0.2388,  0.4600,  0.3576, -0.1626,\n",
       "                      -0.0085,  0.3875,  0.1149,  0.2473, -0.2388,  0.2424,  0.2224,  0.1108,\n",
       "                       0.1665, -0.0384, -0.4611,  0.0734,  0.0355,  0.1194, -0.1577,  0.1917,\n",
       "                      -0.0495, -0.3352, -0.1183, -0.1855, -0.2880, -0.1290, -0.1325,  0.1905,\n",
       "                       0.2731, -0.0820, -0.4156,  0.2660,  0.3795,  0.1281,  0.4757,  0.1615,\n",
       "                      -0.1878,  0.0599,  0.0211,  0.1348,  0.2254,  0.1219,  0.1655, -0.0777,\n",
       "                      -0.3788, -0.0451,  0.3004, -0.1601,  0.3249,  0.0803, -0.3088, -0.0729,\n",
       "                      -0.0280,  0.1788,  0.0205, -0.0997,  0.0654,  0.0928,  0.6529, -0.0774,\n",
       "                      -0.3679,  0.0646,  0.0380, -0.2491, -0.4638, -0.1491, -0.1340, -0.2342,\n",
       "                       0.0592,  0.0218, -0.3004, -0.1981, -0.0646, -0.0912,  0.3046, -0.4181,\n",
       "                       0.3839, -0.0620,  0.1959,  0.4433, -0.2205, -0.3909,  0.0216,  0.2480,\n",
       "                       0.1060,  0.0040, -0.0989, -0.3439,  0.0148, -0.3439,  0.1283,  0.0203,\n",
       "                      -0.6276, -0.0598,  0.1565, -0.1048,  0.1260, -0.0169,  0.4975,  0.1671,\n",
       "                       0.0099,  0.2357, -0.1150, -0.0236, -0.1771, -0.1523, -0.4739, -0.1091,\n",
       "                      -0.2451,  0.1403, -0.3986,  0.0440, -0.4260, -0.3615, -0.1111, -0.1539,\n",
       "                       0.2564, -0.2865,  0.0170,  0.1201, -0.5638, -0.0333,  0.0290,  0.0455,\n",
       "                      -0.0547, -0.2754,  0.0525, -0.6830, -0.0526,  0.0095,  0.0119,  0.0196,\n",
       "                      -0.2544, -0.2073, -0.2146, -0.1489,  0.4499, -0.3175,  0.3310,  0.2837,\n",
       "                      -0.0411, -0.1873,  0.0037,  0.1754, -0.0976,  0.0463, -0.1427,  0.3560,\n",
       "                      -0.3537, -0.2416, -0.3606, -0.1701, -0.3110,  0.0801, -0.1934, -0.2099,\n",
       "                       0.1484, -0.2367, -0.4294, -0.1983,  0.1802,  0.0287, -0.3251, -0.2191,\n",
       "                      -0.0166, -0.1915, -0.4475, -0.1212, -0.3038, -0.1687,  0.0014,  0.3325,\n",
       "                      -0.0489,  0.3149, -0.2366,  0.5264, -0.3280,  0.0653, -0.3024,  0.1579,\n",
       "                      -0.1095,  0.4584,  0.1810, -0.5652,  0.2816, -0.3314, -0.3242,  0.2938,\n",
       "                       0.2860, -0.0283, -0.0011, -0.4035, -0.2009,  0.2764, -0.2616,  0.1351,\n",
       "                      -0.0284,  0.4027, -0.3054, -0.3827,  0.1421,  0.0489,  0.2255, -0.2102,\n",
       "                      -0.1972,  0.1335, -0.3125, -0.0135, -0.1083,  0.2040, -0.1240, -0.2766,\n",
       "                      -0.3528, -0.3205,  0.1876, -0.3892,  0.0035,  0.0230, -0.0627, -0.0029,\n",
       "                      -0.1569,  0.0298, -0.2286,  0.5054, -0.3558, -0.0423, -0.3677, -0.0662,\n",
       "                      -0.0666, -0.3113, -0.4403, -0.0102,  0.1930,  0.1815,  0.4217, -0.0084,\n",
       "                      -0.0021, -0.1139,  0.1017, -0.3512, -0.0721, -0.2492,  0.2775,  0.0537,\n",
       "                      -0.0063,  0.1270,  0.0822, -0.0456, -0.4073,  0.4568,  0.0549,  0.2770,\n",
       "                       0.2877,  0.1893, -0.3413,  0.2638, -0.2916, -0.1505,  0.3255,  0.2296,\n",
       "                      -0.1974, -0.1635, -0.1954,  0.1904, -0.2533, -0.0328,  0.2007, -0.2485,\n",
       "                      -0.0573, -0.5500, -0.4500,  0.1122, -0.1181,  0.4341,  0.4363,  0.1194,\n",
       "                      -0.3630, -0.1941, -0.2441,  0.0328, -0.0110,  0.1328, -0.2889,  0.0860,\n",
       "                      -0.1029, -0.0333,  0.5529,  0.2057, -0.0899,  0.0063, -0.0196, -0.2821,\n",
       "                      -0.0085, -0.0445,  0.0879, -0.4747,  0.1108, -0.2508,  0.2423,  0.3043,\n",
       "                      -0.0602, -0.4112,  0.1187, -0.0993, -0.0145, -0.3322,  0.0233, -0.3061,\n",
       "                      -0.0566,  0.0566, -0.2365, -0.2793, -0.2693,  0.4909, -0.0094,  0.4605,\n",
       "                      -0.3558, -0.2043, -0.2995, -0.1608, -0.2410, -0.1281,  0.1841, -0.4742,\n",
       "                       0.1015, -0.0040,  0.2666,  0.0009,  0.1932,  0.1464,  0.2211,  0.0520,\n",
       "                      -0.5190, -0.3334,  0.7228,  0.0132, -0.2511,  0.1416,  0.2263, -0.1144,\n",
       "                       0.0676, -0.2658, -0.0239,  0.1469, -0.1139,  0.3439, -0.0182,  0.2549,\n",
       "                       0.1717, -0.0892,  0.0724, -0.1444, -0.2594,  0.2377, -0.2307,  0.0214,\n",
       "                      -0.1242,  0.2308, -0.3084,  0.2643, -0.1055, -0.1276, -0.0293, -0.0018])),\n",
       "             ('decoders.6.bn3.running_var',\n",
       "              tensor([0.3082, 1.4166, 1.3414, 0.2242, 0.3011, 0.3986, 0.5837, 0.3799, 0.9180,\n",
       "                      2.5929, 0.4735, 1.9873, 1.7230, 0.4143, 0.6976, 0.7399, 0.2787, 1.1250,\n",
       "                      0.6010, 0.9617, 1.2044, 0.4927, 0.8108, 0.5849, 0.3655, 0.2657, 0.7151,\n",
       "                      0.2705, 1.1030, 0.2900, 0.3836, 1.1257, 0.9435, 1.0400, 0.4034, 0.3230,\n",
       "                      2.2964, 0.5869, 0.6079, 0.8840, 0.6602, 0.6806, 0.5531, 0.0768, 0.4273,\n",
       "                      0.8801, 1.0618, 1.0118, 0.5220, 1.0904, 0.3206, 1.9371, 0.1876, 1.3014,\n",
       "                      0.6896, 0.6745, 0.1330, 0.6128, 0.4701, 0.3152, 0.6204, 0.8380, 0.3743,\n",
       "                      0.6246, 0.4586, 1.2344, 0.7997, 0.3439, 0.9620, 0.3339, 0.4311, 0.5618,\n",
       "                      2.3610, 1.1422, 0.2909, 0.4812, 0.7999, 0.0930, 1.0861, 1.0164, 0.4265,\n",
       "                      1.1748, 0.6152, 0.1610, 1.7097, 2.1119, 0.4000, 1.5559, 0.3726, 1.8351,\n",
       "                      0.7640, 0.5110, 0.2556, 0.1642, 1.6345, 1.7500, 0.1496, 1.2243, 0.4845,\n",
       "                      0.8798, 1.2940, 1.3937, 0.6976, 0.7113, 0.6360, 2.0738, 1.1387, 0.7075,\n",
       "                      0.4598, 0.2206, 0.9320, 1.0608, 0.4502, 0.5441, 0.7178, 0.6660, 0.6270,\n",
       "                      0.1618, 0.4608, 0.3593, 0.7931, 0.9625, 3.0196, 0.5585, 0.3775, 0.3479,\n",
       "                      1.4582, 0.5426, 0.8182, 0.4840, 0.6504, 0.4033, 0.5025, 1.0521, 0.3014,\n",
       "                      0.7951, 1.1012, 0.5015, 1.0128, 0.8823, 0.3852, 0.8062, 0.2563, 0.3985,\n",
       "                      0.8086, 0.6848, 0.3785, 0.4939, 0.7470, 3.2287, 2.8013, 0.6256, 1.7438,\n",
       "                      1.1830, 1.8176, 1.7149, 1.5498, 1.6296, 1.2040, 0.5232, 1.5064, 1.5581,\n",
       "                      0.5579, 0.4806, 2.0600, 0.8727, 0.9085, 0.6156, 0.3483, 0.3452, 0.6395,\n",
       "                      0.4702, 0.3676, 0.9632, 0.5226, 1.5685, 1.5217, 0.2417, 0.1451, 1.6907,\n",
       "                      1.0459, 0.4118, 0.5547, 2.9549, 0.2726, 1.2000, 0.9387, 0.6524, 0.7436,\n",
       "                      1.1226, 1.4034, 0.2769, 1.0109, 0.5575, 1.3391, 0.6402, 1.2732, 3.6170,\n",
       "                      0.4002, 0.7485, 0.9416, 2.0475, 1.4509, 0.7363, 0.5793, 2.3121, 2.4412,\n",
       "                      1.7070, 0.6344, 1.6824, 0.5847, 0.5529, 0.8232, 0.3790, 0.6712, 0.9656,\n",
       "                      1.1644, 0.5705, 0.5597, 0.3075, 0.7666, 0.2079, 1.7351, 0.9190, 2.1885,\n",
       "                      0.5066, 0.6803, 1.0658, 1.3309, 0.6436, 0.9146, 1.2097, 0.6359, 1.6845,\n",
       "                      0.4354, 0.6286, 0.1569, 1.1303, 0.3868, 1.5048, 1.1121, 0.3323, 1.5375,\n",
       "                      1.1184, 1.2259, 1.1992, 0.4886, 1.4170, 0.7499, 0.6148, 0.6638, 0.7764,\n",
       "                      0.6170, 0.6257, 0.4000, 0.4195, 0.6144, 1.4590, 0.4256, 0.5749, 1.7959,\n",
       "                      0.7723, 0.8473, 0.3931, 2.1323, 0.4525, 1.4016, 1.9444, 0.4547, 0.6637,\n",
       "                      1.6139, 1.7740, 0.6708, 1.0666, 0.8803, 1.5651, 0.2354, 0.6328, 0.5112,\n",
       "                      0.7210, 2.0883, 0.6672, 0.8009, 0.6198, 0.6093, 0.4229, 2.0349, 1.3379,\n",
       "                      1.6518, 0.7305, 1.3775, 0.5197, 1.0602, 0.4409, 0.5242, 1.6547, 0.6879,\n",
       "                      0.2273, 0.5430, 0.4435, 0.0752, 1.3087, 0.6686, 0.5072, 0.4263, 0.9154,\n",
       "                      0.8013, 1.5205, 2.7223, 0.3356, 1.3059, 0.5743, 0.4806, 0.6688, 0.3837,\n",
       "                      1.3322, 0.6798, 0.2999, 0.8445, 2.1367, 0.1568, 0.7664, 0.7299, 1.1665,\n",
       "                      0.5620, 0.6545, 0.1122, 1.0310, 0.1804, 1.0881, 0.6004, 0.7844, 0.5620,\n",
       "                      0.2507, 1.5086, 0.5916, 1.0850, 1.0749, 1.4613, 0.4776, 0.6661, 0.4396,\n",
       "                      0.1788, 0.5094, 0.7073, 0.9008, 0.3668, 0.5572, 1.6313, 0.9079, 0.6937,\n",
       "                      0.2115, 0.2060, 0.8680, 0.8194, 0.4456, 0.8024, 1.8286, 1.0438, 1.2779,\n",
       "                      0.1512, 0.5330, 1.0967, 0.3780, 0.8955, 0.9832, 0.4464, 0.2285, 0.2480,\n",
       "                      1.8000, 0.3193, 0.8749, 0.4409, 0.7796, 0.8080, 0.5841, 0.3805, 0.4841,\n",
       "                      0.1983, 0.2262, 0.5242, 1.8503, 1.3214, 0.4536, 0.8179, 0.5589, 0.8308,\n",
       "                      0.1790, 0.2655, 0.4371, 1.6532, 1.8874, 0.7037, 3.3641, 1.4858, 0.4141,\n",
       "                      0.1021, 2.4447, 1.2061, 0.4317, 1.1920, 2.0839, 0.4463, 2.0011, 0.4469,\n",
       "                      1.0041, 0.9267, 1.3614, 0.7776, 1.5718, 0.3961, 0.6523, 0.2829, 0.9351,\n",
       "                      1.4941, 0.8974, 2.4569, 0.7041, 0.3995, 1.4076, 0.4431, 1.5069, 1.0296,\n",
       "                      1.7604, 0.4744, 0.0902, 0.2745, 1.3303, 1.0344, 0.3810, 0.4603, 0.5430,\n",
       "                      0.6686, 1.7594, 1.2394, 1.4900, 0.6910, 0.5947, 0.2487, 1.3854, 0.3294,\n",
       "                      0.6197, 0.9306, 0.1780, 0.4885, 0.3531, 0.6627, 0.5904, 0.5769, 0.4521,\n",
       "                      0.4693, 0.4812, 0.6492, 0.2709, 0.4929, 0.2664, 1.1807, 0.3235, 0.5117,\n",
       "                      0.2826, 0.6745, 0.7403, 0.8008, 0.8877, 0.6801, 1.1859, 0.6209, 0.9065,\n",
       "                      0.7569, 0.1616, 1.4360, 0.6584, 1.1365, 1.1440, 1.3993, 0.8850, 1.1111,\n",
       "                      0.3249, 1.8422, 1.4964, 0.6997, 1.0439, 0.6509, 0.8733, 0.4394, 0.4953,\n",
       "                      1.3327, 0.3353, 0.6924, 0.2591, 0.4092, 2.8957, 0.6734, 1.5765, 0.7982,\n",
       "                      1.5245, 0.5280, 0.5209, 0.9786, 1.6576, 0.6434, 2.0346, 0.9087, 0.1369,\n",
       "                      0.5878, 0.7524, 0.7077, 0.7674, 0.5100, 0.7663, 0.6540, 1.3699])),\n",
       "             ('decoders.6.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense4.weight',\n",
       "              tensor([[-0.0254, -0.0027, -0.0446,  ..., -0.0382, -0.0300, -0.0391],\n",
       "                      [ 0.0044, -0.0128,  0.0052,  ...,  0.0440,  0.0388, -0.0053],\n",
       "                      [ 0.0349, -0.0045, -0.0131,  ..., -0.0222, -0.0310, -0.0547],\n",
       "                      ...,\n",
       "                      [ 0.0088,  0.0187,  0.0232,  ..., -0.0317,  0.0398,  0.0200],\n",
       "                      [ 0.0049, -0.0169, -0.0503,  ..., -0.0246,  0.0128, -0.0106],\n",
       "                      [ 0.0413, -0.0353,  0.0167,  ...,  0.0247, -0.0325, -0.0125]])),\n",
       "             ('decoders.6.bn4.weight',\n",
       "              tensor([1.0264, 1.0258, 1.0251, 1.0260, 1.0255, 1.0234, 1.0265, 1.0289, 1.0257,\n",
       "                      1.0252, 1.0281, 1.0277, 1.0263, 1.0237, 1.0248, 1.0245, 1.0289, 1.0281,\n",
       "                      1.0254, 1.0287, 1.0263, 1.0260, 1.0249, 1.0263, 1.0261, 1.0285, 1.0265,\n",
       "                      1.0273, 1.0307, 1.0255, 1.0236, 1.0241, 1.0278, 1.0266, 1.0268, 1.0216,\n",
       "                      1.0273, 1.0248, 1.0283, 1.0264, 1.0283, 1.0251, 1.0270, 1.0248, 1.0233,\n",
       "                      1.0248, 1.0280, 1.0250, 1.0284, 1.0248, 1.0260, 1.0244, 1.0289, 1.0300,\n",
       "                      1.0264, 1.0266, 1.0248, 1.0262, 1.0260, 1.0286, 1.0260, 1.0272, 1.0278,\n",
       "                      1.0272, 1.0253, 1.0243, 1.0262, 1.0261, 1.0236, 1.0261, 1.0259, 1.0252,\n",
       "                      1.0243, 1.0284, 1.0261, 1.0243, 1.0269, 1.0277, 1.0243, 1.0283, 1.0258,\n",
       "                      1.0266, 1.0273, 1.0231, 1.0250, 1.0299, 1.0274, 1.0247, 1.0254, 1.0287,\n",
       "                      1.0259, 1.0281, 1.0258, 1.0250, 1.0295, 1.0247, 1.0231, 1.0247, 1.0249,\n",
       "                      1.0252, 1.0269, 1.0276, 1.0267, 1.0267, 1.0274, 1.0294, 1.0240, 1.0265,\n",
       "                      1.0296, 1.0267, 1.0246, 1.0259, 1.0286, 1.0283, 1.0251, 1.0252, 1.0272,\n",
       "                      1.0252, 1.0243, 1.0288, 1.0245, 1.0254, 1.0240, 1.0266, 1.0305, 1.0253,\n",
       "                      1.0270, 1.0278, 1.0297, 1.0266, 1.0248, 1.0243, 1.0263, 1.0250, 1.0269,\n",
       "                      1.0266, 1.0287, 1.0282, 1.0230, 1.0229, 1.0269, 1.0242, 1.0249, 1.0260,\n",
       "                      1.0265, 1.0247, 1.0263, 1.0283, 1.0233, 1.0252, 1.0281, 1.0257, 1.0258,\n",
       "                      1.0253, 1.0304, 1.0297, 1.0258, 1.0274, 1.0274, 1.0232, 1.0270, 1.0280,\n",
       "                      1.0254, 1.0249, 1.0260, 1.0265, 1.0259, 1.0275, 1.0259, 1.0243, 1.0269,\n",
       "                      1.0266, 1.0266, 1.0252, 1.0280, 1.0269, 1.0269, 1.0254, 1.0296, 1.0259,\n",
       "                      1.0260, 1.0266, 1.0250, 1.0254, 1.0260, 1.0250, 1.0262, 1.0249, 1.0274,\n",
       "                      1.0281, 1.0263, 1.0242, 1.0273, 1.0245, 1.0267, 1.0278, 1.0238, 1.0335,\n",
       "                      1.0244, 1.0244, 1.0308, 1.0277, 1.0265, 1.0249, 1.0265, 1.0248, 1.0228,\n",
       "                      1.0266, 1.0210, 1.0251, 1.0286, 1.0296, 1.0277, 1.0236, 1.0253, 1.0257,\n",
       "                      1.0263, 1.0271, 1.0269, 1.0269, 1.0267, 1.0257, 1.0241, 1.0238, 1.0243,\n",
       "                      1.0274, 1.0271, 1.0252, 1.0244, 1.0246, 1.0241, 1.0278, 1.0246, 1.0278,\n",
       "                      1.0280, 1.0264, 1.0268, 1.0288, 1.0222, 1.0271, 1.0255, 1.0281, 1.0247,\n",
       "                      1.0252, 1.0252, 1.0254, 1.0239, 1.0269, 1.0292, 1.0240, 1.0268, 1.0275,\n",
       "                      1.0254, 1.0282, 1.0271, 1.0257, 1.0248, 1.0233, 1.0268, 1.0272, 1.0287,\n",
       "                      1.0247, 1.0257, 1.0274, 1.0271, 1.0271, 1.0276, 1.0281, 1.0260, 1.0248,\n",
       "                      1.0257, 1.0256, 1.0311, 1.0260, 1.0266, 1.0271, 1.0249, 1.0267, 1.0285,\n",
       "                      1.0275, 1.0261, 1.0244, 1.0275, 1.0262, 1.0265, 1.0276, 1.0271, 1.0252,\n",
       "                      1.0237, 1.0260, 1.0285, 1.0257, 1.0224, 1.0248, 1.0244, 1.0269, 1.0267,\n",
       "                      1.0301, 1.0263, 1.0279, 1.0248, 1.0269, 1.0267, 1.0249, 1.0251, 1.0262,\n",
       "                      1.0266, 1.0255, 1.0275, 1.0271, 1.0247, 1.0256, 1.0246, 1.0271, 1.0283,\n",
       "                      1.0253, 1.0248, 1.0246, 1.0266, 1.0262, 1.0280, 1.0268, 1.0243, 1.0263,\n",
       "                      1.0255, 1.0288, 1.0249, 1.0273, 1.0257, 1.0252, 1.0284, 1.0276, 1.0239,\n",
       "                      1.0283, 1.0256, 1.0257, 1.0292, 1.0252, 1.0272, 1.0246, 1.0250, 1.0268,\n",
       "                      1.0256, 1.0276, 1.0257, 1.0276, 1.0296, 1.0258, 1.0278, 1.0251, 1.0244,\n",
       "                      1.0230, 1.0222, 1.0279, 1.0285, 1.0268, 1.0245, 1.0265, 1.0247, 1.0250,\n",
       "                      1.0290, 1.0287, 1.0284, 1.0243, 1.0251, 1.0263, 1.0242, 1.0263, 1.0271,\n",
       "                      1.0253, 1.0270, 1.0285, 1.0255, 1.0274, 1.0248, 1.0235, 1.0244, 1.0267,\n",
       "                      1.0256, 1.0265, 1.0272, 1.0274, 1.0251, 1.0253, 1.0274, 1.0242, 1.0250,\n",
       "                      1.0257, 1.0266, 1.0252, 1.0232, 1.0233, 1.0247, 1.0276, 1.0264, 1.0274,\n",
       "                      1.0284, 1.0267, 1.0244, 1.0257, 1.0277, 1.0255, 1.0256, 1.0273, 1.0265,\n",
       "                      1.0242, 1.0259, 1.0273, 1.0259, 1.0258, 1.0285, 1.0275, 1.0237, 1.0258,\n",
       "                      1.0297, 1.0274, 1.0268, 1.0260, 1.0282, 1.0246, 1.0258, 1.0271, 1.0249,\n",
       "                      1.0247, 1.0266, 1.0263, 1.0280, 1.0250, 1.0291, 1.0245, 1.0264, 1.0259,\n",
       "                      1.0254, 1.0254, 1.0272, 1.0258, 1.0249, 1.0277, 1.0272, 1.0263, 1.0259,\n",
       "                      1.0280, 1.0267, 1.0250, 1.0256, 1.0252, 1.0255, 1.0269, 1.0252, 1.0265,\n",
       "                      1.0277, 1.0304, 1.0238, 1.0308, 1.0270, 1.0272, 1.0256, 1.0296, 1.0243,\n",
       "                      1.0246, 1.0265, 1.0238, 1.0263, 1.0243, 1.0250, 1.0249, 1.0249, 1.0287,\n",
       "                      1.0281, 1.0256, 1.0262, 1.0288, 1.0283, 1.0277, 1.0248, 1.0255, 1.0249,\n",
       "                      1.0303, 1.0252, 1.0255, 1.0261, 1.0265, 1.0272, 1.0267, 1.0252, 1.0241,\n",
       "                      1.0262, 1.0271, 1.0271, 1.0263, 1.0240, 1.0245, 1.0250, 1.0271, 1.0266,\n",
       "                      1.0254, 1.0259, 1.0249, 1.0282, 1.0267, 1.0275, 1.0273, 1.0313, 1.0250,\n",
       "                      1.0239, 1.0263, 1.0281, 1.0278, 1.0289, 1.0244, 1.0261, 1.0268])),\n",
       "             ('decoders.6.bn4.bias',\n",
       "              tensor([0.0318, 0.0354, 0.0347, 0.0310, 0.0346, 0.0340, 0.0350, 0.0376, 0.0351,\n",
       "                      0.0351, 0.0378, 0.0368, 0.0356, 0.0344, 0.0340, 0.0344, 0.0374, 0.0374,\n",
       "                      0.0353, 0.0378, 0.0348, 0.0310, 0.0351, 0.0354, 0.0355, 0.0376, 0.0344,\n",
       "                      0.0349, 0.0364, 0.0340, 0.0340, 0.0345, 0.0316, 0.0368, 0.0349, 0.0326,\n",
       "                      0.0363, 0.0340, 0.0373, 0.0376, 0.0364, 0.0334, 0.0353, 0.0344, 0.0344,\n",
       "                      0.0367, 0.0328, 0.0349, 0.0351, 0.0349, 0.0344, 0.0344, 0.0380, 0.0378,\n",
       "                      0.0351, 0.0351, 0.0344, 0.0312, 0.0356, 0.0358, 0.0355, 0.0368, 0.0359,\n",
       "                      0.0368, 0.0353, 0.0354, 0.0316, 0.0351, 0.0338, 0.0346, 0.0307, 0.0350,\n",
       "                      0.0346, 0.0312, 0.0347, 0.0347, 0.0318, 0.0373, 0.0348, 0.0377, 0.0314,\n",
       "                      0.0370, 0.0346, 0.0339, 0.0348, 0.0381, 0.0349, 0.0343, 0.0367, 0.0357,\n",
       "                      0.0352, 0.0366, 0.0347, 0.0335, 0.0380, 0.0338, 0.0344, 0.0348, 0.0344,\n",
       "                      0.0348, 0.0374, 0.0361, 0.0372, 0.0356, 0.0330, 0.0377, 0.0312, 0.0366,\n",
       "                      0.0344, 0.0363, 0.0352, 0.0346, 0.0372, 0.0376, 0.0346, 0.0340, 0.0312,\n",
       "                      0.0347, 0.0339, 0.0310, 0.0342, 0.0315, 0.0339, 0.0359, 0.0358, 0.0347,\n",
       "                      0.0367, 0.0372, 0.0375, 0.0346, 0.0348, 0.0347, 0.0345, 0.0355, 0.0318,\n",
       "                      0.0354, 0.0370, 0.0370, 0.0340, 0.0342, 0.0352, 0.0331, 0.0340, 0.0354,\n",
       "                      0.0351, 0.0347, 0.0340, 0.0376, 0.0327, 0.0342, 0.0373, 0.0340, 0.0349,\n",
       "                      0.0348, 0.0365, 0.0371, 0.0344, 0.0359, 0.0334, 0.0340, 0.0315, 0.0374,\n",
       "                      0.0329, 0.0345, 0.0302, 0.0349, 0.0357, 0.0351, 0.0349, 0.0351, 0.0311,\n",
       "                      0.0350, 0.0352, 0.0359, 0.0319, 0.0354, 0.0356, 0.0298, 0.0374, 0.0348,\n",
       "                      0.0357, 0.0371, 0.0351, 0.0312, 0.0346, 0.0341, 0.0346, 0.0352, 0.0367,\n",
       "                      0.0323, 0.0355, 0.0346, 0.0347, 0.0349, 0.0360, 0.0370, 0.0342, 0.0368,\n",
       "                      0.0342, 0.0349, 0.0348, 0.0365, 0.0380, 0.0346, 0.0354, 0.0341, 0.0343,\n",
       "                      0.0357, 0.0333, 0.0350, 0.0310, 0.0369, 0.0356, 0.0336, 0.0352, 0.0369,\n",
       "                      0.0349, 0.0354, 0.0352, 0.0348, 0.0338, 0.0351, 0.0343, 0.0340, 0.0350,\n",
       "                      0.0351, 0.0376, 0.0336, 0.0346, 0.0300, 0.0349, 0.0353, 0.0350, 0.0355,\n",
       "                      0.0335, 0.0353, 0.0309, 0.0374, 0.0335, 0.0360, 0.0359, 0.0375, 0.0322,\n",
       "                      0.0369, 0.0316, 0.0355, 0.0345, 0.0343, 0.0380, 0.0336, 0.0331, 0.0352,\n",
       "                      0.0356, 0.0374, 0.0368, 0.0346, 0.0350, 0.0333, 0.0345, 0.0350, 0.0371,\n",
       "                      0.0316, 0.0343, 0.0344, 0.0364, 0.0368, 0.0347, 0.0375, 0.0374, 0.0349,\n",
       "                      0.0339, 0.0337, 0.0380, 0.0364, 0.0369, 0.0355, 0.0341, 0.0328, 0.0376,\n",
       "                      0.0349, 0.0350, 0.0344, 0.0340, 0.0320, 0.0374, 0.0324, 0.0351, 0.0368,\n",
       "                      0.0333, 0.0348, 0.0379, 0.0342, 0.0337, 0.0353, 0.0352, 0.0374, 0.0348,\n",
       "                      0.0373, 0.0317, 0.0376, 0.0347, 0.0359, 0.0302, 0.0342, 0.0344, 0.0365,\n",
       "                      0.0345, 0.0349, 0.0325, 0.0376, 0.0350, 0.0349, 0.0338, 0.0348, 0.0367,\n",
       "                      0.0339, 0.0349, 0.0348, 0.0375, 0.0361, 0.0368, 0.0352, 0.0345, 0.0349,\n",
       "                      0.0355, 0.0375, 0.0348, 0.0360, 0.0332, 0.0344, 0.0375, 0.0315, 0.0344,\n",
       "                      0.0373, 0.0320, 0.0315, 0.0360, 0.0353, 0.0374, 0.0349, 0.0305, 0.0353,\n",
       "                      0.0370, 0.0372, 0.0368, 0.0371, 0.0369, 0.0346, 0.0366, 0.0350, 0.0348,\n",
       "                      0.0335, 0.0342, 0.0367, 0.0371, 0.0356, 0.0349, 0.0346, 0.0354, 0.0337,\n",
       "                      0.0354, 0.0375, 0.0363, 0.0337, 0.0306, 0.0311, 0.0337, 0.0348, 0.0312,\n",
       "                      0.0342, 0.0317, 0.0357, 0.0351, 0.0363, 0.0367, 0.0348, 0.0345, 0.0367,\n",
       "                      0.0364, 0.0322, 0.0372, 0.0311, 0.0346, 0.0351, 0.0352, 0.0346, 0.0349,\n",
       "                      0.0350, 0.0352, 0.0342, 0.0349, 0.0351, 0.0339, 0.0343, 0.0372, 0.0357,\n",
       "                      0.0371, 0.0309, 0.0344, 0.0368, 0.0378, 0.0344, 0.0347, 0.0315, 0.0348,\n",
       "                      0.0350, 0.0377, 0.0373, 0.0348, 0.0347, 0.0376, 0.0314, 0.0340, 0.0373,\n",
       "                      0.0376, 0.0317, 0.0349, 0.0347, 0.0344, 0.0337, 0.0353, 0.0347, 0.0350,\n",
       "                      0.0345, 0.0373, 0.0339, 0.0373, 0.0347, 0.0365, 0.0342, 0.0351, 0.0308,\n",
       "                      0.0361, 0.0346, 0.0315, 0.0345, 0.0343, 0.0355, 0.0343, 0.0327, 0.0356,\n",
       "                      0.0360, 0.0351, 0.0344, 0.0340, 0.0346, 0.0339, 0.0381, 0.0351, 0.0305,\n",
       "                      0.0370, 0.0360, 0.0349, 0.0328, 0.0315, 0.0362, 0.0332, 0.0373, 0.0355,\n",
       "                      0.0339, 0.0345, 0.0338, 0.0361, 0.0343, 0.0364, 0.0309, 0.0342, 0.0355,\n",
       "                      0.0369, 0.0370, 0.0354, 0.0376, 0.0373, 0.0365, 0.0345, 0.0363, 0.0342,\n",
       "                      0.0343, 0.0339, 0.0352, 0.0348, 0.0356, 0.0353, 0.0351, 0.0353, 0.0346,\n",
       "                      0.0374, 0.0376, 0.0326, 0.0352, 0.0338, 0.0345, 0.0349, 0.0371, 0.0351,\n",
       "                      0.0323, 0.0352, 0.0354, 0.0344, 0.0354, 0.0372, 0.0347, 0.0364, 0.0347,\n",
       "                      0.0346, 0.0347, 0.0378, 0.0352, 0.0365, 0.0349, 0.0357, 0.0373])),\n",
       "             ('decoders.6.bn4.running_mean',\n",
       "              tensor([-0.6252, -0.6354, -0.5091, -0.6991, -0.7177, -0.8420, -0.3898, -0.5490,\n",
       "                      -0.5110, -0.7234, -0.5786, -0.6165, -0.5332, -0.1652, -0.6528, -0.3712,\n",
       "                      -0.4757, -0.3578, -0.3002, -0.6827, -0.3495, -0.7329, -0.5712, -0.9268,\n",
       "                      -0.6619, -0.3241, -0.1665, -0.6608, -0.3779, -0.5685, -0.3622, -0.8512,\n",
       "                      -0.6526, -0.6713, -0.5397, -0.6390, -0.6494, -0.5869, -0.2923, -0.6849,\n",
       "                      -0.2066, -0.7299, -0.3791, -0.5759, -0.3580, -0.4663, -0.7948, -0.8625,\n",
       "                      -0.4989, -0.7578, -0.4085, -0.5679, -0.1565, -0.7347, -0.6445, -0.6293,\n",
       "                      -0.5349, -0.5368, -0.5929, -0.3914, -0.6215, -0.5519, -0.2739, -0.5048,\n",
       "                      -0.7593, -0.4031, -0.7514, -0.2573, -0.8512, -0.4316, -0.6255, -0.6018,\n",
       "                      -0.6593, -0.8088, -0.5039, -0.5967, -0.5018, -0.2219, -0.7704, -0.7876,\n",
       "                      -0.4768, -0.3380, -0.3311, -1.0150, -0.7630, -0.4873, -0.2382, -0.6756,\n",
       "                      -0.7168, -0.2400, -0.6527, -0.3851, -0.3315, -0.6089, -0.1839, -0.5972,\n",
       "                      -0.8702, -0.6349, -0.3436, -0.7755, -0.1776, -0.4688, -0.5254, -0.3782,\n",
       "                      -0.5070, -0.2390, -0.5861, -0.4941, -0.4217, -0.4694, -0.7323, -0.7251,\n",
       "                      -0.5294, -0.2421, -0.2591, -0.3422, -0.6342, -0.9065, -0.6519, -0.5371,\n",
       "                      -0.4281, -0.7270, -0.8377, -0.5109, -0.5313, -0.7107, -0.5191, -0.4788,\n",
       "                      -0.4167, -0.5885, -0.6595, -0.9565, -0.6037, -0.7290, -0.3393, -0.5143,\n",
       "                      -0.3924, -0.5068, -0.7239, -0.9289, -0.2996, -0.4359, -0.8553, -0.5195,\n",
       "                      -0.3170, -0.4530, -0.5324, -0.5221, -0.8550, -0.5831, -0.2967, -0.5635,\n",
       "                      -0.6136, -0.5148, -0.5537, -0.4944, -0.7053, -0.3463, -0.3924, -0.4278,\n",
       "                      -0.7297, -0.7331, -0.4305, -0.6869, -0.5834, -0.5455, -0.7174, -0.5638,\n",
       "                      -0.6018, -0.5330, -0.8156, -0.7128, -0.8762, -0.8897, -0.5739, -0.4900,\n",
       "                      -0.5503, -0.4199, -0.2508, -0.5730, -0.3859, -0.6918, -0.6781, -0.7135,\n",
       "                      -0.4924, -0.5625, -0.4112, -0.5307, -0.7550, -0.6158, -0.6573, -0.4080,\n",
       "                      -0.3513, -0.5303, -0.5219, -0.4005, -0.5682, -0.1587, -0.3393, -0.4729,\n",
       "                      -0.2857, -0.1455, -0.5704, -0.6340, -0.5989, -0.7180, -0.7688, -0.6808,\n",
       "                      -0.6941, -0.6456, -0.5780, -0.4127, -0.3431, -0.7712, -0.7555, -0.7263,\n",
       "                      -0.9117, -0.6884, -0.6502, -0.7596, -0.4596, -0.4890, -0.8267, -0.6937,\n",
       "                      -0.8029, -0.5607, -0.2295, -0.8505, -0.7005, -0.6656, -0.5733, -0.5899,\n",
       "                      -0.4679, -0.4942, -0.7266, -0.4520, -0.7540, -0.4488, -0.5901, -0.6068,\n",
       "                      -0.4713, -0.7156, -0.5243, -0.5764, -0.5808, -0.7328, -0.7461, -0.6367,\n",
       "                      -0.7393, -0.8136, -0.7887, -0.6202, -0.3871, -0.7420, -0.6082, -0.4587,\n",
       "                      -0.5418, -0.9037, -0.7597, -0.6652, -0.7886, -0.4353, -0.3279, -0.4642,\n",
       "                      -0.6031, -0.6307, -0.4627, -0.2347, -0.8421, -0.7701, -0.5162, -0.5824,\n",
       "                      -0.2400, -0.4620, -0.3927, -0.3006, -0.8869, -0.6065, -0.4817, -0.5845,\n",
       "                      -0.5532, -0.9965, -0.4006, -0.4565, -0.4931, -0.4541, -0.3062, -0.5166,\n",
       "                      -0.7325, -0.5629, -0.2205, -0.5340, -0.9805, -0.7058, -0.7075, -0.6122,\n",
       "                      -0.6127, -0.5462, -0.7533, -0.3237, -0.7247, -0.4202, -0.7512, -0.6112,\n",
       "                      -0.4248, -0.4266, -0.4554, -0.6692, -0.6744, -0.2928, -0.9405, -0.3430,\n",
       "                      -0.7653, -0.3152, -0.3479, -0.4509, -1.0166, -1.0458, -0.3612, -0.6875,\n",
       "                      -0.3025, -0.4458, -0.6284, -0.2809, -0.5790, -0.4057, -0.7480, -0.2794,\n",
       "                      -0.5965, -0.5410, -0.3066, -0.6002, -0.7235, -0.6587, -0.4650, -0.6090,\n",
       "                      -0.0288, -0.7238, -0.7042, -0.8103, -0.6099, -0.6040, -0.6270, -0.4197,\n",
       "                      -0.6287, -0.4156, -0.2847, -0.6650, -0.5085, -0.6866, -0.5083, -0.8411,\n",
       "                      -0.6905, -0.2164, -0.5161, -0.6014, -0.6453, -0.5184, -0.5276, -0.7424,\n",
       "                      -0.4138, -0.4641, -0.4765, -0.7226, -0.6824, -0.6389, -0.8037, -0.4610,\n",
       "                      -0.5730, -0.8265, -0.2816, -0.1843, -0.4672, -0.4968, -0.6752, -0.7979,\n",
       "                      -0.8035, -0.6268, -0.7092, -0.6135, -0.8476, -0.7577, -0.6079, -0.5442,\n",
       "                      -0.5114, -0.5742, -0.5210, -0.5931, -0.4081, -0.7014, -0.6086, -0.7236,\n",
       "                      -0.6483, -0.7619, -0.4908, -0.3341, -0.6292, -0.6025, -0.6811, -0.4343,\n",
       "                      -0.8919, -0.5865, -0.3275, -0.5383, -0.3587, -0.1147, -0.6838, -0.7743,\n",
       "                      -0.4906, -0.5239, -0.5088, -0.6489, -0.8131, -0.4513, -0.4962, -0.5328,\n",
       "                      -0.5077, -0.3048, -0.5445, -0.6961, -0.4616, -0.6086, -0.8753, -0.6805,\n",
       "                      -0.5242, -0.6649, -0.3924, -0.6695, -0.4741, -0.5018, -0.6434, -0.1998,\n",
       "                      -0.5303, -0.5916, -0.6253, -0.6713, -0.4619, -0.3286, -0.5621, -0.4832,\n",
       "                      -0.4970, -0.4460, -0.6136, -0.5815, -0.6996, -0.7814, -0.3806, -0.3522,\n",
       "                      -0.5527, -0.6521, -0.3934, -0.4927, -0.6281, -0.7605, -0.8780, -0.5112,\n",
       "                      -0.4647, -0.1249, -0.5579, -0.6824, -0.7992, -0.8871, -0.8271, -0.5655,\n",
       "                      -0.5263, -0.5299, -0.9523, -0.2658, -0.3191, -0.7514, -0.3446, -0.4554,\n",
       "                      -0.3737, -0.5666, -0.6571, -0.5784, -0.7280, -0.2365, -0.9426, -0.2836,\n",
       "                      -0.7378, -0.5722, -0.5924, -0.5701, -0.4633, -0.9443, -0.7757, -0.6493,\n",
       "                      -0.3814, -0.6091, -0.5850, -0.7118, -0.5994, -0.4307, -0.3722, -0.5190,\n",
       "                      -0.4468, -0.6497, -0.7903, -0.2125, -0.5648, -0.4265, -0.3199, -0.5443,\n",
       "                      -0.6948, -0.7277, -0.7800, -0.3543, -0.4699, -0.6134, -0.4441, -0.6032])),\n",
       "             ('decoders.6.bn4.running_var',\n",
       "              tensor([0.3104, 4.2242, 4.6995, 0.4348, 5.4063, 4.3011, 6.0370, 2.6616, 4.1756,\n",
       "                      5.4424, 3.1024, 3.3312, 4.1011, 0.2970, 4.6614, 3.5521, 3.7633, 3.3811,\n",
       "                      3.0601, 3.8702, 3.9277, 0.3572, 3.8233, 2.6329, 4.3526, 3.7973, 4.3888,\n",
       "                      3.0465, 3.4393, 4.2105, 5.2965, 4.4703, 0.2289, 3.8723, 3.3111, 0.3817,\n",
       "                      4.0254, 7.8292, 2.7907, 2.6031, 4.6686, 7.3667, 3.8927, 4.8210, 3.7347,\n",
       "                      3.1502, 0.4528, 4.0946, 3.1808, 4.2378, 5.4291, 4.0308, 2.9555, 3.5113,\n",
       "                      3.9494, 3.2253, 5.9894, 0.3537, 3.7233, 4.9858, 3.5333, 3.7805, 3.9845,\n",
       "                      3.4195, 3.4991, 3.7612, 0.4246, 3.4719, 4.6183, 4.7954, 0.3217, 4.6768,\n",
       "                      3.6517, 0.4182, 3.7421, 3.2345, 0.2685, 3.6647, 3.2033, 4.4694, 0.3422,\n",
       "                      3.8560, 5.9079, 3.5326, 3.3192, 3.7414, 3.7986, 4.1683, 3.4328, 2.9376,\n",
       "                      4.7386, 4.8972, 5.1164, 4.9757, 2.8549, 4.9803, 3.7757, 3.7496, 4.4461,\n",
       "                      5.7250, 3.6364, 2.4966, 3.8186, 3.6449, 0.3855, 4.4727, 0.3120, 3.1358,\n",
       "                      1.0234, 3.8078, 3.4375, 4.8286, 3.3511, 3.7098, 3.2230, 5.7844, 0.2493,\n",
       "                      3.6005, 6.1439, 0.3221, 3.5283, 0.3620, 3.9852, 4.5889, 6.3329, 3.5547,\n",
       "                      3.8680, 3.3136, 4.7594, 4.3479, 3.7261, 4.1507, 5.6689, 3.0247, 0.3875,\n",
       "                      4.3702, 3.0238, 3.9149, 3.3571, 2.9599, 3.4969, 0.4448, 4.0857, 4.8717,\n",
       "                      2.7433, 5.7905, 3.8881, 4.2599, 6.4638, 3.8214, 5.4975, 0.2972, 4.1284,\n",
       "                      4.7574, 3.4042, 3.3554, 6.5671, 2.6781, 0.3917, 4.5305, 0.2814, 3.9726,\n",
       "                      0.4435, 5.4140, 0.3154, 4.3405, 2.8086, 3.9852, 5.3089, 2.6376, 0.4645,\n",
       "                      4.3589, 2.7218, 3.5429, 0.2832, 4.1104, 4.7783, 0.4003, 3.9542, 4.9571,\n",
       "                      3.2630, 4.2898, 4.5794, 0.4056, 3.6866, 3.8248, 4.3084, 4.5413, 2.8689,\n",
       "                      0.4499, 4.7859, 5.6819, 3.9929, 3.5704, 4.6299, 3.3984, 3.9989, 4.5147,\n",
       "                      3.9058, 3.6640, 0.3065, 4.5168, 2.8333, 4.5979, 3.7833, 4.5690, 4.0091,\n",
       "                      4.2641, 3.3557, 4.6829, 3.1294, 5.3550, 3.5984, 4.8508, 4.0218, 3.6047,\n",
       "                      4.0961, 3.1272, 3.9202, 3.7441, 0.3431, 4.6196, 4.9341, 4.3414, 3.7810,\n",
       "                      3.2063, 3.4292, 6.0306, 3.5704, 0.4001, 3.8357, 0.5102, 3.9502, 6.3450,\n",
       "                      0.3722, 3.7348, 0.4016, 3.5400, 3.3408, 2.8339, 3.4762, 2.6155, 0.2845,\n",
       "                      2.9734, 0.3865, 3.0190, 4.5078, 0.4230, 3.9929, 5.1370, 0.3672, 3.6201,\n",
       "                      3.6096, 4.9483, 3.4276, 5.4896, 4.3146, 4.5096, 5.2012, 3.6678, 3.6104,\n",
       "                      0.2325, 4.5109, 0.2897, 3.2905, 5.5441, 5.0751, 3.5100, 3.3985, 3.0796,\n",
       "                      4.3675, 6.4863, 3.5746, 4.3148, 4.1267, 4.7640, 3.7360, 0.3390, 4.0351,\n",
       "                      3.7525, 5.2542, 3.9097, 0.2939, 0.3297, 4.2545, 0.4250, 4.2539, 4.3379,\n",
       "                      8.0027, 3.6692, 4.3778, 5.8000, 4.4509, 4.0841, 4.4459, 3.5213, 2.8013,\n",
       "                      3.9456, 0.3255, 4.2356, 2.6767, 3.5640, 0.2090, 4.2869, 0.3592, 4.4512,\n",
       "                      4.7706, 4.6462, 0.2855, 3.7557, 2.9605, 4.2190, 3.7167, 4.0359, 2.3180,\n",
       "                      5.5746, 2.8379, 2.6357, 4.6522, 4.4052, 3.8399, 4.1133, 4.7782, 3.9375,\n",
       "                      3.6197, 3.1032, 5.3214, 3.8661, 0.2986, 6.2044, 4.1771, 0.3450, 5.4667,\n",
       "                      4.3217, 0.2977, 0.3866, 2.7754, 2.9381, 3.4070, 2.8670, 0.2172, 5.0089,\n",
       "                      3.6438, 3.3149, 3.9282, 3.6265, 4.6942, 4.5599, 3.5091, 4.6501, 5.1462,\n",
       "                      3.8245, 3.3056, 4.1921, 4.1263, 3.8487, 4.8630, 4.5785, 4.2952, 5.9016,\n",
       "                      3.7163, 3.6726, 3.1941, 4.9361, 0.2846, 0.3648, 3.3863, 6.2866, 1.8292,\n",
       "                      3.9085, 1.4993, 3.5676, 2.5665, 4.0017, 4.3556, 3.3935, 3.2584, 3.7542,\n",
       "                      2.8991, 0.4353, 4.1769, 0.3877, 3.9074, 4.6023, 3.6974, 2.4990, 4.9978,\n",
       "                      4.5462, 3.5483, 6.5051, 3.0475, 2.5800, 5.1696, 0.2736, 4.2176, 3.8746,\n",
       "                      4.2621, 0.4140, 3.4700, 3.8473, 2.2529, 4.7848, 5.1286, 0.4341, 5.1062,\n",
       "                      0.3446, 3.0902, 4.4471, 4.3962, 5.4153, 3.4770, 1.5640, 4.1393, 4.7054,\n",
       "                      5.5389, 0.2876, 3.5975, 4.9869, 0.3861, 7.5107, 4.0664, 4.3523, 4.3177,\n",
       "                      3.8483, 4.6636, 0.3707, 3.4975, 4.2356, 3.5736, 5.6220, 5.0804, 0.5231,\n",
       "                      3.2376, 4.4737, 0.4439, 2.7884, 4.0242, 5.9181, 0.3285, 0.4242, 2.9342,\n",
       "                      0.3350, 3.6736, 4.7924, 3.9911, 2.8172, 4.8205, 3.5077, 6.2327, 0.3425,\n",
       "                      4.0424, 3.5090, 2.8036, 0.3126, 0.4439, 4.3018, 0.3867, 4.3637, 3.7908,\n",
       "                      3.8549, 3.9914, 5.4005, 5.9265, 2.7973, 5.4230, 0.3324, 5.8633, 4.2053,\n",
       "                      2.9466, 2.8112, 3.0633, 2.9438, 3.7946, 4.2044, 4.5897, 3.8429, 5.8882,\n",
       "                      2.2195, 7.2329, 3.4707, 4.0928, 2.9087, 4.3258, 4.2265, 5.3253, 4.7828,\n",
       "                      3.3388, 3.9760, 0.4816, 4.0377, 4.5380, 4.5706, 4.9154, 3.6765, 4.2898,\n",
       "                      0.2600, 4.5385, 3.2628, 0.3141, 5.1649, 2.2389, 4.0469, 0.4496, 3.9159,\n",
       "                      4.2193, 6.4973, 3.5779, 5.5502, 5.7786, 3.3798, 3.6480, 3.2149])),\n",
       "             ('decoders.6.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense5.weight',\n",
       "              tensor([[-3.9923e-02,  1.0351e-03, -8.5042e-05,  ..., -5.5251e-02,\n",
       "                        2.4223e-02,  2.3147e-02],\n",
       "                      [ 6.7527e-03,  1.2413e-02,  8.9335e-03,  ...,  8.5232e-03,\n",
       "                       -2.5913e-02, -2.7313e-02],\n",
       "                      [-4.9993e-02, -6.3947e-02, -3.3663e-02,  ..., -7.0573e-02,\n",
       "                       -1.7095e-02, -4.4567e-02],\n",
       "                      ...,\n",
       "                      [ 8.9980e-03,  1.5555e-02, -3.3636e-02,  ..., -3.3334e-02,\n",
       "                        2.0833e-02, -3.0191e-02],\n",
       "                      [ 3.2314e-03,  2.1464e-02, -5.8633e-04,  ..., -2.7238e-02,\n",
       "                       -4.4904e-02,  1.7480e-02],\n",
       "                      [-2.7271e-02, -3.5735e-02, -2.4088e-03,  ..., -2.7002e-03,\n",
       "                       -1.0505e-02, -2.1886e-02]])),\n",
       "             ('decoders.6.dense5.bias',\n",
       "              tensor([ 0.0171, -0.0580, -0.0346,  ...,  0.0020,  0.0021, -0.0210]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(checkpoint_path+'/model_weights.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_path+'/model_weights.pt',map_location=torch.device('cpu')),strict=True)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "\n",
    "plot_tree_graph(data_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.kwargs[\"input_data\"]='varient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]/home/junyi/.conda/envs/RNA-FM/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 9/9 [00:00<00:00, 23.18it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do you want to look at pca embeddings or learnt representations\n",
    "use_pca = 'UMAP'\n",
    "\n",
    "# pick data loader\n",
    "data_loader = gen_test\n",
    "\n",
    "\n",
    "# each entry in node_embeddings is a dictionary with keys 'prob' and 'z_sample' for each leaf\n",
    "nb_nodes = len(data_tree)\n",
    "node_embeddings = [{'prob': [], 'z_sample': []} for _ in range(nb_nodes)]\n",
    "label_list = []\n",
    "\n",
    "# iterate over test data points\n",
    "for inputs, labels in tqdm(data_loader):\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "\n",
    "    label_list.append(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        node_info = get_node_embeddings(model, inputs_gpu)\n",
    "    node_info = move_to(node_info, 'cpu')\n",
    "\n",
    "    # for each node, append the probability and z_sample to the list\n",
    "\n",
    "    k = 0 # need this variable to skip \"no digits\" nodes\n",
    "    for i in range(nb_nodes):\n",
    "        j = i - k\n",
    "        if data_tree[i][1] == 'no digits':\n",
    "            k += 1\n",
    "            continue\n",
    "\n",
    "        node_embeddings[i]['prob'].append(node_info[j]['prob'].numpy())\n",
    "        node_embeddings[i]['z_sample'].append(node_info[j]['z_sample'].numpy())\n",
    "\n",
    "# flatten the lists\n",
    "k = 0\n",
    "for i in range(nb_nodes):\n",
    "    if data_tree[i][1] == 'no digits':\n",
    "        node_embeddings[i]['prob'] = []\n",
    "        node_embeddings[i]['z_sample'] = []\n",
    "        continue\n",
    "    \n",
    "    node_embeddings[i]['prob'] = np.concatenate(node_embeddings[i]['prob'])\n",
    "    node_embeddings[i]['z_sample'] = np.concatenate(node_embeddings[i]['z_sample'])\n",
    "\n",
    "label_list = np.concatenate(label_list)\n",
    "\n",
    "# Draw the tree graph with scatter plots as nodes and arrows for edges\n",
    "draw_tree_with_scatter_plots(data_tree, node_embeddings, label_list, pca = use_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 302.43it/s]\n"
     ]
    }
   ],
   "source": [
    "inputs_list = []\n",
    "label_list = []\n",
    "for inputs, labels in tqdm(data_loader):\n",
    "    inputs_list.append(inputs.numpy())\n",
    "    label_list.append(labels.numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_af = np.concatenate(inputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237, 7318)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_af[:,:mat_af.shape[1]//2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(mat_af[:,:mat_af.shape[1]//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ar_name = pd.read_csv('/home/junyi/code/treevae/data/Variant/trimmed_starsolo_chrM_cellSNP0_WaldVariant_paperCell/passed_variant_names.txt',header=None,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683G&gt;T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686A&gt;C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687G&gt;T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689T&gt;G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692C&gt;A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15879A&gt;C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15884G&gt;C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15885C&gt;A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886C&gt;A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887T&gt;C</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3972 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [683G>T, 686A>C, 687G>T, 689T>G, 692C>A, 703A>C, 705C>A, 708C>A, 709A>G, 710T>G, 711T>A, 713C>A, 714A>C, 715G>T, 719G>T, 720T>G, 721T>A, 726C>A, 732A>T, 733T>A, 735A>T, 739C>A, 740G>T, 741A>T, 742T>G, 744A>C, 745A>T, 746A>T, 747A>T, 749G>T, 750G>T, 755G>T, 756C>A, 757A>T, 758T>A, 760A>C, 762G>T, 766G>T, 767C>A, 771A>T, 772A>C, 778C>A, 781A>C, 783A>T, 784A>T, 786G>T, 787C>A, 788T>G, 789T>A, 791G>T, 794T>A, 795A>C, 796G>T, 799A>C, 801A>T, 803C>A, 807A>C, 811G>A, 814A>C, 819A>C, 823A>C, 824T>G, 825T>G, 827A>T, 829C>A, 830T>G, 831T>G, 837A>C, 838T>A, 840A>C, 841A>T, 842C>A, 844A>T, 846A>C, 848T>G, 851A>T, 852A>T, 855A>C, 856A>T, 857G>T, 858C>A, 859T>G, 860A>C, 862A>C, 863C>A, 866A>T, 867C>A, 868C>A, 869C>A, 871A>C, 873G>T, 875T>G, 876T>G, 878G>T, 879T>G, 880C>G, 881A>C, 882A>C, 883T>G, 884T>G, ...]\n",
       "\n",
       "[3972 rows x 0 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index = ar_name.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[\"X_treevae_n0\"] = node_embeddings[0][\"z_sample\"]\n",
    "adata.obsm[\"X_treevae_n1\"] = node_embeddings[1][\"z_sample\"]\n",
    "adata.obsm[\"X_treevae_n2\"] = node_embeddings[2][\"z_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"node_lv1\"] = (((node_embeddings[1][\"prob\"]<0.5)*1)+1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"sample\"] =  np.concatenate(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata,use_rep=\"X_treevae_n0\",n_neighbors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=100, facecolor=\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"node_lv1\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"sample\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata, 'node_lv1', method='wilcoxon',key_added='rank_genes_node_lv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degs=sc.get.rank_genes_groups_df(adata,'1',key=\"rank_genes_node_lv1\",pval_cutoff=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degs.sort_values(\"logfoldchanges\",ascending=False).to_csv(\"results/waldvarient_degs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_degs.head() shows the degree distribution of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dgs= df_degs.sort_values(\"logfoldchanges\",ascending=False)\n",
    "df_dgs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dgs.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.heatmap(adata,  list(df_dgs.head(20).names.values) + list(df_dgs.tail(20).names.values), groupby='node_lv1',swap_axes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Train NMI\n",
    "prob_leaves = predict(gen_train_eval, model, device,'prob_leaves')\n",
    "y = np.squeeze(np.argmax(prob_leaves, axis=-1))\n",
    "print('Train NMI:',normalized_mutual_info_score(y, np.squeeze(y_train)))\n",
    "\n",
    "tot_counts = []\n",
    "print(\"                                  Leaf\", np.arange(10))\n",
    "for i in np.unique(y_test):\n",
    "    list_y_hat, counts = np.unique(y[np.squeeze(y_train)==i], return_counts=True)\n",
    "    for j in range(n_d):\n",
    "        if j not in list_y_hat:\n",
    "            list_y_hat = np.insert(list_y_hat, j, j)\n",
    "            counts = np.insert(counts, j, 0)\n",
    "    tot_counts.append(counts)\n",
    "    print(f\"Class {i:<10}\", list_y_hat, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Test NMI\n",
    "prob_leaves = predict(gen_test, model, device,'prob_leaves')\n",
    "y = np.squeeze(np.argmax(prob_leaves, axis=-1))\n",
    "print('Test NMI:', normalized_mutual_info_score(y, np.squeeze(y_test)))\n",
    "\n",
    "tot_counts = []\n",
    "print(\"                                  Leaf\", np.arange(10))\n",
    "for i in np.unique(y_test):\n",
    "    list_y_hat, counts = np.unique(y[np.squeeze(y_test)==i], return_counts=True)\n",
    "    for j in range(n_d):\n",
    "        if j not in list_y_hat:\n",
    "            list_y_hat = np.insert(list_y_hat, j, j)\n",
    "            counts = np.insert(counts, j, 0)\n",
    "    tot_counts.append(counts)\n",
    "    print(f\"Class {i:<10}\", list_y_hat, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_2\"></a> 2. Generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is concerned with unconditionally generating new samples as opposed to reconstructing existing data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterwise generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, given one unconditional random sampling from the root, we visualize the generations for each leaf. That is, each row corresponds to one sample and each column corresponds to one leaf. Above each generation, we provide the probability of falling into the respective leaf for this sample. \n",
    "\n",
    "This way of visualization can provide insights on the characteristics each leaf is associated with. Observe that the generations differ across the leaves, as each leaf decodes the sample in the style of the cluster that it learnt. It is likely that cluster-differences are observed more strongly than in the reconstructions' section, as here, we have no guiding information from the bottom-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_imgs = 15\n",
    "with torch.no_grad():\n",
    "    reconstructions, p_c_z = model.generate_images(n_imgs, device)\n",
    "reconstructions = move_to(reconstructions, 'cpu')\n",
    "for i in range(n_imgs):\n",
    "    fig, axs = plt.subplots(1, n_d, figsize=(15, 15))\n",
    "    for c in range(n_d):\n",
    "        axs[c].imshow(display_image(reconstructions[c][i]), cmap=plt.get_cmap('gray'))\n",
    "        axs[c].set_title(f\"L{c}: \" + f\"p=%.2f\" % torch.round(p_c_z[i][c],))\n",
    "        axs[c].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new images according to cluster assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, given a leaf, we store the first 100 generations, for which this leaf is their most likely cluster assignment. This allows us to gain insights on the cluster and characteristics that each leaf learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we store generations for each leaf simultaneously until\n",
    "# every leaf has n_imgs associated generations, or we iterated through max_iter batches.\n",
    "n_imgs = configs['training']['batch_size']\n",
    "max_iter = 200\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructions, p_c_z = model.generate_images(n_imgs, device)\n",
    "reconstructions = move_to(reconstructions, 'cpu')\n",
    "clusterwise_reconst = [torch.zeros_like(reconstructions[0][0:2]) for i in range(len(reconstructions))]\n",
    "n_iter=0\n",
    "while min([clusterwise_reconst[leaf_ind].shape[0] for leaf_ind in range(len(reconstructions))]) < n_imgs+2 and n_iter < max_iter:\n",
    "    for i in range(n_imgs):\n",
    "        leaf_ind = torch.argmax(p_c_z[i])\n",
    "        if clusterwise_reconst[leaf_ind].shape[0] < n_imgs+2:\n",
    "            clusterwise_reconst[leaf_ind] = torch.vstack([clusterwise_reconst[leaf_ind], reconstructions[leaf_ind][i].unsqueeze(0)])\n",
    "    with torch.no_grad():\n",
    "        reconstructions, p_c_z = model.generate_images(n_imgs, device)\n",
    "    reconstructions = move_to(reconstructions, 'cpu')\n",
    "    n_iter += 1\n",
    "    if n_iter %10 == 0:\n",
    "        print(n_iter)\n",
    "for i in range(len(reconstructions)):\n",
    "    clusterwise_reconst[i] = clusterwise_reconst[i][2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusterwise_reconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each leaf, we visualize n_grid x n_grid generations, \n",
    "# which have highest probability of being assigned to this cluster\n",
    "n_leaves = len(clusterwise_reconst)\n",
    "n_grid = min(5,int((clusterwise_reconst[leaf_ind].shape[0])**.5))\n",
    "\n",
    "k=0\n",
    "for l in range(n_leaves):\n",
    "        fig, axs = plt.subplots(n_grid, n_grid, figsize=(4,4))\n",
    "        i=0\n",
    "        for a in range(n_grid):\n",
    "            for b in range(n_grid):\n",
    "                try:\n",
    "                        axs[a,b].set_axis_off()\n",
    "                        axs[a,b].imshow(display_image(clusterwise_reconst[k][i]), cmap=plt.get_cmap('gray'))\n",
    "                        i+=1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "        fig.suptitle(f\"Leaf {k} samples\",fontsize=25)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.87)\n",
    "        k+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For closer inspection, one can select a specific leaf by leaf_ind and investigate more generations.\n",
    "leaf_ind = 0\n",
    "    \n",
    "n_grid = int((clusterwise_reconst[leaf_ind].shape[0])**.5)\n",
    "fig, axs = plt.subplots(n_grid, n_grid, figsize=(15,15))\n",
    "\n",
    "i=0\n",
    "for a in range(n_grid):\n",
    "    for b in range(n_grid):\n",
    "        axs[a,b].set_axis_off()\n",
    "        axs[a,b].imshow(display_image(clusterwise_reconst[leaf_ind][i]), cmap=plt.get_cmap('gray'))\n",
    "        i+=1\n",
    "fig.suptitle(f\"Leaf {leaf_ind} samples\",fontsize=25)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_3\"></a> 3. Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is concerned with computing reconstructions of input samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterwise reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, given one input image, we visualize the reconstructions for each leaf. That is, each row corresponds to one input image and each column corresponds to one leaf. Above each reconstruction, we provide the probability of falling into the respective leaf for this sample. \n",
    "\n",
    "This way of visualization can provide insights on the characteristics each leaf is associated with. Observe that the reconstructions differ across the leaves, as each leaf reconstructs the image in the style of the cluster that it learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Set\n",
    "gen_train_eval_iter = iter(gen_train_eval)\n",
    "inputs, labels = next(gen_train_eval_iter)\n",
    "\n",
    "\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Class:\", labels[i].item())\n",
    "    fig, axs = plt.subplots(1, n_d+1, figsize=(15, 15))\n",
    "    axs[n_d].imshow(display_image(inputs[i]), cmap=plt.get_cmap('gray'))\n",
    "    axs[n_d].set_title(\"Original\")\n",
    "    axs[n_d].axis('off')\n",
    "    for c in range(n_d):\n",
    "        axs[c].imshow(display_image(reconstructions[c][i]), cmap=plt.get_cmap('gray'))\n",
    "        axs[c].set_title(f\"L{c}: \" + f\"p=%.2f\" % torch.round(node_leaves[c]['prob'][i]))\n",
    "        axs[c].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test Set\n",
    "gen_test_iter = iter(gen_test)\n",
    "inputs, labels = next(gen_test_iter)\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Class:\", labels[i].item())\n",
    "    fig, axs = plt.subplots(1, n_d+1, figsize=(15, 15))\n",
    "    axs[n_d].imshow(display_image(inputs[i]), cmap=plt.get_cmap('gray'))\n",
    "    axs[n_d].set_title(\"Original\")\n",
    "    axs[n_d].axis('off')\n",
    "    for c in range(n_d):\n",
    "        axs[c].imshow(display_image(reconstructions[c][i]), cmap=plt.get_cmap('gray'))\n",
    "        axs[c].set_title(f\"L{c}: \" + f\"p=%.2f\" % torch.round(node_leaves[c]['prob'][i]))\n",
    "        axs[c].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group reconstructions according to cluster assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, given a leaf, we store the reconstructions of the first 100 samples, for which this leaf is their most likely cluster assignment. This allows us to visualize for each leaf, which samples fall into it, in order to gain insights on the cluster that each leaf learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "# Here, we store samples for each leaf simultaneously by iterating through the training set until\n",
    "# every leaf has n_imgs associated samples, or we iterated through max_iter batches.\n",
    "max_iter = 100\n",
    "n_imgs = configs['training']['batch_size']\n",
    "\n",
    "n_iter=0\n",
    "gen_test_iter = iter(gen_test)\n",
    "inputs, labels = next(gen_test_iter)\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "p_c_z = torch.stack([node_leaves[i]['prob'] for i in range(len(node_leaves))],1)\n",
    "clusterwise_reconst = [torch.zeros_like(reconstructions[0][0:2]) for i in range(len(reconstructions))]\n",
    "while min([clusterwise_reconst[leaf_ind].shape[0] for leaf_ind in range(len(reconstructions))]) < n_imgs+2 and n_iter < max_iter:\n",
    "    n_iter += 1\n",
    "    if n_iter %10 == 0:\n",
    "        print(n_iter)\n",
    "    for i in range(n_imgs):\n",
    "        leaf_ind = p_c_z[i].numpy().argmax()\n",
    "        if clusterwise_reconst[leaf_ind].shape[0] < n_imgs+2:\n",
    "            clusterwise_reconst[leaf_ind] = torch.vstack([clusterwise_reconst[leaf_ind], reconstructions[leaf_ind][i].unsqueeze(0)])\n",
    "    inputs, labels = next(gen_test_iter)\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "    reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "    node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "    p_c_z = torch.stack([node_leaves[i]['prob'] for i in range(len(node_leaves))],1)\n",
    "for i in range(len(reconstructions)):\n",
    "    clusterwise_reconst[i] = clusterwise_reconst[i][2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each leaf, we visualize n_grid x n_grid reconstructions of samples, \n",
    "# which have highest probability of being assigned to this cluster\n",
    "n_leaves = len(clusterwise_reconst)\n",
    "n_grid = min(5,int((clusterwise_reconst[leaf_ind].shape[0])**.5))\n",
    "\n",
    "k=0\n",
    "for l in range(n_leaves):\n",
    "        fig, axs = plt.subplots(n_grid, n_grid, figsize=(4,4))\n",
    "        i=0\n",
    "        for a in range(n_grid):\n",
    "            for b in range(n_grid):\n",
    "                axs[a,b].set_axis_off()\n",
    "                axs[a,b].imshow(display_image(clusterwise_reconst[k][i]), cmap=plt.get_cmap('gray'))\n",
    "                i+=1\n",
    "        fig.suptitle(f\"Leaf {k} samples\",fontsize=25)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.87)\n",
    "        k+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For closer inspection, one can select a specific leaf by leaf_ind and investigate more reconstructions.\n",
    "leaf_ind = 0\n",
    "    \n",
    "n_grid = int((clusterwise_reconst[leaf_ind].shape[0])**.5)\n",
    "fig, axs = plt.subplots(n_grid, n_grid, figsize=(15,15))\n",
    "\n",
    "i=0\n",
    "for a in range(n_grid):\n",
    "    for b in range(n_grid):\n",
    "        axs[a,b].set_axis_off()\n",
    "        axs[a,b].imshow(display_image(clusterwise_reconst[leaf_ind][i]), cmap=plt.get_cmap('gray'))\n",
    "        i+=1\n",
    "fig.suptitle(f\"Leaf {leaf_ind} samples\",fontsize=25)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_4\"></a> 4. Tree and Representation Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we explore the structure of the learnt tree as well as the representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we visualize the learnt embeddings by performing PCA on each node. Set use_pca to False if you want to directly see the first two dimensions without dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want to look at pca embeddings or learnt representations\n",
    "use_pca = True\n",
    "\n",
    "# pick data loader\n",
    "data_loader = gen_test\n",
    "\n",
    "\n",
    "# each entry in node_embeddings is a dictionary with keys 'prob' and 'z_sample' for each leaf\n",
    "nb_nodes = len(data_tree)\n",
    "node_embeddings = [{'prob': [], 'z_sample': []} for _ in range(nb_nodes)]\n",
    "label_list = []\n",
    "\n",
    "# iterate over test data points\n",
    "for inputs, labels in tqdm(data_loader):\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "\n",
    "    label_list.append(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        node_info = get_node_embeddings(model, inputs_gpu)\n",
    "    node_info = move_to(node_info, 'cpu')\n",
    "\n",
    "    # for each node, append the probability and z_sample to the list\n",
    "\n",
    "    k = 0 # need this variable to skip \"no digits\" nodes\n",
    "    for i in range(nb_nodes):\n",
    "        j = i - k\n",
    "        if data_tree[i][1] == 'no digits':\n",
    "            k += 1\n",
    "            continue\n",
    "\n",
    "        node_embeddings[i]['prob'].append(node_info[j]['prob'].numpy())\n",
    "        node_embeddings[i]['z_sample'].append(node_info[j]['z_sample'].numpy())\n",
    "\n",
    "# flatten the lists\n",
    "k = 0\n",
    "for i in range(nb_nodes):\n",
    "    if data_tree[i][1] == 'no digits':\n",
    "        node_embeddings[i]['prob'] = []\n",
    "        node_embeddings[i]['z_sample'] = []\n",
    "        continue\n",
    "    \n",
    "    node_embeddings[i]['prob'] = np.concatenate(node_embeddings[i]['prob'])\n",
    "    node_embeddings[i]['z_sample'] = np.concatenate(node_embeddings[i]['z_sample'])\n",
    "\n",
    "label_list = np.concatenate(label_list)\n",
    "\n",
    "# Draw the tree graph with scatter plots as nodes and arrows for edges\n",
    "draw_tree_with_scatter_plots(data_tree, node_embeddings, label_list, pca = use_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaf embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we visualize the learnt leaf embeddings after performing PCA. This allows for a closer inspection of the leaf embeddings, which are also visualized in the tree above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get leaf embeddings for each test data point\n",
    "gen_test_iter = iter(gen_test)\n",
    "inputs, labels = next(gen_test_iter)\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "\n",
    "# each entry in node_leaves is a dictionary with keys 'prob' and 'z_sample' for each leaf\n",
    "node_leaves = [{'prob': [], 'z_sample': []} for _ in range(n_d)]\n",
    "label_list = []\n",
    "\n",
    "for inputs, labels in tqdm(gen_test):\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "\n",
    "    label_list.append(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "        node_leaves_cpu = move_to(node_leaves_gpu, 'cpu')\n",
    "        \n",
    "    # for each leaf, append the probability and z_sample to the list\n",
    "    for i in range(n_d):\n",
    "        node_leaves[i]['prob'].append(node_leaves_cpu[i]['prob'].numpy())\n",
    "        node_leaves[i]['z_sample'].append(node_leaves_cpu[i]['z_sample'].numpy())\n",
    "\n",
    "# flatten the lists\n",
    "for i in range(n_d):\n",
    "    node_leaves[i]['prob'] = np.concatenate(node_leaves[i]['prob'])\n",
    "    node_leaves[i]['z_sample'] = np.concatenate(node_leaves[i]['z_sample'])\n",
    "\n",
    "label_list = np.concatenate(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize z_sample for each leaf, do PCA and plot in 2D\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA on node_leaves['z_sample']\n",
    "colors = label_list\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(n_d):\n",
    "    z_sample = node_leaves[i]['z_sample']\n",
    "    weights = node_leaves[i]['prob']\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    z_sample_pca = pca.fit_transform(z_sample)\n",
    "\n",
    "    plt.subplot(2, -(-len(node_leaves)//2), i+1)\n",
    "    plt.scatter(z_sample_pca[:, 0], z_sample_pca[:, 1], c=colors, cmap='tab10', alpha=weights)\n",
    "    plt.title(f\"Leaf {i}\")\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_5\"></a> 5. CelebA attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is designated for analyzing the learnt splits and clusters of datasets without ground truth cluster labels, but various attributes. It is designed with a focus on CelebA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert configs['data']['data_name'] == 'celeba'\n",
    "import pandas as pd\n",
    "data_dir = './data/celeba/'\n",
    "attr = pd.read_csv(data_dir+'/list_attr_celeba.txt', sep=\"\\s+\", skiprows=1)\n",
    "y_test = attr[182637:]\n",
    "y_train = attr[:162770]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cluster-matching attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing step where we store for every node, the indeces of the test samples, whose most likely path went through said node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to leafwise view of samples\n",
    "prob_leaves = predict(gen_test, model, device,'prob_leaves')\n",
    "y = np.squeeze(np.argmax(prob_leaves, axis=-1))\n",
    "sample_ind = []\n",
    "for i in range(len(np.unique(y))):\n",
    "    sample_ind.append([])\n",
    "for i in np.unique(y):\n",
    "    sample_ind[i] = np.where(y==i)[0]\n",
    "    \n",
    "# Fill all internal nodes and create datatree with corresponding samples\n",
    "data_tree_ids = []\n",
    "for i in range(len(data_tree)):\n",
    "    data_tree_ids.append([i,[]])\n",
    "for listnode in reversed(data_tree_ids):\n",
    "    i = listnode[0]\n",
    "    if data_tree[i][3] == 1:\n",
    "        # If leaf, just copy samples from above\n",
    "        data_tree_ids[i][1] = sample_ind[i-(len(data_tree_ids)-len(sample_ind))]\n",
    "    else:\n",
    "        # If internal node, take samples from children\n",
    "        children = []\n",
    "        for j in range(len(data_tree)):\n",
    "            if data_tree[j][2] == i:\n",
    "                children.append(j)\n",
    "        assert len(children)==2\n",
    "        data_tree_ids[i][1] = np.sort(np.concatenate((data_tree_ids[children[0]][1],data_tree_ids[children[1]][1])))\n",
    "        \n",
    "        \n",
    "        \n",
    "# Final ID-tree, where for each node, we store which test sample went through it\n",
    "data_tree_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each split, we additionally store the five attribute that correlate most highly with the the split. This gives an intuition on what attributes the split is based on, i.e. which characteristics the split differentiates between.\n",
    "\n",
    "Note that for CelebA, the \"ground truth\" attributes are in our opinion not the most descriptive ones regarding overall image&cluster impression and focus sometimes on details, on which we don't pick up on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Highest correlated features per split\n",
    "data_tree_new = data_tree.copy()\n",
    "for i in range(len(data_tree_ids)):\n",
    "    in_leaf = False\n",
    "    node_ind = data_tree_ids[i][1]\n",
    "    # Samples in node before split\n",
    "    node_samples = y_test.iloc[node_ind]\n",
    "    # Split of samples\n",
    "    node_split = np.zeros(len(y_test))\n",
    "    children = []\n",
    "    for j in range(len(data_tree)):\n",
    "        if data_tree[j][2] == i:\n",
    "            children.append(j)\n",
    "        if children == []:\n",
    "            in_leaf = True\n",
    "        else:\n",
    "            in_leaf = False\n",
    "    if not in_leaf: \n",
    "        child_left = children[0]\n",
    "        node_split[data_tree_ids[child_left][1]] = 1\n",
    "        node_split = node_split[node_ind]\n",
    "        # Store corr coefficients\n",
    "        corr = np.corrcoef(np.concatenate((np.array(node_samples),np.expand_dims(node_split,1)),1).T)[len(y_test.columns),0:len(y_test.columns)]\n",
    "        data_tree_ids[i].append(corr)\n",
    "        \n",
    "        # Store 5 strongest correlations\n",
    "        ind = np.abs(corr).argsort()[-5:][::-1]\n",
    "        features = y_test.columns[ind].tolist()\n",
    "        for k in range(len(ind)):\n",
    "            if corr[ind[k]] < 0:\n",
    "                features[k] = 'not ' + features[k]\n",
    "            features[k] = features[k] + ' ({})'.format(round(corr[ind[k]], 2))\n",
    "        data_tree_ids[i].append(features)\n",
    "        \n",
    "data_tree_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a summary, for each attribute, we print the split that has the highest correlation with it. This gives an intuition on what internal node differentiates the most according to a given attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributewise node with highest correlation (i.e. internal node that was splitting attribute the most)\n",
    "attr_maxnode = y_test.columns.tolist()\n",
    "for i in range(len(y_test.columns)):\n",
    "    attrcorr = []\n",
    "    for node in range(len(data_tree_ids)):\n",
    "        if len(data_tree_ids[node])==len(data_tree_ids[0]):\n",
    "            attrcorr.append(data_tree_ids[node][2][i])\n",
    "    attrcorr = np.array(attrcorr)\n",
    "    if len(np.argwhere(np.isnan(attrcorr)).squeeze(1))>0:\n",
    "        attrcorr[np.argwhere(np.isnan(attrcorr)).squeeze(1)] = 0\n",
    "    ind = np.argmax(np.abs(attrcorr))\n",
    "    attr_maxnode[i] = attr_maxnode[i] + \": \" + f'{ind}' ' ({})'.format(round(attrcorr[ind], 2))\n",
    "attr_maxnode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the clustering quality according to certain attributes. To do this, in the second cell, pick the indeces of the attributes, whose intersections you want to determine as ground truth clusterings. Then, the NMI is calculated for treating the selected attributes' intersections as ground-truth clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick labels here\n",
    "label_ind = [2,20,39]\n",
    "print([attr_maxnode[i] for i in label_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(label_ind)==2:\n",
    "    label_dict = {\n",
    "        (-1, -1): 0,\n",
    "        (-1, 1): 1,\n",
    "        (1, -1): 2,\n",
    "        (1, 1): 3\n",
    "    }\n",
    "else:\n",
    "    label_dict = {\n",
    "        (-1, -1, -1): 0,\n",
    "        (-1, -1, 1): 1,\n",
    "        (-1, 1, -1): 2,\n",
    "        (-1, 1, 1): 3,\n",
    "        (1, -1, -1): 4,\n",
    "        (1, -1, 1): 5,\n",
    "        (1, 1, -1): 6,\n",
    "        (1, 1, 1): 7\n",
    "    }\n",
    "selected_classes = np.array(y_test.iloc[:, label_ind])\n",
    "selected_classes = [tuple([x for x in a]) for a in selected_classes]\n",
    "label_true = [label_dict[sample_labels] for sample_labels in selected_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NMI:')\n",
    "normalized_mutual_info_score(y, label_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create attribute-wise percentage table for leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subsection presents the frequency of the attributes for each leaf. The numbers indicate the percentage of samples assigned to a given leaf, that contain a certain attribute. For example: 67% of all people assigned to leaf 3 are blonde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_attr = []\n",
    "n_leaves = len(np.unique(y))\n",
    "for i in range(1,1+n_leaves):\n",
    "    data_tree_ids[-i].append((y_test.iloc[data_tree_ids[-i][1]] == 1).mean())\n",
    "    leaf_attr.append((y_test.iloc[data_tree_ids[-i][1]] == 1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_attr_table = pd.DataFrame(np.stack(leaf_attr)[::-1])\n",
    "leaf_attr_table.columns = y_test.columns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "leaf_attr_table.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, one can create new attributes by combining previous attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vars =[]\n",
    "for i in range(1,1+n_leaves):\n",
    "    temp = y_test.iloc[data_tree_ids[-i][1]] == 1\n",
    "    temp['Hair_Loss'] = np.clip(temp['Bald'] + temp['Receding_Hairline'],0,1)\n",
    "    temp['Dark_Hair'] = np.clip(temp['Brown_Hair'] + temp['Black_Hair'],0,1)\n",
    "    temp['Happy'] = np.clip(temp['Smiling'] + temp['Mouth_Slightly_Open'],0,1)\n",
    "    temp['Light_Hair'] = np.clip(temp['Blond_Hair'] + temp['Gray_Hair'],0,1)\n",
    "    temp['Beard'] = np.clip(temp['5_o_Clock_Shadow'] + 1-temp['No_Beard'],0,1)\n",
    "\n",
    "    new_vars.append([temp['Hair_Loss'].mean(),temp['Dark_Hair'].mean(),temp['Happy'].mean(),temp['Light_Hair'].mean(),temp['Beard'].mean()])\n",
    "    \n",
    "new_vars_table = pd.DataFrame(np.stack(new_vars)[::-1])\n",
    "new_vars_table.columns = ['Hair_Loss','Dark_Hair','Happy','Light_Hair','Beard']\n",
    "new_vars_table.round(3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA-FM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
