{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreeVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Of Contents\n",
    "1. [Data Loading](#section_1)\n",
    "2. [Generations](#section_2)\n",
    "3. [Reconstructions](#section_3)\n",
    "4. [Tree and Representation Analysis](#section_4)\n",
    "5. [CelebA Attributes](#section_5)\n",
    "\n",
    "This is the notebook for analyzing and visualizing the trees learnt by TreeVAE. \n",
    "\n",
    "Trees can be learnt by running main.py and stored by setting the option save_model to True in the config file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_1\"></a> 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always execute this section first. This section loads the data and model and computes the NMI to ensure that the model was loaded correctly. Make sure to set the path in the second cell to the specific model that you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyi/.conda/envs/RNA-FM/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from models.model import TreeVAE\n",
    "import scipy\n",
    "import os\n",
    "import yaml\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score\n",
    "from pathlib import Path\n",
    "from utils.utils import reset_random_seeds, display_image\n",
    "from utils.data_utils import get_data, get_gen\n",
    "from utils.training_utils import compute_leaves, predict, move_to\n",
    "from train.validate_tree import compute_likelihood\n",
    "from models.model_smalltree import SmallTreeVAE\n",
    "from models.losses import loss_reconstruction_binary, loss_reconstruction_mse, loss_reconstruction_cov_mse_eval\n",
    "from utils.model_utils import Node, construct_tree_fromnpy, return_list_tree, construct_data_tree, construct_tree_fromnpy\n",
    "from utils.plotting_utils import plot_tree_graph, get_node_embeddings, draw_tree_with_scatter_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'data_name': 'bpdcn712LRT', 'num_clusters_data': 10, 'return_full_data': False, 'varient_path': '/home/junyi/code/treevae/data/Variant/bpdcn712_assemble_trimmed_aligned_mt_addtag_cellSNP0_LRTVariant_paperCell/'}, 'globals': {'config_name': 'bpdcn712LRT', 'eager_mode': True, 'results_dir': PosixPath('/home/junyi/code/treevae/models/experiments'), 'save_model': True, 'seed': 42, 'wandb_logging': 'disabled'}, 'parser': {}, 'run_name': 'bpdcn712LRT', 'training': {'activation': 'sigmoid', 'aug_decisions_weight': 1, 'augment': False, 'augmentation_method': ['simple'], 'batch_size': 256, 'compute_ll': False, 'decay_kl': 0.001, 'decay_lr': 0.1, 'decay_stepsize': 100, 'encoder': 'mlp', 'grow': True, 'initial_depth': 1, 'inp_shape': 2740, 'input_data': 'varient', 'kl_start': 0.0, 'latent_dim': [32, 32, 32], 'lr': 0.001, 'mlp_layers': [128, 128, 128], 'num_clusters_tree': 10, 'num_epochs': 150, 'num_epochs_finetuning': 200, 'num_epochs_intermediate_fulltrain': 80, 'num_epochs_smalltree': 150, 'prune': True, 'weight_decay': 1e-05}}\n"
     ]
    }
   ],
   "source": [
    "path = 'models/experiments/'\n",
    "#ex_path = 'waldvarient/20240517-152258_398b7' # INSERT YOUR PATH HERE previous\n",
    "#ex_path = 'waldvarient/20240520-165201_0bf0e'\n",
    "#ex_path = 'waldvarient/20240521-160839_c28bd'\n",
    "#ex_path = 'waldvarient/20240521-162133_3c9cd'\n",
    "ex_path = 'waldvarient/20240521-163048_ad4c3' # Wald \n",
    "#ex_path = 'bpdcn712LRT/20240522-165608_92439'\n",
    "checkpoint_path = path+ex_path\n",
    "with open(checkpoint_path + \"/config.yaml\", 'r') as stream:\n",
    "    configs = yaml.load(stream,Loader=yaml.Loader)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'data_name': 'bpdcn712LRT',\n",
       "  'num_clusters_data': 10,\n",
       "  'return_full_data': False,\n",
       "  'varient_path': '/home/junyi/code/treevae/data/Variant/bpdcn712_assemble_trimmed_aligned_mt_addtag_cellSNP0_LRTVariant_paperCell/'},\n",
       " 'globals': {'config_name': 'bpdcn712LRT',\n",
       "  'eager_mode': True,\n",
       "  'results_dir': PosixPath('/home/junyi/code/treevae/models/experiments'),\n",
       "  'save_model': True,\n",
       "  'seed': 42,\n",
       "  'wandb_logging': 'disabled'},\n",
       " 'parser': {},\n",
       " 'run_name': 'bpdcn712LRT',\n",
       " 'training': {'activation': 'sigmoid',\n",
       "  'aug_decisions_weight': 1,\n",
       "  'augment': False,\n",
       "  'augmentation_method': ['simple'],\n",
       "  'batch_size': 256,\n",
       "  'compute_ll': False,\n",
       "  'decay_kl': 0.001,\n",
       "  'decay_lr': 0.1,\n",
       "  'decay_stepsize': 100,\n",
       "  'encoder': 'mlp',\n",
       "  'grow': True,\n",
       "  'initial_depth': 1,\n",
       "  'inp_shape': 2740,\n",
       "  'input_data': 'varient',\n",
       "  'kl_start': 0.0,\n",
       "  'latent_dim': [32, 32, 32],\n",
       "  'lr': 0.001,\n",
       "  'mlp_layers': [128, 128, 128],\n",
       "  'num_clusters_tree': 10,\n",
       "  'num_epochs': 150,\n",
       "  'num_epochs_finetuning': 200,\n",
       "  'num_epochs_intermediate_fulltrain': 80,\n",
       "  'num_epochs_smalltree': 150,\n",
       "  'prune': True,\n",
       "  'weight_decay': 1e-05}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'data_name': 'bpdcn712LRT',\n",
       "  'num_clusters_data': 10,\n",
       "  'return_full_data': False,\n",
       "  'varient_path': '/home/junyi/code/treevae/data/Variant/bpdcn712_assemble_trimmed_aligned_mt_addtag_cellSNP0_LRTVariant_paperCell/'},\n",
       " 'globals': {'config_name': 'bpdcn712LRT',\n",
       "  'eager_mode': True,\n",
       "  'results_dir': PosixPath('/home/junyi/code/treevae/models/experiments'),\n",
       "  'save_model': True,\n",
       "  'seed': 42,\n",
       "  'wandb_logging': 'disabled'},\n",
       " 'parser': {},\n",
       " 'run_name': 'bpdcn712LRT',\n",
       " 'training': {'activation': 'sigmoid',\n",
       "  'aug_decisions_weight': 1,\n",
       "  'augment': False,\n",
       "  'augmentation_method': ['simple'],\n",
       "  'batch_size': 256,\n",
       "  'compute_ll': False,\n",
       "  'decay_kl': 0.001,\n",
       "  'decay_lr': 0.1,\n",
       "  'decay_stepsize': 100,\n",
       "  'encoder': 'mlp',\n",
       "  'grow': True,\n",
       "  'initial_depth': 1,\n",
       "  'inp_shape': 2740,\n",
       "  'input_data': 'varient',\n",
       "  'kl_start': 0.0,\n",
       "  'latent_dim': [32, 32, 32],\n",
       "  'lr': 0.001,\n",
       "  'mlp_layers': [128, 128, 128],\n",
       "  'num_clusters_tree': 10,\n",
       "  'num_epochs': 150,\n",
       "  'num_epochs_finetuning': 200,\n",
       "  'num_epochs_intermediate_fulltrain': 80,\n",
       "  'num_epochs_smalltree': 150,\n",
       "  'prune': True,\n",
       "  'weight_decay': 1e-05}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waldvarient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyi/code/treevae/utils/data_utils.py:332: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainset.dataset.targets = torch.tensor(trainset.dataset.tensors[1])\n",
      "/home/junyi/code/treevae/utils/data_utils.py:333: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainset_eval.dataset.targets = torch.tensor(trainset_eval.dataset.tensors[1])\n",
      "/home/junyi/code/treevae/utils/data_utils.py:334: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  testset.dataset.targets = torch.tensor(testset.dataset.tensors[1])\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "configs['data'].update({'return_full_data': True})\n",
    "trainset, trainset_eval, testset = get_data(configs)\n",
    "gen_train = get_gen(trainset, configs, validation=False, shuffle=False)\n",
    "gen_train_eval = get_gen(trainset_eval, configs, validation=True, shuffle=False)\n",
    "gen_test = get_gen(testset, configs, validation=True, shuffle=False)\n",
    "gen_train_eval_iter = iter(gen_train_eval)\n",
    "gen_test_iter = iter(gen_test)\n",
    "y_train = trainset_eval.dataset.targets[trainset_eval.indices].numpy()\n",
    "y_test = testset.dataset.targets[testset.indices].numpy()\n",
    "\n",
    "# Load Model\n",
    "n_d = configs['training']['num_clusters_tree']\n",
    "configs[\"input_data\"]='varient'\n",
    "model = TreeVAE(**configs['training'])\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "data_tree = np.load(checkpoint_path+'/data_tree.npy', allow_pickle=True)\n",
    "model = construct_tree_fromnpy(model, data_tree, configs)\n",
    "if not configs['globals']['eager_mode']:\n",
    "    model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7faf63eb3d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bottom_up.0.dense1.weight',\n",
       "              tensor([[ 0.0030,  0.0304,  0.0047,  ...,  0.0151,  0.0055, -0.0070],\n",
       "                      [ 0.0096, -0.0125, -0.0057,  ..., -0.0006, -0.0037,  0.0153],\n",
       "                      [ 0.0081, -0.0091, -0.0007,  ..., -0.0028,  0.0018, -0.0019],\n",
       "                      ...,\n",
       "                      [ 0.0226,  0.0147,  0.0148,  ..., -0.0032,  0.0320, -0.0067],\n",
       "                      [-0.0049,  0.0066,  0.0195,  ...,  0.0160,  0.0188,  0.0072],\n",
       "                      [ 0.0136,  0.0065,  0.0007,  ...,  0.0131,  0.0134,  0.0067]])),\n",
       "             ('bottom_up.0.bn1.weight',\n",
       "              tensor([0.9943, 0.9997, 0.9999, 0.9944, 1.0113, 0.9986, 0.9969, 0.9874, 0.9810,\n",
       "                      0.9999, 0.9972, 0.9978, 0.9888, 0.9868, 0.9913, 0.9999, 1.0116, 1.0078,\n",
       "                      0.9935, 1.0060, 0.9886, 0.9955, 0.9926, 1.0002, 1.0146, 0.9955, 1.0106,\n",
       "                      0.9886, 0.9932, 1.0033, 0.9876, 1.0071, 0.9904, 0.9990, 0.9914, 0.9889,\n",
       "                      1.0064, 0.9915, 0.9782, 0.9980, 0.9990, 1.0077, 0.9954, 0.9916, 1.0100,\n",
       "                      1.0178, 1.0056, 0.9922, 0.9883, 0.9826, 1.0021, 0.9838, 0.9875, 1.0119,\n",
       "                      1.0176, 0.9862, 1.0139, 0.9906, 0.9943, 0.9875, 0.9853, 1.0027, 0.9926,\n",
       "                      0.9946, 0.9883, 1.0112, 1.0017, 0.9918, 0.9945, 1.0039, 0.9839, 1.0039,\n",
       "                      1.0059, 0.9932, 0.9853, 1.0056, 0.9920, 1.0027, 0.9958, 1.0074, 1.0002,\n",
       "                      1.0057, 0.9920, 0.9891, 0.9968, 0.9902, 1.0016, 0.9994, 1.0053, 0.9949,\n",
       "                      1.0019, 0.9900, 0.9911, 0.9956, 0.9978, 0.9841, 0.9973, 0.9986, 0.9838,\n",
       "                      0.9913, 0.9825, 0.9962, 0.9942, 1.0056, 1.0069, 1.0026, 0.9893, 1.0060,\n",
       "                      1.0082, 0.9862, 1.0205, 1.0036, 0.9787, 0.9880, 0.9969, 0.9973, 1.0047,\n",
       "                      0.9805, 1.0042, 0.9823, 1.0004, 0.9997, 0.9858, 1.0001, 1.0072, 0.9949,\n",
       "                      0.9952, 1.0051, 0.9856, 1.0025, 0.9850, 1.0027, 0.9865, 1.0068, 1.0058,\n",
       "                      0.9919, 0.9922, 1.0001, 0.9965, 1.0007, 1.0058, 0.9909, 1.0083, 1.0130,\n",
       "                      0.9949, 0.9893, 1.0104, 0.9920, 0.9898, 1.0067, 0.9939, 1.0003, 0.9927,\n",
       "                      1.0009, 0.9969, 0.9984, 1.0011, 0.9985, 1.0040, 1.0043, 1.0089, 0.9928,\n",
       "                      0.9857, 1.0005, 0.9991, 0.9903, 0.9934, 0.9936, 1.0016, 0.9935, 0.9971,\n",
       "                      0.9995, 0.9962, 0.9993, 1.0149, 1.0031, 1.0033, 0.9923, 0.9987, 0.9953,\n",
       "                      0.9837, 0.9967, 1.0127, 0.9855, 1.0086, 0.9844, 0.9892, 0.9877, 0.9917,\n",
       "                      0.9941, 0.9912, 1.0007, 0.9957, 0.9945, 0.9871, 1.0172, 0.9959, 0.9863,\n",
       "                      0.9999, 0.9970, 0.9951, 0.9853, 1.0078, 1.0016, 0.9759, 1.0086, 0.9967,\n",
       "                      1.0066, 0.9965, 1.0150, 0.9862, 0.9989, 0.9980, 0.9901, 1.0154, 1.0042,\n",
       "                      0.9931, 1.0080, 1.0162, 1.0050, 0.9856, 1.0242, 0.9922, 1.0128, 1.0038,\n",
       "                      1.0050, 0.9845, 1.0037, 0.9964, 0.9896, 0.9991, 1.0071, 1.0050, 0.9885,\n",
       "                      1.0048, 0.9890, 0.9877, 0.9933, 1.0174, 1.0194, 0.9961, 0.9926, 0.9904,\n",
       "                      1.0036, 1.0030, 0.9941, 1.0011, 0.9925, 1.0129, 0.9976, 1.0061, 0.9994,\n",
       "                      0.9865, 1.0062, 1.0060, 0.9939, 1.0102, 1.0072, 0.9924, 1.0038, 1.0091,\n",
       "                      1.0007, 0.9950, 0.9871, 1.0060, 1.0130, 1.0145, 1.0017, 0.9943, 1.0021,\n",
       "                      0.9961, 1.0027, 1.0052, 1.0108, 0.9842, 0.9906, 1.0119, 1.0142, 0.9841,\n",
       "                      1.0013, 0.9888, 1.0023, 0.9871, 0.9838, 0.9952, 0.9938, 0.9926, 1.0047,\n",
       "                      0.9859, 0.9952, 0.9930, 1.0036, 0.9900, 0.9827, 0.9973, 0.9953, 0.9958,\n",
       "                      1.0110, 0.9974, 1.0041, 0.9908, 0.9944, 1.0139, 1.0103, 0.9940, 0.9812,\n",
       "                      1.0057, 1.0022, 0.9892, 1.0027, 1.0024, 1.0043, 0.9997, 1.0152, 0.9826,\n",
       "                      1.0087, 1.0024, 0.9950, 1.0010, 0.9859, 1.0021, 0.9831, 0.9818, 0.9847,\n",
       "                      0.9987, 0.9901, 0.9913, 1.0032, 0.9995, 1.0004, 0.9948, 1.0060, 0.9957,\n",
       "                      1.0137, 0.9790, 0.9980, 0.9835, 1.0076, 1.0117, 0.9954, 1.0041, 0.9910,\n",
       "                      1.0003, 1.0051, 1.0037, 1.0035, 0.9950, 1.0015, 0.9920, 0.9898, 1.0023,\n",
       "                      0.9902, 1.0050, 0.9875, 1.0078, 0.9967, 0.9963, 1.0171, 0.9947, 0.9834,\n",
       "                      1.0049, 0.9971, 0.9821, 1.0006, 0.9868, 0.9892, 1.0059, 1.0018, 1.0140,\n",
       "                      0.9980, 0.9978, 0.9981, 0.9909, 0.9950, 0.9842, 1.0091, 0.9960, 0.9925,\n",
       "                      0.9922, 0.9889, 0.9903, 1.0003, 0.9877, 0.9855, 1.0047, 1.0077, 0.9977,\n",
       "                      1.0106, 0.9926, 0.9977, 0.9938, 0.9955, 0.9840, 0.9956, 0.9970, 0.9994,\n",
       "                      1.0135, 1.0036, 1.0148, 1.0147, 0.9953, 0.9937, 0.9994, 0.9836, 0.9990,\n",
       "                      1.0026, 1.0043, 1.0014, 0.9908, 1.0011, 0.9886, 1.0153, 0.9970, 1.0004,\n",
       "                      0.9891, 0.9939, 0.9884, 0.9903, 1.0042, 0.9996, 1.0057, 1.0023, 1.0000,\n",
       "                      1.0040, 0.9984, 0.9987, 0.9907, 0.9902, 1.0108, 0.9915, 0.9829, 0.9992,\n",
       "                      1.0062, 0.9952, 0.9976, 0.9953, 0.9952, 0.9899, 1.0061, 1.0066, 1.0150,\n",
       "                      1.0051, 1.0082, 1.0022, 0.9964, 0.9728, 1.0056, 0.9927, 0.9946, 0.9852,\n",
       "                      0.9945, 1.0045, 1.0053, 0.9970, 0.9891, 0.9781, 0.9986, 0.9984, 0.9995,\n",
       "                      0.9996, 0.9968, 0.9929, 0.9973, 1.0078, 0.9996, 0.9785, 0.9921, 0.9999,\n",
       "                      1.0039, 0.9863, 0.9948, 1.0140, 1.0105, 0.9903, 1.0078, 1.0076, 0.9994,\n",
       "                      1.0021, 1.0007, 0.9928, 0.9904, 1.0022, 0.9990, 0.9848, 1.0003, 1.0124,\n",
       "                      1.0000, 0.9967, 0.9891, 1.0104, 0.9905, 0.9925, 1.0220, 0.9903, 0.9931,\n",
       "                      0.9931, 1.0063, 0.9905, 1.0114, 0.9932, 0.9906, 1.0046, 1.0016, 0.9972,\n",
       "                      1.0037, 0.9929, 1.0046, 1.0198, 0.9927, 0.9936, 1.0077, 1.0027])),\n",
       "             ('bottom_up.0.bn1.bias',\n",
       "              tensor([-1.6412e-03,  1.9762e-03,  1.1098e-02,  3.3949e-03,  1.5634e-02,\n",
       "                       9.5463e-03, -3.9759e-03, -6.7144e-03, -8.3412e-03, -5.2794e-03,\n",
       "                       1.4637e-02,  1.8122e-02, -1.4452e-02, -1.0451e-02,  1.5346e-03,\n",
       "                      -4.4905e-03,  2.3452e-02,  2.7668e-03, -1.1288e-02,  1.3685e-02,\n",
       "                      -7.2544e-03,  4.1431e-03, -1.1012e-02, -5.3953e-03,  2.0931e-02,\n",
       "                      -1.7692e-03,  1.7127e-02, -8.5656e-03,  9.7924e-05,  4.5919e-03,\n",
       "                      -9.4258e-03,  8.6107e-03, -5.3653e-03,  1.1292e-02, -2.6186e-03,\n",
       "                      -3.4562e-03,  9.7128e-04, -1.1777e-02, -5.1077e-03,  3.9940e-03,\n",
       "                      -1.8737e-03,  1.5228e-02, -2.7003e-03, -2.9489e-03,  1.3816e-02,\n",
       "                       2.5511e-02, -1.1638e-03, -1.2763e-02, -8.8092e-03, -1.3089e-02,\n",
       "                       7.3666e-03,  4.0293e-03, -9.0086e-03,  1.5041e-02,  2.9280e-02,\n",
       "                       2.3632e-03,  2.1987e-02, -1.5047e-02, -3.0333e-03, -3.9238e-03,\n",
       "                      -9.5651e-03,  1.9388e-02, -3.3849e-03, -1.8159e-03, -1.3065e-02,\n",
       "                       2.7769e-02,  1.0496e-02, -5.7270e-03,  5.7209e-03,  1.4171e-02,\n",
       "                      -1.1328e-02,  7.7747e-03,  1.4862e-03, -5.1996e-03, -1.7602e-03,\n",
       "                       1.8402e-03, -1.0866e-02,  6.9294e-03,  6.0010e-03,  2.2865e-02,\n",
       "                       2.5365e-03, -5.2432e-04, -5.9027e-03, -2.2935e-03, -8.7989e-04,\n",
       "                      -9.0629e-03,  1.2495e-02,  9.3391e-03, -5.4714e-04, -1.4058e-03,\n",
       "                       3.8560e-03, -1.8268e-02, -7.3791e-04, -2.4127e-03, -3.3294e-03,\n",
       "                      -6.8814e-03,  1.5584e-02, -9.0120e-04, -7.7323e-03,  6.0322e-03,\n",
       "                      -1.7009e-02, -5.0279e-03,  7.8664e-03,  2.7202e-02,  1.9966e-02,\n",
       "                       1.3725e-02,  2.7078e-03,  1.6294e-02,  1.6376e-02, -6.5081e-03,\n",
       "                       2.4774e-02,  7.6796e-03, -2.0571e-02, -3.7035e-03,  5.2602e-03,\n",
       "                       6.1669e-03,  1.5184e-02,  1.5846e-03,  1.9772e-03, -8.4109e-03,\n",
       "                       7.1227e-03, -5.5060e-03,  8.3066e-04, -2.3771e-03,  3.7965e-03,\n",
       "                      -1.3790e-02,  1.1128e-04,  1.9125e-02, -1.0422e-02,  1.9249e-02,\n",
       "                      -8.7652e-03,  5.6067e-03, -1.4699e-02,  5.3307e-03,  1.4344e-02,\n",
       "                       1.1499e-04, -1.4943e-02,  8.0480e-03,  7.6471e-03,  9.5336e-05,\n",
       "                       2.2079e-02, -4.2867e-03,  1.5295e-02,  2.3587e-02,  4.7280e-03,\n",
       "                      -5.1526e-03,  1.4827e-02,  1.5289e-03, -5.6438e-03,  1.6360e-02,\n",
       "                      -1.3267e-03,  3.0004e-03, -7.9490e-03, -1.4251e-03,  8.2699e-03,\n",
       "                       5.3398e-04,  1.0393e-02, -4.6537e-03,  9.6174e-03,  8.0082e-03,\n",
       "                       1.2250e-02,  4.7723e-04,  3.2668e-04,  8.0156e-04, -2.2542e-03,\n",
       "                      -1.1409e-03, -1.2362e-02, -3.5415e-03,  1.0337e-02,  3.8038e-03,\n",
       "                       3.7791e-03,  2.5158e-02,  1.1568e-02,  1.3281e-02,  2.2619e-02,\n",
       "                      -4.2564e-03,  1.1014e-02, -3.5904e-03,  6.7179e-03, -4.4404e-03,\n",
       "                      -1.3411e-02, -1.3073e-03,  1.3141e-02, -9.6496e-03,  2.0622e-02,\n",
       "                      -7.5136e-03,  1.4666e-02, -4.7517e-03,  8.4448e-03,  2.2212e-03,\n",
       "                      -6.0715e-03, -4.1616e-03,  1.3735e-02, -1.2004e-02, -1.0447e-02,\n",
       "                       2.7918e-02, -2.8552e-03, -6.2734e-03,  9.6094e-03, -7.7663e-04,\n",
       "                      -4.8874e-03, -1.1596e-02,  2.2968e-02,  1.1346e-02, -1.4922e-02,\n",
       "                       1.7711e-02, -1.4335e-02,  3.1615e-02,  4.5704e-03,  2.6185e-02,\n",
       "                      -5.2125e-03,  1.2778e-02, -7.7470e-03, -1.1264e-02,  1.8287e-02,\n",
       "                       7.6158e-04, -1.5488e-03,  1.5478e-02,  1.9415e-02,  4.4342e-02,\n",
       "                      -7.0519e-03,  2.2052e-02,  4.4775e-03,  1.5979e-02, -2.2312e-03,\n",
       "                       2.2988e-02, -7.2749e-03,  1.0724e-02, -5.9991e-03,  3.0763e-03,\n",
       "                       1.2458e-02,  1.7914e-02,  6.4708e-03, -4.2263e-04,  1.0303e-02,\n",
       "                       3.2069e-03, -1.0015e-02, -1.4464e-02,  1.2229e-02,  2.6329e-02,\n",
       "                      -2.6975e-03,  1.9314e-03, -8.1637e-03,  1.3279e-02,  1.2077e-02,\n",
       "                      -3.9601e-03,  4.9684e-03, -6.4226e-03,  1.7537e-02,  5.4211e-03,\n",
       "                       7.7149e-03,  1.5963e-02, -2.2932e-02,  4.5475e-04,  1.2888e-02,\n",
       "                      -2.3672e-03,  1.5791e-02,  1.3135e-02,  3.6149e-03,  4.5057e-03,\n",
       "                       2.0986e-03,  9.0628e-03, -7.9494e-04, -2.0078e-02,  1.4449e-02,\n",
       "                       1.4920e-02,  1.9692e-02,  9.7038e-03, -4.2624e-03,  1.3455e-03,\n",
       "                      -2.3879e-03, -1.8503e-03,  1.1578e-02,  2.1186e-02, -9.9455e-03,\n",
       "                      -1.2644e-02,  1.7634e-02,  1.9065e-02, -8.2301e-03, -8.2632e-04,\n",
       "                       1.3965e-02,  1.3010e-02,  1.3185e-03, -6.7936e-03, -2.3334e-03,\n",
       "                      -1.5937e-03, -4.5813e-03,  7.5513e-03,  4.5612e-04,  3.3709e-03,\n",
       "                       1.1621e-02,  1.6821e-02, -7.5528e-03, -1.3216e-02,  1.8946e-03,\n",
       "                       1.8583e-03, -3.8181e-03,  1.2314e-02,  1.0089e-02,  9.4437e-03,\n",
       "                       6.7351e-03,  3.0221e-03,  1.7375e-02,  1.5004e-02, -2.3512e-03,\n",
       "                      -1.0225e-02,  3.4560e-03,  6.6051e-03,  8.4614e-04,  1.1869e-02,\n",
       "                       5.4769e-03,  2.6236e-03,  3.4198e-03,  2.3315e-02, -1.0736e-02,\n",
       "                       1.1025e-02,  2.7009e-04, -3.2201e-03,  2.2500e-03, -4.3863e-04,\n",
       "                      -2.4712e-03, -1.1091e-02, -6.0797e-03, -1.1390e-02,  4.0778e-03,\n",
       "                      -4.8418e-03, -1.1807e-02,  2.0978e-02,  9.2331e-03,  9.4529e-03,\n",
       "                       1.9895e-03,  1.7821e-03,  1.5997e-02,  2.2891e-02, -1.3623e-02,\n",
       "                      -4.7311e-03, -1.3473e-02,  8.8207e-03,  2.2127e-02,  1.3067e-03,\n",
       "                       2.2785e-02,  1.3998e-03,  1.1829e-02,  1.2310e-03,  1.2664e-02,\n",
       "                       1.8751e-02,  3.5243e-03,  4.2237e-03, -1.4944e-02, -4.0387e-03,\n",
       "                       7.5927e-03, -3.6407e-03,  3.6260e-03, -1.0006e-02,  1.0440e-02,\n",
       "                       1.3342e-02,  5.3645e-03,  2.1757e-02,  2.7012e-03, -5.0025e-03,\n",
       "                       9.0227e-03, -5.4901e-03, -2.2206e-03,  6.3608e-03, -1.4901e-02,\n",
       "                       7.4599e-04,  2.1638e-02,  1.1177e-02,  2.9175e-02,  5.6377e-03,\n",
       "                       3.3911e-03,  4.1406e-03,  2.7769e-03,  6.7563e-03, -1.4721e-02,\n",
       "                       4.0711e-03, -5.8450e-04,  1.6488e-03,  8.8584e-03, -1.9089e-03,\n",
       "                      -1.3478e-02,  8.8789e-03, -5.6861e-03, -1.8512e-02,  2.1306e-02,\n",
       "                       3.3756e-03, -4.6736e-03,  8.3445e-03, -6.6117e-03,  1.6693e-03,\n",
       "                      -6.2245e-04,  7.7814e-03,  3.7276e-03,  6.9353e-03,  1.6196e-02,\n",
       "                       4.3122e-03,  2.1813e-02,  5.8088e-03,  4.1169e-02,  2.2726e-02,\n",
       "                       1.7140e-04,  5.5182e-03, -3.1369e-04, -1.1472e-02,  7.4650e-03,\n",
       "                       8.9381e-03,  9.6467e-03,  4.3733e-03, -1.8358e-03,  1.4974e-02,\n",
       "                      -8.2001e-03,  1.9667e-02,  1.0747e-02,  1.0984e-02, -9.4477e-03,\n",
       "                      -7.9970e-03, -3.5440e-04, -1.6370e-02,  7.0381e-03,  6.9801e-03,\n",
       "                       1.3253e-02,  8.2591e-03, -5.6622e-05,  1.7419e-02,  2.0782e-02,\n",
       "                       2.7246e-03,  9.6639e-03, -2.9374e-03,  3.2757e-03, -1.3005e-02,\n",
       "                      -6.2454e-03, -3.7473e-03,  3.6461e-02, -2.6734e-03,  1.0114e-02,\n",
       "                       1.3870e-02, -1.1995e-03, -8.6702e-03,  4.4409e-03,  1.4269e-03,\n",
       "                       2.7360e-02,  1.1917e-02,  1.5847e-02,  1.5217e-02, -1.1368e-02,\n",
       "                      -2.4752e-02,  8.1495e-03,  1.1027e-04, -4.3937e-03, -1.8700e-02,\n",
       "                       2.0581e-03,  1.0612e-02, -2.4405e-04, -2.5952e-03, -5.4538e-03,\n",
       "                      -1.8916e-02,  1.0441e-02,  9.5318e-03,  2.3687e-04,  2.8062e-02,\n",
       "                       7.3138e-04,  1.5423e-03, -2.3187e-04,  1.9811e-02,  4.5099e-03,\n",
       "                      -2.6361e-02,  3.5667e-03,  2.8527e-03, -1.1345e-03, -1.3646e-02,\n",
       "                       6.6512e-03,  5.0422e-03,  2.1963e-02,  1.3300e-02, -2.3270e-03,\n",
       "                       1.5777e-02,  5.2838e-03,  1.9857e-03,  7.5209e-03, -1.0027e-03,\n",
       "                       1.7648e-03,  6.9485e-03,  1.9578e-02, -1.8249e-02, -4.9601e-03,\n",
       "                       3.0748e-02,  5.0550e-03, -5.1774e-03,  6.5951e-03,  2.4812e-02,\n",
       "                      -2.8787e-03, -3.8376e-04,  1.5515e-02, -9.1424e-03,  2.6602e-03,\n",
       "                      -7.7410e-03,  7.3340e-03, -7.4888e-03,  1.9478e-02, -7.8740e-03,\n",
       "                      -2.9743e-03,  1.2807e-02,  1.3977e-02,  4.3140e-04,  1.9669e-02,\n",
       "                       1.7480e-02,  1.4956e-02,  2.6840e-02, -6.7533e-03, -6.7312e-03,\n",
       "                       4.8618e-03,  1.5536e-02])),\n",
       "             ('bottom_up.0.bn1.running_mean',\n",
       "              tensor([ 6.5612e-03, -4.8501e-03, -4.3905e-02,  9.8781e-03,  2.6703e-03,\n",
       "                      -2.7790e-02, -3.8478e-02, -4.1894e-02,  7.8705e-03,  1.9147e-02,\n",
       "                      -3.5519e-02, -5.7680e-03, -2.7439e-02, -1.8576e-02, -2.0802e-02,\n",
       "                      -7.0644e-03,  4.5906e-02, -4.7362e-02,  7.7471e-03, -1.8297e-02,\n",
       "                       8.8631e-03, -2.7798e-03,  2.1642e-02,  2.8485e-02,  1.7491e-02,\n",
       "                      -3.2435e-02, -2.8747e-02,  7.8557e-03,  2.3345e-02,  2.0076e-02,\n",
       "                       4.0557e-02, -3.4900e-02,  5.6150e-03,  9.1710e-03,  2.3038e-02,\n",
       "                      -1.2953e-02,  1.2007e-02, -2.4248e-02,  3.8859e-02, -3.4185e-02,\n",
       "                      -1.2876e-02,  3.3521e-02, -1.8692e-02,  1.9840e-02,  1.6568e-02,\n",
       "                      -3.9114e-03,  1.0831e-02,  5.7582e-02,  3.6330e-02, -4.1281e-02,\n",
       "                       4.2786e-03,  1.8605e-02, -2.9445e-02, -1.8437e-02, -1.7620e-02,\n",
       "                       2.7593e-03,  4.8601e-03, -3.1295e-02,  9.3675e-03,  1.6186e-02,\n",
       "                      -3.7365e-02,  3.9634e-02,  5.0347e-02,  5.5323e-02, -2.5344e-02,\n",
       "                       1.5439e-03, -1.9058e-03,  3.2723e-02, -1.5099e-02,  2.1641e-02,\n",
       "                      -1.6059e-02,  2.2727e-02, -2.1303e-02, -1.6313e-02,  1.9684e-03,\n",
       "                       6.0202e-03,  1.3447e-02,  2.4098e-02,  6.7605e-03, -2.8987e-02,\n",
       "                      -7.6681e-02, -1.3767e-02, -2.5989e-02,  4.9107e-02,  6.9363e-03,\n",
       "                      -1.0755e-01,  9.8352e-03, -3.5033e-02,  3.4338e-02, -1.2250e-02,\n",
       "                      -3.1708e-02, -2.5557e-02,  1.0090e-02, -1.0229e-03, -8.2582e-03,\n",
       "                       2.2919e-02,  4.1152e-02, -3.7601e-02,  4.8337e-02, -4.6658e-02,\n",
       "                      -1.2611e-02,  2.9670e-02,  4.1547e-02, -2.9151e-02,  4.2522e-02,\n",
       "                       1.3086e-02,  9.8557e-03, -7.2964e-03,  6.0377e-03, -3.5587e-02,\n",
       "                       2.7318e-03,  2.6817e-03, -3.2857e-02, -1.4706e-03,  1.2617e-02,\n",
       "                       2.4983e-02, -2.5922e-02, -3.3177e-02, -2.4928e-03, -2.4814e-02,\n",
       "                      -3.1172e-03, -4.7237e-03,  3.0686e-02, -3.8290e-02,  4.2413e-02,\n",
       "                      -3.6357e-02,  2.6568e-04, -3.4248e-02, -4.0805e-02, -1.9024e-02,\n",
       "                       3.6177e-02, -2.6768e-02, -2.6800e-02, -1.8887e-02, -2.0179e-02,\n",
       "                      -3.5074e-02,  2.2005e-02,  7.6000e-02,  9.6893e-04,  1.5579e-02,\n",
       "                       1.7997e-02, -2.0986e-03,  3.9053e-02, -4.1671e-02, -1.4956e-02,\n",
       "                       6.0880e-04,  2.8856e-03,  1.8653e-02, -3.2122e-02, -1.3904e-02,\n",
       "                       2.2066e-02, -2.0249e-02,  4.4983e-02, -3.4197e-02,  2.7179e-02,\n",
       "                      -3.5442e-02,  1.9878e-02, -3.7765e-02, -1.9750e-02,  4.1246e-02,\n",
       "                       1.7062e-02, -5.4197e-02,  5.3624e-02, -2.8238e-02, -8.6769e-03,\n",
       "                      -5.2425e-02, -4.0932e-02,  3.3444e-02,  3.0216e-02,  2.1852e-02,\n",
       "                      -3.6464e-03, -9.1750e-03, -1.9572e-02, -4.4933e-03,  8.4015e-03,\n",
       "                       1.3400e-02,  1.0504e-02, -1.1571e-02,  3.3213e-02,  2.9210e-02,\n",
       "                      -8.9582e-03, -1.4481e-02, -2.2071e-02, -8.3470e-03,  2.6756e-02,\n",
       "                       1.1688e-02,  9.5989e-03, -4.9590e-02,  5.1518e-02,  3.3978e-02,\n",
       "                       4.2544e-02,  9.5888e-03,  1.9244e-02,  1.8360e-02, -1.0452e-02,\n",
       "                      -2.1778e-02, -1.7423e-02, -2.5290e-02, -1.1340e-02, -2.6735e-02,\n",
       "                      -2.2915e-02, -3.4779e-03, -2.3674e-02, -3.1056e-02,  3.7722e-02,\n",
       "                      -1.9392e-02, -1.9637e-02,  3.4680e-02, -2.1026e-02, -1.1647e-02,\n",
       "                      -3.3188e-03, -1.4743e-02,  2.4090e-02,  3.9432e-02,  6.1335e-03,\n",
       "                       2.4648e-02, -1.8208e-02,  4.9622e-03, -7.2910e-03, -1.4219e-02,\n",
       "                       4.5613e-03, -2.1610e-02,  1.6336e-02,  1.1049e-02,  5.9385e-02,\n",
       "                       8.2562e-03,  6.2973e-03,  2.8324e-02, -1.1289e-03,  6.4843e-03,\n",
       "                      -1.3000e-02, -2.7948e-02, -1.5986e-02,  2.6127e-02,  1.0471e-02,\n",
       "                       1.2288e-03, -1.2492e-02, -5.9492e-02,  2.4714e-02,  8.0647e-03,\n",
       "                      -4.2313e-02, -1.6005e-02,  6.0723e-02, -1.0475e-02, -5.8536e-03,\n",
       "                       1.7868e-03,  4.0808e-02, -2.4984e-02,  2.2409e-02,  1.6216e-02,\n",
       "                      -1.8352e-03, -7.9345e-04,  1.8997e-02, -1.3782e-02,  2.6838e-02,\n",
       "                       8.1421e-03, -8.3977e-05, -1.0062e-03,  2.6923e-02,  2.4293e-02,\n",
       "                      -7.4245e-03,  8.8084e-03, -7.2625e-04,  1.4401e-02, -1.9131e-02,\n",
       "                      -5.7444e-02, -2.6059e-02, -3.1523e-02, -2.8278e-02, -3.2172e-02,\n",
       "                      -8.9117e-02, -3.2931e-02,  2.0746e-02, -1.8136e-02,  1.5627e-02,\n",
       "                       2.0798e-02,  1.6638e-03, -1.1900e-02,  1.0525e-02, -4.7811e-02,\n",
       "                       6.1970e-02, -5.5161e-03, -3.0659e-03, -2.6752e-02,  2.6052e-02,\n",
       "                       2.2011e-02,  1.8911e-02, -3.6202e-03, -3.0821e-02,  1.6451e-02,\n",
       "                       1.4805e-03,  2.3197e-03,  3.5299e-02, -1.4515e-02, -4.7283e-02,\n",
       "                      -4.7828e-03,  1.2263e-02, -2.6007e-03, -5.0663e-02, -3.7946e-02,\n",
       "                      -3.7933e-02,  4.6750e-03,  4.7400e-03,  3.0290e-02,  6.1929e-02,\n",
       "                      -3.2101e-03,  2.1462e-02, -1.7939e-02,  2.5421e-02, -1.1655e-03,\n",
       "                      -3.4870e-02,  2.1267e-02, -6.8837e-03, -1.3208e-02, -2.2410e-02,\n",
       "                      -5.1765e-03,  2.2953e-02, -1.5110e-02,  3.9816e-02,  4.2589e-02,\n",
       "                       2.5838e-02,  9.0738e-03, -4.2613e-02, -6.1813e-03, -1.3256e-03,\n",
       "                      -2.8318e-02,  5.1871e-02,  2.3477e-03, -3.3211e-02,  1.6762e-02,\n",
       "                      -3.9206e-02, -5.0590e-03, -2.5493e-02, -1.0342e-02,  1.7272e-02,\n",
       "                       4.6074e-03, -3.3208e-02,  3.6612e-03,  4.6476e-03,  1.0959e-02,\n",
       "                       6.3909e-04,  4.2013e-02,  2.9558e-02, -2.5797e-02,  4.8268e-02,\n",
       "                       2.4320e-02, -1.8636e-03,  1.0187e-02, -6.0275e-02,  1.0260e-02,\n",
       "                      -1.1513e-02,  2.6496e-02, -1.6508e-03,  3.8744e-02, -1.1687e-02,\n",
       "                       2.6188e-02, -1.4344e-02,  2.8837e-03, -1.1245e-02, -1.1696e-02,\n",
       "                      -4.6219e-03,  7.6133e-02, -7.6736e-03, -2.1047e-02, -5.2020e-03,\n",
       "                      -5.9994e-03, -3.9421e-03,  6.4248e-03,  4.8971e-03, -6.9575e-03,\n",
       "                      -8.6534e-02,  2.4686e-02, -7.8334e-03, -3.0708e-02, -5.9982e-03,\n",
       "                       3.9299e-02, -8.0605e-02, -1.7222e-02,  1.5691e-02, -2.8136e-02,\n",
       "                      -2.0545e-02, -8.5377e-03, -1.2772e-02,  9.1994e-03,  1.2908e-02,\n",
       "                       1.6501e-02, -1.7525e-02,  4.3669e-02, -9.1876e-03,  4.1651e-02,\n",
       "                      -2.0835e-02, -3.2746e-02, -5.4018e-02,  1.9893e-02, -2.4452e-02,\n",
       "                       2.9054e-02,  3.2084e-03,  2.8277e-02, -2.8686e-02, -8.9181e-03,\n",
       "                      -1.2773e-02,  6.1858e-02, -8.6261e-03, -9.7522e-03, -2.6486e-02,\n",
       "                      -1.6653e-02,  1.8126e-02, -3.4366e-02,  1.8074e-02,  2.1548e-02,\n",
       "                       2.0702e-02,  2.9723e-02, -3.9023e-02, -3.2276e-02, -5.6592e-03,\n",
       "                      -4.5002e-03, -5.7493e-02,  1.5024e-02,  5.0537e-03, -1.0223e-02,\n",
       "                      -1.6703e-02,  4.7528e-02,  2.5480e-02,  1.8150e-02,  3.8475e-03,\n",
       "                      -3.3696e-02, -4.7453e-02, -1.8680e-04,  4.0454e-02,  2.4044e-02,\n",
       "                       2.8387e-02, -2.8997e-02, -3.1578e-02,  6.6741e-03, -7.9954e-03,\n",
       "                      -4.7991e-02, -3.6295e-02, -1.0709e-02,  2.1112e-02, -1.9899e-02,\n",
       "                       1.0414e-02,  1.7596e-02,  2.4317e-02,  2.9651e-02, -4.8743e-03,\n",
       "                      -1.6922e-02,  2.4031e-03,  1.3624e-02, -1.3645e-02, -1.1624e-02,\n",
       "                      -6.7896e-02,  7.9144e-03,  3.0501e-02,  1.1125e-02, -8.2771e-03,\n",
       "                      -1.1621e-02,  2.2703e-02, -2.0624e-02,  3.0144e-02,  1.9872e-02,\n",
       "                       3.1325e-02,  6.4871e-03,  2.6920e-02,  1.8952e-02,  3.0924e-02,\n",
       "                      -7.6665e-03, -3.1192e-02,  5.1521e-02,  4.8052e-02, -1.9006e-02,\n",
       "                      -7.5496e-03,  6.2889e-03,  1.1324e-02,  2.7216e-04,  4.5289e-02,\n",
       "                      -4.4563e-02, -1.1714e-02, -1.0228e-03,  2.1728e-02,  5.6768e-02,\n",
       "                      -5.5101e-03,  5.6718e-02,  3.0391e-03, -2.3726e-03, -2.1926e-02,\n",
       "                       1.7130e-02, -4.5684e-02, -2.7976e-02, -2.2264e-03, -1.9752e-02,\n",
       "                       1.8609e-04,  3.2524e-02,  3.5653e-02, -1.2793e-02, -2.3317e-03,\n",
       "                      -4.1458e-02,  3.8401e-02,  3.3981e-02,  8.1862e-03,  2.4822e-02,\n",
       "                       1.0474e-03,  3.8802e-02,  4.4171e-02,  3.5632e-02,  1.6075e-02,\n",
       "                      -4.4427e-02, -4.2424e-02, -2.3993e-02,  9.4548e-03,  3.0536e-02,\n",
       "                      -3.4567e-02,  2.1956e-02])),\n",
       "             ('bottom_up.0.bn1.running_var',\n",
       "              tensor([0.0008, 0.0007, 0.0008, 0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0007, 0.0008, 0.0008, 0.0007, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0009, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008,\n",
       "                      0.0007, 0.0008, 0.0007, 0.0007, 0.0008, 0.0007, 0.0008, 0.0007, 0.0008,\n",
       "                      0.0008, 0.0008, 0.0007, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
       "                      0.0008, 0.0010, 0.0007, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "                      0.0009, 0.0008, 0.0009, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008, 0.0009,\n",
       "                      0.0007, 0.0007, 0.0008, 0.0008, 0.0007, 0.0008, 0.0009, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007,\n",
       "                      0.0008, 0.0010, 0.0008, 0.0008, 0.0008, 0.0009, 0.0008, 0.0007, 0.0009,\n",
       "                      0.0007, 0.0007, 0.0007, 0.0008, 0.0007, 0.0008, 0.0008, 0.0007, 0.0008,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0007, 0.0008, 0.0008, 0.0007, 0.0008, 0.0009,\n",
       "                      0.0007, 0.0008, 0.0009, 0.0009, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007,\n",
       "                      0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0008, 0.0007, 0.0007, 0.0008,\n",
       "                      0.0009, 0.0008, 0.0007, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0009,\n",
       "                      0.0007, 0.0009, 0.0008, 0.0009, 0.0008, 0.0009, 0.0007, 0.0008, 0.0009,\n",
       "                      0.0007, 0.0008, 0.0007, 0.0008, 0.0007, 0.0008, 0.0007, 0.0008, 0.0007,\n",
       "                      0.0007, 0.0009, 0.0008, 0.0007, 0.0008, 0.0007, 0.0008, 0.0008, 0.0007,\n",
       "                      0.0007, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007, 0.0008, 0.0009,\n",
       "                      0.0009, 0.0008, 0.0008, 0.0008, 0.0007, 0.0008, 0.0007, 0.0010, 0.0007,\n",
       "                      0.0007, 0.0007, 0.0008, 0.0007, 0.0008, 0.0007, 0.0009, 0.0008, 0.0009,\n",
       "                      0.0007, 0.0007, 0.0007, 0.0008, 0.0008, 0.0007, 0.0009, 0.0008, 0.0007,\n",
       "                      0.0010, 0.0008, 0.0007, 0.0007, 0.0009, 0.0008, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0009, 0.0007, 0.0008, 0.0007, 0.0009, 0.0007, 0.0007, 0.0008, 0.0008,\n",
       "                      0.0007, 0.0008, 0.0008, 0.0011, 0.0008, 0.0009, 0.0008, 0.0008, 0.0008,\n",
       "                      0.0010, 0.0008, 0.0009, 0.0009, 0.0007, 0.0009, 0.0009, 0.0007, 0.0007,\n",
       "                      0.0007, 0.0008, 0.0007, 0.0007, 0.0008, 0.0010, 0.0008, 0.0009, 0.0007,\n",
       "                      0.0008, 0.0007, 0.0007, 0.0008, 0.0007, 0.0010, 0.0007, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0007, 0.0007, 0.0008, 0.0008, 0.0007, 0.0008, 0.0008, 0.0007,\n",
       "                      0.0009, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0006,\n",
       "                      0.0009, 0.0007, 0.0009, 0.0010, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
       "                      0.0007, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0008,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007, 0.0007, 0.0008,\n",
       "                      0.0009, 0.0010, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0008, 0.0007,\n",
       "                      0.0007, 0.0009, 0.0008, 0.0010, 0.0007, 0.0007, 0.0007, 0.0008, 0.0008,\n",
       "                      0.0008, 0.0009, 0.0007, 0.0007, 0.0007, 0.0008, 0.0009, 0.0008, 0.0007,\n",
       "                      0.0007, 0.0007, 0.0007, 0.0009, 0.0007, 0.0008, 0.0011, 0.0009, 0.0009,\n",
       "                      0.0009, 0.0007, 0.0007, 0.0007, 0.0009, 0.0007, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0007, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007, 0.0007, 0.0008,\n",
       "                      0.0009, 0.0007, 0.0008, 0.0008, 0.0009, 0.0008, 0.0009, 0.0007, 0.0009,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0010, 0.0008, 0.0008, 0.0010, 0.0007, 0.0008,\n",
       "                      0.0008, 0.0007, 0.0007, 0.0007, 0.0011, 0.0007, 0.0009, 0.0009, 0.0008,\n",
       "                      0.0009, 0.0007, 0.0007, 0.0007, 0.0007, 0.0009, 0.0007, 0.0008, 0.0008,\n",
       "                      0.0007, 0.0007, 0.0007, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007,\n",
       "                      0.0008, 0.0008, 0.0011, 0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0008,\n",
       "                      0.0008, 0.0008, 0.0010, 0.0007, 0.0008, 0.0007, 0.0008, 0.0007, 0.0008,\n",
       "                      0.0007, 0.0007, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0009,\n",
       "                      0.0011, 0.0008, 0.0008, 0.0008, 0.0008, 0.0009, 0.0008, 0.0008, 0.0007,\n",
       "                      0.0009, 0.0007, 0.0009, 0.0008, 0.0008, 0.0007, 0.0007, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0008, 0.0008, 0.0009,\n",
       "                      0.0007, 0.0007, 0.0008, 0.0008, 0.0009, 0.0008, 0.0009, 0.0007, 0.0008,\n",
       "                      0.0009, 0.0007, 0.0008, 0.0007, 0.0008, 0.0009, 0.0008, 0.0007, 0.0007,\n",
       "                      0.0007, 0.0007, 0.0006, 0.0009, 0.0008, 0.0007, 0.0007, 0.0008, 0.0007,\n",
       "                      0.0007, 0.0007, 0.0009, 0.0008, 0.0008, 0.0009, 0.0007, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0007, 0.0008, 0.0008, 0.0008, 0.0007, 0.0010, 0.0008, 0.0007,\n",
       "                      0.0008, 0.0008, 0.0008, 0.0009, 0.0008, 0.0007, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0007, 0.0008, 0.0009, 0.0008, 0.0009, 0.0007, 0.0007, 0.0008])),\n",
       "             ('bottom_up.0.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.0.dense2.weight',\n",
       "              tensor([[ 0.0288, -0.0413,  0.0313,  ...,  0.0103, -0.0075, -0.0464],\n",
       "                      [-0.0277,  0.0031, -0.0119,  ..., -0.0053, -0.0165, -0.0233],\n",
       "                      [-0.0031, -0.0408,  0.0296,  ...,  0.0049,  0.0072,  0.0022],\n",
       "                      ...,\n",
       "                      [ 0.0094, -0.0217, -0.0365,  ...,  0.0449,  0.0119, -0.0477],\n",
       "                      [ 0.0112,  0.0066, -0.0171,  ...,  0.0401, -0.0049, -0.0423],\n",
       "                      [ 0.0311,  0.0030, -0.0202,  ..., -0.0342,  0.0481,  0.0054]])),\n",
       "             ('bottom_up.0.bn2.weight',\n",
       "              tensor([1.0124, 1.0127, 1.0077, 1.0053, 1.0046, 0.9852, 0.9826, 0.9941, 0.9933,\n",
       "                      0.9822, 1.0041, 1.0049, 1.0047, 0.9905, 1.0128, 1.0088, 1.0112, 1.0037,\n",
       "                      1.0039, 1.0087, 0.9997, 1.0025, 0.9821, 0.9973, 1.0093, 1.0057, 0.9888,\n",
       "                      0.9925, 1.0199, 1.0172, 1.0036, 0.9915, 0.9962, 0.9987, 0.9985, 1.0028,\n",
       "                      0.9960, 0.9984, 0.9979, 0.9911, 0.9949, 0.9972, 0.9866, 1.0075, 1.0039,\n",
       "                      0.9928, 0.9974, 0.9951, 0.9954, 0.9875, 1.0013, 1.0161, 0.9863, 0.9890,\n",
       "                      0.9883, 0.9996, 0.9962, 1.0088, 0.9784, 1.0039, 1.0075, 1.0017, 0.9927,\n",
       "                      0.9874, 0.9973, 0.9885, 0.9853, 1.0074, 1.0029, 1.0061, 0.9990, 0.9927,\n",
       "                      1.0056, 0.9963, 0.9867, 0.9933, 0.9939, 0.9856, 0.9948, 0.9928, 0.9998,\n",
       "                      0.9927, 0.9795, 0.9931, 0.9990, 0.9793, 0.9956, 0.9884, 0.9966, 1.0055,\n",
       "                      0.9941, 0.9853, 0.9838, 0.9954, 1.0038, 0.9916, 0.9970, 0.9973, 1.0159,\n",
       "                      0.9859, 1.0155, 0.9963, 1.0139, 0.9934, 1.0021, 0.9984, 0.9968, 1.0062,\n",
       "                      0.9817, 1.0007, 0.9920, 0.9920, 0.9912, 1.0119, 1.0065, 1.0036, 1.0141,\n",
       "                      0.9949, 0.9908, 0.9905, 0.9927, 0.9934, 1.0017, 0.9866, 1.0059, 0.9813,\n",
       "                      1.0000, 1.0130, 0.9925, 1.0196, 0.9939, 0.9901, 1.0081, 0.9977, 0.9860,\n",
       "                      0.9977, 0.9806, 0.9948, 1.0024, 0.9913, 1.0161, 0.9788, 0.9872, 1.0163,\n",
       "                      0.9921, 1.0047, 0.9879, 1.0014, 0.9993, 1.0008, 1.0066, 1.0143, 0.9897,\n",
       "                      0.9941, 0.9864, 1.0056, 0.9839, 1.0050, 0.9958, 1.0100, 0.9919, 1.0010,\n",
       "                      1.0027, 1.0055, 1.0116, 1.0133, 0.9931, 0.9941, 0.9906, 0.9978, 1.0105,\n",
       "                      1.0122, 0.9844, 1.0045, 0.9953, 1.0024, 1.0041, 0.9989, 0.9842, 0.9933,\n",
       "                      0.9977, 0.9954, 0.9864, 0.9914, 1.0101, 0.9874, 0.9924, 0.9984, 1.0001,\n",
       "                      0.9937, 0.9935, 1.0136, 1.0100, 1.0013, 0.9916, 0.9990, 0.9975, 1.0051,\n",
       "                      0.9943, 0.9975, 0.9935, 0.9939, 0.9931, 0.9939, 0.9989, 1.0115, 0.9998,\n",
       "                      1.0098, 0.9848, 0.9968, 0.9946, 1.0003, 1.0116, 0.9858, 0.9924, 0.9955,\n",
       "                      0.9909, 0.9928, 0.9982, 1.0051, 1.0128, 0.9932, 0.9908, 0.9951, 1.0095,\n",
       "                      1.0044, 0.9979, 0.9926, 0.9960, 1.0105, 1.0018, 1.0049, 0.9966, 1.0053,\n",
       "                      0.9857, 1.0045, 1.0045, 1.0110, 1.0086, 1.0076, 0.9976, 0.9961, 1.0018,\n",
       "                      1.0000, 0.9969, 0.9817, 1.0018, 1.0056, 1.0063, 0.9982, 0.9899, 0.9981,\n",
       "                      1.0058, 0.9939, 1.0126, 0.9992, 0.9959, 1.0105, 0.9797, 0.9926, 0.9994,\n",
       "                      0.9937, 0.9957, 1.0105, 1.0055, 1.0125, 1.0114, 0.9915, 0.9832, 1.0072,\n",
       "                      1.0032, 1.0047, 0.9985, 1.0042, 1.0012, 1.0037, 0.9889, 0.9938, 0.9936,\n",
       "                      1.0097, 0.9941, 0.9827, 1.0016, 0.9812, 1.0109, 0.9871, 0.9901, 1.0096,\n",
       "                      0.9847, 0.9843, 0.9936, 0.9981, 0.9879, 1.0024, 1.0013, 0.9963, 0.9975,\n",
       "                      1.0020, 0.9947, 1.0096, 0.9888, 1.0076, 1.0033, 1.0027, 0.9904, 1.0108,\n",
       "                      1.0013, 1.0166, 0.9935, 0.9964, 0.9983, 0.9932, 0.9908, 0.9941, 0.9984,\n",
       "                      0.9874, 0.9946, 0.9999, 0.9990, 1.0064, 1.0093, 1.0061, 0.9925, 1.0102,\n",
       "                      0.9902, 1.0013, 1.0076, 0.9963, 1.0015, 0.9850, 0.9950, 0.9951, 1.0125,\n",
       "                      0.9961, 0.9961, 0.9883, 1.0018, 0.9854, 0.9938, 1.0002, 1.0016, 1.0021,\n",
       "                      1.0179, 0.9862, 1.0020, 0.9833, 1.0051, 0.9985, 0.9991, 1.0028, 0.9987,\n",
       "                      1.0010, 0.9931, 1.0129, 0.9931, 1.0096, 0.9903, 1.0025, 1.0013, 0.9899,\n",
       "                      0.9889, 1.0005, 0.9929, 0.9921, 0.9865, 0.9977, 1.0022, 0.9837, 0.9853,\n",
       "                      1.0113, 0.9865, 0.9992, 1.0136, 0.9863, 0.9912, 0.9969, 1.0064, 0.9914,\n",
       "                      0.9994, 0.9936, 0.9873, 0.9950, 1.0006, 1.0048, 1.0010, 1.0108, 0.9886,\n",
       "                      0.9922, 0.9957, 1.0008, 1.0031, 1.0058, 0.9951, 1.0093, 1.0083, 1.0062,\n",
       "                      1.0009, 1.0056, 1.0022, 0.9947, 0.9913, 0.9893, 1.0003, 1.0075, 0.9830,\n",
       "                      0.9907, 0.9871, 0.9873, 0.9961, 0.9940, 0.9948, 0.9946, 1.0019, 1.0007,\n",
       "                      1.0018, 1.0105, 1.0061, 0.9943, 0.9900, 0.9868, 0.9934, 0.9963, 1.0100,\n",
       "                      1.0071, 0.9924, 0.9883, 0.9894, 0.9919, 1.0085, 1.0000, 0.9967, 0.9884,\n",
       "                      0.9999, 0.9998, 1.0109, 1.0157, 0.9985, 0.9893, 1.0110, 0.9900, 0.9941,\n",
       "                      0.9960, 1.0002, 0.9925, 0.9978, 0.9814, 0.9870, 1.0051, 0.9947, 1.0159,\n",
       "                      0.9902, 0.9878, 1.0031, 0.9937, 0.9900, 0.9943, 1.0126, 1.0071, 0.9989,\n",
       "                      1.0050, 1.0192, 1.0137, 0.9991, 1.0026, 0.9950, 1.0093, 0.9977, 1.0075,\n",
       "                      0.9945, 0.9990, 0.9941, 0.9999, 1.0114, 1.0010, 1.0034, 0.9973, 0.9997,\n",
       "                      1.0090, 1.0087, 0.9941, 0.9959, 1.0072, 1.0115, 1.0023, 0.9764, 0.9903,\n",
       "                      0.9941, 0.9880, 0.9898, 0.9877, 0.9931, 1.0192, 0.9786, 0.9869, 1.0147,\n",
       "                      1.0049, 1.0030, 1.0022, 0.9916, 1.0090, 1.0066, 1.0012, 0.9979, 1.0023,\n",
       "                      0.9930, 0.9942, 1.0099, 0.9989, 0.9887, 0.9947, 0.9890, 0.9890])),\n",
       "             ('bottom_up.0.bn2.bias',\n",
       "              tensor([ 3.5116e-02,  1.9162e-02,  1.7258e-02,  4.6209e-02, -2.3328e-03,\n",
       "                       1.0877e-02, -7.5171e-03,  3.7089e-04,  1.2923e-02, -1.4844e-02,\n",
       "                       2.9125e-02,  4.5184e-03,  1.9114e-02,  6.3667e-03,  2.1663e-02,\n",
       "                       1.8673e-02,  2.2557e-02, -5.9106e-03,  1.2457e-02,  2.2201e-02,\n",
       "                       2.6426e-02,  1.5950e-02, -9.0023e-03,  8.8882e-03,  2.5764e-02,\n",
       "                       1.8434e-02, -1.0392e-02,  2.7856e-03,  2.3448e-02,  2.2333e-02,\n",
       "                       2.4796e-02,  3.6369e-03, -5.0838e-03,  2.4133e-02,  3.1706e-02,\n",
       "                       1.3865e-02, -1.7950e-03,  1.6674e-02,  2.5846e-02,  1.3720e-02,\n",
       "                      -3.1338e-03,  1.2861e-03, -1.4537e-02,  8.9817e-03,  1.5740e-02,\n",
       "                      -6.6961e-03,  6.3206e-03,  5.2750e-03, -4.8298e-03, -1.6082e-02,\n",
       "                       2.1595e-02,  2.0074e-02, -2.2865e-03,  6.2911e-03,  1.7675e-02,\n",
       "                       7.1388e-03, -5.6725e-03,  2.2478e-02, -1.0423e-02,  6.5437e-03,\n",
       "                       2.6143e-02,  1.1297e-02,  1.6748e-02, -9.0694e-03,  2.9275e-03,\n",
       "                      -1.0304e-02, -5.8561e-03,  2.2363e-02,  6.9149e-03,  1.1008e-03,\n",
       "                       1.2663e-02, -2.1855e-04,  1.9845e-02, -7.4844e-03,  3.2307e-03,\n",
       "                      -4.0867e-03,  1.5893e-02, -8.6360e-03,  8.1469e-04, -5.6490e-03,\n",
       "                       1.2562e-02,  1.8260e-02,  7.8078e-03, -2.6366e-04,  9.3322e-03,\n",
       "                      -1.2548e-02,  1.4216e-02,  3.5782e-03,  1.3858e-02,  2.4964e-03,\n",
       "                       1.9028e-03,  1.5370e-02, -6.0815e-03, -7.2752e-04,  8.1422e-03,\n",
       "                      -9.4927e-03, -1.0063e-02,  1.9301e-02,  2.2616e-02, -1.3111e-02,\n",
       "                       2.2259e-02, -7.5199e-03,  1.6925e-02,  1.0798e-02,  2.3762e-02,\n",
       "                       1.7799e-02,  7.2792e-04,  6.1730e-03, -1.4732e-02, -6.1260e-04,\n",
       "                       3.6862e-02, -3.8216e-03,  3.0175e-03,  2.3730e-02,  1.8945e-02,\n",
       "                       2.2409e-02,  2.4687e-02,  4.8252e-03, -6.8897e-03, -1.2274e-02,\n",
       "                      -5.0952e-03,  8.1176e-03,  5.0321e-04,  2.1516e-04,  2.6198e-02,\n",
       "                      -1.4942e-02,  1.4177e-02,  2.0486e-02,  9.5558e-04,  3.3631e-02,\n",
       "                      -4.4751e-03,  2.4681e-02,  1.9113e-02,  1.1534e-03, -4.1304e-03,\n",
       "                       1.8122e-02, -1.6247e-02,  6.6245e-03,  1.9248e-02,  1.1961e-02,\n",
       "                       2.1531e-02, -1.5903e-02,  5.0555e-03,  2.4651e-02, -4.7041e-04,\n",
       "                       1.5527e-02,  1.6653e-02,  1.2934e-04,  5.1016e-03, -3.6636e-03,\n",
       "                       1.6269e-02,  2.3512e-02, -5.8225e-03,  1.7876e-03, -1.9818e-03,\n",
       "                       1.7940e-02, -6.5037e-03,  1.4108e-02,  6.8508e-03,  2.3010e-02,\n",
       "                       1.9011e-03,  1.9044e-02,  2.2257e-02,  2.6449e-02, -1.1995e-03,\n",
       "                       1.6094e-02,  1.4310e-02,  7.3881e-05, -1.0046e-02, -2.9929e-03,\n",
       "                       5.6688e-04,  2.2765e-02,  1.4384e-03,  1.3788e-02,  6.5188e-03,\n",
       "                       1.8321e-02,  1.4068e-02,  1.3625e-02, -4.3430e-03,  2.1679e-02,\n",
       "                      -9.0415e-03,  1.9943e-02,  1.9477e-03, -2.9520e-03,  1.1769e-02,\n",
       "                      -8.8277e-03, -6.0156e-04,  7.4510e-03,  1.6272e-02,  1.1240e-02,\n",
       "                       1.1223e-02,  2.2352e-02,  2.8454e-03, -3.8506e-03, -9.6526e-03,\n",
       "                      -2.6936e-03,  1.7711e-02, -6.3454e-03,  1.1702e-02, -1.2156e-02,\n",
       "                       6.5057e-03, -1.7383e-03, -5.4893e-03,  2.7429e-02,  1.2400e-02,\n",
       "                       1.5651e-02,  2.3204e-04,  1.8323e-02, -8.6476e-03, -1.2859e-02,\n",
       "                      -2.3506e-03,  1.3428e-02,  1.9732e-02, -7.9532e-03,  7.0906e-03,\n",
       "                       1.0804e-02, -2.4944e-03,  1.4765e-02,  1.4705e-02,  2.7152e-02,\n",
       "                       1.5891e-02,  5.5010e-03, -1.0520e-02,  2.6016e-02,  2.2162e-02,\n",
       "                       4.0812e-03,  1.5566e-02, -5.4426e-03,  8.8312e-04,  1.4032e-02,\n",
       "                       1.4630e-02,  1.0365e-02,  5.0041e-03,  8.5316e-03, -6.3287e-05,\n",
       "                       3.1136e-02,  2.1374e-02,  1.2810e-02,  2.7269e-02,  2.1596e-02,\n",
       "                       1.6638e-02,  1.7680e-03, -1.1119e-03,  1.6613e-02,  9.3571e-03,\n",
       "                      -3.1132e-03,  2.6215e-03,  1.8104e-02,  4.3338e-03, -2.6102e-03,\n",
       "                       1.4569e-02, -1.7123e-03,  2.1367e-02,  2.2454e-02,  2.5970e-02,\n",
       "                       9.3828e-03,  4.6022e-05,  9.5967e-03, -1.4613e-02, -6.0430e-03,\n",
       "                       1.4551e-02,  1.3214e-02,  1.9039e-02,  2.0048e-02,  1.9025e-02,\n",
       "                       1.1100e-02,  1.9646e-02, -6.4135e-03, -1.1599e-02,  3.8041e-03,\n",
       "                       1.3931e-02,  1.6362e-02,  9.6320e-03,  2.3890e-02,  1.1873e-02,\n",
       "                       1.9776e-02, -9.0916e-03,  4.6612e-03,  3.6984e-03,  2.1367e-02,\n",
       "                      -3.2964e-03, -1.7858e-02,  3.3636e-03, -7.8654e-03,  2.0636e-02,\n",
       "                      -8.5110e-03, -5.3502e-03,  3.1355e-02,  2.3275e-03, -3.1247e-03,\n",
       "                      -2.4997e-03,  2.0005e-02, -1.2814e-02,  1.7005e-02,  2.3501e-02,\n",
       "                       4.6528e-03,  1.1087e-02,  7.1059e-03, -1.6368e-03,  1.9858e-02,\n",
       "                       1.5898e-03,  2.0047e-02,  1.5578e-02,  3.3560e-02, -6.4273e-03,\n",
       "                       1.7552e-02,  2.2516e-02,  2.4016e-02, -8.5515e-05, -3.0700e-03,\n",
       "                       1.2234e-02, -8.3009e-03, -1.3890e-03, -6.3061e-03,  1.0748e-02,\n",
       "                      -9.0586e-03,  1.4225e-02,  6.9658e-03,  2.1272e-02,  1.2684e-02,\n",
       "                       3.7683e-02,  1.8163e-02, -3.7768e-03,  2.2917e-02,  1.5176e-02,\n",
       "                       2.3207e-02,  2.4702e-03, -5.6373e-03, -3.9379e-03, -9.6199e-03,\n",
       "                      -3.7371e-03, -1.1849e-03,  1.8049e-02,  3.0416e-03, -3.6794e-03,\n",
       "                       1.6726e-04,  1.4318e-02, -6.5722e-03,  6.5976e-03,  9.9960e-03,\n",
       "                       1.1975e-02,  9.0124e-03,  2.1928e-02,  8.8025e-04,  1.6110e-02,\n",
       "                       4.5473e-03,  1.3368e-02,  2.6452e-02,  1.1931e-02,  1.6928e-02,\n",
       "                       9.4899e-03,  1.5623e-02,  1.3316e-02,  2.9408e-02,  6.3338e-03,\n",
       "                       1.0126e-02,  1.0101e-02,  1.3213e-02,  8.0121e-03,  8.1896e-03,\n",
       "                      -6.2330e-03,  3.4135e-03, -1.0202e-02,  8.1155e-03, -4.3325e-03,\n",
       "                       5.5118e-04,  2.4187e-02, -7.8344e-03,  8.5889e-03,  2.4382e-02,\n",
       "                      -2.0154e-02,  3.2189e-04,  2.1613e-02,  4.1628e-03, -4.4796e-03,\n",
       "                       1.0110e-02,  1.0285e-02,  5.9926e-03, -2.3348e-04,  7.7357e-03,\n",
       "                       1.0063e-02,  1.0415e-02,  1.6432e-02, -2.7492e-03,  4.8555e-04,\n",
       "                       2.2608e-02,  1.1994e-02, -1.8804e-03, -6.6257e-03,  1.8259e-02,\n",
       "                      -1.7410e-03,  2.6908e-02, -3.8748e-03,  2.9804e-02,  1.9883e-02,\n",
       "                       2.6342e-02,  1.3570e-02,  2.8681e-03,  3.2523e-02, -1.1362e-02,\n",
       "                       8.3274e-03,  1.3114e-02,  1.2109e-02,  2.1887e-02, -1.2662e-02,\n",
       "                       1.0353e-03, -9.3415e-03, -4.4016e-03,  8.5114e-04,  1.6149e-02,\n",
       "                      -9.7949e-03,  2.5250e-02,  5.2116e-03,  1.3116e-02,  1.3342e-02,\n",
       "                       1.7257e-02,  1.5716e-02,  5.0624e-03,  2.0316e-03, -8.8876e-03,\n",
       "                      -6.1876e-03,  6.3768e-03,  2.2700e-02, -4.5167e-04,  3.5399e-03,\n",
       "                       1.1346e-02, -1.5201e-03, -6.9741e-03,  2.0658e-02,  2.2980e-02,\n",
       "                       1.1277e-02,  1.2579e-02,  1.7538e-02,  1.2724e-02,  2.0115e-02,\n",
       "                       2.2190e-02,  2.6311e-03, -7.5600e-03,  2.3898e-02,  2.1677e-04,\n",
       "                       3.5598e-03,  1.8102e-02, -9.7095e-04,  1.5042e-02,  2.6111e-02,\n",
       "                      -2.2050e-02, -1.2270e-02,  5.9854e-03,  1.0289e-02,  2.1091e-02,\n",
       "                       4.4183e-03,  7.1186e-04, -3.4251e-03,  2.4124e-03,  6.4838e-04,\n",
       "                       2.4643e-02,  2.2707e-02, -6.4587e-03, -7.6730e-03,  2.0702e-02,\n",
       "                       2.2838e-02,  1.9207e-02,  1.0825e-02,  5.3290e-03,  2.1161e-02,\n",
       "                       1.7095e-02,  7.0694e-03,  1.9499e-02,  3.1056e-02, -9.2344e-03,\n",
       "                       8.5661e-03,  1.8179e-02,  2.6032e-02,  2.0536e-02,  2.1888e-02,\n",
       "                      -2.5258e-03,  8.3269e-03,  2.5651e-03, -2.2017e-03, -9.7012e-03,\n",
       "                       6.8216e-04,  3.1095e-02,  1.7607e-03,  7.1395e-03, -1.8273e-02,\n",
       "                       7.7763e-03,  2.3856e-02,  2.0176e-03, -1.5180e-03, -1.0322e-02,\n",
       "                      -2.1281e-03,  2.8455e-02, -1.4387e-02, -9.9299e-03,  2.9123e-02,\n",
       "                       1.0230e-02,  1.7867e-02,  1.8336e-02, -6.8671e-03,  2.5278e-02,\n",
       "                       1.8067e-02,  2.1376e-02,  5.5165e-03,  2.0201e-02,  1.0509e-02,\n",
       "                       1.3777e-02,  2.4092e-02,  1.0239e-02, -1.6966e-03,  9.4047e-03,\n",
       "                       1.8566e-03, -5.6341e-03])),\n",
       "             ('bottom_up.0.bn2.running_mean',\n",
       "              tensor([-8.2970e-01,  3.7773e-02, -1.4927e-01, -2.3615e-01,  4.3752e-01,\n",
       "                      -1.7519e-02,  4.1891e-02, -3.3634e-01, -2.2839e-01,  3.2971e-01,\n",
       "                      -1.6219e-01,  2.8470e-01, -2.0355e-01, -5.2700e-01,  5.3088e-02,\n",
       "                      -1.8163e-01, -2.0865e-01,  4.9347e-01, -1.3497e-01, -3.8804e-01,\n",
       "                       1.9871e-01, -4.0248e-01, -2.8185e-01, -9.2679e-02, -1.3159e-01,\n",
       "                      -3.7208e-01, -1.5309e-02, -3.6285e-01,  1.7114e-01,  3.9452e-01,\n",
       "                      -2.1940e-01, -2.8148e-01,  2.8132e-01, -6.6617e-01, -1.4694e-01,\n",
       "                      -1.6994e-01,  2.7535e-01, -2.3691e-01,  1.1539e-01, -1.3864e-02,\n",
       "                       3.1995e-01, -1.3108e-01,  3.0150e-01,  2.8074e-01, -5.7644e-01,\n",
       "                       1.3089e-01, -2.3577e-01, -3.2377e-01,  3.4047e-01,  1.6436e-01,\n",
       "                       1.3589e-01, -4.1107e-02, -4.5206e-02, -3.2723e-01,  6.9470e-02,\n",
       "                      -1.1335e-01,  1.8512e-01, -1.0558e-01, -1.8532e-01, -4.7594e-01,\n",
       "                      -2.5572e-01, -9.9250e-02, -4.1252e-01,  2.5910e-01, -3.6255e-01,\n",
       "                       1.4163e-01, -2.2821e-01,  1.1626e-01, -2.7422e-01,  4.6156e-01,\n",
       "                      -1.0273e-01,  1.7958e-01, -3.3663e-01, -3.9733e-01, -5.3461e-01,\n",
       "                      -1.8029e-01, -2.9051e-01, -3.2080e-01,  2.4836e-01, -4.9019e-02,\n",
       "                      -1.6454e-01, -1.9308e-01,  2.5379e-01,  2.1373e-01,  2.6942e-01,\n",
       "                      -2.0368e-01, -4.8736e-01, -2.3889e-01, -5.0238e-02,  4.9035e-02,\n",
       "                      -1.2442e-01, -3.9966e-01, -7.5807e-02,  1.8929e-01,  1.3300e-01,\n",
       "                       9.3974e-02, -1.4090e-01, -2.0989e-01,  7.6204e-02, -3.4216e-01,\n",
       "                      -4.3007e-01, -3.2382e-01,  2.4278e-01, -3.0767e-02, -3.0771e-02,\n",
       "                      -4.3027e-01, -1.0059e-01,  8.2480e-02, -2.4023e-01,  4.5034e-01,\n",
       "                       8.0509e-02,  1.0994e-01, -9.4727e-02, -4.5677e-02,  5.2307e-01,\n",
       "                      -1.3451e-02, -6.6483e-01,  5.4266e-03,  4.5305e-01,  2.2038e-01,\n",
       "                      -1.6395e-01, -2.7282e-01,  4.1141e-02, -4.9699e-01, -4.0734e-01,\n",
       "                       4.4155e-03,  5.1215e-01,  4.6237e-02,  8.3951e-02, -2.2223e-01,\n",
       "                       1.6297e-01, -3.6461e-01,  4.3705e-02,  2.3456e-01, -1.7371e-01,\n",
       "                      -4.0076e-01,  2.9783e-01, -1.5558e-01, -3.0769e-01, -2.3791e-01,\n",
       "                       2.2462e-01, -9.0775e-02,  4.1972e-03, -3.1952e-02, -1.1230e-01,\n",
       "                       1.3504e-01, -2.1301e-01,  1.6004e-01,  1.7323e-01,  5.0156e-01,\n",
       "                      -4.1952e-01, -4.3418e-01, -1.8860e-01,  2.3632e-01, -1.2000e-01,\n",
       "                      -2.3632e-01, -5.6950e-03, -2.4575e-01,  1.1810e-01,  4.6574e-01,\n",
       "                      -5.2066e-01,  1.0299e-01, -2.4082e-01, -1.2255e-01,  7.0455e-01,\n",
       "                       1.1078e-01, -6.6488e-01,  6.3099e-02,  4.5090e-01,  3.7862e-01,\n",
       "                       6.9048e-01, -5.0386e-01, -5.0364e-01, -5.8906e-01, -2.8418e-01,\n",
       "                      -1.6832e-01,  1.3852e-01, -3.0273e-01, -7.0805e-03, -2.9152e-01,\n",
       "                       4.8496e-01,  7.4526e-02, -2.1625e-01,  1.4927e-01,  9.3251e-02,\n",
       "                       2.8609e-03,  1.4307e-01, -1.6261e-01, -1.7824e-01, -2.9118e-01,\n",
       "                       1.5246e-01,  4.7759e-02, -3.1995e-01,  5.8494e-01,  3.1233e-01,\n",
       "                       2.3646e-01, -2.4799e-02,  1.4319e-01, -3.0555e-01, -8.3176e-02,\n",
       "                      -5.7156e-01, -1.5332e-01, -1.8964e-01, -5.1517e-01, -2.3422e-01,\n",
       "                       1.2753e-01, -8.0441e-01,  2.9281e-02, -4.1322e-01,  4.3754e-01,\n",
       "                       8.2847e-02, -3.1600e-02, -8.3489e-02,  3.4197e-03, -2.7169e-01,\n",
       "                      -2.2404e-01,  4.7998e-03, -5.0322e-01, -1.4323e-01,  3.2682e-02,\n",
       "                      -5.9419e-02, -4.1136e-01,  4.5786e-02,  2.3626e-02,  1.2731e-01,\n",
       "                       3.7726e-01, -5.4134e-01, -1.5814e-01, -5.1157e-01,  4.0809e-01,\n",
       "                       1.2157e-01,  3.8058e-01,  3.7248e-01, -5.8378e-01,  1.5840e-01,\n",
       "                      -1.7307e-01, -5.0916e-01,  2.5653e-01, -1.9812e-01,  7.7241e-02,\n",
       "                      -2.0963e-01,  7.2564e-01,  2.8864e-01,  6.3586e-02, -3.4941e-01,\n",
       "                       2.2256e-02, -4.6294e-01, -3.7720e-01, -2.0147e-01,  3.5157e-01,\n",
       "                      -5.3410e-01, -3.2073e-01, -2.2787e-01, -3.6788e-01, -5.2407e-01,\n",
       "                       2.8137e-01, -4.3623e-04,  2.6926e-01,  1.6474e-01, -2.5453e-01,\n",
       "                      -6.2138e-01, -2.5606e-01, -2.7046e-01, -3.3237e-01, -1.6663e-01,\n",
       "                       4.8927e-01, -3.2821e-01, -3.6841e-01, -2.8703e-01,  6.0644e-01,\n",
       "                       5.2802e-01, -6.6396e-02, -3.2884e-01, -7.5022e-01, -4.3159e-01,\n",
       "                      -1.5810e-01,  1.7035e-01, -2.4443e-01,  6.5218e-02, -4.4428e-01,\n",
       "                       9.5550e-02,  5.8694e-02,  3.4508e-01, -9.4477e-02, -3.3937e-01,\n",
       "                      -2.4365e-01, -7.1344e-01,  8.0999e-02,  1.4014e-01, -4.0298e-01,\n",
       "                      -9.7032e-02, -5.2671e-01, -4.0717e-02, -6.0188e-01, -1.1102e-01,\n",
       "                      -2.4373e-01, -2.7735e-01, -1.1391e-01,  2.8284e-01, -1.4536e-02,\n",
       "                      -2.6877e-01, -6.6954e-02,  2.5829e-01,  4.5480e-02,  5.4855e-02,\n",
       "                       1.6158e-01, -9.5817e-02,  6.0067e-02,  4.5849e-01, -2.9380e-02,\n",
       "                      -1.5056e-01,  4.3008e-01,  1.2021e-01, -1.8324e-01, -5.7135e-02,\n",
       "                      -5.8617e-01,  4.4536e-02, -3.2751e-02, -6.1604e-02,  2.6193e-01,\n",
       "                      -1.1926e-01,  7.0802e-02,  9.7044e-02,  3.7203e-02, -4.3295e-01,\n",
       "                       1.6057e-01,  4.7412e-01, -4.1640e-02,  3.0144e-01,  2.1479e-01,\n",
       "                       2.9306e-01,  4.4752e-01,  6.8065e-01,  6.9747e-03,  4.2399e-01,\n",
       "                      -2.2756e-01, -1.7255e-03, -5.0910e-01, -3.3981e-01,  2.6846e-01,\n",
       "                       4.1934e-01, -1.5081e-02, -5.3961e-02, -5.5059e-01, -1.4730e-01,\n",
       "                      -2.8098e-01, -4.2801e-01,  6.0364e-02, -2.1031e-01, -6.2427e-01,\n",
       "                      -8.8707e-01, -2.9210e-02, -6.7088e-01, -3.8916e-01, -3.6307e-03,\n",
       "                       3.4254e-01, -9.2558e-02,  2.6921e-01, -2.3462e-01, -2.9620e-01,\n",
       "                      -2.9649e-01,  2.0255e-01, -3.3192e-02,  4.0828e-02, -4.8147e-01,\n",
       "                      -2.7209e-01, -2.1569e-01, -1.1023e-01, -3.3918e-01,  9.2056e-02,\n",
       "                       1.8774e-01,  6.5101e-01,  3.0465e-01, -1.1703e-01, -1.9767e-03,\n",
       "                      -4.4720e-01, -1.2672e-01, -2.7252e-01, -2.7067e-01, -1.6740e-01,\n",
       "                      -4.0636e-01, -4.4639e-01, -7.3232e-02,  3.0166e-01, -1.6020e-02,\n",
       "                       1.1034e-01, -4.3341e-01, -7.5364e-02, -3.3040e-01, -3.3396e-01,\n",
       "                       3.0056e-01, -2.2603e-01,  5.5824e-01, -3.1828e-02,  1.7500e-01,\n",
       "                      -4.5942e-01, -5.3131e-01,  1.8455e-01, -3.1643e-01, -2.9821e-01,\n",
       "                      -3.2210e-01, -2.9847e-01,  4.7836e-01, -1.5049e-01,  3.1181e-02,\n",
       "                      -1.8517e-01,  2.1807e-02, -5.4697e-01,  1.6466e-01, -6.1799e-01,\n",
       "                       1.7258e-01, -4.3720e-01, -1.2955e-01, -3.3604e-01, -2.2323e-01,\n",
       "                       3.8463e-01, -3.4467e-01, -3.7571e-02,  6.5522e-02, -3.7129e-01,\n",
       "                      -4.1300e-01, -9.6622e-02, -3.2054e-01,  4.2185e-01, -1.1630e-01,\n",
       "                      -3.0038e-01, -1.6270e-01,  3.0157e-01, -4.7387e-01, -1.9605e-02,\n",
       "                      -4.9685e-01,  2.3439e-01,  2.4215e-02, -8.5086e-01, -2.6660e-01,\n",
       "                       9.0105e-02,  3.2866e-01, -3.9699e-01,  4.2710e-02,  1.2708e-01,\n",
       "                       2.3787e-01, -2.1601e-01, -6.4490e-01, -4.1714e-01,  1.1530e-01,\n",
       "                      -7.1328e-02,  1.3282e-01,  2.5460e-01,  1.6565e-01, -2.2476e-01,\n",
       "                       2.8061e-01,  6.6662e-02,  2.0649e-01, -1.3723e-01,  4.1352e-01,\n",
       "                      -2.8193e-02,  1.7335e-01,  1.4349e-01,  3.2164e-01, -1.4344e-01,\n",
       "                      -2.8619e-01,  3.1865e-01, -3.8891e-01,  3.1037e-01, -5.0748e-01,\n",
       "                      -2.8189e-01, -6.2822e-02,  1.7513e-01, -3.3954e-01,  5.7845e-01,\n",
       "                      -1.0018e-01,  2.4430e-01,  1.1857e-01, -2.9518e-01, -3.8195e-01,\n",
       "                       1.9501e-01,  3.2367e-01,  1.7880e-01,  4.3762e-01,  9.4572e-02,\n",
       "                      -3.2364e-01, -5.3379e-01,  2.9338e-01,  3.8429e-01, -5.0011e-01,\n",
       "                      -9.2796e-02, -5.2578e-01, -2.7213e-01,  8.7688e-02, -2.3194e-01,\n",
       "                      -1.1359e-01, -2.9035e-02, -1.2870e-01, -1.7381e-01, -5.1975e-01,\n",
       "                       4.4113e-01,  5.4931e-02, -3.6629e-02,  2.6215e-01, -3.5670e-01,\n",
       "                       1.5421e-01,  6.6460e-02, -3.1381e-01, -1.5193e-01, -2.8394e-01,\n",
       "                      -2.6967e-01,  1.0242e-01, -5.1461e-01, -4.8094e-01,  2.5508e-01,\n",
       "                      -2.4627e-01, -3.6492e-02])),\n",
       "             ('bottom_up.0.bn2.running_var',\n",
       "              tensor([0.9027, 1.1972, 0.5495, 1.1733, 0.2948, 0.9470, 0.3325, 0.7866, 0.7346,\n",
       "                      0.3203, 1.1466, 0.5863, 1.7021, 0.3821, 1.3056, 1.2795, 1.6163, 0.3711,\n",
       "                      1.3629, 0.9579, 1.1768, 1.1464, 0.4708, 1.1789, 1.2781, 1.6686, 0.3522,\n",
       "                      0.3799, 1.7166, 1.0915, 0.9119, 0.2784, 0.3175, 1.2995, 1.0787, 0.8844,\n",
       "                      0.1992, 1.4456, 1.0046, 0.7767, 0.2101, 0.2536, 0.3306, 1.5665, 0.8471,\n",
       "                      0.2545, 0.6655, 0.8869, 0.4677, 0.3640, 0.5205, 1.5095, 0.4823, 0.6539,\n",
       "                      0.7261, 0.4383, 0.2971, 1.1786, 0.3944, 0.3633, 0.7780, 0.9400, 0.8507,\n",
       "                      0.2847, 0.4022, 0.4490, 0.3972, 0.8849, 0.6616, 0.3190, 0.6081, 0.2066,\n",
       "                      0.9158, 0.2686, 0.6771, 0.4292, 0.9006, 0.2592, 0.2785, 0.4231, 1.1452,\n",
       "                      0.9117, 0.6894, 0.3603, 0.3488, 0.2217, 0.9717, 0.3138, 0.6500, 0.2866,\n",
       "                      0.7593, 0.5115, 0.3559, 0.2496, 0.9294, 0.1989, 0.2365, 0.7887, 1.3133,\n",
       "                      0.2304, 1.2034, 0.2710, 1.4158, 0.4762, 1.0421, 0.7361, 0.4829, 0.9995,\n",
       "                      0.3935, 0.3621, 0.9751, 0.3879, 0.3885, 0.6776, 0.9844, 1.5043, 1.3136,\n",
       "                      0.3089, 0.4339, 0.3390, 0.3194, 1.0179, 0.5679, 0.3409, 1.5952, 0.2191,\n",
       "                      0.3346, 1.3358, 0.5351, 0.9813, 0.2670, 0.8144, 1.4513, 0.2218, 0.5203,\n",
       "                      0.7510, 0.2148, 0.4031, 1.0221, 0.6111, 1.4177, 0.3700, 1.0744, 1.3222,\n",
       "                      0.2657, 1.1575, 0.8359, 0.8383, 0.4573, 0.3017, 0.4897, 1.7206, 0.4729,\n",
       "                      0.4810, 0.2598, 1.0394, 0.4199, 1.8819, 0.3797, 0.7597, 0.4286, 0.9917,\n",
       "                      1.3089, 0.6200, 0.2377, 1.2162, 0.2745, 0.5254, 0.6665, 0.2871, 0.5136,\n",
       "                      1.2004, 0.4410, 0.2378, 1.1938, 1.3011, 0.6008, 0.7677, 0.2964, 0.4699,\n",
       "                      0.3237, 0.6505, 0.5493, 0.6440, 0.7394, 0.3957, 0.3322, 0.9747, 1.3150,\n",
       "                      0.4897, 0.8453, 1.8813, 1.2661, 0.3315, 0.2343, 0.3009, 0.5003, 0.3434,\n",
       "                      0.7845, 0.5831, 0.5359, 0.2504, 0.2864, 0.8091, 0.2760, 0.7814, 0.2421,\n",
       "                      0.8806, 0.2344, 0.3988, 0.5129, 0.6079, 0.9536, 0.3346, 1.3937, 0.7473,\n",
       "                      0.2751, 0.3372, 0.4414, 1.4644, 1.5249, 0.8400, 0.2287, 0.7035, 1.5080,\n",
       "                      0.5338, 0.7297, 0.3404, 0.2146, 0.6023, 0.8912, 0.2377, 0.7985, 0.2866,\n",
       "                      0.5745, 1.1676, 0.4164, 0.7447, 1.0340, 0.9563, 0.4654, 0.2304, 0.6801,\n",
       "                      0.4425, 1.0869, 0.3546, 0.2451, 1.6628, 0.5672, 0.2558, 0.4128, 0.2583,\n",
       "                      1.1738, 0.2799, 1.0620, 0.8441, 0.3586, 0.9122, 0.2174, 0.3006, 0.6190,\n",
       "                      0.4796, 0.5438, 1.5782, 1.2062, 0.6534, 1.7917, 0.2538, 0.1912, 0.2327,\n",
       "                      0.8554, 0.7071, 0.6398, 0.5233, 0.2326, 1.1083, 0.3306, 0.3399, 0.3059,\n",
       "                      1.2709, 0.2446, 0.2805, 0.3598, 0.3305, 1.8836, 0.2146, 0.2831, 1.4157,\n",
       "                      0.6426, 0.8695, 0.6966, 1.1321, 0.2614, 0.3370, 1.1117, 0.3921, 0.6838,\n",
       "                      0.6072, 0.3990, 1.7044, 0.4269, 1.2387, 1.4599, 0.9514, 0.1920, 1.4415,\n",
       "                      1.2698, 1.3283, 0.2665, 0.3424, 0.4607, 0.2077, 0.3119, 0.4298, 0.7087,\n",
       "                      0.2099, 0.7465, 0.4025, 0.6021, 1.7664, 1.1252, 0.7269, 0.2285, 1.3742,\n",
       "                      0.8212, 1.1130, 0.2475, 0.4226, 0.3038, 0.4882, 0.3389, 0.3312, 0.4175,\n",
       "                      0.7727, 0.5546, 0.2468, 1.1668, 0.2422, 0.2727, 0.4314, 0.9973, 0.4983,\n",
       "                      1.3734, 0.2772, 0.9954, 0.6577, 1.4433, 0.8893, 0.4161, 0.8408, 0.7053,\n",
       "                      1.0391, 0.3741, 1.0353, 0.8926, 0.5816, 1.3415, 0.5740, 0.7359, 0.4563,\n",
       "                      0.2643, 0.4931, 0.2371, 0.7569, 0.2630, 0.6098, 0.7035, 0.2464, 0.5292,\n",
       "                      1.5225, 0.2874, 0.2609, 1.3746, 0.5609, 0.1969, 1.3478, 1.0216, 0.2830,\n",
       "                      0.2851, 0.7348, 0.6402, 0.3207, 0.8913, 0.2835, 0.5259, 1.0343, 0.3512,\n",
       "                      0.2090, 0.2265, 0.6676, 0.2568, 0.8634, 0.2019, 0.8664, 1.2122, 0.9006,\n",
       "                      0.2236, 0.4520, 1.1367, 0.2360, 0.8086, 0.6061, 0.3857, 1.1889, 0.3089,\n",
       "                      0.6349, 0.4177, 0.2303, 0.6098, 0.6845, 0.2723, 0.5297, 0.4531, 0.4149,\n",
       "                      1.0357, 0.8797, 1.4231, 0.3114, 0.3136, 0.2351, 0.2524, 1.0157, 0.6185,\n",
       "                      0.3004, 0.8148, 0.6327, 0.3303, 0.3273, 1.1867, 0.9615, 0.4674, 1.0247,\n",
       "                      1.0081, 0.3822, 1.3263, 1.9576, 0.5397, 0.4430, 1.0126, 0.5325, 0.2759,\n",
       "                      0.6788, 0.2521, 0.4680, 1.0139, 0.2284, 0.2008, 0.3067, 1.0770, 2.0673,\n",
       "                      0.7222, 0.3070, 0.2408, 0.3981, 0.2131, 1.1392, 1.5118, 0.6932, 0.3175,\n",
       "                      1.0921, 1.7291, 1.3968, 1.0299, 0.5201, 0.6435, 1.6225, 0.8784, 1.3036,\n",
       "                      0.6888, 0.4065, 0.4915, 0.8978, 1.2103, 1.3250, 1.3486, 0.2881, 0.3754,\n",
       "                      0.4201, 0.3195, 0.2613, 0.4381, 0.7183, 0.4854, 0.4324, 0.2071, 1.2407,\n",
       "                      0.6658, 0.2663, 0.3126, 0.2803, 0.3360, 1.2172, 0.2272, 0.2326, 1.4914,\n",
       "                      0.3655, 0.4474, 0.9265, 0.2683, 1.2629, 1.0351, 0.4877, 0.3176, 1.0599,\n",
       "                      0.7393, 1.0186, 0.9414, 0.2223, 0.3358, 0.7025, 0.2912, 0.4791])),\n",
       "             ('bottom_up.0.bn2.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.0.dense3.weight',\n",
       "              tensor([[-0.0342, -0.0004, -0.0164,  ...,  0.0282, -0.0335, -0.0250],\n",
       "                      [-0.0371,  0.0394,  0.0499,  ..., -0.0043, -0.0330, -0.0040],\n",
       "                      [ 0.0254, -0.0216,  0.0189,  ..., -0.0241, -0.0188, -0.0001],\n",
       "                      ...,\n",
       "                      [ 0.0081, -0.0431, -0.0266,  ...,  0.0405, -0.0181,  0.0093],\n",
       "                      [ 0.0241, -0.0575,  0.0086,  ..., -0.0078, -0.0151,  0.0232],\n",
       "                      [ 0.0026, -0.0384, -0.0373,  ...,  0.0145, -0.0165,  0.0399]])),\n",
       "             ('bottom_up.0.bn3.weight',\n",
       "              tensor([0.9775, 1.0105, 1.0065, 1.0079, 1.0048, 0.9830, 1.0110, 0.9925, 1.0091,\n",
       "                      1.0021, 1.0208, 0.9942, 1.0075, 1.0158, 1.0072, 1.0173, 0.9976, 0.9780,\n",
       "                      1.0029, 1.0036, 0.9832, 0.9908, 0.9910, 0.9859, 0.9835, 1.0076, 0.9939,\n",
       "                      0.9952, 1.0046, 1.0126, 0.9971, 1.0011, 1.0117, 0.9891, 1.0126, 0.9852,\n",
       "                      0.9785, 0.9801, 0.9787, 0.9948, 1.0055, 0.9923, 1.0058, 1.0124, 0.9822,\n",
       "                      0.9882, 0.9910, 0.9983, 0.9878, 1.0078, 0.9841, 1.0142, 0.9864, 1.0013,\n",
       "                      0.9878, 0.9985, 0.9759, 0.9936, 0.9971, 0.9887, 1.0087, 1.0009, 1.0022,\n",
       "                      0.9933, 1.0151, 1.0048, 1.0059, 0.9824, 0.9980, 1.0001, 1.0016, 0.9994,\n",
       "                      1.0021, 0.9941, 1.0068, 1.0158, 0.9867, 1.0134, 0.9769, 1.0069, 1.0175,\n",
       "                      1.0004, 0.9870, 1.0160, 0.9790, 0.9803, 0.9856, 1.0150, 0.9901, 0.9847,\n",
       "                      0.9788, 1.0054, 1.0042, 0.9937, 1.0041, 0.9896, 0.9828, 1.0179, 0.9906,\n",
       "                      1.0134, 1.0043, 1.0030, 0.9806, 1.0198, 1.0005, 0.9919, 0.9859, 1.0035,\n",
       "                      0.9896, 0.9962, 0.9735, 1.0142, 1.0209, 0.9968, 1.0125, 1.0002, 1.0015,\n",
       "                      0.9905, 0.9934, 1.0084, 0.9936, 1.0198, 1.0088, 1.0285, 0.9868, 1.0184,\n",
       "                      1.0134, 0.9932, 1.0098, 1.0126, 0.9924, 0.9912, 0.9897, 0.9821, 1.0095,\n",
       "                      1.0042, 0.9917, 0.9956, 1.0029, 0.9840, 1.0130, 1.0017, 1.0059, 0.9975,\n",
       "                      0.9966, 0.9889, 1.0130, 1.0079, 0.9853, 0.9831, 0.9977, 1.0087, 1.0062,\n",
       "                      1.0113, 1.0063, 0.9976, 0.9888, 0.9902, 1.0066, 0.9873, 0.9940, 0.9934,\n",
       "                      0.9922, 1.0134, 0.9988, 1.0021, 0.9978, 0.9856, 1.0134, 1.0008, 0.9864,\n",
       "                      0.9936, 1.0004, 1.0018, 1.0135, 0.9911, 1.0125, 0.9915, 0.9901, 0.9998,\n",
       "                      0.9902, 0.9807, 1.0017, 1.0198, 0.9895, 1.0168, 0.9855, 1.0034, 0.9817,\n",
       "                      1.0061, 0.9905, 0.9940, 0.9900, 1.0142, 0.9967, 0.9918, 0.9806, 0.9890,\n",
       "                      1.0041, 1.0197, 0.9902, 1.0119, 0.9916, 0.9861, 0.9968, 0.9848, 0.9848,\n",
       "                      1.0133, 0.9908, 1.0021, 1.0080, 1.0156, 0.9865, 1.0169, 1.0038, 0.9946,\n",
       "                      0.9966, 1.0053, 0.9971, 0.9921, 0.9817, 0.9895, 1.0139, 0.9961, 1.0140,\n",
       "                      0.9964, 1.0175, 0.9952, 0.9851, 1.0015, 0.9895, 1.0130, 0.9890, 1.0037,\n",
       "                      0.9911, 1.0075, 0.9878, 1.0113, 1.0046, 1.0075, 0.9850, 1.0141, 1.0055,\n",
       "                      0.9850, 0.9883, 0.9956, 1.0040, 0.9971, 1.0124, 1.0082, 0.9829, 0.9904,\n",
       "                      1.0067, 1.0125, 0.9863, 0.9980])),\n",
       "             ('bottom_up.0.bn3.bias',\n",
       "              tensor([-1.9950e-02, -4.7573e-03,  1.6195e-02,  2.2757e-02,  1.6551e-02,\n",
       "                      -8.7730e-03,  2.3336e-02, -6.9015e-03,  2.8132e-02,  1.9734e-02,\n",
       "                       1.1224e-02, -2.8557e-03,  1.9232e-02,  2.4603e-02,  1.1326e-02,\n",
       "                       1.6575e-02,  1.0537e-02, -2.1839e-02,  2.2892e-02,  1.5897e-02,\n",
       "                      -9.0313e-03,  1.6367e-02, -1.6932e-03, -6.3043e-03, -1.0904e-02,\n",
       "                       2.2497e-02, -7.3904e-03,  7.9103e-03,  9.8124e-03,  1.7947e-02,\n",
       "                      -5.0235e-03,  1.9441e-02,  2.2230e-02,  2.9052e-02,  1.4614e-02,\n",
       "                      -1.4500e-02, -2.0447e-02, -2.1189e-02,  1.7491e-02,  6.8755e-03,\n",
       "                       2.7198e-02, -1.2979e-02,  1.6224e-02,  1.8285e-02, -4.6853e-03,\n",
       "                       1.2329e-02, -1.7769e-05,  1.2940e-02, -2.0584e-02,  1.2892e-02,\n",
       "                       2.1881e-05,  1.8205e-02,  5.0275e-03,  3.1945e-02, -5.2404e-03,\n",
       "                      -1.2299e-02, -8.2705e-03,  1.8389e-02,  3.2269e-02, -7.0561e-03,\n",
       "                       2.9382e-02,  2.0688e-02,  8.5641e-03,  5.7328e-03,  3.4030e-02,\n",
       "                       2.5529e-02,  1.2006e-02, -1.3367e-02, -1.0047e-02,  1.7193e-02,\n",
       "                       1.3075e-02,  1.0966e-02,  1.3112e-02,  1.1868e-02,  1.4330e-02,\n",
       "                       1.5551e-02, -1.6471e-02,  2.1038e-02, -6.1670e-03,  8.9585e-03,\n",
       "                       1.7301e-02,  1.8944e-02,  1.2783e-03,  1.8386e-02, -1.2051e-02,\n",
       "                      -2.2489e-02, -1.8558e-02,  1.7265e-02,  8.2055e-04, -2.0488e-03,\n",
       "                      -2.0654e-02,  2.1114e-02,  2.3240e-02,  8.6189e-03, -9.5668e-04,\n",
       "                      -1.4502e-02, -2.8131e-03,  1.9686e-02, -1.3529e-03,  1.7492e-02,\n",
       "                       3.2322e-02,  1.9222e-02, -1.9331e-02,  1.7553e-02,  1.4032e-02,\n",
       "                       1.3684e-02, -1.2681e-04,  1.7192e-02,  4.0375e-03,  1.4717e-02,\n",
       "                      -2.5827e-02,  2.1482e-02,  1.6806e-02,  3.6768e-03,  2.0348e-02,\n",
       "                       1.7994e-02,  5.2717e-03,  4.1048e-03,  1.2357e-02,  1.7484e-02,\n",
       "                       5.3599e-03,  1.7885e-02,  2.4497e-02,  2.1343e-02,  2.1463e-02,\n",
       "                       1.9411e-02,  4.3037e-02,  1.5841e-02,  1.4100e-02,  1.8754e-02,\n",
       "                       1.4025e-02,  2.9764e-03, -5.5914e-03, -1.4364e-02,  2.0061e-02,\n",
       "                       2.3717e-02,  2.1541e-02,  6.7921e-03,  1.2180e-02, -6.2887e-03,\n",
       "                       1.4003e-02, -1.6003e-02,  1.0762e-02, -8.6076e-03,  1.7333e-02,\n",
       "                      -1.6736e-02,  2.3450e-02,  3.1868e-02, -9.7274e-03, -6.7182e-03,\n",
       "                       9.1666e-03,  1.5959e-02,  1.3583e-02,  2.4110e-02,  2.3691e-02,\n",
       "                       2.1562e-02,  1.9290e-02,  1.2238e-02,  1.5316e-02, -5.8064e-03,\n",
       "                      -1.3097e-02, -3.6437e-03,  3.2122e-02,  2.2752e-02,  1.4199e-02,\n",
       "                       2.1649e-02,  1.9685e-02,  3.0930e-03,  2.1573e-02,  1.3198e-02,\n",
       "                      -1.9687e-02, -8.2211e-03,  1.3472e-02,  1.4514e-02,  1.8808e-02,\n",
       "                      -1.7798e-03,  2.5100e-02,  1.3236e-03, -4.5801e-03,  1.2876e-02,\n",
       "                       1.9222e-02, -1.4206e-02,  1.4301e-02,  2.3458e-02,  1.1562e-02,\n",
       "                       2.6222e-02, -9.7935e-03,  1.9626e-02, -8.2391e-03, -6.5747e-04,\n",
       "                      -2.3677e-03,  1.7668e-02, -1.4825e-02,  1.7751e-02,  8.7744e-03,\n",
       "                      -2.8913e-03, -1.2378e-02,  1.2259e-03,  1.3374e-02,  2.0241e-02,\n",
       "                       7.0958e-03,  1.2444e-02, -8.9902e-03,  1.9691e-03,  1.2154e-02,\n",
       "                      -1.0161e-02, -7.3572e-03,  1.8728e-02,  3.0783e-02, -1.6002e-02,\n",
       "                       2.7863e-02,  2.9324e-02, -3.5937e-03,  1.8293e-02,  1.1281e-02,\n",
       "                       2.0736e-02,  3.3469e-02,  1.8311e-02,  8.2017e-03,  1.6544e-02,\n",
       "                      -1.1798e-02, -4.5525e-03,  1.1026e-02,  2.5766e-02,  1.8301e-02,\n",
       "                       1.2593e-03,  2.0548e-02,  6.9221e-03,  2.8247e-03,  2.2282e-02,\n",
       "                      -2.0408e-03,  1.7768e-02, -6.2935e-03,  2.6766e-02,  1.6662e-02,\n",
       "                      -4.1238e-03,  2.8452e-04,  1.4935e-02,  1.4535e-02,  1.4182e-02,\n",
       "                      -1.8960e-02,  2.4216e-02,  1.6751e-02, -2.8217e-03, -8.2528e-03,\n",
       "                       2.1413e-02,  2.9907e-02,  2.2802e-02,  1.7042e-02,  1.4555e-02,\n",
       "                      -5.9490e-03, -8.1542e-03,  1.9750e-02,  2.2433e-02, -6.0563e-03,\n",
       "                       2.3204e-02])),\n",
       "             ('bottom_up.0.bn3.running_mean',\n",
       "              tensor([-2.3717e-01, -8.9972e-02, -5.5281e-01, -3.6355e-01, -2.2569e-01,\n",
       "                      -2.8230e-01, -2.2694e-01, -7.0398e-02, -3.5587e-01, -9.5253e-01,\n",
       "                       5.1740e-02,  1.3936e-01, -5.1978e-01,  1.6414e-01, -4.1063e-04,\n",
       "                      -4.3573e-02, -5.2250e-02,  2.0280e-01, -4.5961e-01,  3.1634e-02,\n",
       "                      -3.7518e-01,  1.7481e-01, -2.2542e-01,  8.5645e-02,  1.5466e-01,\n",
       "                      -1.5046e-01,  1.1372e-01, -4.9843e-01,  1.9191e-02, -3.3633e-01,\n",
       "                       2.7954e-01, -6.6382e-01, -1.0852e-01, -4.8857e-01,  9.9537e-02,\n",
       "                       3.7424e-02,  6.0380e-01,  8.0792e-01, -2.7468e-01,  2.0497e-01,\n",
       "                      -7.2022e-01,  1.5167e-01, -1.3328e-01, -2.5777e-01, -2.2258e-01,\n",
       "                      -2.0891e-01, -5.8198e-01, -3.4343e-01,  6.4805e-01, -1.3821e-02,\n",
       "                      -8.7944e-01,  4.8699e-02, -4.1896e-01, -5.3962e-01, -4.3585e-01,\n",
       "                       7.4330e-01, -1.2233e-01, -2.9039e-01, -8.4615e-01,  2.0564e-01,\n",
       "                      -8.0828e-01,  2.3827e-01, -2.8687e-01, -1.8453e-01, -1.1122e+00,\n",
       "                      -6.0527e-01,  4.2730e-01, -6.2869e-01,  2.5275e-01, -1.1874e-01,\n",
       "                      -8.9053e-02, -7.2261e-01,  3.1475e-01, -6.1303e-01,  2.0824e-01,\n",
       "                      -1.2929e-01,  4.3689e-02, -3.8256e-01,  3.2716e-01,  1.3121e-01,\n",
       "                      -4.9778e-03, -7.9361e-02, -1.4007e-03, -4.0845e-01,  2.1368e-01,\n",
       "                       2.4574e-01,  2.6852e-01, -3.0674e-01,  2.6889e-01, -4.6378e-01,\n",
       "                      -2.9936e-01, -6.4286e-01,  1.1207e-01, -1.5277e-01,  8.3599e-02,\n",
       "                       3.6236e-03, -2.2478e-01,  5.8956e-02, -6.3026e-02, -1.9772e-01,\n",
       "                      -7.2606e-01, -2.7818e-01, -6.3959e-02,  8.4960e-02, -1.1166e-01,\n",
       "                      -4.3663e-01, -3.1365e-01,  6.3360e-02, -8.5407e-01,  8.0316e-02,\n",
       "                      -1.9456e-01, -2.5372e-01, -1.1467e-01, -3.6926e-02, -3.4835e-04,\n",
       "                      -4.0443e-01,  3.3759e-01, -2.2692e-01, -3.2151e-01, -1.7187e-01,\n",
       "                      -2.2017e-01,  2.0195e-01, -2.9827e-01, -3.3308e-01, -3.8538e-01,\n",
       "                      -6.7387e-02, -3.2657e-01, -3.5366e-01,  2.6216e-01, -5.4513e-01,\n",
       "                      -7.4547e-01,  2.4682e-01, -3.9292e-01, -4.0166e-01, -3.1416e-01,\n",
       "                      -4.7688e-01, -5.1868e-01,  1.6464e-01, -3.2996e-01,  1.7502e-01,\n",
       "                       6.2386e-01,  1.2067e+00, -2.9795e-01,  4.0808e-01, -4.7444e-01,\n",
       "                       2.0323e-01, -6.6987e-02, -5.3776e-01,  8.6793e-02, -3.3006e-01,\n",
       "                      -9.1225e-02, -9.8258e-02,  3.9634e-01, -7.4336e-01, -9.3377e-01,\n",
       "                      -2.9232e-01, -8.2610e-01, -2.7218e-01, -1.9308e-01, -7.6714e-01,\n",
       "                      -8.7333e-02,  4.1100e-02, -5.7157e-02, -2.0463e-01,  4.2325e-01,\n",
       "                      -6.2583e-01, -4.2241e-01, -6.8250e-02,  2.7297e-01, -4.9806e-01,\n",
       "                       4.1080e-01, -1.0895e-01, -1.7746e-01,  1.7452e-01,  1.8492e-01,\n",
       "                       2.6941e-01, -6.3973e-01, -6.9970e-01, -6.4047e-01, -5.8576e-01,\n",
       "                      -3.4469e-01,  4.1235e-01, -3.7623e-01, -3.0329e-01, -4.5453e-01,\n",
       "                       7.6277e-02, -3.3159e-04, -4.2502e-01,  4.5699e-02,  4.2156e-01,\n",
       "                      -5.1358e-01, -6.1016e-01,  5.6765e-01, -1.3294e-02,  9.8333e-02,\n",
       "                       1.8311e-01, -1.5752e-02, -8.3284e-01,  4.6204e-01, -2.5816e-01,\n",
       "                      -3.4660e-01,  5.3958e-02,  7.1320e-02, -5.0599e-01, -5.7563e-01,\n",
       "                      -6.3159e-02, -8.1901e-02, -1.6358e-01, -5.3584e-01,  5.2423e-01,\n",
       "                      -8.3992e-01, -6.0758e-01,  5.6516e-01, -1.0050e-01,  6.7047e-01,\n",
       "                       1.5382e-01, -6.6526e-01, -3.4186e-01, -7.7045e-01, -7.0963e-02,\n",
       "                       3.6211e-03, -6.7244e-01, -6.9475e-02, -8.4606e-01, -1.7012e-01,\n",
       "                       2.1853e-02,  6.3583e-02, -8.0681e-01, -5.0526e-01, -2.3736e-01,\n",
       "                      -2.9366e-01, -1.1300e-01, -4.6077e-02,  6.9804e-02, -3.8372e-01,\n",
       "                       3.9463e-01, -2.7783e-01, -6.9522e-02, -7.1322e-01,  9.9315e-02,\n",
       "                       4.8866e-01, -1.5855e-01, -2.7424e-01, -6.5115e-01, -5.8862e-01,\n",
       "                       4.2151e-02, -5.3980e-01, -6.7942e-01, -1.5310e-01, -2.6605e-01,\n",
       "                       3.3290e-02, -4.0546e-01,  1.7229e-01,  1.3363e-01, -6.4269e-01,\n",
       "                      -8.4764e-01])),\n",
       "             ('bottom_up.0.bn3.running_var',\n",
       "              tensor([0.2718, 2.6030, 2.9400, 2.6269, 4.1770, 0.5392, 3.4993, 2.3628, 1.4300,\n",
       "                      1.2321, 4.2756, 1.6239, 2.4217, 3.8554, 3.6169, 4.3776, 2.0718, 0.3150,\n",
       "                      2.8705, 3.4248, 0.5857, 2.8790, 0.2354, 1.1145, 0.6935, 4.3250, 1.5953,\n",
       "                      1.3572, 2.9773, 3.1286, 2.6986, 2.0752, 3.6209, 0.4840, 5.0453, 1.0596,\n",
       "                      0.3794, 0.3085, 0.9671, 2.4657, 0.4394, 1.2587, 3.9256, 3.4666, 1.0054,\n",
       "                      2.5699, 0.2900, 0.5934, 0.6630, 3.4298, 0.9285, 4.0130, 0.7983, 1.1458,\n",
       "                      0.6640, 0.5076, 0.6298, 0.7342, 0.4020, 0.7655, 0.9511, 2.6754, 2.1945,\n",
       "                      0.9419, 0.6572, 0.5117, 3.9375, 0.6735, 0.7248, 2.3717, 2.1586, 0.4988,\n",
       "                      2.9913, 2.8350, 2.6844, 4.7599, 1.0610, 3.6236, 0.9944, 3.9976, 2.4382,\n",
       "                      0.4735, 0.3947, 3.8542, 0.5515, 0.4512, 0.6164, 5.2724, 0.6810, 0.4860,\n",
       "                      0.5919, 3.2397, 1.5928, 2.6429, 3.0010, 2.7105, 0.5941, 4.8903, 0.9912,\n",
       "                      5.8322, 1.3166, 4.3489, 0.4821, 5.2831, 1.2316, 0.7912, 1.3992, 3.4769,\n",
       "                      0.4691, 1.2849, 0.7052, 2.4513, 3.3068, 0.3992, 4.3842, 1.2346, 2.9885,\n",
       "                      3.2237, 0.7008, 2.5315, 2.0342, 5.7391, 4.3182, 4.9986, 0.7628, 5.3716,\n",
       "                      2.0871, 0.5508, 4.7625, 3.6868, 0.5428, 2.1368, 0.7062, 0.4259, 3.3558,\n",
       "                      1.7632, 1.7941, 1.3076, 0.9838, 0.9214, 1.1916, 0.4320, 3.2897, 2.7192,\n",
       "                      2.2213, 0.3364, 2.3925, 1.8939, 1.1466, 0.5269, 1.9619, 3.1646, 3.0446,\n",
       "                      2.9999, 0.5458, 1.5284, 0.6537, 1.4968, 2.7309, 0.3596, 2.3427, 1.3960,\n",
       "                      1.0377, 2.6117, 1.8513, 3.3959, 1.4125, 2.0777, 4.0450, 2.1814, 0.7263,\n",
       "                      1.8179, 2.6711, 3.6434, 4.0098, 1.3210, 3.0284, 0.3510, 0.6029, 4.0142,\n",
       "                      1.5358, 0.2154, 1.6864, 5.6142, 1.4543, 2.7926, 0.8147, 2.6968, 2.1960,\n",
       "                      2.8898, 0.8988, 0.6485, 0.6096, 4.8248, 1.2070, 1.6298, 0.7314, 1.7923,\n",
       "                      3.3651, 4.4891, 0.5682, 2.7173, 1.1372, 0.3851, 0.5596, 0.5044, 0.5586,\n",
       "                      4.4845, 0.9949, 1.0089, 1.2597, 2.6972, 0.5223, 3.7742, 1.5339, 2.6547,\n",
       "                      1.2823, 3.0684, 0.8919, 2.9142, 0.3798, 0.8004, 2.1919, 0.4928, 4.5418,\n",
       "                      2.5495, 2.7961, 0.3731, 1.7476, 2.4834, 0.9263, 3.7596, 0.3720, 1.0950,\n",
       "                      2.2180, 2.9223, 1.4068, 3.1930, 0.7636, 3.0246, 0.4922, 4.1114, 3.6186,\n",
       "                      0.9339, 0.4407, 1.2378, 1.6493, 0.5225, 3.9816, 2.9584, 0.7261, 2.3733,\n",
       "                      3.7872, 3.1012, 1.5721, 2.4295])),\n",
       "             ('bottom_up.0.bn3.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.0.dense4.weight',\n",
       "              tensor([[ 0.0332, -0.0419, -0.0304,  ..., -0.0359,  0.0525,  0.0045],\n",
       "                      [ 0.0262,  0.0104, -0.0336,  ...,  0.0308, -0.0076, -0.0481],\n",
       "                      [-0.0478,  0.0103, -0.0073,  ..., -0.0604,  0.0214,  0.0589],\n",
       "                      ...,\n",
       "                      [-0.0294,  0.0512,  0.0315,  ...,  0.0455, -0.0366,  0.0509],\n",
       "                      [ 0.0254,  0.0355, -0.0197,  ..., -0.0469, -0.0557,  0.0309],\n",
       "                      [ 0.0126, -0.0207, -0.0176,  ..., -0.0232,  0.0439, -0.0559]])),\n",
       "             ('bottom_up.0.bn4.weight',\n",
       "              tensor([1.0155, 0.9870, 0.9974, 0.9962, 0.9883, 0.9839, 1.0178, 0.9887, 0.9821,\n",
       "                      0.9850, 0.9879, 1.0072, 0.9944, 1.0002, 1.0141, 1.0090, 1.0132, 1.0018,\n",
       "                      1.0112, 1.0246, 0.9980, 1.0129, 0.9864, 1.0046, 1.0139, 0.9844, 0.9952,\n",
       "                      0.9923, 0.9798, 0.9793, 1.0074, 1.0037, 0.9798, 1.0097, 1.0179, 1.0157,\n",
       "                      1.0104, 0.9950, 0.9876, 0.9848, 0.9859, 0.9759, 1.0093, 1.0067, 1.0146,\n",
       "                      0.9872, 0.9853, 0.9977, 1.0072, 0.9873, 1.0075, 0.9883, 1.0014, 0.9971,\n",
       "                      0.9769, 0.9924, 0.9966, 0.9846, 0.9984, 1.0142, 1.0159, 0.9847, 0.9972,\n",
       "                      0.9934, 0.9860, 0.9901, 0.9989, 0.9819, 1.0082, 0.9961, 0.9871, 0.9855,\n",
       "                      1.0111, 0.9759, 0.9901, 0.9896, 0.9822, 1.0017, 1.0106, 0.9972, 0.9926,\n",
       "                      1.0131, 1.0032, 0.9890, 1.0086, 0.9792, 0.9886, 1.0179, 1.0045, 1.0183,\n",
       "                      0.9989, 0.9946, 1.0067, 1.0130, 0.9853, 0.9850, 0.9897, 0.9876, 1.0080,\n",
       "                      1.0146, 0.9889, 1.0112, 1.0108, 0.9819, 0.9939, 0.9840, 0.9941, 1.0115,\n",
       "                      0.9801, 0.9834, 1.0184, 1.0124, 0.9886, 1.0146, 1.0148, 1.0019, 0.9890,\n",
       "                      1.0177, 1.0153, 0.9840, 1.0024, 0.9884, 0.9885, 1.0099, 0.9906, 1.0045,\n",
       "                      1.0123, 0.9815])),\n",
       "             ('bottom_up.0.bn4.bias',\n",
       "              tensor([ 0.0279,  0.0042,  0.0036,  0.0086, -0.0063,  0.0169,  0.0208,  0.0171,\n",
       "                      -0.0007, -0.0104, -0.0072,  0.0146,  0.0104,  0.0182,  0.0198,  0.0140,\n",
       "                       0.0175,  0.0128,  0.0215,  0.0168,  0.0163,  0.0191, -0.0144,  0.0134,\n",
       "                       0.0183, -0.0132,  0.0137,  0.0275,  0.0076, -0.0196,  0.0260,  0.0098,\n",
       "                       0.0141,  0.0193,  0.0212,  0.0202,  0.0348, -0.0264,  0.0059,  0.0130,\n",
       "                       0.0288, -0.0361,  0.0220,  0.0156,  0.0182,  0.0101, -0.0002,  0.0191,\n",
       "                       0.0254, -0.0148,  0.0178,  0.0116,  0.0135, -0.0015, -0.0045,  0.0117,\n",
       "                       0.0026, -0.0130,  0.0120,  0.0278,  0.0331, -0.0234, -0.0073,  0.0119,\n",
       "                       0.0019, -0.0017,  0.0386, -0.0113,  0.0191,  0.0167,  0.0152,  0.0141,\n",
       "                       0.0214,  0.0065, -0.0019, -0.0169, -0.0112, -0.0009,  0.0226, -0.0026,\n",
       "                       0.0078,  0.0257,  0.0325, -0.0309,  0.0195, -0.0089,  0.0020,  0.0203,\n",
       "                       0.0114,  0.0096,  0.0026,  0.0279,  0.0141,  0.0267, -0.0152, -0.0028,\n",
       "                       0.0004,  0.0294,  0.0253,  0.0197,  0.0173,  0.0160,  0.0263,  0.0181,\n",
       "                       0.0284, -0.0091,  0.0232,  0.0199, -0.0159, -0.0202,  0.0158,  0.0233,\n",
       "                       0.0063,  0.0186,  0.0230,  0.0172,  0.0198,  0.0162,  0.0216, -0.0124,\n",
       "                       0.0223,  0.0157,  0.0215,  0.0215,  0.0029,  0.0063,  0.0191, -0.0024])),\n",
       "             ('bottom_up.0.bn4.running_mean',\n",
       "              tensor([-3.8937e-01, -4.7467e-01,  2.5286e-01,  3.3071e-01,  2.2135e-01,\n",
       "                      -2.8405e-01, -3.3861e-01, -3.7465e-01, -6.7194e-01, -6.2388e-02,\n",
       "                      -1.7172e-01,  5.4802e-02, -2.5832e-01, -3.3950e-01, -6.9996e-01,\n",
       "                      -1.6839e-01, -5.6554e-02, -2.4309e-01, -2.4897e-01,  1.3573e-01,\n",
       "                      -7.9282e-01, -4.4933e-01,  1.9223e-01, -2.8463e-01,  5.5321e-02,\n",
       "                      -3.2024e-01, -1.4185e-01, -7.0347e-01, -4.3258e-01,  4.5218e-02,\n",
       "                      -7.2147e-01, -9.6354e-02, -5.1967e-01, -2.5028e-01,  2.2129e-01,\n",
       "                      -2.3144e-01, -9.2562e-01,  2.9557e-01, -1.3828e-01, -2.6078e-01,\n",
       "                       3.0102e-01,  6.6121e-02, -5.4517e-01,  3.0657e-01, -3.3879e-01,\n",
       "                      -3.9339e-01, -2.7478e-02, -8.0563e-01, -5.0280e-01,  2.4552e-01,\n",
       "                      -1.9852e-01, -2.8364e-01,  1.3691e-01,  5.5129e-01, -3.2221e-01,\n",
       "                      -4.4946e-01,  3.2329e-01,  3.2847e-02, -1.9762e-01, -2.6342e-01,\n",
       "                      -6.7284e-01,  5.4287e-01,  1.4910e-01, -6.0910e-01, -4.5080e-01,\n",
       "                      -2.1713e-01, -7.5746e-01,  3.1218e-02, -6.8510e-02, -2.3925e-01,\n",
       "                      -5.6894e-01, -3.2854e-02, -1.6538e-01,  9.8372e-03, -1.9241e-01,\n",
       "                       3.9118e-01, -3.7397e-01,  2.6837e-01, -9.8775e-02, -4.4170e-02,\n",
       "                       4.1822e-01,  4.1878e-01, -6.2263e-01,  4.6658e-01, -1.1897e-02,\n",
       "                      -6.6997e-02, -3.5122e-01, -1.1069e-01,  2.3319e-01,  1.0557e-01,\n",
       "                       1.2996e-01, -6.9196e-01,  1.8204e-01, -7.4166e-04,  1.9953e-01,\n",
       "                       1.2774e-01, -5.7109e-01, -5.2908e-01, -1.6367e-01, -4.9878e-03,\n",
       "                      -6.9478e-01,  1.4650e-01, -2.8267e-01, -3.5350e-01, -6.9155e-01,\n",
       "                       6.2615e-02, -6.9168e-01, -5.3777e-01, -3.9993e-01, -3.3446e-01,\n",
       "                       2.1237e-01, -2.3192e-01, -6.7241e-02, -8.7900e-02, -3.6888e-01,\n",
       "                      -1.4256e-01, -1.9644e-01,  2.6998e-01, -7.3962e-01,  2.4748e-02,\n",
       "                      -5.6521e-01, -1.0054e-01, -2.9687e-01,  9.5097e-02,  3.0911e-01,\n",
       "                       1.2584e-01, -3.0634e-01,  1.3455e-01])),\n",
       "             ('bottom_up.0.bn4.running_var',\n",
       "              tensor([0.8560, 1.2435, 1.9981, 1.7188, 1.0796, 1.4756, 4.6461, 1.2845, 0.6119,\n",
       "                      2.2532, 1.8479, 3.0907, 1.5109, 2.0129, 2.0582, 2.8810, 1.9616, 2.6383,\n",
       "                      2.5209, 2.0295, 0.2703, 2.9619, 1.2910, 2.7359, 2.5753, 0.2730, 3.1751,\n",
       "                      0.6685, 1.1449, 1.0015, 0.9656, 1.9401, 1.1504, 2.5568, 2.6615, 2.2431,\n",
       "                      0.2648, 0.6245, 1.7367, 0.4750, 1.9746, 0.7261, 1.8993, 3.2541, 2.2749,\n",
       "                      0.4099, 2.2136, 0.3709, 0.5553, 1.6631, 2.7272, 0.4176, 3.7281, 1.0627,\n",
       "                      0.9839, 0.3638, 2.8306, 1.0161, 1.6180, 1.4516, 1.1837, 0.5039, 1.1909,\n",
       "                      0.1728, 1.1629, 1.8904, 0.6458, 0.5944, 2.4034, 2.0067, 0.5308, 1.9783,\n",
       "                      2.0242, 2.2140, 1.7662, 0.5578, 0.2818, 1.6628, 2.6804, 2.1556, 0.6414,\n",
       "                      1.3493, 0.2943, 0.3388, 3.0449, 0.4460, 1.2253, 3.3630, 2.2024, 3.8729,\n",
       "                      2.2077, 1.3502, 1.4706, 1.9894, 0.7274, 2.0274, 1.1316, 0.9860, 1.9179,\n",
       "                      2.6854, 0.4759, 2.2875, 1.6438, 0.4665, 0.3463, 1.6489, 0.7291, 1.5365,\n",
       "                      0.8567, 2.5399, 3.8959, 2.8140, 1.2635, 2.5755, 1.8594, 2.2708, 2.0924,\n",
       "                      2.9896, 0.9032, 0.7241, 1.3446, 1.9554, 1.3213, 1.7759, 2.2829, 2.2707,\n",
       "                      2.7603, 1.2314])),\n",
       "             ('bottom_up.0.bn4.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.1.dense1.weight',\n",
       "              tensor([[ 0.0581,  0.0960, -0.0124,  ...,  0.0538,  0.0141, -0.0676],\n",
       "                      [ 0.0862,  0.0677,  0.0605,  ...,  0.0030,  0.0672, -0.0561],\n",
       "                      [ 0.0441,  0.0929,  0.0264,  ...,  0.0775,  0.0575,  0.0080],\n",
       "                      ...,\n",
       "                      [-0.0103,  0.0440,  0.0765,  ...,  0.0853,  0.0204,  0.0615],\n",
       "                      [-0.0753, -0.0310, -0.0441,  ..., -0.0675,  0.0190, -0.0850],\n",
       "                      [-0.0167, -0.0493, -0.0380,  ..., -0.0707,  0.0159, -0.0428]])),\n",
       "             ('bottom_up.1.bn1.weight',\n",
       "              tensor([1.0197, 1.0157, 0.9881, 1.0148, 1.0015, 1.0179, 0.9926, 1.0213, 1.0203,\n",
       "                      1.0238, 0.9825, 0.9898, 1.0135, 0.9833, 1.0062, 1.0099, 0.9789, 1.0261,\n",
       "                      0.9908, 1.0088, 1.0117, 0.9856, 1.0233, 0.9870, 1.0216, 1.0044, 1.0195,\n",
       "                      1.0205, 0.9814, 1.0230, 0.9940, 1.0186, 1.0207, 0.9987, 0.9984, 0.9929,\n",
       "                      1.0201, 1.0241, 1.0130, 1.0125, 1.0119, 1.0077, 1.0110, 0.9959, 1.0222,\n",
       "                      1.0044, 1.0112, 1.0067, 1.0206, 1.0175, 1.0201, 1.0015, 1.0134, 1.0033,\n",
       "                      0.9888, 1.0165, 1.0042, 1.0089, 1.0087, 1.0183, 1.0153, 1.0283, 1.0108,\n",
       "                      1.0084, 1.0094, 1.0199, 1.0179, 1.0181, 0.9774, 1.0122, 0.9825, 0.9980,\n",
       "                      1.0176, 1.0026, 1.0023, 1.0177, 1.0127, 0.9930, 1.0068, 1.0206, 1.0027,\n",
       "                      1.0162, 0.9914, 1.0199, 0.9824, 1.0170, 0.9899, 0.9951, 1.0212, 1.0231,\n",
       "                      1.0191, 1.0122, 0.9955, 1.0208, 1.0034, 1.0215, 1.0072, 1.0119, 1.0161,\n",
       "                      1.0184, 1.0169, 1.0233, 1.0163, 1.0123, 0.9920, 1.0205, 1.0280, 1.0127,\n",
       "                      1.0252, 1.0188, 0.9878, 1.0111, 1.0123, 1.0091, 1.0344, 1.0155, 1.0130,\n",
       "                      0.9881, 1.0122, 0.9894, 0.9886, 1.0071, 1.0243, 1.0134, 1.0257, 1.0052,\n",
       "                      1.0104, 1.0216])),\n",
       "             ('bottom_up.1.bn1.bias',\n",
       "              tensor([ 0.0216,  0.0273,  0.0044,  0.0163, -0.0004,  0.0199, -0.0296,  0.0216,\n",
       "                       0.0240,  0.0234,  0.0131,  0.0318,  0.0273, -0.0064,  0.0253,  0.0207,\n",
       "                      -0.0090,  0.0154,  0.0103,  0.0241,  0.0248, -0.0110,  0.0224, -0.0199,\n",
       "                       0.0212,  0.0272,  0.0236,  0.0222, -0.0263,  0.0287, -0.0002,  0.0297,\n",
       "                       0.0214, -0.0187,  0.0152,  0.0051,  0.0168,  0.0267,  0.0203,  0.0299,\n",
       "                       0.0124,  0.0098,  0.0141,  0.0111,  0.0247,  0.0385,  0.0463,  0.0073,\n",
       "                       0.0243,  0.0210,  0.0219,  0.0287,  0.0182,  0.0017, -0.0159,  0.0067,\n",
       "                       0.0044,  0.0054,  0.0295,  0.0254,  0.0367,  0.0248,  0.0186,  0.0114,\n",
       "                       0.0192,  0.0204,  0.0193,  0.0106, -0.0208,  0.0180,  0.0094,  0.0025,\n",
       "                       0.0288, -0.0009,  0.0167,  0.0226,  0.0265, -0.0290,  0.0218,  0.0202,\n",
       "                       0.0294,  0.0313,  0.0173,  0.0252,  0.0095,  0.0214,  0.0258,  0.0156,\n",
       "                       0.0233,  0.0299,  0.0270,  0.0180,  0.0235,  0.0227,  0.0220,  0.0248,\n",
       "                       0.0087,  0.0214,  0.0261,  0.0164,  0.0229,  0.0220,  0.0167,  0.0371,\n",
       "                       0.0119,  0.0201,  0.0290,  0.0198,  0.0217,  0.0205, -0.0058,  0.0238,\n",
       "                       0.0288, -0.0017,  0.0618,  0.0279,  0.0212, -0.0117,  0.0275, -0.0127,\n",
       "                      -0.0249,  0.0174,  0.0225,  0.0123,  0.0282,  0.0188,  0.0347,  0.0188])),\n",
       "             ('bottom_up.1.bn1.running_mean',\n",
       "              tensor([ 0.1345,  0.0939, -0.0412, -0.4078, -0.2546, -0.2924,  0.1185, -0.0785,\n",
       "                       0.1745, -0.3441,  0.0155,  0.3701,  0.4133,  0.0749, -0.2972, -0.1848,\n",
       "                       0.0674,  0.2183, -0.2890, -0.1418, -0.1292, -0.1399, -0.3374, -0.1775,\n",
       "                      -0.1077, -0.1403, -0.1433, -0.0106, -0.1700, -0.8893,  0.0862,  0.0610,\n",
       "                      -0.0095, -0.3983, -0.0379,  0.2795, -0.3345, -0.0328, -0.0383, -0.0721,\n",
       "                      -0.3319, -0.1896, -0.3662,  0.4725, -0.1988, -0.0054, -0.6083, -0.2361,\n",
       "                       0.3499, -0.1729, -0.2581, -0.0262, -0.2584, -0.1552,  0.0907,  0.3302,\n",
       "                       0.5381,  0.3082,  0.0207,  0.3730,  0.2697, -0.0649,  0.3248,  0.1256,\n",
       "                      -0.4204, -0.1291,  0.2408, -0.0906, -0.1233,  0.1243,  0.0581, -0.1140,\n",
       "                       0.2196, -0.2078, -0.2022, -0.0146, -0.3970,  0.2604, -0.2525, -0.2336,\n",
       "                      -0.5268, -0.3577,  0.0034, -0.2651,  0.1122, -0.2742, -0.3628,  0.1955,\n",
       "                       0.3228, -0.0140,  0.1793, -0.1256, -0.4310, -0.1848,  0.0473, -0.4950,\n",
       "                       0.5252, -0.1904,  0.2618, -0.1892, -0.0827,  0.0818, -0.0922,  0.0488,\n",
       "                      -0.2408, -0.1276, -0.3779, -0.3656, -0.4850, -0.2815, -0.2914, -0.0900,\n",
       "                      -0.1362, -0.3455, -0.0902, -0.0548, -0.2138,  0.0296,  0.5006, -0.1215,\n",
       "                      -0.0954, -0.1555,  0.0904, -0.2674,  0.3206,  0.0252, -0.5071, -0.0260])),\n",
       "             ('bottom_up.1.bn1.running_var',\n",
       "              tensor([0.9620, 0.8527, 0.5140, 0.9559, 0.1813, 1.7020, 0.2299, 1.7065, 1.0291,\n",
       "                      0.2852, 0.5694, 0.3125, 0.9222, 0.3478, 0.3274, 0.9466, 0.1903, 1.0841,\n",
       "                      0.3194, 0.6606, 0.7624, 0.1148, 0.8361, 0.1063, 1.1748, 0.9980, 0.8346,\n",
       "                      1.1225, 0.2819, 0.0684, 0.1698, 1.1189, 2.3816, 0.1925, 1.3522, 0.2826,\n",
       "                      0.9320, 1.6060, 1.1804, 0.9195, 1.1025, 1.3853, 0.8708, 0.2149, 0.9162,\n",
       "                      0.5000, 0.4945, 0.3532, 2.2746, 1.1919, 1.8236, 0.3186, 0.5788, 0.6190,\n",
       "                      0.4194, 0.6341, 0.3494, 0.4871, 0.2438, 1.0954, 0.6123, 0.2272, 0.4812,\n",
       "                      0.8120, 0.8132, 1.3491, 1.4459, 1.0845, 0.2209, 1.1886, 0.6700, 1.1665,\n",
       "                      1.0021, 0.6098, 0.5671, 1.9052, 1.0638, 0.1937, 0.7898, 0.8619, 0.2622,\n",
       "                      0.8927, 0.1388, 1.0372, 0.1674, 2.7565, 0.3785, 1.0105, 1.0315, 2.0898,\n",
       "                      1.2752, 0.6366, 0.1929, 1.3213, 1.2449, 0.5608, 0.3276, 1.0505, 1.9489,\n",
       "                      0.5490, 0.6690, 0.9789, 1.3207, 1.0716, 1.2543, 0.5513, 0.6333, 0.5136,\n",
       "                      0.0784, 0.7921, 0.1529, 1.7770, 1.2513, 0.2080, 1.1249, 1.1473, 2.0973,\n",
       "                      0.7105, 0.1445, 0.3245, 0.2498, 0.7626, 1.6878, 0.6799, 0.6776, 0.7638,\n",
       "                      0.4313, 2.0180])),\n",
       "             ('bottom_up.1.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.1.mu.weight',\n",
       "              tensor([[-0.0796, -0.0454, -0.0232,  ...,  0.0545,  0.0296, -0.0882],\n",
       "                      [-0.0764, -0.0093,  0.0225,  ..., -0.0481,  0.0642, -0.0332],\n",
       "                      [ 0.0060, -0.0484,  0.0445,  ...,  0.0057, -0.0009, -0.0681],\n",
       "                      ...,\n",
       "                      [ 0.0624,  0.0032, -0.0289,  ..., -0.0516, -0.0279, -0.0075],\n",
       "                      [-0.0431, -0.0764, -0.0074,  ...,  0.0005,  0.0341, -0.0573],\n",
       "                      [-0.0025,  0.0744, -0.0270,  ...,  0.0705, -0.0186, -0.0459]])),\n",
       "             ('bottom_up.1.mu.bias',\n",
       "              tensor([-0.0415, -0.0842, -0.0484,  0.0696, -0.0718,  0.0342, -0.0789, -0.0580,\n",
       "                       0.0575, -0.0221, -0.0055, -0.0372, -0.0446, -0.0129,  0.0188, -0.0029,\n",
       "                      -0.0077, -0.0365,  0.0551, -0.0676, -0.0868,  0.0288,  0.0828, -0.0527,\n",
       "                      -0.0234,  0.0755,  0.0294, -0.0259,  0.0744, -0.0650,  0.0612, -0.0535])),\n",
       "             ('bottom_up.1.sigma.weight',\n",
       "              tensor([[ 0.0783, -0.0045, -0.0663,  ..., -0.0881, -0.0404,  0.0248],\n",
       "                      [-0.0069, -0.0322,  0.0337,  ..., -0.0805,  0.0286,  0.0157],\n",
       "                      [-0.0698,  0.0059, -0.0327,  ..., -0.0642, -0.0758,  0.0509],\n",
       "                      ...,\n",
       "                      [ 0.0751,  0.0718, -0.0599,  ..., -0.0758, -0.0208, -0.0366],\n",
       "                      [-0.0603,  0.0128, -0.0267,  ..., -0.0845,  0.0026, -0.0721],\n",
       "                      [ 0.0658, -0.0034,  0.0448,  ...,  0.0703, -0.0364, -0.0069]])),\n",
       "             ('bottom_up.1.sigma.bias',\n",
       "              tensor([-0.0466, -0.0096,  0.0222, -0.0669, -0.0028,  0.0098, -0.0282, -0.0311,\n",
       "                      -0.0188, -0.0189,  0.0414,  0.0266, -0.0143,  0.0710,  0.0135,  0.0865,\n",
       "                      -0.0737,  0.0247,  0.0717,  0.0090, -0.0806,  0.0706,  0.0771,  0.0426,\n",
       "                      -0.0747, -0.0800, -0.0686,  0.0874,  0.0415, -0.0637, -0.0528,  0.0592])),\n",
       "             ('bottom_up.2.dense1.weight',\n",
       "              tensor([[-0.0915, -0.0275, -0.0256,  ..., -0.0686, -0.0435, -0.0011],\n",
       "                      [ 0.0116,  0.0396,  0.0284,  ..., -0.0372,  0.0396, -0.0092],\n",
       "                      [-0.1093,  0.0482, -0.0451,  ..., -0.0756, -0.0339, -0.0627],\n",
       "                      ...,\n",
       "                      [-0.0222, -0.0381, -0.0121,  ..., -0.0765, -0.0432, -0.0261],\n",
       "                      [-0.0650, -0.0930,  0.0302,  ...,  0.0765,  0.0799,  0.0167],\n",
       "                      [-0.0920, -0.0077,  0.0144,  ...,  0.0392,  0.0047, -0.0059]])),\n",
       "             ('bottom_up.2.bn1.weight',\n",
       "              tensor([0.9841, 0.9793, 1.0128, 1.0072, 0.9740, 0.9673, 0.9901, 1.0109, 0.9737,\n",
       "                      1.0100, 0.9715, 1.0063, 0.9836, 0.9856, 1.0090, 1.0146, 1.0062, 0.9788,\n",
       "                      0.9844, 1.0185, 0.9679, 0.9865, 1.0165, 0.9858, 0.9956, 0.9968, 0.9813,\n",
       "                      0.9643, 0.9897, 1.0116, 1.0027, 1.0147, 0.9863, 0.9912, 0.9902, 1.0008,\n",
       "                      0.9913, 1.0096, 0.9696, 0.9894, 1.0133, 1.0095, 1.0103, 0.9855, 0.9809,\n",
       "                      1.0078, 0.9867, 0.9823, 0.9898, 1.0085, 1.0124, 0.9982, 0.9707, 0.9926,\n",
       "                      0.9905, 0.9955, 0.9847, 0.9864, 0.9777, 1.0107, 1.0049, 1.0016, 1.0093,\n",
       "                      0.9890, 0.9721, 1.0133, 0.9785, 0.9838, 1.0041, 0.9898, 1.0142, 1.0119,\n",
       "                      0.9940, 1.0127, 0.9965, 1.0072, 0.9748, 0.9901, 0.9782, 1.0020, 0.9729,\n",
       "                      0.9876, 0.9910, 0.9920, 0.9996, 0.9794, 0.9992, 0.9773, 0.9810, 0.9985,\n",
       "                      0.9826, 1.0037, 0.9752, 0.9704, 0.9912, 1.0053, 0.9903, 0.9872, 0.9843,\n",
       "                      1.0038, 0.9880, 0.9998, 0.9863, 0.9839, 0.9858, 0.9891, 0.9904, 0.9869,\n",
       "                      0.9995, 0.9684, 1.0010, 1.0018, 0.9960, 0.9940, 0.9736, 0.9779, 0.9930,\n",
       "                      1.0066, 0.9927, 0.9880, 0.9950, 0.9900, 0.9820, 1.0100, 0.9985, 0.9813,\n",
       "                      0.9948, 1.0013])),\n",
       "             ('bottom_up.2.bn1.bias',\n",
       "              tensor([-0.0265, -0.0210,  0.0166,  0.0121,  0.0007,  0.0013,  0.0223,  0.0280,\n",
       "                      -0.0150,  0.0187, -0.0386,  0.0120, -0.0121, -0.0089,  0.0175,  0.0161,\n",
       "                       0.0186,  0.0119, -0.0018,  0.0185, -0.0188,  0.0045,  0.0136,  0.0143,\n",
       "                       0.0008,  0.0115,  0.0014,  0.0006,  0.0004,  0.0186,  0.0086,  0.0194,\n",
       "                      -0.0158,  0.0175,  0.0077,  0.0107,  0.0112,  0.0138, -0.0338,  0.0092,\n",
       "                       0.0126,  0.0148,  0.0158, -0.0088, -0.0126,  0.0271, -0.0285, -0.0144,\n",
       "                      -0.0240,  0.0154,  0.0154,  0.0243, -0.0200, -0.0284, -0.0186, -0.0114,\n",
       "                      -0.0026, -0.0092, -0.0241,  0.0154,  0.0194,  0.0220,  0.0089, -0.0129,\n",
       "                      -0.0263,  0.0281, -0.0043,  0.0088,  0.0151,  0.0016,  0.0162,  0.0179,\n",
       "                       0.0154,  0.0162,  0.0092,  0.0178, -0.0138, -0.0160,  0.0083,  0.0077,\n",
       "                      -0.0188, -0.0003,  0.0028, -0.0086,  0.0097, -0.0316, -0.0029, -0.0004,\n",
       "                       0.0127,  0.0033,  0.0259,  0.0083, -0.0473, -0.0253, -0.0107,  0.0109,\n",
       "                       0.0090,  0.0111, -0.0297,  0.0228,  0.0137,  0.0118, -0.0095, -0.0153,\n",
       "                      -0.0162,  0.0109,  0.0096, -0.0103,  0.0057, -0.0519,  0.0200,  0.0144,\n",
       "                       0.0047,  0.0039, -0.0168, -0.0242, -0.0075,  0.0149,  0.0175, -0.0211,\n",
       "                       0.0008,  0.0068, -0.0184,  0.0158,  0.0175,  0.0133,  0.0128,  0.0041])),\n",
       "             ('bottom_up.2.bn1.running_mean',\n",
       "              tensor([ 0.0796, -0.0640, -0.2254, -0.1494,  0.1286, -0.3607,  0.0884, -0.3299,\n",
       "                      -0.1333,  0.0633, -0.0488, -0.1789, -0.0775, -0.2797, -0.3317, -0.2364,\n",
       "                      -0.2865, -0.0420,  0.3957,  0.1895, -0.2703, -0.1508, -0.2252, -0.2485,\n",
       "                       0.0919, -0.4585, -0.0501,  0.0129, -0.1247, -0.3038, -0.2941, -0.1873,\n",
       "                      -0.2415, -0.1316,  0.0377, -0.3228, -0.0025,  0.1174, -0.5398,  0.0294,\n",
       "                      -0.1630, -0.2572, -0.3041, -0.2480, -0.3106, -0.3436,  0.0269,  0.1064,\n",
       "                       0.1926, -0.4640, -0.2189, -0.2602,  0.0499,  0.3174,  0.4049,  0.1360,\n",
       "                      -0.3934,  0.1469,  0.0775, -0.2645,  0.1134, -0.3756, -0.4125, -0.1744,\n",
       "                      -0.1398, -0.3915, -0.3882, -0.0360, -0.0335, -0.0936, -0.1004, -0.3746,\n",
       "                      -0.6218, -0.1460, -0.2372, -0.4522, -0.4118, -0.4424, -0.1423,  0.1821,\n",
       "                      -0.0124,  0.2636, -0.1098,  0.3229,  0.1328, -0.3052,  0.4469, -0.2394,\n",
       "                       0.0462,  0.2204, -0.3667,  0.0629, -0.2550, -0.1145, -0.2066, -0.1892,\n",
       "                      -0.4105, -0.1271,  0.3460, -0.0339, -0.0281,  0.0272, -0.2176, -0.3437,\n",
       "                      -0.3142, -0.3159, -0.2476, -0.3499, -0.3658, -0.0203, -0.2859, -0.2343,\n",
       "                      -0.1808,  0.0632,  0.1408, -0.3215,  0.0998, -0.2571, -0.1996,  0.3323,\n",
       "                      -0.2235,  0.3161, -0.1185, -0.2214, -0.3047, -0.1303,  0.2585, -0.3396])),\n",
       "             ('bottom_up.2.bn1.running_var',\n",
       "              tensor([0.2109, 1.1400, 1.9557, 1.1896, 1.2792, 0.8741, 0.2113, 0.4862, 1.1501,\n",
       "                      0.9867, 0.1792, 0.4760, 0.6382, 0.9061, 0.6822, 0.4090, 0.9508, 0.6560,\n",
       "                      1.3595, 1.0068, 0.1625, 0.8091, 1.2467, 0.5207, 1.2734, 0.0738, 0.5185,\n",
       "                      1.1066, 0.7182, 1.3050, 0.6073, 1.0124, 0.0513, 0.6229, 0.5887, 1.2340,\n",
       "                      0.5007, 1.7743, 0.7245, 1.3029, 1.3580, 1.2932, 0.3489, 0.1807, 1.0107,\n",
       "                      0.2921, 0.4551, 0.7014, 0.2958, 2.2040, 0.8073, 0.2226, 1.0342, 0.3203,\n",
       "                      0.3290, 0.3697, 0.1336, 0.6468, 0.2525, 0.7248, 0.2861, 0.3542, 0.8635,\n",
       "                      0.2858, 0.3398, 0.8875, 0.6357, 0.4333, 1.3780, 0.4791, 0.5736, 0.8427,\n",
       "                      0.2881, 0.9801, 0.5035, 0.5970, 0.3587, 0.1365, 1.1161, 1.0336, 0.4986,\n",
       "                      0.6444, 0.3462, 0.3273, 0.6355, 0.1064, 0.2643, 0.3930, 1.2481, 0.7418,\n",
       "                      0.1585, 0.8188, 0.3064, 0.6887, 0.2435, 0.5156, 0.3413, 1.2599, 0.4149,\n",
       "                      0.3197, 0.8306, 1.0079, 0.2133, 0.3742, 1.1584, 0.7452, 0.3408, 0.0746,\n",
       "                      0.6398, 0.4793, 0.9973, 0.3208, 0.9317, 0.9736, 0.6921, 0.1581, 1.0071,\n",
       "                      0.7449, 1.1916, 0.2986, 0.5934, 0.1372, 0.3903, 1.1765, 1.1329, 0.7855,\n",
       "                      0.6249, 0.1551])),\n",
       "             ('bottom_up.2.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('bottom_up.2.mu.weight',\n",
       "              tensor([[-0.0513, -0.0620,  0.0019,  ..., -0.0076, -0.0673,  0.0661],\n",
       "                      [-0.0108,  0.0040, -0.0795,  ...,  0.0375,  0.0449, -0.0855],\n",
       "                      [ 0.0550, -0.0459, -0.0155,  ...,  0.0791, -0.0067,  0.0321],\n",
       "                      ...,\n",
       "                      [ 0.0502,  0.0306, -0.0200,  ...,  0.0694,  0.0837, -0.0779],\n",
       "                      [ 0.0469,  0.0736, -0.0108,  ..., -0.0742, -0.0751, -0.0634],\n",
       "                      [ 0.0013, -0.0845,  0.0439,  ...,  0.0267, -0.0619,  0.0504]])),\n",
       "             ('bottom_up.2.mu.bias',\n",
       "              tensor([ 0.0585,  0.0188,  0.0237, -0.0460, -0.0216,  0.0392,  0.0764,  0.0416,\n",
       "                       0.0644, -0.0499,  0.0606, -0.0035,  0.0205, -0.0787, -0.0556,  0.0873,\n",
       "                      -0.0872, -0.0674,  0.0411,  0.0405, -0.0566, -0.0630,  0.0220, -0.0728,\n",
       "                      -0.0778,  0.0682, -0.0510,  0.0489,  0.0554,  0.0872, -0.0776, -0.0474])),\n",
       "             ('bottom_up.2.sigma.weight',\n",
       "              tensor([[-0.0809, -0.0712, -0.0266,  ..., -0.0259, -0.0686, -0.0819],\n",
       "                      [ 0.0394,  0.0650, -0.0524,  ..., -0.0042, -0.0187,  0.0161],\n",
       "                      [ 0.0865,  0.0414, -0.0423,  ...,  0.0231,  0.0690, -0.0757],\n",
       "                      ...,\n",
       "                      [ 0.0121, -0.0759,  0.0554,  ..., -0.0513,  0.0388, -0.0588],\n",
       "                      [-0.0321, -0.0208,  0.0844,  ...,  0.0747, -0.0003, -0.0038],\n",
       "                      [-0.0077, -0.0493,  0.0882,  ..., -0.0464,  0.0073,  0.0696]])),\n",
       "             ('bottom_up.2.sigma.bias',\n",
       "              tensor([-0.0594, -0.0820, -0.0147, -0.0512,  0.0630, -0.0552, -0.0597, -0.0809,\n",
       "                      -0.0134, -0.0727,  0.0567, -0.0683, -0.0188, -0.0213,  0.0119, -0.0778,\n",
       "                       0.0132,  0.0504,  0.0690, -0.0203,  0.0463,  0.0535,  0.0660, -0.0163,\n",
       "                       0.0734, -0.0255, -0.0111,  0.0385, -0.0764,  0.0447,  0.0404, -0.0456])),\n",
       "             ('transformations.1.dense1.weight',\n",
       "              tensor([[-0.0686,  0.1131, -0.0921,  ...,  0.0435, -0.0845, -0.0924],\n",
       "                      [ 0.1396, -0.0828,  0.1229,  ...,  0.1589, -0.0520, -0.0975],\n",
       "                      [-0.1174,  0.0749, -0.1174,  ..., -0.1097,  0.1322,  0.1020],\n",
       "                      ...,\n",
       "                      [ 0.1273, -0.1212, -0.0145,  ..., -0.0865,  0.1406, -0.1117],\n",
       "                      [ 0.1207,  0.1366,  0.1516,  ..., -0.1165, -0.0432, -0.0578],\n",
       "                      [-0.1227,  0.0057, -0.0553,  ..., -0.1560,  0.0827, -0.0398]])),\n",
       "             ('transformations.1.bn1.weight',\n",
       "              tensor([1.0065, 0.9829, 0.9793, 1.0015, 0.9992, 0.9916, 0.9905, 1.0094, 0.9775,\n",
       "                      0.9902, 0.9858, 0.9773, 1.0132, 0.9934, 0.9800, 0.9979, 1.0094, 0.9823,\n",
       "                      1.0153, 0.9767, 1.0390, 0.9948, 1.0132, 1.0156, 1.0016, 0.9984, 1.0031,\n",
       "                      1.0163, 1.0044, 1.0135, 1.0203, 1.0024, 1.0009, 1.0019, 0.9891, 0.9817,\n",
       "                      1.0000, 0.9958, 0.9916, 0.9930, 0.9809, 0.9998, 0.9828, 0.9964, 1.0122,\n",
       "                      0.9840, 1.0024, 0.9787, 0.9969, 1.0011, 0.9983, 1.0081, 0.9937, 1.0170,\n",
       "                      1.0189, 0.9672, 1.0175, 1.0123, 0.9889, 1.0095, 0.9953, 1.0023, 1.0052,\n",
       "                      0.9749, 1.0019, 0.9876, 0.9959, 1.0116, 0.9976, 0.9826, 1.0114, 1.0029,\n",
       "                      0.9998, 0.9924, 0.9889, 0.9995, 0.9782, 0.9929, 0.9938, 1.0155, 0.9917,\n",
       "                      1.0077, 1.0000, 1.0128, 0.9733, 0.9793, 0.9897, 0.9751, 0.9993, 0.9871,\n",
       "                      1.0140, 1.0213, 0.9941, 1.0045, 0.9890, 1.0024, 0.9895, 1.0062, 0.9908,\n",
       "                      0.9871, 0.9965, 1.0033, 0.9889, 0.9982, 0.9905, 1.0198, 1.0068, 0.9968,\n",
       "                      0.9887, 1.0037, 0.9955, 1.0003, 0.9934, 1.0011, 1.0020, 0.9804, 0.9828,\n",
       "                      0.9947, 0.9919, 0.9814, 1.0010, 0.9992, 0.9834, 1.0166, 1.0281, 0.9893,\n",
       "                      0.9805, 1.0136])),\n",
       "             ('transformations.1.bn1.bias',\n",
       "              tensor([ 6.6853e-03, -9.3171e-03, -2.9468e-02,  2.1380e-02, -6.2819e-03,\n",
       "                       1.9206e-02, -3.8193e-02, -2.5510e-02, -1.7010e-02, -5.0656e-04,\n",
       "                       1.4361e-02, -2.3853e-03, -7.5453e-03,  2.7488e-02, -6.4864e-03,\n",
       "                      -3.0939e-02,  3.2415e-02, -2.3830e-02,  1.1747e-03, -2.5870e-02,\n",
       "                       8.2472e-02, -5.6944e-02,  5.7224e-02,  2.1502e-02, -1.4146e-02,\n",
       "                       6.8572e-05,  4.9016e-02, -1.5471e-02,  2.8443e-02,  3.0860e-02,\n",
       "                       5.4806e-02, -1.1447e-03, -2.0979e-02,  3.2048e-02, -2.5361e-02,\n",
       "                      -1.0902e-02, -2.1823e-04,  3.3198e-02, -2.0763e-02,  1.2820e-02,\n",
       "                       2.7515e-02, -1.8864e-03, -8.3497e-03, -2.7076e-02,  4.5935e-02,\n",
       "                      -1.3045e-02, -9.0797e-03, -1.8321e-03,  2.9069e-03, -1.2727e-02,\n",
       "                       2.7171e-03, -3.3794e-02,  4.1788e-03,  5.7653e-02,  6.2480e-02,\n",
       "                      -3.5344e-02,  4.5992e-02,  4.4013e-02, -9.3851e-03,  1.2993e-03,\n",
       "                       2.5769e-02,  2.0051e-02,  4.8545e-02, -4.2052e-02, -2.1909e-02,\n",
       "                      -4.6036e-03,  4.4561e-02,  5.3283e-02,  1.3981e-02, -2.6423e-02,\n",
       "                       1.9481e-02, -2.5863e-02,  2.0322e-02, -5.6840e-02, -2.8588e-02,\n",
       "                       4.3267e-02, -2.1019e-02, -1.8509e-02,  6.6951e-03, -1.3073e-02,\n",
       "                      -9.0016e-03,  4.1855e-02, -4.3061e-02,  2.9589e-02, -5.3372e-02,\n",
       "                      -2.5867e-02,  1.0479e-02, -3.6295e-02,  4.0411e-02, -3.0622e-03,\n",
       "                      -1.4714e-02,  6.6779e-02,  4.1116e-02, -4.5451e-02,  2.9259e-02,\n",
       "                      -3.8896e-02, -1.7695e-04,  4.7768e-02, -4.4896e-02, -2.1276e-02,\n",
       "                       4.9013e-02,  3.8519e-02,  2.6059e-02, -9.3528e-03,  1.4544e-02,\n",
       "                       3.7171e-02,  3.7416e-02,  1.9172e-02, -1.0393e-02, -2.5684e-02,\n",
       "                       4.6742e-02,  2.5843e-02,  3.2530e-02, -8.4751e-02, -3.8523e-03,\n",
       "                       5.6017e-03, -9.6947e-03, -1.9572e-02,  1.8833e-02, -1.6296e-02,\n",
       "                      -1.5316e-03,  3.3708e-02, -8.0637e-03, -4.5094e-03,  1.2321e-01,\n",
       "                      -9.5936e-03, -3.4660e-02, -4.8436e-04])),\n",
       "             ('transformations.1.bn1.running_mean',\n",
       "              tensor([ 0.0021,  0.0013, -0.0018, -0.0052, -0.0138, -0.0100, -0.0076,  0.0134,\n",
       "                      -0.0035, -0.0023, -0.0084,  0.0021, -0.0085,  0.0033, -0.0031,  0.0007,\n",
       "                       0.0087, -0.0061,  0.0043,  0.0051, -0.0059, -0.0057, -0.0010, -0.0088,\n",
       "                      -0.0139,  0.0023, -0.0069,  0.0006,  0.0085,  0.0116, -0.0057,  0.0070,\n",
       "                       0.0022,  0.0072,  0.0074,  0.0090,  0.0008,  0.0060, -0.0027, -0.0079,\n",
       "                      -0.0036,  0.0025, -0.0019,  0.0057, -0.0019,  0.0062, -0.0102, -0.0016,\n",
       "                      -0.0132, -0.0007,  0.0107,  0.0074, -0.0031,  0.0024, -0.0140, -0.0007,\n",
       "                       0.0074, -0.0007, -0.0051,  0.0009,  0.0074,  0.0069,  0.0073, -0.0020,\n",
       "                       0.0017, -0.0056, -0.0029, -0.0128,  0.0042,  0.0086, -0.0004, -0.0041,\n",
       "                       0.0011, -0.0012, -0.0067,  0.0072, -0.0097, -0.0075,  0.0054,  0.0027,\n",
       "                       0.0025,  0.0044,  0.0089, -0.0060,  0.0040,  0.0047,  0.0045,  0.0066,\n",
       "                       0.0098, -0.0040, -0.0058,  0.0016, -0.0007,  0.0039, -0.0095, -0.0051,\n",
       "                      -0.0054, -0.0076,  0.0084, -0.0046, -0.0011,  0.0022,  0.0061, -0.0034,\n",
       "                       0.0048, -0.0060,  0.0079, -0.0070,  0.0045,  0.0022,  0.0025, -0.0030,\n",
       "                      -0.0009,  0.0033, -0.0073, -0.0057,  0.0012, -0.0058,  0.0060,  0.0022,\n",
       "                       0.0084, -0.0019,  0.0088,  0.0022, -0.0033, -0.0037, -0.0060,  0.0087])),\n",
       "             ('transformations.1.bn1.running_var',\n",
       "              tensor([0.2436, 0.3553, 0.3697, 0.3491, 0.3216, 0.3528, 0.2680, 0.3685, 0.3780,\n",
       "                      0.4403, 0.3755, 0.3041, 0.4844, 0.2931, 0.2516, 0.3007, 0.3347, 0.4129,\n",
       "                      0.4443, 0.2870, 0.4298, 0.3159, 0.4214, 0.3776, 0.4129, 0.3298, 0.3043,\n",
       "                      0.3996, 0.3585, 0.2782, 0.3918, 0.3024, 0.3649, 0.3407, 0.3744, 0.2495,\n",
       "                      0.2152, 0.2643, 0.2933, 0.4586, 0.3426, 0.3203, 0.3386, 0.3321, 0.3603,\n",
       "                      0.4675, 0.4491, 0.3665, 0.3944, 0.3002, 0.3101, 0.2410, 0.3897, 0.3233,\n",
       "                      0.3662, 0.2536, 0.3770, 0.3469, 0.2915, 0.3708, 0.3123, 0.3316, 0.3453,\n",
       "                      0.3645, 0.4162, 0.3209, 0.3897, 0.3923, 0.3511, 0.2589, 0.2732, 0.3964,\n",
       "                      0.2883, 0.4215, 0.2664, 0.2796, 0.4038, 0.3168, 0.2994, 0.2971, 0.3700,\n",
       "                      0.3135, 0.3882, 0.3149, 0.3582, 0.2656, 0.3871, 0.2844, 0.3592, 0.4311,\n",
       "                      0.3117, 0.3745, 0.3100, 0.3678, 0.3514, 0.2752, 0.3295, 0.3949, 0.4282,\n",
       "                      0.3222, 0.3856, 0.4145, 0.4201, 0.3438, 0.4592, 0.3549, 0.2762, 0.2476,\n",
       "                      0.2561, 0.3675, 0.3178, 0.3987, 0.2808, 0.2445, 0.3299, 0.3197, 0.3310,\n",
       "                      0.4171, 0.3699, 0.2486, 0.3075, 0.2895, 0.2846, 0.3398, 0.3814, 0.3374,\n",
       "                      0.3364, 0.3421])),\n",
       "             ('transformations.1.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('transformations.1.mu.weight',\n",
       "              tensor([[-0.0756, -0.0341,  0.0091,  ..., -0.0550, -0.0753, -0.0524],\n",
       "                      [ 0.0283, -0.0774,  0.0053,  ...,  0.0315, -0.0667, -0.0408],\n",
       "                      [-0.0433,  0.0732, -0.0418,  ...,  0.0683,  0.0006,  0.0114],\n",
       "                      ...,\n",
       "                      [ 0.0284, -0.0241, -0.0865,  ..., -0.0376,  0.0697, -0.0833],\n",
       "                      [ 0.0819,  0.0544,  0.0689,  ...,  0.0168, -0.0225, -0.0806],\n",
       "                      [ 0.0060, -0.0580,  0.0677,  ...,  0.0020, -0.0296, -0.0614]])),\n",
       "             ('transformations.1.mu.bias',\n",
       "              tensor([ 0.0040,  0.0442, -0.0031,  0.0008, -0.0360,  0.0839,  0.0229,  0.0338,\n",
       "                       0.1203,  0.0685, -0.0872,  0.0165,  0.0295,  0.0750,  0.0142,  0.1229,\n",
       "                       0.0593,  0.0091, -0.0824, -0.0203,  0.0189,  0.1023,  0.0294, -0.0044,\n",
       "                       0.0084, -0.0981, -0.0069, -0.0983, -0.1003, -0.0110,  0.0701, -0.0100])),\n",
       "             ('transformations.1.sigma.weight',\n",
       "              tensor([[-0.0678,  0.0648, -0.0541,  ...,  0.0410, -0.0695, -0.0384],\n",
       "                      [-0.1197, -0.0530,  0.0314,  ..., -0.0623,  0.0316, -0.0604],\n",
       "                      [-0.0969,  0.0553,  0.0119,  ...,  0.0563, -0.0094,  0.0297],\n",
       "                      ...,\n",
       "                      [ 0.0460,  0.0005,  0.0502,  ...,  0.0455, -0.0856, -0.0027],\n",
       "                      [ 0.0070, -0.0468,  0.0211,  ..., -0.0328, -0.0050,  0.0308],\n",
       "                      [-0.0592,  0.0273, -0.0189,  ..., -0.0173, -0.0262,  0.0535]])),\n",
       "             ('transformations.1.sigma.bias',\n",
       "              tensor([ 0.0596, -0.1221,  0.0435, -0.0490, -0.0221,  0.0677,  0.0607,  0.0225,\n",
       "                      -0.0566, -0.0611, -0.0825, -0.0421,  0.0264, -0.0621, -0.0881,  0.0584,\n",
       "                       0.0396, -0.0610, -0.0991,  0.0517, -0.1088, -0.0260, -0.1208,  0.0146,\n",
       "                       0.0811, -0.0172, -0.0413,  0.0028, -0.0133, -0.0332,  0.0446, -0.0224])),\n",
       "             ('transformations.2.dense1.weight',\n",
       "              tensor([[ 0.1220, -0.1693,  0.1246,  ...,  0.1189, -0.1498,  0.0210],\n",
       "                      [ 0.1238,  0.0976,  0.0187,  ..., -0.0324,  0.0270,  0.0960],\n",
       "                      [-0.1769,  0.0156,  0.1736,  ...,  0.1441,  0.0918,  0.0529],\n",
       "                      ...,\n",
       "                      [-0.1294,  0.1331, -0.1640,  ..., -0.0529, -0.0962, -0.0297],\n",
       "                      [-0.1915, -0.1463,  0.0227,  ...,  0.1434,  0.1720, -0.0531],\n",
       "                      [-0.1691, -0.0723,  0.0964,  ..., -0.1128,  0.0310, -0.1313]])),\n",
       "             ('transformations.2.bn1.weight',\n",
       "              tensor([1.0041, 1.0150, 1.0242, 1.0038, 1.0067, 1.0173, 1.0143, 0.9852, 0.9903,\n",
       "                      1.0026, 0.9787, 1.0180, 1.0141, 1.0064, 1.0114, 1.0145, 1.0115, 0.9791,\n",
       "                      0.9798, 0.9862, 1.0035, 1.0176, 1.0058, 1.0070, 0.9788, 1.0010, 1.0430,\n",
       "                      1.0096, 1.0066, 0.9753, 0.9977, 0.9801, 0.9801, 1.0016, 1.0043, 0.9825,\n",
       "                      1.0094, 1.0157, 1.0082, 1.0078, 0.9830, 1.0118, 1.0275, 1.0014, 0.9861,\n",
       "                      1.0178, 0.9747, 0.9835, 1.0161, 1.0215, 1.0167, 0.9909, 0.9909, 1.0011,\n",
       "                      1.0117, 0.9868, 1.0060, 1.0094, 1.0170, 0.9912, 0.9789, 0.9954, 0.9880,\n",
       "                      1.0163, 0.9830, 1.0196, 1.0130, 0.9898, 0.9711, 0.9972, 0.9789, 1.0137,\n",
       "                      1.0200, 1.0281, 1.0022, 0.9789, 0.9920, 1.0099, 1.0085, 1.0045, 0.9898,\n",
       "                      0.9929, 0.9912, 0.9981, 0.9914, 1.0199, 1.0199, 1.0013, 0.9984, 1.0020,\n",
       "                      0.9771, 0.9792, 1.0160, 1.0101, 0.9990, 1.0374, 0.9973, 1.0288, 0.9787,\n",
       "                      0.9887, 0.9917, 1.0077, 1.0172, 1.0164, 1.0166, 0.9823, 1.0025, 0.9853,\n",
       "                      0.9999, 0.9954, 0.9991, 1.0119, 0.9806, 0.9905, 1.0035, 0.9851, 1.0072,\n",
       "                      0.9805, 1.0172, 0.9877, 0.9971, 0.9776, 1.0279, 1.0095, 0.9978, 0.9867,\n",
       "                      1.0234, 0.9819])),\n",
       "             ('transformations.2.bn1.bias',\n",
       "              tensor([ 0.0474,  0.0177,  0.1025, -0.0221,  0.0063,  0.0586,  0.0003,  0.0140,\n",
       "                      -0.0339,  0.0181, -0.0081,  0.0651, -0.0044,  0.0284, -0.0213, -0.0061,\n",
       "                      -0.0173, -0.0165, -0.0031,  0.0157, -0.0299, -0.0166,  0.0391,  0.0422,\n",
       "                       0.0048,  0.0354,  0.0532,  0.0226, -0.0002,  0.0031, -0.0123,  0.0115,\n",
       "                      -0.0378,  0.0207,  0.0537,  0.0190, -0.0058,  0.0361,  0.0305, -0.0075,\n",
       "                      -0.0332, -0.0186,  0.0474,  0.0160, -0.0029,  0.0558, -0.0156, -0.0112,\n",
       "                       0.0544,  0.0455,  0.0354,  0.0276, -0.0061,  0.0375, -0.0123, -0.0193,\n",
       "                       0.0159, -0.0416,  0.0690,  0.0019, -0.0634,  0.0257,  0.0233,  0.0418,\n",
       "                       0.0013,  0.0453,  0.0528, -0.0669, -0.0218,  0.0166, -0.0248, -0.0048,\n",
       "                       0.0547,  0.0498,  0.0478,  0.0133, -0.0193, -0.0082, -0.0347, -0.0127,\n",
       "                       0.0200,  0.0054, -0.0379,  0.0292,  0.0155,  0.0642,  0.0399,  0.0192,\n",
       "                       0.0339,  0.0983, -0.0404, -0.0406,  0.0330, -0.0274,  0.0699,  0.0606,\n",
       "                       0.0268,  0.0769, -0.0191,  0.0239,  0.0256, -0.0248,  0.0485, -0.0008,\n",
       "                      -0.0078, -0.0005,  0.0323, -0.0230,  0.0181,  0.0239, -0.0154, -0.0316,\n",
       "                      -0.0191, -0.0064, -0.0164, -0.0468,  0.0253, -0.0153, -0.0059, -0.0032,\n",
       "                       0.0020, -0.0218,  0.0760,  0.0175,  0.0244, -0.0090,  0.0426, -0.0040])),\n",
       "             ('transformations.2.bn1.running_mean',\n",
       "              tensor([ 7.2336e-03,  4.5906e-03,  8.5914e-03,  1.3636e-02, -1.7961e-03,\n",
       "                       3.2868e-03, -9.5035e-04, -1.7300e-03, -2.2209e-04, -4.4707e-03,\n",
       "                       2.6561e-03, -2.7062e-03, -6.4716e-03,  1.6834e-03,  3.2846e-04,\n",
       "                      -3.0995e-03, -4.3404e-03,  6.3595e-03, -1.5757e-03,  5.1143e-03,\n",
       "                      -7.1167e-04, -2.5005e-03, -6.0835e-03,  6.2181e-03, -2.0243e-03,\n",
       "                      -4.6719e-03, -7.7682e-03, -1.2078e-04,  8.5434e-03, -5.3638e-04,\n",
       "                      -2.0938e-03, -6.8023e-03,  1.1966e-03,  1.5848e-02,  6.7103e-03,\n",
       "                       4.5648e-03, -6.8501e-03,  6.2557e-03, -5.4491e-03, -6.5553e-03,\n",
       "                       3.5789e-03, -2.7329e-03, -6.2419e-04, -4.1800e-03,  3.6460e-03,\n",
       "                       9.4745e-03,  1.2905e-04,  3.5846e-04, -1.9478e-03, -4.0603e-03,\n",
       "                      -6.1909e-03, -1.0688e-02,  4.0157e-03,  2.6894e-04,  2.6384e-04,\n",
       "                      -6.8760e-03, -1.1181e-02,  1.5547e-03, -3.3279e-03, -3.1984e-04,\n",
       "                       6.5929e-03,  1.1066e-03,  4.0655e-04,  9.3286e-03,  2.5930e-03,\n",
       "                       7.5487e-03,  4.6174e-03,  5.3412e-03,  4.6695e-03,  5.9691e-03,\n",
       "                      -5.6874e-03, -3.5903e-03,  1.3094e-05, -1.0101e-02, -5.5186e-03,\n",
       "                      -9.9882e-03,  7.8495e-03, -2.8716e-03,  4.2207e-03,  1.8749e-03,\n",
       "                      -6.5265e-03,  5.7801e-04,  1.0719e-02,  1.4049e-02, -1.1662e-02,\n",
       "                      -6.3904e-03,  3.3648e-03,  7.7991e-03,  4.7154e-03, -2.5744e-03,\n",
       "                       3.1128e-03, -8.6365e-04, -7.8195e-03,  1.6453e-03,  6.3590e-03,\n",
       "                       5.3730e-03, -2.7927e-03,  6.3214e-03, -4.0821e-03, -2.1701e-03,\n",
       "                       1.8389e-03,  8.7586e-03, -3.2593e-04, -9.0060e-04, -1.1957e-02,\n",
       "                       5.6602e-03,  2.6732e-03,  1.0725e-03, -2.5989e-03, -7.1015e-03,\n",
       "                       4.9784e-03,  7.1358e-03, -5.7683e-03, -1.1747e-02,  9.6183e-04,\n",
       "                       5.3053e-04,  1.6526e-03, -5.7017e-03, -3.6815e-03,  1.2466e-02,\n",
       "                       6.1181e-03, -1.1023e-02,  6.9381e-03,  8.3172e-03,  9.1944e-03,\n",
       "                       2.0175e-03, -2.6485e-03,  1.0293e-02])),\n",
       "             ('transformations.2.bn1.running_var',\n",
       "              tensor([0.2918, 0.3221, 0.4392, 0.3059, 0.2796, 0.2735, 0.4206, 0.3760, 0.2779,\n",
       "                      0.3194, 0.2514, 0.3525, 0.3624, 0.3880, 0.2932, 0.3888, 0.4129, 0.2919,\n",
       "                      0.2586, 0.2790, 0.3894, 0.2889, 0.2527, 0.2530, 0.2918, 0.4221, 0.2934,\n",
       "                      0.2243, 0.3940, 0.3986, 0.3405, 0.2969, 0.3765, 0.3843, 0.3028, 0.3203,\n",
       "                      0.3785, 0.4133, 0.3219, 0.3350, 0.3051, 0.2895, 0.3198, 0.2620, 0.3388,\n",
       "                      0.4517, 0.3726, 0.3408, 0.3466, 0.3430, 0.3424, 0.3111, 0.3114, 0.3722,\n",
       "                      0.3532, 0.3383, 0.3272, 0.2788, 0.3835, 0.3508, 0.3243, 0.4127, 0.2982,\n",
       "                      0.4038, 0.2883, 0.2960, 0.3609, 0.3036, 0.3259, 0.2998, 0.2712, 0.4218,\n",
       "                      0.2211, 0.3581, 0.3285, 0.3551, 0.2959, 0.2906, 0.2390, 0.3473, 0.3700,\n",
       "                      0.2589, 0.2732, 0.3248, 0.2454, 0.3070, 0.3725, 0.3709, 0.3276, 0.3485,\n",
       "                      0.3441, 0.3011, 0.3512, 0.3113, 0.3802, 0.3568, 0.3714, 0.2689, 0.3205,\n",
       "                      0.2581, 0.3182, 0.3238, 0.2303, 0.3305, 0.4465, 0.3162, 0.3811, 0.2922,\n",
       "                      0.2586, 0.3994, 0.4211, 0.3779, 0.3582, 0.4070, 0.3108, 0.4096, 0.4216,\n",
       "                      0.4201, 0.4276, 0.2859, 0.4122, 0.4037, 0.4871, 0.3553, 0.2682, 0.3628,\n",
       "                      0.4517, 0.3738])),\n",
       "             ('transformations.2.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('transformations.2.mu.weight',\n",
       "              tensor([[-0.0700,  0.0534, -0.0834,  ...,  0.0711, -0.0742,  0.0525],\n",
       "                      [ 0.0071,  0.0553,  0.0639,  ...,  0.0365,  0.0124,  0.0856],\n",
       "                      [ 0.0766, -0.0361,  0.0527,  ...,  0.0252,  0.0030,  0.0036],\n",
       "                      ...,\n",
       "                      [-0.0465,  0.0559,  0.0757,  ...,  0.0965, -0.0228, -0.0474],\n",
       "                      [ 0.0866,  0.0943, -0.0441,  ..., -0.0246, -0.0033,  0.0552],\n",
       "                      [ 0.0459,  0.0638,  0.0138,  ...,  0.0870,  0.0721,  0.0345]])),\n",
       "             ('transformations.2.mu.bias',\n",
       "              tensor([-0.0269,  0.0654,  0.0903, -0.0209, -0.0455,  0.0882, -0.0183, -0.0865,\n",
       "                      -0.0067,  0.0864,  0.0474, -0.0794,  0.0814, -0.0176,  0.0388,  0.0095,\n",
       "                       0.0935,  0.0611,  0.0278, -0.0857,  0.0040, -0.1018, -0.0542,  0.0029,\n",
       "                      -0.1070, -0.0538,  0.0165,  0.0485, -0.0176, -0.0316, -0.0338, -0.0475])),\n",
       "             ('transformations.2.sigma.weight',\n",
       "              tensor([[-0.0043, -0.0619,  0.0725,  ..., -0.0413, -0.0732, -0.0729],\n",
       "                      [ 0.0453, -0.0138, -0.1026,  ..., -0.0954, -0.0969, -0.0991],\n",
       "                      [ 0.0254, -0.0338, -0.0256,  ..., -0.0091, -0.0784, -0.0921],\n",
       "                      ...,\n",
       "                      [ 0.0364,  0.0433, -0.0335,  ...,  0.0251, -0.0084,  0.0365],\n",
       "                      [-0.0606, -0.0074,  0.0185,  ..., -0.0107, -0.0794, -0.0315],\n",
       "                      [ 0.0494, -0.1182,  0.0102,  ..., -0.0680, -0.1001, -0.0373]])),\n",
       "             ('transformations.2.sigma.bias',\n",
       "              tensor([ 0.0696,  0.0198,  0.0575, -0.0927, -0.0688,  0.0435, -0.0848, -0.0154,\n",
       "                      -0.0192, -0.0578, -0.0988, -0.0429,  0.0367, -0.0487,  0.0190, -0.0977,\n",
       "                       0.0057,  0.0417, -0.1271, -0.0260, -0.0755, -0.0205,  0.0191, -0.0309,\n",
       "                      -0.0206, -0.0047,  0.0059, -0.0003, -0.0726, -0.0866,  0.0305,  0.0022])),\n",
       "             ('transformations.3.dense1.weight',\n",
       "              tensor([[-0.1826, -0.1072,  0.0451,  ..., -0.0395, -0.1256,  0.0963],\n",
       "                      [ 0.0476,  0.1431, -0.0785,  ...,  0.1332, -0.1632,  0.0598],\n",
       "                      [-0.1452,  0.0627, -0.1608,  ...,  0.0726, -0.0483, -0.0073],\n",
       "                      ...,\n",
       "                      [ 0.0352, -0.1245, -0.0882,  ...,  0.1773, -0.1449,  0.1552],\n",
       "                      [-0.0767,  0.0768, -0.1465,  ..., -0.1560,  0.1590,  0.0471],\n",
       "                      [ 0.1701, -0.0418,  0.0040,  ..., -0.1599,  0.1505, -0.1510]])),\n",
       "             ('transformations.3.bn1.weight',\n",
       "              tensor([0.9760, 0.9924, 1.0065, 0.9985, 0.9913, 1.0097, 0.9865, 0.9944, 1.0127,\n",
       "                      1.0137, 1.0120, 0.9878, 1.0082, 0.9946, 1.0192, 0.9873, 0.9913, 1.0099,\n",
       "                      0.9944, 0.9923, 1.0228, 0.9919, 0.9858, 1.0024, 1.0077, 0.9870, 1.0062,\n",
       "                      0.9977, 1.0125, 1.0228, 0.9915, 1.0056, 1.0164, 0.9988, 1.0182, 0.9851,\n",
       "                      0.9995, 0.9989, 0.9942, 1.0214, 0.9979, 0.9772, 1.0013, 1.0140, 0.9971,\n",
       "                      0.9824, 0.9909, 0.9944, 1.0127, 0.9907, 1.0148, 1.0265, 0.9842, 1.0086,\n",
       "                      1.0196, 1.0182, 0.9933, 1.0142, 1.0252, 0.9906, 0.9853, 1.0189, 0.9863,\n",
       "                      1.0207, 1.0151, 0.9918, 0.9721, 1.0124, 0.9878, 1.0135, 0.9838, 0.9775,\n",
       "                      0.9972, 1.0299, 1.0210, 0.9925, 0.9916, 1.0057, 1.0052, 1.0003, 0.9824,\n",
       "                      0.9988, 0.9972, 0.9977, 1.0220, 1.0048, 0.9957, 0.9938, 1.0101, 1.0041,\n",
       "                      0.9819, 1.0249, 1.0079, 1.0254, 0.9939, 1.0242, 0.9832, 0.9973, 1.0094,\n",
       "                      0.9949, 0.9954, 1.0171, 0.9910, 1.0157, 1.0123, 1.0001, 0.9912, 1.0110,\n",
       "                      0.9943, 1.0049, 1.0050, 0.9981, 0.9702, 0.9879, 0.9964, 1.0167, 1.0092,\n",
       "                      0.9923, 1.0093, 0.9751, 1.0110, 1.0113, 0.9901, 1.0060, 0.9835, 0.9839,\n",
       "                      1.0079, 1.0325])),\n",
       "             ('transformations.3.bn1.bias',\n",
       "              tensor([-1.4934e-02,  6.8270e-03,  4.9873e-02,  1.3521e-02, -2.0513e-04,\n",
       "                       4.8935e-02, -1.5455e-02, -4.4486e-02,  2.0718e-02,  6.3166e-02,\n",
       "                       2.8700e-02, -6.0436e-02,  4.7270e-02, -3.4256e-02,  7.4673e-02,\n",
       "                      -1.0464e-04,  2.0444e-02,  4.5154e-02,  2.1865e-02,  6.4912e-03,\n",
       "                       6.7815e-02,  2.0823e-02, -1.3018e-03, -1.0212e-02,  2.0512e-02,\n",
       "                       1.5914e-02,  2.2015e-02,  7.0856e-03,  4.3211e-02,  4.6568e-02,\n",
       "                       9.5111e-03,  2.5397e-02,  3.3388e-02,  3.7870e-02,  9.7248e-02,\n",
       "                      -4.6510e-02, -1.8787e-02,  1.0289e-02,  1.4460e-02,  5.5182e-02,\n",
       "                      -8.8047e-03, -8.5784e-04,  7.5194e-04,  5.1021e-02,  3.0186e-02,\n",
       "                      -1.8662e-02,  1.4735e-02,  1.0538e-03,  6.8498e-02, -7.6092e-03,\n",
       "                       2.6825e-02,  8.2819e-02, -2.1058e-02,  5.5678e-02,  1.2015e-01,\n",
       "                       7.1061e-02, -6.5533e-03,  2.3050e-02,  5.8787e-02, -1.2984e-02,\n",
       "                      -2.1781e-04,  8.5823e-02,  9.4530e-03,  1.4432e-02,  5.9973e-02,\n",
       "                      -3.4088e-02, -1.7063e-02,  3.0618e-02, -4.6250e-03,  3.7680e-02,\n",
       "                      -3.7051e-02, -2.2796e-02, -3.9174e-03,  7.5232e-02,  4.6821e-02,\n",
       "                      -3.1610e-03,  1.4406e-02,  1.1440e-02, -3.3978e-03,  1.8149e-02,\n",
       "                      -9.6315e-03,  2.1827e-02,  1.1872e-02, -3.0001e-02,  6.0438e-02,\n",
       "                       1.3720e-02,  1.2202e-03,  1.7619e-03,  7.8413e-02,  6.3713e-03,\n",
       "                       1.3955e-03,  4.0489e-02,  2.4601e-02,  7.7166e-02,  2.8574e-03,\n",
       "                       9.0728e-02, -2.2213e-02, -3.3108e-03,  2.4554e-02,  2.3667e-03,\n",
       "                      -3.5473e-02,  3.3567e-02, -2.1260e-02,  6.0709e-02,  6.7430e-02,\n",
       "                       3.2809e-02, -8.2425e-03,  2.6834e-02,  1.2318e-02,  1.6121e-02,\n",
       "                       3.2516e-02,  1.2535e-02, -1.9129e-02, -1.1855e-02,  1.6916e-02,\n",
       "                       4.3512e-02,  4.6400e-02, -2.1343e-02,  7.6726e-03, -2.1471e-02,\n",
       "                       5.5013e-02,  4.7801e-02,  4.0361e-03,  7.8434e-02, -1.6681e-02,\n",
       "                      -2.3505e-02,  2.1838e-02,  7.0498e-02])),\n",
       "             ('transformations.3.bn1.running_mean',\n",
       "              tensor([ 0.0086, -0.0415,  0.0035, -0.0137, -0.0212, -0.0500,  0.0513, -0.0353,\n",
       "                      -0.1126, -0.0929,  0.0938, -0.0538, -0.0512, -0.1654,  0.0240, -0.0380,\n",
       "                      -0.0724,  0.0163, -0.0197, -0.0113, -0.0572, -0.0361,  0.0818, -0.0659,\n",
       "                      -0.0399, -0.0771,  0.0787, -0.0120, -0.0462, -0.0159,  0.0049, -0.0037,\n",
       "                      -0.1244, -0.0136,  0.0611, -0.0984,  0.0512,  0.0769,  0.0869,  0.1080,\n",
       "                       0.0981,  0.1228, -0.0285,  0.1501, -0.0021,  0.1576, -0.0474, -0.0852,\n",
       "                       0.0535,  0.1608,  0.0443,  0.0096, -0.0045, -0.0707,  0.0011, -0.1009,\n",
       "                      -0.0208, -0.0466,  0.0105, -0.0290, -0.0566,  0.1518, -0.0830,  0.0518,\n",
       "                       0.0950,  0.0265, -0.0582, -0.0112,  0.0266,  0.0764,  0.0469, -0.0146,\n",
       "                      -0.0955, -0.1790,  0.1304, -0.0663, -0.0283,  0.0030, -0.0041, -0.1055,\n",
       "                      -0.0747, -0.0471,  0.1088,  0.0220,  0.0329,  0.0977,  0.0803,  0.0635,\n",
       "                      -0.0696, -0.0589,  0.0558, -0.1527, -0.0550,  0.0612, -0.0778, -0.0156,\n",
       "                      -0.0584, -0.0748,  0.0938,  0.0087, -0.1106, -0.1130,  0.0973,  0.1843,\n",
       "                       0.0586, -0.0047, -0.0824,  0.0128,  0.0159, -0.0999,  0.0183, -0.0563,\n",
       "                       0.0432, -0.0526, -0.1630, -0.0313,  0.1094,  0.0688, -0.1171, -0.0669,\n",
       "                      -0.0828, -0.0421,  0.0108, -0.0742, -0.0715, -0.0892, -0.0820, -0.0734])),\n",
       "             ('transformations.3.bn1.running_var',\n",
       "              tensor([0.2389, 0.6127, 0.2580, 0.3268, 0.1474, 0.1614, 0.1227, 0.1274, 0.4452,\n",
       "                      0.1504, 0.1973, 0.1987, 0.1312, 0.3301, 0.1532, 0.2995, 0.2131, 0.2399,\n",
       "                      0.2146, 0.1199, 0.1331, 0.1312, 0.1930, 0.7268, 0.3054, 0.1967, 0.1356,\n",
       "                      0.5307, 0.1478, 0.1179, 0.1209, 0.4199, 0.4829, 0.1347, 0.1291, 0.6208,\n",
       "                      0.1916, 0.1386, 0.1259, 0.2612, 0.1956, 0.1354, 0.3636, 0.2372, 0.1312,\n",
       "                      0.1658, 0.1765, 0.1543, 0.2233, 0.4310, 0.4485, 0.1204, 0.2139, 0.1861,\n",
       "                      0.1241, 0.1248, 0.2367, 0.5659, 0.1278, 0.7340, 0.2889, 0.1699, 0.0907,\n",
       "                      0.3791, 0.2330, 0.4687, 0.2386, 0.2977, 0.1414, 0.1440, 0.1541, 0.2371,\n",
       "                      0.3930, 0.4555, 0.1965, 0.2451, 0.1197, 0.8059, 0.7711, 0.2704, 0.4875,\n",
       "                      0.5871, 0.1566, 0.2857, 0.1352, 0.1406, 0.1851, 0.1144, 0.2505, 0.1920,\n",
       "                      0.4210, 0.6567, 0.1027, 0.1503, 0.4020, 0.1506, 0.1260, 0.1740, 0.1523,\n",
       "                      0.1503, 0.2057, 0.1505, 0.1220, 0.1345, 0.2544, 0.1079, 0.1382, 0.2056,\n",
       "                      0.1976, 0.6653, 0.2719, 0.2813, 0.1564, 0.2178, 0.3460, 0.3266, 0.1841,\n",
       "                      0.1434, 0.6193, 0.1460, 0.1332, 0.1295, 0.5219, 0.1548, 0.2276, 0.1495,\n",
       "                      0.2142, 0.2544])),\n",
       "             ('transformations.3.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.3.mu.weight',\n",
       "              tensor([[ 0.0866,  0.0823,  0.0149,  ...,  0.0166, -0.0609, -0.0443],\n",
       "                      [-0.0461, -0.0433,  0.0580,  ..., -0.0315,  0.1038, -0.0474],\n",
       "                      [ 0.0381,  0.0091, -0.0506,  ..., -0.0315,  0.0561,  0.0033],\n",
       "                      ...,\n",
       "                      [-0.0664,  0.0324, -0.0072,  ...,  0.0447, -0.0149, -0.0987],\n",
       "                      [ 0.0674, -0.0799, -0.0918,  ...,  0.0342,  0.0022, -0.0403],\n",
       "                      [ 0.0637, -0.0511, -0.0155,  ..., -0.0394, -0.0081,  0.0161]])),\n",
       "             ('transformations.3.mu.bias',\n",
       "              tensor([ 0.0055,  0.0347, -0.0439, -0.1102,  0.0072,  0.0780, -0.0561, -0.0606,\n",
       "                      -0.0593, -0.1453,  0.0075,  0.0322, -0.0951, -0.0101,  0.1014,  0.0369,\n",
       "                      -0.0441,  0.1237,  0.0648,  0.0244, -0.0624, -0.0625, -0.0521,  0.0555,\n",
       "                      -0.0979,  0.0269, -0.0200,  0.0728,  0.0183, -0.0820, -0.0699,  0.0303])),\n",
       "             ('transformations.3.sigma.weight',\n",
       "              tensor([[-0.0346,  0.0718, -0.0020,  ..., -0.0727, -0.0231, -0.0558],\n",
       "                      [ 0.0890, -0.0289, -0.0348,  ...,  0.0497, -0.0696, -0.0544],\n",
       "                      [-0.0123,  0.0442,  0.0448,  ..., -0.0467, -0.0878, -0.0953],\n",
       "                      ...,\n",
       "                      [-0.0411,  0.0022,  0.0218,  ...,  0.0757,  0.0633,  0.0275],\n",
       "                      [ 0.0536, -0.0657, -0.0536,  ..., -0.0415,  0.0102, -0.0232],\n",
       "                      [ 0.0170,  0.0217,  0.0706,  ..., -0.0701, -0.0930, -0.0094]])),\n",
       "             ('transformations.3.sigma.bias',\n",
       "              tensor([ 0.0244,  0.0297, -0.0660, -0.0392,  0.0015, -0.0804, -0.0261,  0.0119,\n",
       "                       0.0748,  0.0523, -0.0435,  0.0728,  0.0177, -0.0362, -0.0221, -0.1036,\n",
       "                       0.0267,  0.0432, -0.0766,  0.0740,  0.1222,  0.0078, -0.0452,  0.0620,\n",
       "                       0.0499, -0.0935, -0.0252,  0.0355, -0.0085, -0.0568,  0.1016, -0.0440])),\n",
       "             ('transformations.4.dense1.weight',\n",
       "              tensor([[-0.0822, -0.0248,  0.0537,  ..., -0.0039, -0.0017,  0.1311],\n",
       "                      [-0.1057,  0.0538, -0.1475,  ..., -0.0290,  0.1015, -0.0735],\n",
       "                      [ 0.0260,  0.0650, -0.0357,  ...,  0.0915,  0.0952, -0.0582],\n",
       "                      ...,\n",
       "                      [-0.0665, -0.1337, -0.0853,  ..., -0.0922,  0.1372, -0.1538],\n",
       "                      [ 0.0034, -0.1337,  0.0501,  ...,  0.0209, -0.0642, -0.1589],\n",
       "                      [-0.0994,  0.1484, -0.0989,  ..., -0.1403, -0.1763, -0.0281]])),\n",
       "             ('transformations.4.bn1.weight',\n",
       "              tensor([0.9859, 0.9852, 0.9807, 0.9857, 0.9940, 0.9834, 0.9901, 0.9946, 0.9891,\n",
       "                      1.0060, 0.9897, 0.9902, 0.9951, 0.9900, 1.0034, 1.0040, 1.0023, 0.9980,\n",
       "                      1.0096, 0.9903, 1.0129, 1.0071, 0.9864, 0.9867, 0.9998, 0.9894, 1.0069,\n",
       "                      0.9931, 0.9849, 1.0136, 0.9988, 0.9823, 1.0009, 0.9831, 0.9940, 0.9917,\n",
       "                      0.9942, 0.9950, 1.0048, 0.9933, 1.0008, 0.9850, 0.9863, 0.9874, 1.0100,\n",
       "                      1.0067, 0.9922, 1.0061, 0.9835, 1.0016, 1.0024, 1.0061, 0.9876, 0.9895,\n",
       "                      0.9941, 0.9860, 0.9894, 0.9850, 0.9891, 0.9800, 0.9924, 0.9924, 0.9915,\n",
       "                      0.9868, 1.0009, 1.0043, 0.9911, 0.9974, 0.9860, 1.0013, 0.9981, 0.9958,\n",
       "                      0.9921, 0.9975, 0.9972, 0.9970, 0.9990, 0.9864, 0.9920, 0.9876, 0.9896,\n",
       "                      0.9855, 0.9962, 0.9952, 0.9933, 1.0046, 0.9938, 1.0038, 0.9927, 0.9898,\n",
       "                      1.0012, 0.9835, 0.9924, 1.0000, 0.9983, 0.9778, 0.9923, 0.9858, 0.9902,\n",
       "                      0.9899, 0.9954, 0.9872, 0.9819, 0.9930, 0.9916, 0.9958, 1.0051, 0.9862,\n",
       "                      1.0000, 1.0026, 1.0041, 0.9862, 1.0053, 0.9845, 0.9878, 0.9923, 0.9924,\n",
       "                      0.9974, 0.9926, 0.9905, 0.9852, 0.9893, 0.9870, 0.9901, 0.9989, 0.9928,\n",
       "                      0.9863, 0.9974])),\n",
       "             ('transformations.4.bn1.bias',\n",
       "              tensor([-2.1874e-02, -1.9129e-02, -2.7365e-02, -2.7157e-03, -1.1642e-02,\n",
       "                      -8.9530e-03, -9.2436e-03, -9.5191e-03, -7.2353e-03, -8.2921e-03,\n",
       "                       1.2780e-03, -1.2426e-02,  7.5150e-03,  3.3279e-03,  1.2866e-02,\n",
       "                       1.6183e-02,  5.9088e-03,  3.6842e-03,  1.9284e-02,  8.4169e-05,\n",
       "                       1.1888e-02,  1.3521e-02, -1.8550e-02, -4.5465e-03,  5.7868e-03,\n",
       "                      -2.2248e-02,  1.5734e-02, -1.4447e-02, -1.4039e-02,  1.1315e-02,\n",
       "                      -8.9434e-03,  3.1092e-03,  2.7895e-03, -1.5168e-02, -2.9234e-03,\n",
       "                      -5.2385e-03,  7.9720e-03, -7.5248e-03,  9.5068e-03,  1.1215e-02,\n",
       "                       1.3945e-02, -5.3040e-04, -1.3064e-02, -1.1447e-02,  7.0624e-03,\n",
       "                       6.4326e-03, -9.7359e-03,  1.6496e-02, -1.1662e-02,  3.6553e-03,\n",
       "                       1.2177e-02, -4.8972e-03, -1.0788e-02, -1.1049e-02,  8.1884e-03,\n",
       "                      -1.5979e-02, -1.0605e-02, -4.5014e-03, -1.3392e-02, -1.9414e-02,\n",
       "                       1.0329e-03, -2.2132e-03, -8.8250e-03,  4.6742e-03,  1.2192e-02,\n",
       "                       9.2340e-03, -6.0482e-04,  4.2981e-03, -1.5268e-02, -2.1555e-04,\n",
       "                      -1.8350e-03, -5.9751e-03,  1.6301e-03,  9.0235e-03, -1.7369e-03,\n",
       "                       9.4474e-03,  9.5571e-03, -1.7051e-02, -5.6240e-04, -1.7465e-02,\n",
       "                      -1.6877e-03, -9.5039e-03,  7.6501e-03, -1.0836e-02,  4.8187e-03,\n",
       "                       1.8864e-04,  1.5963e-02,  5.3249e-03,  8.3008e-03,  7.5724e-03,\n",
       "                       3.8284e-03, -1.0775e-02, -1.1657e-02,  1.0714e-02,  2.0286e-03,\n",
       "                      -6.3465e-03,  4.1106e-03, -1.0188e-02, -4.6275e-03, -1.2493e-02,\n",
       "                      -1.0706e-02, -1.2267e-02, -2.8183e-02,  6.6010e-03, -1.4428e-02,\n",
       "                      -4.7697e-03,  7.3226e-03, -1.4728e-02,  4.7065e-03,  1.8060e-02,\n",
       "                      -8.6976e-03, -1.7996e-02,  6.3159e-03, -1.3377e-02, -2.3597e-02,\n",
       "                      -7.0088e-03, -6.2708e-03, -8.7469e-03,  1.0878e-02, -1.0334e-03,\n",
       "                      -1.7892e-02, -1.6723e-02, -4.6545e-03,  4.8409e-03,  7.7208e-03,\n",
       "                      -2.7858e-03, -1.3337e-02,  4.8061e-03])),\n",
       "             ('transformations.4.bn1.running_mean',\n",
       "              tensor([ 3.1775e-02,  2.6228e-02, -4.3398e-03,  3.2173e-02,  1.2235e-01,\n",
       "                       7.6594e-02, -1.0917e-01,  7.5095e-02,  4.9856e-02, -8.8700e-02,\n",
       "                      -9.6546e-04, -9.3566e-03, -9.2200e-02, -1.3695e-02, -7.4990e-02,\n",
       "                      -1.4746e-01,  3.6481e-02,  5.3156e-03,  5.5808e-02, -9.6824e-02,\n",
       "                       4.9177e-02, -4.6064e-03,  7.1536e-02, -1.5836e-01, -5.4899e-02,\n",
       "                       9.4308e-04,  9.2294e-02,  5.4141e-02, -2.3164e-02,  6.1305e-02,\n",
       "                       6.1876e-03,  9.9634e-02, -5.8343e-02, -1.2875e-01,  1.2135e-02,\n",
       "                       1.2529e-03, -1.5383e-02, -4.0050e-02, -3.1558e-02, -1.9242e-02,\n",
       "                      -1.0008e-01,  4.1680e-02,  1.0507e-02, -9.4579e-02, -1.6024e-02,\n",
       "                      -5.1603e-02, -9.4717e-02,  5.1722e-02, -1.0151e-01, -3.5605e-02,\n",
       "                       8.8077e-02, -1.3123e-01, -1.3168e-02,  1.1931e-01,  1.1288e-01,\n",
       "                       4.7884e-02,  7.3941e-02,  6.7298e-02, -4.5930e-02, -2.4206e-02,\n",
       "                       2.2741e-02,  1.0576e-02,  1.2389e-01,  6.9145e-02, -1.4276e-01,\n",
       "                      -8.4428e-02,  2.1563e-02, -2.0770e-02,  6.8106e-02,  3.1872e-02,\n",
       "                      -4.6618e-02,  8.3577e-03,  7.7350e-02, -9.1650e-02, -9.9099e-02,\n",
       "                       1.5566e-02,  6.4903e-02, -1.2190e-01,  6.7534e-02,  2.2145e-02,\n",
       "                      -5.4091e-02,  1.5475e-01,  2.4166e-03, -1.4719e-01, -2.5377e-02,\n",
       "                      -3.6243e-03, -1.4879e-01,  8.1502e-02, -1.1661e-05,  7.4783e-03,\n",
       "                       6.6044e-02, -5.1438e-02, -2.3698e-02, -6.0024e-03,  1.8270e-01,\n",
       "                      -5.2002e-02, -1.9989e-03,  6.6262e-03,  5.8554e-02, -2.4545e-02,\n",
       "                      -4.9888e-02,  4.3066e-02,  9.8498e-02, -5.6508e-02,  3.1847e-02,\n",
       "                      -4.3095e-02, -3.5842e-02,  6.4831e-02, -1.0443e-01, -1.4402e-01,\n",
       "                      -5.6146e-02, -1.1026e-01, -1.1202e-01, -4.1835e-02, -5.6578e-02,\n",
       "                       2.1044e-02,  5.5531e-02, -3.7407e-03,  4.5575e-02,  1.4869e-02,\n",
       "                       1.4998e-03,  1.3014e-01,  1.6717e-02, -5.8774e-02,  1.4123e-01,\n",
       "                       2.0312e-02,  1.5303e-01,  1.2355e-01])),\n",
       "             ('transformations.4.bn1.running_var',\n",
       "              tensor([0.1936, 0.2001, 0.1453, 0.4638, 0.1524, 0.0899, 0.1555, 0.1409, 0.1150,\n",
       "                      0.1195, 0.1179, 0.3401, 0.1338, 0.2631, 0.2026, 0.1321, 0.1941, 0.1275,\n",
       "                      0.7572, 0.1596, 0.8405, 0.1352, 0.1029, 0.1748, 0.1639, 0.1684, 0.9739,\n",
       "                      0.1351, 0.2546, 0.1683, 0.3229, 0.3166, 0.1408, 0.1063, 0.2362, 0.2064,\n",
       "                      0.1230, 0.2533, 0.1242, 0.2855, 0.1818, 0.2654, 0.3797, 0.1376, 0.1473,\n",
       "                      0.3270, 0.1295, 0.5182, 0.1106, 0.1283, 0.4074, 0.1772, 0.1810, 0.1166,\n",
       "                      0.4964, 0.1633, 0.4636, 0.1795, 0.1730, 0.1351, 0.1525, 0.1699, 0.2494,\n",
       "                      0.1486, 0.2223, 0.3450, 0.1694, 0.2827, 0.1518, 0.1364, 0.3424, 0.1799,\n",
       "                      0.2036, 0.1744, 0.3773, 0.5810, 0.2180, 0.2647, 0.1327, 0.2401, 0.2898,\n",
       "                      0.1086, 0.1197, 0.1634, 0.2537, 0.1333, 0.1602, 0.1537, 0.3719, 0.1945,\n",
       "                      0.1656, 0.1296, 0.1568, 0.1793, 0.1936, 0.1324, 0.2827, 0.1354, 0.2413,\n",
       "                      0.2197, 0.2300, 0.2769, 0.2561, 0.1171, 0.1415, 0.3692, 0.1554, 0.6453,\n",
       "                      0.2108, 0.2171, 0.1310, 0.1503, 0.1734, 0.1062, 0.1598, 0.1774, 0.1296,\n",
       "                      0.2364, 0.1403, 0.1329, 0.1307, 0.3989, 0.1210, 0.1934, 0.3337, 0.1496,\n",
       "                      0.1683, 0.2812])),\n",
       "             ('transformations.4.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.4.mu.weight',\n",
       "              tensor([[-0.0037, -0.0649,  0.0184,  ...,  0.0768,  0.0897,  0.0101],\n",
       "                      [ 0.0036,  0.0675, -0.0704,  ...,  0.0315, -0.0057, -0.0269],\n",
       "                      [-0.0076,  0.0072,  0.0217,  ..., -0.0888, -0.0057,  0.0545],\n",
       "                      ...,\n",
       "                      [ 0.0384, -0.0895,  0.0437,  ...,  0.0595,  0.0806,  0.0768],\n",
       "                      [ 0.0810, -0.0317, -0.0778,  ..., -0.0524, -0.0508,  0.0075],\n",
       "                      [-0.0406,  0.0686, -0.0200,  ..., -0.0069,  0.0228,  0.0118]])),\n",
       "             ('transformations.4.mu.bias',\n",
       "              tensor([-0.0751, -0.0724,  0.0314, -0.0591,  0.0311,  0.0493, -0.1049, -0.0688,\n",
       "                      -0.0793,  0.1290, -0.0244,  0.0604, -0.0428,  0.0176, -0.0897, -0.0556,\n",
       "                       0.0474, -0.0526, -0.0736, -0.0741, -0.0774,  0.0885,  0.0104,  0.0253,\n",
       "                       0.0035,  0.0313, -0.0136, -0.0657, -0.0637, -0.0269, -0.0188,  0.0739])),\n",
       "             ('transformations.4.sigma.weight',\n",
       "              tensor([[ 0.0465,  0.0124,  0.0409,  ..., -0.0585, -0.0271, -0.0429],\n",
       "                      [ 0.0002,  0.0638, -0.0097,  ...,  0.0626,  0.0436,  0.0281],\n",
       "                      [ 0.0493, -0.0478,  0.0507,  ..., -0.0817, -0.0534, -0.0928],\n",
       "                      ...,\n",
       "                      [-0.0715,  0.0640, -0.0526,  ...,  0.0643,  0.0288, -0.0341],\n",
       "                      [ 0.0232, -0.0655, -0.0404,  ..., -0.0566,  0.0548, -0.0649],\n",
       "                      [-0.0989, -0.0196, -0.1049,  ..., -0.1015,  0.0177, -0.0081]])),\n",
       "             ('transformations.4.sigma.bias',\n",
       "              tensor([-0.0972,  0.0079,  0.0075,  0.0234, -0.0436,  0.0031, -0.0121,  0.0263,\n",
       "                      -0.0370,  0.0293, -0.0969, -0.0644,  0.0960,  0.0631, -0.0479, -0.0874,\n",
       "                      -0.0535, -0.0844, -0.0102, -0.0981,  0.0875, -0.0100, -0.0304, -0.0111,\n",
       "                      -0.0472,  0.0663,  0.0619,  0.0124, -0.0527, -0.0742, -0.0587,  0.0551])),\n",
       "             ('transformations.5.dense1.weight',\n",
       "              tensor([[ 1.5402e-01, -8.0664e-03,  1.2693e-01,  ..., -6.3718e-02,\n",
       "                       -1.0289e-02,  2.1247e-02],\n",
       "                      [ 1.5599e-01, -7.8339e-02,  1.1734e-01,  ...,  1.2571e-02,\n",
       "                        1.1697e-01, -6.0343e-05],\n",
       "                      [-1.4269e-01, -3.8417e-02, -4.2474e-02,  ..., -1.7417e-01,\n",
       "                        7.1408e-02,  5.3252e-02],\n",
       "                      ...,\n",
       "                      [ 1.6927e-01, -3.4610e-02,  5.0681e-02,  ...,  1.7086e-02,\n",
       "                        9.1131e-02, -1.1927e-01],\n",
       "                      [ 1.4938e-01, -4.9646e-02, -1.2955e-01,  ..., -6.0779e-02,\n",
       "                       -6.4876e-02,  1.0835e-01],\n",
       "                      [ 1.0844e-01, -4.0129e-02, -1.4075e-01,  ..., -1.2508e-01,\n",
       "                       -7.1547e-02,  9.7936e-02]])),\n",
       "             ('transformations.5.bn1.weight',\n",
       "              tensor([0.9814, 1.0028, 0.9854, 0.9777, 1.0020, 0.9718, 0.9809, 1.0132, 1.0290,\n",
       "                      1.0147, 1.0006, 0.9866, 1.0139, 1.0002, 1.0256, 0.9835, 0.9930, 1.0006,\n",
       "                      0.9914, 0.9897, 1.0158, 0.9912, 0.9977, 0.9902, 1.0160, 0.9980, 1.0206,\n",
       "                      1.0141, 0.9868, 1.0121, 0.9732, 1.0274, 1.0196, 0.9900, 1.0108, 0.9907,\n",
       "                      1.0186, 0.9702, 1.0223, 1.0017, 1.0147, 1.0150, 1.0152, 1.0035, 0.9955,\n",
       "                      1.0126, 0.9971, 1.0003, 0.9977, 1.0279, 1.0091, 0.9905, 0.9927, 1.0082,\n",
       "                      1.0095, 0.9884, 0.9897, 0.9940, 0.9756, 1.0035, 0.9957, 1.0110, 1.0023,\n",
       "                      0.9983, 0.9806, 0.9762, 0.9992, 0.9890, 0.9930, 1.0192, 0.9709, 0.9860,\n",
       "                      0.9965, 1.0119, 1.0296, 1.0186, 1.0179, 1.0014, 0.9830, 0.9940, 0.9793,\n",
       "                      1.0027, 0.9861, 1.0012, 0.9989, 0.9966, 0.9760, 0.9893, 1.0243, 1.0228,\n",
       "                      0.9743, 1.0272, 0.9898, 1.0067, 1.0016, 1.0196, 0.9989, 0.9895, 0.9957,\n",
       "                      0.9876, 1.0271, 0.9845, 1.0034, 0.9913, 0.9755, 1.0134, 0.9880, 0.9905,\n",
       "                      0.9931, 1.0347, 0.9921, 0.9994, 1.0079, 1.0102, 1.0049, 1.0311, 1.0007,\n",
       "                      1.0310, 0.9844, 0.9995, 1.0033, 1.0055, 1.0010, 1.0237, 0.9955, 0.9982,\n",
       "                      1.0287, 1.0062])),\n",
       "             ('transformations.5.bn1.bias',\n",
       "              tensor([ 1.8207e-02,  4.9243e-02, -1.1314e-02, -1.1550e-02,  3.0119e-02,\n",
       "                       1.3040e-02, -2.9793e-02,  3.3970e-02,  3.9640e-02,  3.7919e-02,\n",
       "                       1.5824e-02,  8.0873e-03,  5.6900e-02,  1.1822e-02,  5.9709e-02,\n",
       "                       5.7729e-05,  4.1652e-02,  2.6156e-02,  2.2173e-03, -2.3884e-03,\n",
       "                       5.9203e-02, -2.5415e-03,  1.2183e-02, -2.7665e-02,  7.6746e-02,\n",
       "                      -2.4466e-02,  8.2347e-02,  7.4405e-02, -2.0310e-02,  6.8484e-02,\n",
       "                      -3.1441e-02,  7.2519e-02,  2.7438e-02,  4.1214e-03,  4.4811e-02,\n",
       "                      -1.1929e-02,  6.5972e-02, -6.0204e-02,  5.6278e-02,  3.2648e-02,\n",
       "                       4.9638e-02,  7.1197e-02,  4.1217e-02, -7.1856e-03,  5.1969e-02,\n",
       "                       9.3865e-02,  3.7757e-02, -2.4867e-02,  4.7153e-03,  5.2331e-02,\n",
       "                       3.0978e-02,  2.7466e-02,  3.5880e-02,  6.1207e-02,  4.3971e-02,\n",
       "                       1.3032e-02,  1.4381e-02,  4.4376e-02, -2.3169e-02,  3.8253e-02,\n",
       "                      -3.3310e-02,  4.0710e-02, -2.2022e-03, -3.6332e-03,  3.9732e-03,\n",
       "                      -2.8282e-02,  1.4046e-02, -2.1418e-02,  3.3570e-02,  7.1334e-02,\n",
       "                      -3.0635e-02,  2.2511e-03, -1.5461e-02,  6.0677e-02,  6.2795e-02,\n",
       "                       7.8020e-02,  4.0566e-02,  2.2684e-02, -1.6331e-02,  3.3503e-02,\n",
       "                      -2.7121e-02,  3.7136e-02, -3.3101e-02,  1.5513e-02, -2.1357e-03,\n",
       "                       1.0562e-02, -2.8551e-02,  3.5613e-02,  5.7758e-02,  7.4470e-02,\n",
       "                      -3.5301e-02,  5.7083e-02, -9.9479e-03,  1.6400e-02,  2.3326e-02,\n",
       "                       5.2019e-02,  2.6739e-02,  2.8584e-02, -6.4343e-05,  4.4348e-03,\n",
       "                       9.3171e-02, -1.5061e-02,  2.3920e-02,  3.0140e-02, -1.7915e-02,\n",
       "                       1.5936e-02, -1.2664e-02, -1.6322e-02,  2.6120e-02,  5.1904e-02,\n",
       "                       1.7587e-02,  5.0544e-02,  2.8278e-02,  5.4571e-02,  7.4878e-02,\n",
       "                       4.7026e-02, -1.3347e-03,  6.8115e-02, -1.0292e-02,  2.2831e-02,\n",
       "                       6.1686e-02, -1.9434e-03,  7.2371e-03,  8.8871e-02,  9.2509e-03,\n",
       "                       3.9401e-02,  1.1465e-01,  6.3844e-02])),\n",
       "             ('transformations.5.bn1.running_mean',\n",
       "              tensor([-0.0302, -0.0126, -0.0429,  0.0032, -0.0223,  0.0269, -0.0878,  0.0813,\n",
       "                       0.0184, -0.0363, -0.0263,  0.0802,  0.0235, -0.0440,  0.0139,  0.0790,\n",
       "                      -0.3061,  0.0120, -0.0503,  0.0567,  0.1606, -0.0788, -0.2060, -0.0437,\n",
       "                      -0.1920, -0.0135, -0.0669,  0.0034, -0.0284, -0.0675, -0.0036,  0.0343,\n",
       "                       0.0495,  0.0405, -0.0479, -0.0839,  0.0352,  0.0425,  0.1688, -0.3126,\n",
       "                      -0.0647, -0.0668,  0.1113, -0.0461,  0.1349,  0.0112, -0.1036, -0.1455,\n",
       "                      -0.1729,  0.1452,  0.1185,  0.0533, -0.1686,  0.0261, -0.0070,  0.0114,\n",
       "                      -0.1428, -0.0295, -0.1418,  0.1134, -0.0981,  0.1147,  0.2155, -0.0331,\n",
       "                      -0.1110,  0.1491, -0.0957, -0.1297,  0.1028,  0.2318,  0.0524, -0.1046,\n",
       "                      -0.2154, -0.0327, -0.0139,  0.0906, -0.2981, -0.2088, -0.0346, -0.0603,\n",
       "                       0.0662,  0.1446, -0.0393, -0.1548,  0.0645, -0.1837, -0.0672, -0.0377,\n",
       "                       0.0287, -0.1005, -0.1250,  0.1000,  0.0446,  0.0031,  0.0786, -0.0131,\n",
       "                       0.0354,  0.0837,  0.2319, -0.0806,  0.0959, -0.1929, -0.0375,  0.0733,\n",
       "                      -0.0008, -0.0562, -0.0044,  0.0609,  0.0183,  0.0885, -0.0285, -0.0475,\n",
       "                       0.0844,  0.2467, -0.0831, -0.0936, -0.0441,  0.0678, -0.0827,  0.0539,\n",
       "                       0.0612, -0.1848, -0.1749,  0.1240, -0.1669,  0.1404, -0.0064, -0.1674])),\n",
       "             ('transformations.5.bn1.running_var',\n",
       "              tensor([0.1214, 0.1014, 0.1243, 0.1086, 0.1189, 0.1069, 0.4109, 0.1694, 0.1625,\n",
       "                      0.1800, 0.1637, 0.1646, 0.2608, 0.2369, 0.1417, 0.1175, 0.3820, 0.1167,\n",
       "                      0.1630, 0.1578, 0.4589, 0.1407, 0.7194, 0.3257, 0.2656, 0.1878, 0.1168,\n",
       "                      0.0982, 0.1446, 0.2543, 0.3940, 0.1912, 0.1189, 0.1368, 0.1468, 0.1404,\n",
       "                      0.1417, 0.1370, 0.3006, 0.3806, 0.1353, 0.1795, 0.1801, 0.1863, 0.2677,\n",
       "                      0.1380, 0.2705, 0.2301, 0.2826, 0.2117, 0.2118, 0.1766, 0.4223, 0.1272,\n",
       "                      0.1712, 0.1638, 0.1881, 0.1504, 0.1820, 0.1179, 0.1898, 0.1676, 0.2365,\n",
       "                      0.1428, 0.1123, 0.5333, 0.1883, 0.2297, 0.3004, 0.6486, 0.2177, 0.1345,\n",
       "                      0.3919, 0.1790, 0.1327, 0.7131, 0.4211, 0.1431, 0.1722, 0.1357, 0.0831,\n",
       "                      0.3802, 0.1686, 0.3943, 0.1525, 0.4719, 0.1300, 0.1301, 0.1840, 0.1735,\n",
       "                      0.1932, 0.2203, 0.1788, 0.1300, 0.1370, 0.2354, 0.1481, 0.0722, 0.1917,\n",
       "                      0.1936, 0.1771, 0.2633, 0.0856, 0.1405, 0.1251, 0.2756, 0.1237, 0.1530,\n",
       "                      0.1157, 0.1741, 0.1371, 0.1331, 0.1395, 0.4351, 0.1742, 0.1975, 0.2811,\n",
       "                      0.1571, 0.1205, 0.3113, 0.1607, 0.4993, 0.1306, 0.3471, 0.2692, 0.1695,\n",
       "                      0.1490, 0.1105])),\n",
       "             ('transformations.5.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.5.mu.weight',\n",
       "              tensor([[ 0.0850,  0.0822,  0.0592,  ...,  0.0448, -0.0273, -0.0445],\n",
       "                      [-0.0530, -0.0480,  0.0779,  ..., -0.0272,  0.0518, -0.0379],\n",
       "                      [-0.0168, -0.0010, -0.0406,  ...,  0.0496, -0.0780,  0.0720],\n",
       "                      ...,\n",
       "                      [-0.0600,  0.0622, -0.0916,  ...,  0.0309, -0.0022, -0.0250],\n",
       "                      [-0.0363,  0.0484,  0.0313,  ...,  0.0447,  0.0176,  0.0540],\n",
       "                      [-0.0289, -0.0429, -0.0079,  ..., -0.0349,  0.0800,  0.0518]])),\n",
       "             ('transformations.5.mu.bias',\n",
       "              tensor([-0.0281, -0.0273, -0.0820,  0.0439, -0.0250, -0.0813,  0.0115,  0.0309,\n",
       "                       0.1639, -0.1451, -0.0977, -0.0321,  0.0819,  0.0658, -0.0323, -0.0358,\n",
       "                       0.0678, -0.0658, -0.0307,  0.0755,  0.0015, -0.1433, -0.0956, -0.1086,\n",
       "                      -0.0984, -0.0404,  0.0873,  0.0561, -0.0154, -0.0545, -0.0634,  0.0431])),\n",
       "             ('transformations.5.sigma.weight',\n",
       "              tensor([[ 0.0207, -0.0090, -0.0091,  ..., -0.0422, -0.0804,  0.0821],\n",
       "                      [ 0.0352, -0.0516,  0.0130,  ..., -0.0017,  0.0059,  0.0706],\n",
       "                      [ 0.0318, -0.0721,  0.0664,  ...,  0.0681, -0.0116,  0.0777],\n",
       "                      ...,\n",
       "                      [ 0.0207, -0.1079,  0.0193,  ..., -0.0350, -0.0839,  0.0353],\n",
       "                      [ 0.0112,  0.0447, -0.0379,  ...,  0.0290,  0.0314, -0.0900],\n",
       "                      [ 0.0287,  0.0086,  0.0494,  ..., -0.0056, -0.0003,  0.0161]])),\n",
       "             ('transformations.5.sigma.bias',\n",
       "              tensor([-0.0234,  0.0163, -0.0262,  0.0403,  0.0549, -0.0424,  0.0064, -0.0800,\n",
       "                      -0.0628, -0.0489,  0.0923,  0.0307,  0.0995,  0.0681,  0.0854,  0.0061,\n",
       "                       0.0737,  0.0306, -0.0236, -0.0284, -0.0299, -0.0714,  0.0062, -0.0115,\n",
       "                       0.0119, -0.0002, -0.1305,  0.0508, -0.0083, -0.0395,  0.0463,  0.0702])),\n",
       "             ('transformations.6.dense1.weight',\n",
       "              tensor([[-0.0998,  0.0113,  0.1517,  ..., -0.1505,  0.0976,  0.1553],\n",
       "                      [-0.0689, -0.1611, -0.0385,  ..., -0.0946, -0.1461, -0.0794],\n",
       "                      [-0.0486,  0.1583,  0.0316,  ...,  0.0586,  0.1170,  0.1327],\n",
       "                      ...,\n",
       "                      [ 0.0998, -0.1497,  0.0075,  ...,  0.0993,  0.0079, -0.0865],\n",
       "                      [ 0.0873,  0.0437,  0.1746,  ..., -0.1138, -0.0285, -0.1410],\n",
       "                      [ 0.1109, -0.1633, -0.0909,  ...,  0.1161,  0.0612,  0.0884]])),\n",
       "             ('transformations.6.bn1.weight',\n",
       "              tensor([0.9909, 0.9995, 0.9945, 0.9868, 1.0042, 0.9968, 0.9850, 1.0030, 0.9813,\n",
       "                      0.9979, 0.9780, 0.9813, 0.9746, 0.9982, 1.0005, 1.0034, 0.9908, 1.0095,\n",
       "                      0.9965, 0.9963, 0.9897, 0.9943, 0.9895, 0.9952, 0.9811, 1.0040, 0.9919,\n",
       "                      1.0120, 0.9934, 0.9869, 0.9946, 0.9994, 0.9879, 0.9930, 1.0073, 0.9991,\n",
       "                      1.0037, 0.9865, 0.9935, 0.9904, 1.0008, 0.9857, 0.9805, 0.9889, 0.9859,\n",
       "                      0.9802, 1.0051, 0.9978, 0.9952, 0.9705, 1.0054, 1.0054, 1.0053, 0.9848,\n",
       "                      0.9930, 0.9861, 0.9972, 0.9754, 0.9845, 0.9846, 1.0026, 0.9974, 0.9961,\n",
       "                      0.9843, 1.0057, 1.0010, 0.9807, 0.9917, 0.9971, 0.9928, 0.9903, 0.9982,\n",
       "                      0.9891, 0.9834, 1.0025, 0.9807, 0.9905, 0.9901, 0.9944, 0.9824, 0.9966,\n",
       "                      0.9919, 0.9836, 0.9856, 0.9839, 0.9706, 0.9991, 1.0033, 0.9972, 0.9988,\n",
       "                      1.0089, 0.9990, 0.9907, 0.9774, 0.9936, 0.9989, 0.9839, 0.9991, 0.9881,\n",
       "                      0.9885, 0.9877, 0.9769, 1.0019, 1.0073, 0.9877, 1.0021, 0.9852, 0.9960,\n",
       "                      0.9918, 0.9958, 0.9869, 1.0082, 1.0116, 0.9826, 0.9817, 0.9910, 0.9964,\n",
       "                      0.9978, 0.9878, 1.0015, 0.9830, 0.9947, 0.9829, 0.9772, 0.9930, 0.9986,\n",
       "                      1.0116, 0.9887])),\n",
       "             ('transformations.6.bn1.bias',\n",
       "              tensor([-1.0071e-03, -1.1836e-02, -1.0340e-02, -1.5178e-02,  1.6178e-02,\n",
       "                       7.7960e-04,  3.2622e-03,  7.5360e-03, -1.4018e-02,  4.0169e-03,\n",
       "                      -7.2846e-03, -4.2838e-03, -9.4021e-03, -1.2031e-03,  1.4500e-03,\n",
       "                       1.2572e-02, -1.5592e-03,  1.0854e-02,  3.3852e-03, -1.8413e-03,\n",
       "                      -7.7744e-03,  9.2565e-04, -1.6228e-02, -8.9611e-03, -8.6480e-03,\n",
       "                       1.4480e-02,  8.6582e-03,  1.6497e-02, -2.0209e-02, -6.9474e-03,\n",
       "                      -1.5262e-02, -1.3058e-02,  5.6815e-04, -5.8185e-04, -7.3423e-03,\n",
       "                      -1.2395e-03,  3.1473e-03, -4.3548e-03,  4.7313e-03, -7.7130e-03,\n",
       "                       3.6899e-03, -9.8401e-03, -1.3189e-02,  8.0823e-03, -9.8859e-03,\n",
       "                      -2.0391e-02, -4.1096e-04,  6.3280e-03,  2.5794e-03, -1.8689e-02,\n",
       "                       7.3767e-04,  4.7904e-03,  1.2852e-02, -4.6851e-03, -6.1675e-03,\n",
       "                      -1.2659e-02,  1.2137e-02, -1.7756e-02, -2.2028e-02, -1.4189e-02,\n",
       "                       1.4662e-02, -6.1703e-03, -4.0162e-03, -2.4222e-02,  9.6329e-03,\n",
       "                      -2.9898e-03, -1.7001e-02, -1.1755e-02, -2.6399e-03, -1.7936e-03,\n",
       "                       2.6464e-03,  8.4784e-03, -8.3719e-03, -1.7535e-02, -7.0889e-03,\n",
       "                       2.9856e-03, -5.2227e-03, -1.3253e-02, -6.1667e-03, -4.6272e-03,\n",
       "                      -2.6426e-03,  2.4304e-03,  5.4172e-03, -2.3007e-02, -2.3918e-02,\n",
       "                      -1.3141e-02, -5.5783e-03,  1.2593e-02, -2.1321e-03,  1.0733e-02,\n",
       "                       8.7117e-03,  1.3241e-02, -1.0857e-02, -5.5005e-03, -5.8488e-03,\n",
       "                      -1.1054e-03, -1.8369e-02, -3.6761e-03, -7.5046e-03, -4.2663e-03,\n",
       "                      -3.4693e-03, -5.3519e-03, -1.3393e-02,  6.2938e-03, -7.8864e-03,\n",
       "                       2.5944e-03, -3.1091e-02, -9.6907e-03, -2.2725e-03, -8.9017e-03,\n",
       "                      -7.1026e-03,  8.8960e-03,  8.9665e-03, -4.3415e-03, -1.5703e-02,\n",
       "                       2.9062e-03,  1.0845e-02,  2.1378e-03,  5.8014e-03, -8.4695e-05,\n",
       "                      -2.0317e-02, -1.7315e-02, -1.5095e-02, -1.3954e-02,  1.3115e-02,\n",
       "                       4.8376e-03,  6.0128e-03, -1.2451e-02])),\n",
       "             ('transformations.6.bn1.running_mean',\n",
       "              tensor([-0.0305,  0.2004,  0.1937, -0.0741,  0.1561, -0.0581, -0.1801,  0.0455,\n",
       "                       0.0302, -0.0249, -0.2600,  0.1642, -0.0584,  0.0990, -0.0857,  0.2460,\n",
       "                       0.0211,  0.0480, -0.1485, -0.0589, -0.0491, -0.1908,  0.1018, -0.1431,\n",
       "                       0.0534, -0.0870, -0.1142,  0.1967,  0.2342, -0.0525,  0.1153,  0.0617,\n",
       "                      -0.1074,  0.1548, -0.0387,  0.0333,  0.0697, -0.0660,  0.0860,  0.0231,\n",
       "                      -0.1197, -0.0303, -0.1727, -0.0559,  0.0331, -0.1815, -0.0750,  0.1965,\n",
       "                       0.0521, -0.0160, -0.2270,  0.0348,  0.2783,  0.1077,  0.0219,  0.1511,\n",
       "                       0.1186,  0.0637,  0.2030,  0.0582,  0.0421,  0.0723, -0.0024,  0.0101,\n",
       "                       0.1950,  0.1336, -0.0384, -0.0654, -0.1752,  0.1569,  0.0376,  0.0275,\n",
       "                       0.0907, -0.0435, -0.0240, -0.0032, -0.0542, -0.1680,  0.0348,  0.0997,\n",
       "                       0.1252, -0.0964, -0.1194,  0.1037, -0.1155,  0.0082,  0.2209,  0.0849,\n",
       "                      -0.2282,  0.1971, -0.3149,  0.1554, -0.0758,  0.1634, -0.0173,  0.0737,\n",
       "                      -0.0441,  0.0658, -0.1422, -0.1058, -0.2195,  0.0297, -0.0754, -0.1118,\n",
       "                      -0.0322,  0.2268, -0.1034, -0.0230, -0.0705, -0.1599,  0.0013,  0.0502,\n",
       "                      -0.2328, -0.0537,  0.1255, -0.0913, -0.0657, -0.2544,  0.0924, -0.0216,\n",
       "                      -0.0681, -0.0409,  0.0055,  0.0705,  0.1143,  0.0117,  0.0326,  0.0449])),\n",
       "             ('transformations.6.bn1.running_var',\n",
       "              tensor([0.1445, 0.2751, 0.3249, 0.2265, 0.1266, 0.2289, 0.7655, 0.0975, 0.1805,\n",
       "                      0.2399, 0.5677, 0.1600, 0.1468, 0.1352, 0.1227, 0.5211, 0.1040, 0.1419,\n",
       "                      0.2026, 0.1383, 0.1117, 0.1832, 0.1754, 0.1459, 0.1178, 0.4423, 0.2815,\n",
       "                      0.4519, 0.6025, 0.1315, 0.1212, 0.1221, 0.2732, 0.3047, 0.2124, 0.1434,\n",
       "                      0.2562, 0.1592, 0.2715, 0.1388, 0.1318, 0.1337, 0.3797, 0.2779, 0.2129,\n",
       "                      0.3763, 0.1709, 0.2473, 0.1560, 0.1868, 0.6780, 0.1301, 0.3574, 0.1804,\n",
       "                      0.2350, 0.1374, 0.2511, 0.1173, 0.2142, 0.1525, 0.1339, 0.2311, 0.1480,\n",
       "                      0.1891, 0.5407, 0.1905, 0.1165, 0.1200, 0.4616, 0.1743, 0.1786, 0.1500,\n",
       "                      0.0951, 0.1598, 0.4776, 0.1102, 0.1290, 0.3989, 0.1597, 0.1544, 0.6730,\n",
       "                      0.2049, 0.3056, 0.1239, 0.1927, 0.2069, 0.3632, 0.1231, 0.3031, 0.1478,\n",
       "                      1.0688, 0.3660, 0.1500, 0.1518, 0.1554, 0.4611, 0.1331, 0.1154, 0.6607,\n",
       "                      0.2623, 0.6496, 0.1107, 0.3048, 0.1391, 0.1652, 0.2837, 0.1202, 0.1935,\n",
       "                      0.3903, 0.7079, 0.1203, 0.1172, 0.3923, 0.2273, 0.1280, 0.2541, 0.1196,\n",
       "                      0.3830, 0.1662, 0.1290, 0.1817, 0.0990, 0.1639, 0.1203, 0.1473, 0.1173,\n",
       "                      0.1843, 0.1327])),\n",
       "             ('transformations.6.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('transformations.6.mu.weight',\n",
       "              tensor([[-0.0536,  0.0729, -0.0758,  ...,  0.0600, -0.0881, -0.0179],\n",
       "                      [-0.0687, -0.0229, -0.0325,  ...,  0.0810, -0.0210,  0.0341],\n",
       "                      [ 0.0506, -0.0657, -0.0391,  ...,  0.0603,  0.0564,  0.0038],\n",
       "                      ...,\n",
       "                      [ 0.0660, -0.0625,  0.0770,  ...,  0.0337, -0.0256, -0.0742],\n",
       "                      [ 0.0338, -0.0375, -0.0799,  ..., -0.0281,  0.0290,  0.0063],\n",
       "                      [ 0.0709, -0.0207,  0.0218,  ..., -0.0178, -0.0513,  0.0696]])),\n",
       "             ('transformations.6.mu.bias',\n",
       "              tensor([-0.0501, -0.0134,  0.1142,  0.0222, -0.0504,  0.0657,  0.0859, -0.0105,\n",
       "                      -0.0435,  0.0643, -0.0272, -0.0113,  0.0808, -0.0747, -0.0226,  0.0717,\n",
       "                       0.0802,  0.0292,  0.0350, -0.0390,  0.0107,  0.0367,  0.0418,  0.0701,\n",
       "                       0.1264,  0.0752, -0.0214,  0.0139, -0.0395, -0.0598, -0.0582,  0.0403])),\n",
       "             ('transformations.6.sigma.weight',\n",
       "              tensor([[ 0.0095, -0.0200,  0.0597,  ..., -0.0416, -0.0927,  0.0326],\n",
       "                      [ 0.0070, -0.0246, -0.0691,  ..., -0.0850,  0.0366,  0.0546],\n",
       "                      [-0.0974,  0.0273, -0.0856,  ...,  0.0365, -0.0554,  0.0568],\n",
       "                      ...,\n",
       "                      [-0.0480,  0.0232,  0.0374,  ..., -0.0369,  0.0724, -0.0651],\n",
       "                      [-0.0185, -0.0029,  0.0010,  ..., -0.1016,  0.0640, -0.0343],\n",
       "                      [-0.0990, -0.0913, -0.0794,  ..., -0.0876, -0.0830,  0.0470]])),\n",
       "             ('transformations.6.sigma.bias',\n",
       "              tensor([-8.9339e-03, -7.7778e-03, -3.3792e-02, -1.2869e-02, -7.9617e-02,\n",
       "                      -1.1033e-01, -8.9232e-02, -5.9588e-02, -4.8195e-02, -9.5087e-02,\n",
       "                      -4.6733e-02, -1.0233e-01,  1.9539e-02, -3.6468e-02,  6.0524e-02,\n",
       "                      -4.1575e-02,  6.5597e-02,  6.3320e-02,  9.0028e-02, -4.5027e-03,\n",
       "                      -7.1344e-02, -1.5704e-02, -2.6411e-02, -8.0468e-02, -1.1362e-01,\n",
       "                      -7.0853e-02,  2.2011e-02, -6.4899e-02,  3.1559e-02, -7.3791e-02,\n",
       "                      -8.7652e-06, -5.6320e-03])),\n",
       "             ('denses.0.mu.weight',\n",
       "              tensor([[ 0.0930, -0.0721, -0.0505,  ..., -0.0331, -0.0706,  0.0485],\n",
       "                      [-0.0434, -0.0400,  0.0234,  ...,  0.0418,  0.0199, -0.0053],\n",
       "                      [ 0.0446, -0.0371,  0.0837,  ...,  0.0583, -0.0635, -0.0880],\n",
       "                      ...,\n",
       "                      [ 0.0401, -0.0371,  0.0163,  ...,  0.0305, -0.0559,  0.0076],\n",
       "                      [ 0.0616,  0.0571, -0.0115,  ...,  0.0216,  0.0265,  0.0594],\n",
       "                      [ 0.0913, -0.0432,  0.0832,  ..., -0.0469,  0.0152, -0.0298]])),\n",
       "             ('denses.0.mu.bias',\n",
       "              tensor([ 0.1892,  0.0571,  0.1990, -0.2563, -0.3020, -0.2147,  0.0908, -0.0006,\n",
       "                       0.2687,  0.2574, -0.1269,  0.1036,  0.0103,  0.3247, -0.1168,  0.2417,\n",
       "                      -0.3073, -0.2821,  0.1468, -0.0546,  0.1632,  0.1581,  0.2909, -0.2783,\n",
       "                      -0.3614, -0.1598,  0.0674, -0.2322, -0.0849,  0.2679, -0.0688, -0.0438])),\n",
       "             ('denses.0.sigma.weight',\n",
       "              tensor([[ 0.0120,  0.0146, -0.0432,  ...,  0.0197,  0.0863,  0.0587],\n",
       "                      [ 0.0184,  0.0024, -0.0163,  ..., -0.0380,  0.0165, -0.0041],\n",
       "                      [-0.0111,  0.0130,  0.0401,  ...,  0.0925, -0.0231,  0.0817],\n",
       "                      ...,\n",
       "                      [ 0.0925,  0.0247,  0.0664,  ...,  0.0049,  0.0085, -0.0332],\n",
       "                      [-0.0496, -0.0362,  0.0951,  ...,  0.0487, -0.0245, -0.0609],\n",
       "                      [ 0.0064, -0.0191,  0.0556,  ..., -0.0511, -0.0279,  0.0108]])),\n",
       "             ('denses.0.sigma.bias',\n",
       "              tensor([ 0.0410,  0.0420,  0.0019,  0.1121,  0.0482, -0.0157, -0.0291,  0.0185,\n",
       "                      -0.0599,  0.0925, -0.0177,  0.0110,  0.0336,  0.0600,  0.0312,  0.0926,\n",
       "                      -0.0335, -0.0060, -0.0340, -0.0453,  0.0454, -0.0031, -0.0421,  0.0303,\n",
       "                       0.0470,  0.0282, -0.0250,  0.0802,  0.0403,  0.0537, -0.0640,  0.0166])),\n",
       "             ('denses.1.mu.weight',\n",
       "              tensor([[-0.0116, -0.0541, -0.0444,  ..., -0.0430,  0.0156, -0.0360],\n",
       "                      [ 0.0636, -0.0788, -0.0251,  ..., -0.0745, -0.0028,  0.0430],\n",
       "                      [-0.0415, -0.0320, -0.0679,  ..., -0.0402,  0.0146,  0.0652],\n",
       "                      ...,\n",
       "                      [-0.0319, -0.0082, -0.0624,  ..., -0.0061,  0.0162, -0.0549],\n",
       "                      [-0.0022, -0.0301, -0.0541,  ..., -0.0628,  0.0771,  0.0613],\n",
       "                      [ 0.0344, -0.0615,  0.0691,  ..., -0.0081, -0.0720, -0.0677]])),\n",
       "             ('denses.1.mu.bias',\n",
       "              tensor([ 0.1077, -0.0600,  0.0495,  0.1371, -0.0157, -0.0916, -0.0493, -0.0135,\n",
       "                      -0.0351, -0.0958,  0.0516, -0.0867,  0.0530, -0.0442,  0.0882, -0.0257,\n",
       "                      -0.1168,  0.0532,  0.0081, -0.0933,  0.0871, -0.0233, -0.0251, -0.0077,\n",
       "                      -0.1114,  0.1090,  0.0365,  0.0580,  0.1529,  0.0563, -0.0421,  0.0817])),\n",
       "             ('denses.1.sigma.weight',\n",
       "              tensor([[-0.0286,  0.0859, -0.1104,  ...,  0.0407, -0.0322,  0.0867],\n",
       "                      [-0.0776, -0.0466, -0.0971,  ..., -0.0335,  0.0351,  0.0448],\n",
       "                      [-0.0435,  0.0865,  0.0647,  ...,  0.0157, -0.0655,  0.0556],\n",
       "                      ...,\n",
       "                      [ 0.0189,  0.0803,  0.0639,  ...,  0.0213,  0.0626, -0.0058],\n",
       "                      [ 0.0496,  0.0891,  0.0922,  ...,  0.0223, -0.0246, -0.0405],\n",
       "                      [ 0.0265, -0.0243,  0.0344,  ..., -0.0485,  0.0638, -0.0239]])),\n",
       "             ('denses.1.sigma.bias',\n",
       "              tensor([ 0.0518,  0.0039,  0.1010,  0.1043,  0.0731,  0.0655, -0.0145,  0.0780,\n",
       "                       0.0640,  0.0486,  0.0479, -0.0099, -0.0406, -0.0843,  0.0131,  0.0254,\n",
       "                       0.0507, -0.0591,  0.1047, -0.0696,  0.0076, -0.0439, -0.0144,  0.0117,\n",
       "                      -0.0261,  0.0556, -0.0400,  0.0278, -0.0193,  0.0616,  0.0200, -0.0158])),\n",
       "             ('denses.2.mu.weight',\n",
       "              tensor([[-0.0344,  0.0703, -0.0199,  ..., -0.0376, -0.0366, -0.0113],\n",
       "                      [-0.0361, -0.0597,  0.0776,  ..., -0.0164,  0.0840, -0.0225],\n",
       "                      [-0.0124,  0.0070,  0.0534,  ..., -0.0522,  0.0490, -0.0524],\n",
       "                      ...,\n",
       "                      [ 0.0110,  0.0023, -0.0674,  ...,  0.0223, -0.0050,  0.0400],\n",
       "                      [ 0.0926, -0.0717, -0.0737,  ..., -0.0747,  0.0684,  0.0166],\n",
       "                      [-0.0345, -0.0354, -0.0754,  ..., -0.0621, -0.0007,  0.0007]])),\n",
       "             ('denses.2.mu.bias',\n",
       "              tensor([ 0.1429, -0.0813, -0.0089, -0.1500, -0.0435,  0.0273,  0.0126,  0.0637,\n",
       "                      -0.0732,  0.0064,  0.0428, -0.0165,  0.0398,  0.0185,  0.0449,  0.0867,\n",
       "                      -0.0352, -0.1274, -0.0428,  0.1574,  0.0522, -0.0386,  0.0582, -0.0634,\n",
       "                       0.1087,  0.1224,  0.0168,  0.0410,  0.0716,  0.0674, -0.0311,  0.0627])),\n",
       "             ('denses.2.sigma.weight',\n",
       "              tensor([[ 0.0677,  0.0339,  0.0637,  ...,  0.0815, -0.0522,  0.0319],\n",
       "                      [ 0.0622, -0.0361,  0.1204,  ..., -0.0342,  0.0941, -0.0961],\n",
       "                      [-0.0105, -0.0749,  0.0370,  ...,  0.0382, -0.0049, -0.0452],\n",
       "                      ...,\n",
       "                      [-0.0673,  0.0202,  0.1176,  ..., -0.0353,  0.0882, -0.0653],\n",
       "                      [-0.0302, -0.0163,  0.0612,  ..., -0.0406,  0.0287,  0.0087],\n",
       "                      [ 0.0369,  0.0134,  0.0982,  ..., -0.0192,  0.0475,  0.0237]])),\n",
       "             ('denses.2.sigma.bias',\n",
       "              tensor([ 0.0695,  0.0229,  0.0145,  0.0103, -0.0420, -0.0925, -0.0341, -0.0594,\n",
       "                      -0.0005,  0.0119,  0.0655, -0.0564, -0.0944,  0.0899,  0.0060,  0.0356,\n",
       "                      -0.0635, -0.0764, -0.0115,  0.0917,  0.0188,  0.1162, -0.0661,  0.0481,\n",
       "                      -0.0919,  0.0077,  0.1118,  0.0841, -0.0331,  0.0204,  0.1025, -0.0116])),\n",
       "             ('denses.3.mu.weight',\n",
       "              tensor([[ 0.0187, -0.0448, -0.0598,  ..., -0.0715, -0.0822,  0.0099],\n",
       "                      [-0.0409, -0.0227, -0.0914,  ..., -0.0261,  0.0712, -0.0900],\n",
       "                      [ 0.0129,  0.0155,  0.0523,  ..., -0.0198, -0.0132,  0.0473],\n",
       "                      ...,\n",
       "                      [-0.0020, -0.0396,  0.0460,  ..., -0.0573,  0.0263,  0.0383],\n",
       "                      [ 0.0133, -0.0563,  0.0516,  ...,  0.0533,  0.0827,  0.0558],\n",
       "                      [-0.0110, -0.0514,  0.0229,  ..., -0.0489, -0.0650, -0.0499]])),\n",
       "             ('denses.3.mu.bias',\n",
       "              tensor([-0.1085, -0.0565, -0.0268,  0.1371, -0.0941,  0.0593,  0.0119,  0.0541,\n",
       "                       0.0841,  0.0096, -0.0054, -0.1672,  0.0662, -0.1061, -0.0680, -0.0454,\n",
       "                      -0.0043, -0.0437,  0.0470, -0.1380,  0.0084,  0.0378,  0.0161,  0.0251,\n",
       "                       0.0822,  0.0505, -0.0634,  0.0885, -0.0474, -0.0210,  0.0145,  0.0209])),\n",
       "             ('denses.3.sigma.weight',\n",
       "              tensor([[ 0.0269,  0.0783, -0.0274,  ..., -0.0503, -0.0536,  0.0564],\n",
       "                      [-0.0835, -0.0800, -0.0300,  ...,  0.0762,  0.0252, -0.0600],\n",
       "                      [ 0.0516, -0.1159,  0.0640,  ..., -0.0232, -0.0417,  0.0040],\n",
       "                      ...,\n",
       "                      [ 0.0569,  0.0092,  0.0311,  ...,  0.0547,  0.0051,  0.0710],\n",
       "                      [-0.1063, -0.1415, -0.0476,  ..., -0.0347, -0.0689,  0.0757],\n",
       "                      [-0.1065,  0.0546, -0.0519,  ...,  0.0251,  0.0402,  0.0859]])),\n",
       "             ('denses.3.sigma.bias',\n",
       "              tensor([-0.0663,  0.0003,  0.0708, -0.0124,  0.0245,  0.0662, -0.0585, -0.0023,\n",
       "                       0.0253, -0.0832,  0.0028,  0.0346,  0.0063,  0.0370,  0.0004, -0.0053,\n",
       "                       0.0083,  0.0348,  0.0516,  0.0613,  0.0370, -0.0348,  0.0345, -0.0107,\n",
       "                       0.0345, -0.0550, -0.0664, -0.0964, -0.0511,  0.0447,  0.0071, -0.0797])),\n",
       "             ('denses.4.mu.weight',\n",
       "              tensor([[ 0.0962,  0.0034, -0.0091,  ..., -0.0325, -0.0490, -0.0049],\n",
       "                      [-0.0063, -0.0621, -0.0858,  ..., -0.0577, -0.0873, -0.0658],\n",
       "                      [-0.0027,  0.0319, -0.0412,  ..., -0.0485,  0.0500, -0.0074],\n",
       "                      ...,\n",
       "                      [-0.0403,  0.0209, -0.0154,  ..., -0.0528, -0.0052,  0.0428],\n",
       "                      [ 0.0212, -0.0133,  0.0529,  ...,  0.0714, -0.0183,  0.0963],\n",
       "                      [ 0.0088,  0.0746,  0.0209,  ..., -0.0739, -0.0528, -0.0587]])),\n",
       "             ('denses.4.mu.bias',\n",
       "              tensor([ 0.0643, -0.0886,  0.0535,  0.0494,  0.0470,  0.0126,  0.0424,  0.0285,\n",
       "                      -0.0300, -0.0645, -0.0935, -0.0369, -0.0435,  0.0318,  0.0129, -0.0327,\n",
       "                      -0.0356,  0.0723, -0.0018, -0.0661, -0.0785,  0.0213,  0.0952, -0.0158,\n",
       "                       0.0111,  0.0476, -0.0131, -0.0710,  0.0219, -0.0397,  0.0214,  0.0472])),\n",
       "             ('denses.4.sigma.weight',\n",
       "              tensor([[-0.0097,  0.0110,  0.0282,  ..., -0.0016, -0.0402,  0.0718],\n",
       "                      [-0.0601, -0.0269, -0.0206,  ...,  0.0105,  0.0132, -0.0386],\n",
       "                      [ 0.0922,  0.0221, -0.0142,  ..., -0.0652,  0.0144, -0.0641],\n",
       "                      ...,\n",
       "                      [ 0.0663,  0.0132,  0.0060,  ..., -0.0094,  0.0747, -0.0440],\n",
       "                      [-0.0647,  0.0231,  0.0834,  ...,  0.0337,  0.0583,  0.0662],\n",
       "                      [ 0.0160, -0.0356, -0.0347,  ...,  0.0787, -0.0282, -0.0502]])),\n",
       "             ('denses.4.sigma.bias',\n",
       "              tensor([-0.0363, -0.0035,  0.0565,  0.0646, -0.0679, -0.0617,  0.0572,  0.0062,\n",
       "                      -0.0231,  0.1008,  0.0248,  0.0625,  0.0140, -0.0414, -0.0556,  0.0562,\n",
       "                      -0.0514, -0.0561, -0.0343, -0.0912, -0.0323,  0.0442, -0.0355,  0.0225,\n",
       "                      -0.0259,  0.0485, -0.0111, -0.0755,  0.0560, -0.0216, -0.0293, -0.0395])),\n",
       "             ('denses.5.mu.weight',\n",
       "              tensor([[-0.0772,  0.0639,  0.0492,  ...,  0.0258, -0.0060, -0.0401],\n",
       "                      [-0.0655, -0.0346, -0.0028,  ...,  0.0164,  0.0745, -0.0048],\n",
       "                      [ 0.0536, -0.0029, -0.0690,  ...,  0.0714, -0.0399, -0.0497],\n",
       "                      ...,\n",
       "                      [-0.0437, -0.0433,  0.0327,  ..., -0.0213,  0.0595,  0.0410],\n",
       "                      [-0.0205,  0.0807,  0.0054,  ...,  0.0253, -0.0448,  0.0139],\n",
       "                      [ 0.0979, -0.0298, -0.0238,  ..., -0.0894, -0.0148,  0.0251]])),\n",
       "             ('denses.5.mu.bias',\n",
       "              tensor([-0.0588, -0.0260,  0.1692, -0.0767,  0.1603,  0.1458,  0.0939, -0.0240,\n",
       "                      -0.0414,  0.0172, -0.0222, -0.0925, -0.0755, -0.0545, -0.0433,  0.0123,\n",
       "                       0.0009,  0.0923,  0.1097,  0.0842,  0.0566,  0.1308,  0.0519, -0.0006,\n",
       "                       0.0681,  0.1017, -0.0842,  0.0654,  0.0114, -0.0167,  0.0903,  0.1136])),\n",
       "             ('denses.5.sigma.weight',\n",
       "              tensor([[ 0.0163, -0.0266,  0.0819,  ..., -0.0605, -0.0174,  0.0126],\n",
       "                      [ 0.0094,  0.0142, -0.0723,  ..., -0.0187, -0.0686, -0.0465],\n",
       "                      [ 0.0204,  0.0092,  0.0436,  ..., -0.0573,  0.0164, -0.0460],\n",
       "                      ...,\n",
       "                      [ 0.0727,  0.0042, -0.0458,  ...,  0.0917,  0.0770,  0.0609],\n",
       "                      [-0.0091,  0.0135,  0.0267,  ..., -0.0092,  0.0541, -0.0641],\n",
       "                      [ 0.0277, -0.0707,  0.0213,  ..., -0.0307,  0.0313,  0.0130]])),\n",
       "             ('denses.5.sigma.bias',\n",
       "              tensor([-0.0665,  0.0414,  0.0831,  0.0401,  0.0413,  0.0597, -0.0398, -0.0535,\n",
       "                       0.0107,  0.0659, -0.0150, -0.0354, -0.0898,  0.0773, -0.0189, -0.0182,\n",
       "                      -0.0566,  0.0454,  0.0316, -0.0750, -0.0121,  0.0462, -0.0673,  0.0364,\n",
       "                       0.0413, -0.0588,  0.0154, -0.0723, -0.0844, -0.0123,  0.0916,  0.0708])),\n",
       "             ('denses.6.mu.weight',\n",
       "              tensor([[ 0.0273,  0.0063, -0.0633,  ...,  0.0241, -0.0142, -0.0710],\n",
       "                      [-0.0884,  0.0599, -0.0687,  ..., -0.0525, -0.0623,  0.0473],\n",
       "                      [-0.0003, -0.0260,  0.0357,  ...,  0.0291, -0.0465, -0.0476],\n",
       "                      ...,\n",
       "                      [-0.0080, -0.0113, -0.0240,  ...,  0.0548,  0.0550,  0.0939],\n",
       "                      [ 0.0492, -0.0555,  0.0067,  ...,  0.0482,  0.0548, -0.0226],\n",
       "                      [-0.0188, -0.0224,  0.0725,  ..., -0.0043,  0.0887,  0.0906]])),\n",
       "             ('denses.6.mu.bias',\n",
       "              tensor([-0.0327, -0.0324, -0.0336,  0.0072, -0.0701, -0.0785,  0.0532, -0.0688,\n",
       "                       0.0221, -0.0579,  0.0309, -0.0586, -0.0029, -0.0126, -0.0603,  0.0300,\n",
       "                       0.0181, -0.0666,  0.0407, -0.0584,  0.0872, -0.0864,  0.0303,  0.0272,\n",
       "                      -0.0616,  0.0816,  0.0619,  0.0074, -0.0523, -0.0006,  0.0018,  0.0245])),\n",
       "             ('denses.6.sigma.weight',\n",
       "              tensor([[-0.0150, -0.0280, -0.0060,  ..., -0.1058, -0.0178, -0.0163],\n",
       "                      [ 0.0686, -0.0338,  0.0666,  ...,  0.0067, -0.0066, -0.0287],\n",
       "                      [ 0.0500, -0.0689,  0.0141,  ...,  0.0518, -0.0095,  0.0813],\n",
       "                      ...,\n",
       "                      [-0.0599, -0.0236, -0.0743,  ..., -0.0388,  0.0051, -0.0081],\n",
       "                      [ 0.0652, -0.0698,  0.0744,  ...,  0.0725, -0.0630,  0.0607],\n",
       "                      [-0.0694,  0.0806, -0.0192,  ...,  0.0869, -0.0591, -0.0279]])),\n",
       "             ('denses.6.sigma.bias',\n",
       "              tensor([-0.0783,  0.0561,  0.0485,  0.0367, -0.0488,  0.0235,  0.0060, -0.0557,\n",
       "                       0.0168, -0.0338,  0.0243, -0.0216,  0.0365, -0.0291,  0.0597,  0.0115,\n",
       "                       0.0663, -0.0625,  0.0431,  0.0298, -0.0448, -0.0503, -0.0521, -0.0687,\n",
       "                      -0.0250,  0.0281,  0.0631, -0.0370, -0.0902, -0.0483,  0.0936, -0.0032])),\n",
       "             ('decisions.0.dense1.weight',\n",
       "              tensor([[-0.0234, -0.0526, -0.0290,  ..., -0.0904,  0.0024, -0.0027],\n",
       "                      [-0.0774,  0.0485,  0.0891,  ...,  0.0069,  0.0648, -0.0245],\n",
       "                      [ 0.0980, -0.0840, -0.0191,  ..., -0.0147,  0.0401,  0.0353],\n",
       "                      ...,\n",
       "                      [-0.0706,  0.0006, -0.0242,  ..., -0.0195,  0.0416, -0.1041],\n",
       "                      [ 0.1090, -0.0429, -0.0071,  ...,  0.0675, -0.0366,  0.0059],\n",
       "                      [-0.0110,  0.0041, -0.0047,  ..., -0.0411,  0.0008, -0.0517]])),\n",
       "             ('decisions.0.dense2.weight',\n",
       "              tensor([[ 2.0471e-02, -3.2093e-03, -1.5177e-02,  ...,  5.7195e-02,\n",
       "                       -7.8092e-03,  1.6179e-02],\n",
       "                      [ 1.4282e-02, -9.7344e-03,  6.1383e-03,  ..., -2.7248e-03,\n",
       "                        5.3805e-05, -3.2895e-03],\n",
       "                      [ 1.2745e-02, -4.2129e-04, -2.0496e-03,  ...,  1.8843e-02,\n",
       "                       -1.4063e-04,  1.1398e-02],\n",
       "                      ...,\n",
       "                      [ 5.0271e-03, -7.9734e-03,  1.9782e-04,  ...,  1.0441e-02,\n",
       "                       -7.0516e-03,  1.8855e-02],\n",
       "                      [ 7.6294e-04, -3.1650e-04, -3.3307e-02,  ...,  7.4619e-04,\n",
       "                       -2.9494e-03, -1.0002e-02],\n",
       "                      [-5.0298e-04, -4.1863e-03, -6.7485e-03,  ...,  1.0295e-02,\n",
       "                       -3.8191e-03,  1.2534e-02]])),\n",
       "             ('decisions.0.bn1.weight',\n",
       "              tensor([0.5499, 0.6137, 0.6569, 0.6779, 0.7128, 0.6678, 0.6244, 0.5551, 0.6278,\n",
       "                      0.5752, 0.6476, 0.6708, 0.6200, 0.6351, 0.6488, 0.6341, 0.6455, 0.5086,\n",
       "                      0.5715, 0.5943, 0.5878, 0.6897, 0.6594, 0.5436, 0.5905, 0.6541, 0.6145,\n",
       "                      0.6346, 0.6807, 0.6714, 0.6516, 0.6691, 0.6330, 0.5623, 0.6868, 0.6446,\n",
       "                      0.5514, 0.5598, 0.5932, 0.6210, 0.5935, 0.6231, 0.6835, 0.5760, 0.5990,\n",
       "                      0.5914, 0.6057, 0.6008, 0.6675, 0.6009, 0.6821, 0.7179, 0.7184, 0.6934,\n",
       "                      0.6609, 0.5665, 0.5379, 0.5586, 0.6957, 0.6530, 0.6396, 0.5459, 0.5589,\n",
       "                      0.6967, 0.6506, 0.6832, 0.6047, 0.5396, 0.6488, 0.6612, 0.6468, 0.5425,\n",
       "                      0.6459, 0.5076, 0.6700, 0.6354, 0.7126, 0.6286, 0.6292, 0.5781, 0.6658,\n",
       "                      0.5688, 0.6985, 0.7547, 0.6451, 0.6850, 0.5530, 0.5942, 0.7046, 0.5713,\n",
       "                      0.6342, 0.5825, 0.6651, 0.5914, 0.6999, 0.6633, 0.5788, 0.6648, 0.6955,\n",
       "                      0.6321, 0.6375, 0.5939, 0.6866, 0.6855, 0.5497, 0.6702, 0.5510, 0.6066,\n",
       "                      0.5708, 0.6003, 0.6456, 0.5420, 0.6170, 0.6761, 0.5998, 0.7168, 0.5960,\n",
       "                      0.6263, 0.6619, 0.5742, 0.5543, 0.6083, 0.6892, 0.7271, 0.7636, 0.6327,\n",
       "                      0.5788, 0.5887])),\n",
       "             ('decisions.0.bn1.bias',\n",
       "              tensor([-2.8054e-02,  6.6811e-02,  2.3378e-02,  3.0915e-02,  8.8270e-02,\n",
       "                       4.3524e-02,  7.2542e-03, -5.8964e-02, -9.9021e-04, -2.6165e-02,\n",
       "                      -1.7250e-05,  6.8170e-03, -6.8253e-03,  1.8790e-02, -1.3695e-02,\n",
       "                      -1.0644e-02,  2.1243e-02, -4.7215e-02,  5.0502e-03, -9.1200e-04,\n",
       "                       1.9047e-04,  4.8704e-02,  3.7207e-02, -1.1181e-02,  3.7956e-03,\n",
       "                       2.8331e-02,  2.0089e-02, -5.5945e-03,  2.3759e-02,  9.6459e-02,\n",
       "                       4.6805e-04,  2.7090e-02, -4.3218e-03, -3.7476e-02,  1.1796e-02,\n",
       "                       5.7567e-02, -1.9358e-02,  1.0828e-02, -2.0097e-02,  2.0295e-02,\n",
       "                       7.7533e-03,  1.0406e-02,  2.8821e-02,  2.5481e-05,  4.8989e-02,\n",
       "                      -1.7960e-02,  2.9633e-02,  9.1420e-03,  5.9303e-02,  7.0928e-03,\n",
       "                      -1.3820e-02,  5.2612e-02,  5.4351e-02,  5.7809e-02,  2.4352e-02,\n",
       "                       2.2370e-03, -3.8402e-02, -4.5357e-03,  5.5082e-02,  5.2871e-02,\n",
       "                      -4.3315e-02,  5.6310e-03, -4.2842e-03,  5.8668e-02,  8.5156e-03,\n",
       "                      -4.1424e-03, -2.4504e-05, -2.2137e-02,  3.3282e-02,  3.2119e-02,\n",
       "                       2.8147e-02, -1.5806e-02, -7.0726e-03, -4.2362e-02,  4.1825e-02,\n",
       "                       4.4533e-02,  5.4066e-03,  3.6193e-02, -8.6953e-03,  2.2363e-02,\n",
       "                       2.6012e-03, -1.0693e-02,  6.6708e-03,  4.0622e-02, -2.5794e-02,\n",
       "                       4.4684e-02, -4.4744e-02,  1.4807e-02,  3.4101e-02,  1.9799e-03,\n",
       "                       2.6904e-02, -2.2843e-02,  6.4304e-02, -7.4798e-04,  1.9922e-02,\n",
       "                      -1.7104e-02,  7.6756e-04,  3.7156e-04,  7.2731e-03, -2.4284e-03,\n",
       "                       2.5543e-02,  5.0968e-03,  2.8523e-02, -4.3736e-04, -1.3294e-02,\n",
       "                      -6.0239e-04, -3.5667e-02,  2.8168e-03, -2.6140e-02,  7.0426e-04,\n",
       "                       4.3364e-02, -1.1521e-02,  4.2444e-02,  1.6256e-02, -2.2037e-03,\n",
       "                       2.0362e-02, -6.1637e-04,  1.9519e-03,  1.7165e-02, -6.7726e-03,\n",
       "                      -3.6542e-02, -1.2821e-02,  6.9120e-02,  2.4284e-02,  2.8137e-02,\n",
       "                       4.1209e-04, -2.3795e-02, -3.4977e-02])),\n",
       "             ('decisions.0.bn1.running_mean',\n",
       "              tensor([ 1.7331e-03,  2.4708e-03,  7.8960e-04,  4.5393e-04,  2.5218e-03,\n",
       "                       7.1504e-04,  4.1181e-03, -3.5160e-04, -6.1365e-03,  2.3805e-03,\n",
       "                      -2.4823e-03,  1.3306e-03,  4.1442e-03, -3.7942e-03,  1.3389e-03,\n",
       "                      -2.6287e-04,  9.7823e-04, -4.2846e-03,  1.5141e-03,  2.0123e-03,\n",
       "                       6.1448e-03, -3.7355e-03, -5.7953e-04,  3.5329e-03, -4.3537e-04,\n",
       "                       8.4043e-03,  1.9976e-03,  5.1640e-04,  8.9166e-04, -3.8041e-03,\n",
       "                      -1.4350e-03, -2.1304e-03, -7.9832e-04, -5.1799e-03, -2.7148e-03,\n",
       "                       1.4450e-03, -7.7624e-04,  2.6340e-04,  2.9488e-03,  1.8096e-03,\n",
       "                       5.3274e-03,  1.4114e-03,  7.2637e-06,  3.8906e-03,  1.9282e-03,\n",
       "                      -4.9016e-04,  1.2280e-04,  1.3951e-03, -4.6969e-03, -3.3791e-03,\n",
       "                      -2.2463e-03,  2.3724e-03,  1.5423e-03, -2.2824e-03, -2.0161e-03,\n",
       "                       5.7947e-03, -1.0674e-03, -2.4395e-03, -4.3641e-03, -1.9437e-04,\n",
       "                       7.8256e-03, -1.6026e-03,  9.3400e-04, -4.8941e-03, -4.6266e-03,\n",
       "                       7.6410e-03,  4.0167e-03, -2.8954e-03,  2.4100e-04,  1.7970e-03,\n",
       "                      -2.1444e-03, -4.6110e-03,  1.4663e-03, -6.2088e-04,  4.7015e-03,\n",
       "                       4.0536e-03, -2.5011e-03,  5.8516e-04, -2.4300e-03,  1.2773e-03,\n",
       "                       1.3898e-03, -2.6965e-03, -9.5296e-04,  5.1888e-03, -4.1027e-03,\n",
       "                      -3.3449e-03,  3.2251e-03,  2.9787e-03,  9.6359e-03,  4.9762e-03,\n",
       "                       4.6277e-03,  1.7551e-03, -9.9388e-04,  7.8523e-05,  3.3752e-03,\n",
       "                      -1.6090e-03, -3.6457e-03,  1.2871e-03,  8.9811e-04,  8.7871e-03,\n",
       "                      -2.8055e-03, -2.2691e-03,  2.7296e-03, -6.0402e-03, -4.8032e-03,\n",
       "                       4.7747e-04,  2.7941e-03, -9.6988e-04, -1.5461e-03, -1.1583e-03,\n",
       "                      -5.6454e-03, -2.1357e-03,  1.6461e-03, -1.8431e-03, -2.0067e-03,\n",
       "                       2.3969e-03,  5.2364e-04, -1.2424e-03,  5.4611e-03,  2.4238e-03,\n",
       "                       2.7956e-03, -7.2806e-03, -7.9178e-03, -3.4203e-03,  1.6384e-03,\n",
       "                      -4.1142e-03,  1.5619e-03, -5.8494e-05])),\n",
       "             ('decisions.0.bn1.running_var',\n",
       "              tensor([0.1058, 0.1397, 0.1644, 0.1663, 0.2121, 0.2400, 0.1352, 0.1466, 0.0973,\n",
       "                      0.0995, 0.1572, 0.1508, 0.2035, 0.1349, 0.1542, 0.1268, 0.2262, 0.0870,\n",
       "                      0.1517, 0.1099, 0.1728, 0.1907, 0.1716, 0.1191, 0.1230, 0.1824, 0.1394,\n",
       "                      0.1648, 0.1857, 0.1556, 0.2201, 0.2024, 0.1474, 0.1214, 0.1914, 0.1331,\n",
       "                      0.1239, 0.1574, 0.1442, 0.1485, 0.1551, 0.1466, 0.2493, 0.1512, 0.1417,\n",
       "                      0.1090, 0.1919, 0.1084, 0.2038, 0.1298, 0.1538, 0.1933, 0.1429, 0.1563,\n",
       "                      0.1663, 0.1184, 0.1015, 0.1177, 0.1325, 0.2054, 0.1491, 0.0978, 0.1220,\n",
       "                      0.1684, 0.1925, 0.1906, 0.1335, 0.0889, 0.1492, 0.2060, 0.1604, 0.1288,\n",
       "                      0.1401, 0.1015, 0.2179, 0.1397, 0.1408, 0.1570, 0.1580, 0.1334, 0.1520,\n",
       "                      0.0897, 0.1831, 0.1452, 0.1675, 0.1423, 0.0978, 0.1762, 0.1700, 0.1132,\n",
       "                      0.1553, 0.1018, 0.1577, 0.1183, 0.1269, 0.1575, 0.1139, 0.1651, 0.1838,\n",
       "                      0.1465, 0.1757, 0.1533, 0.1928, 0.1732, 0.1324, 0.2170, 0.1165, 0.1460,\n",
       "                      0.1305, 0.1146, 0.2043, 0.1107, 0.1952, 0.1279, 0.1568, 0.1946, 0.1144,\n",
       "                      0.1420, 0.1704, 0.0752, 0.1022, 0.1378, 0.2222, 0.2001, 0.1507, 0.1371,\n",
       "                      0.1232, 0.1354])),\n",
       "             ('decisions.0.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('decisions.0.bn2.weight',\n",
       "              tensor([0.5516, 0.5670, 0.4866, 0.5862, 0.5459, 0.5853, 0.5116, 0.5245, 0.5867,\n",
       "                      0.5662, 0.5527, 0.5934, 0.5559, 0.5362, 0.5846, 0.5233, 0.5452, 0.6081,\n",
       "                      0.5515, 0.5658, 0.5436, 0.5301, 0.5803, 0.5320, 0.5645, 0.5459, 0.5322,\n",
       "                      0.5573, 0.5564, 0.5620, 0.5198, 0.5005, 0.5371, 0.5682, 0.5419, 0.5008,\n",
       "                      0.5160, 0.5522, 0.5736, 0.5777, 0.4661, 0.5603, 0.5891, 0.6104, 0.5401,\n",
       "                      0.5385, 0.4805, 0.6214, 0.5582, 0.5726, 0.5798, 0.5246, 0.5357, 0.5767,\n",
       "                      0.6038, 0.5705, 0.6109, 0.5264, 0.5709, 0.4791, 0.5254, 0.5721, 0.5795,\n",
       "                      0.5815, 0.5792, 0.6023, 0.5809, 0.5752, 0.5746, 0.5491, 0.5800, 0.5980,\n",
       "                      0.5554, 0.5746, 0.5338, 0.4802, 0.5534, 0.5898, 0.5373, 0.5569, 0.5741,\n",
       "                      0.5795, 0.4960, 0.5019, 0.5405, 0.5341, 0.5083, 0.5821, 0.5545, 0.5193,\n",
       "                      0.6166, 0.5400, 0.5706, 0.5554, 0.5779, 0.5866, 0.5879, 0.5043, 0.5807,\n",
       "                      0.6060, 0.5746, 0.5265, 0.5540, 0.4853, 0.5703, 0.5049, 0.5789, 0.5348,\n",
       "                      0.5696, 0.5661, 0.5255, 0.6029, 0.5248, 0.5571, 0.6077, 0.5485, 0.5412,\n",
       "                      0.5101, 0.5109, 0.5627, 0.5855, 0.4637, 0.5955, 0.5887, 0.5784, 0.5025,\n",
       "                      0.5236, 0.5033])),\n",
       "             ('decisions.0.bn2.bias',\n",
       "              tensor([-1.6360e-02,  5.0315e-04, -2.5114e-02,  1.0089e-02, -2.1408e-02,\n",
       "                       1.1103e-02,  6.7829e-03, -2.0319e-02,  3.2991e-02,  5.0115e-03,\n",
       "                      -1.1988e-03,  1.3805e-02,  7.7925e-03, -2.0590e-02,  7.3795e-03,\n",
       "                      -2.0969e-02, -1.3305e-05, -4.2268e-02, -4.1114e-02,  6.4779e-03,\n",
       "                      -9.0100e-03, -3.2541e-02, -3.7685e-04, -2.9767e-02, -1.4995e-02,\n",
       "                      -2.6283e-02, -2.3788e-02,  4.5596e-02, -1.8947e-02, -1.4322e-02,\n",
       "                      -2.7117e-02, -3.2095e-02, -1.6669e-02,  2.5065e-02, -4.6425e-02,\n",
       "                       8.4510e-03, -1.3057e-02, -3.0461e-02, -1.5462e-02,  3.0914e-02,\n",
       "                      -2.7062e-02, -1.6821e-05, -1.0483e-04,  7.1073e-02, -1.8231e-02,\n",
       "                      -9.2019e-03, -2.5085e-02,  5.5754e-02, -2.9223e-03,  1.4573e-02,\n",
       "                       1.8579e-02, -5.8572e-04, -8.0103e-03,  5.3134e-02,  5.0933e-02,\n",
       "                      -2.1190e-02,  2.5485e-02, -2.3083e-02,  5.1891e-03, -2.9208e-02,\n",
       "                       1.8338e-02, -9.7465e-03,  4.3294e-02,  2.9935e-02, -1.2525e-03,\n",
       "                       3.4389e-02, -6.7068e-03,  4.8582e-02,  2.0811e-02, -7.5165e-04,\n",
       "                       2.0994e-02,  2.8175e-02, -7.4864e-04, -6.7675e-04, -2.1948e-02,\n",
       "                      -2.5483e-02, -1.4784e-03,  3.8737e-02, -1.8754e-02,  2.3144e-03,\n",
       "                      -2.4138e-02,  2.3065e-02, -1.3603e-02, -2.5978e-02,  4.1797e-04,\n",
       "                      -1.9929e-02, -3.3667e-02,  7.2359e-04, -2.6230e-02, -2.6849e-02,\n",
       "                       4.6198e-02, -1.9277e-02, -1.6112e-02,  4.1951e-02,  4.0195e-02,\n",
       "                       2.1783e-02, -1.6497e-02, -2.2878e-02,  5.2666e-04,  3.2395e-02,\n",
       "                       6.7592e-03, -3.7405e-02,  4.7627e-02, -1.9704e-02, -1.9595e-02,\n",
       "                      -3.5087e-02, -2.0523e-02, -2.3502e-02,  3.5010e-02,  4.1640e-02,\n",
       "                       1.0416e-02,  1.6296e-03, -1.1749e-02, -2.1770e-02,  5.2878e-02,\n",
       "                       5.4137e-06,  2.5120e-02, -3.0318e-02, -2.6546e-02,  5.6746e-02,\n",
       "                      -2.0445e-03, -2.2385e-02,  2.0018e-02,  1.1747e-03,  5.2673e-02,\n",
       "                      -2.9374e-02, -7.4816e-04, -2.7415e-02])),\n",
       "             ('decisions.0.bn2.running_mean',\n",
       "              tensor([ 1.5630e-03,  9.2562e-02,  1.2983e-03, -4.1182e-03,  1.7248e-01,\n",
       "                       4.1677e-03, -5.7122e-02,  1.4301e-01, -1.1510e-01, -1.8163e-01,\n",
       "                      -4.7707e-02, -2.7900e-01,  3.2721e-02, -2.9442e-02,  9.3405e-02,\n",
       "                       1.6773e-02,  5.8950e-02,  2.1195e-01,  5.4087e-02, -1.0884e-02,\n",
       "                      -5.7017e-02,  3.9152e-02, -1.3037e-01,  1.6868e-01,  1.8618e-01,\n",
       "                       1.6503e-01, -1.5056e-02, -1.2324e-01,  2.0994e-01,  1.7005e-01,\n",
       "                      -1.5764e-02,  1.2086e-01,  1.5016e-01, -2.7640e-01,  1.5022e-01,\n",
       "                      -2.1257e-02,  1.3544e-01,  2.1342e-01, -1.2657e-03, -2.9605e-01,\n",
       "                       6.0233e-02,  1.1277e-01,  1.0031e-01, -2.2723e-01,  1.4089e-01,\n",
       "                       1.3109e-01,  2.8681e-02, -1.3187e-01,  1.9128e-01, -2.0749e-01,\n",
       "                      -2.7816e-01,  2.8151e-04, -6.4115e-02, -1.3069e-01, -2.3119e-01,\n",
       "                       1.9855e-01, -3.3435e-01,  1.3986e-01, -2.6486e-02,  3.4084e-02,\n",
       "                      -4.0999e-02,  9.3286e-02, -9.4922e-02, -3.3134e-01, -7.5125e-02,\n",
       "                      -3.8087e-01,  5.5283e-02, -1.4847e-01, -6.2265e-02, -1.1677e-01,\n",
       "                      -2.7380e-01, -1.6805e-01, -7.3171e-02,  1.2663e-01,  2.4891e-02,\n",
       "                       2.2612e-02, -9.9707e-02, -3.3701e-01, -6.4516e-02, -1.2563e-01,\n",
       "                       7.6179e-02, -3.0221e-01,  8.0346e-02,  1.2223e-01, -1.2097e-01,\n",
       "                       1.5186e-01,  5.9829e-02, -7.8087e-02, -2.7003e-02, -5.0636e-03,\n",
       "                      -4.1232e-01,  7.3853e-02,  3.8189e-02, -1.0846e-01, -9.8900e-02,\n",
       "                       6.2857e-02,  1.2769e-01, -1.5370e-02,  1.5122e-02, -3.2198e-01,\n",
       "                      -1.8406e-01,  6.6342e-02, -9.3172e-02, -2.9656e-02, -5.6320e-03,\n",
       "                       1.3861e-01,  2.5332e-02,  3.5436e-02, -8.2793e-02, -1.2267e-01,\n",
       "                      -2.7583e-02,  1.6455e-01,  1.1025e-01,  4.9752e-02, -4.5337e-02,\n",
       "                      -1.3496e-01, -5.0680e-02,  6.6099e-02,  1.2603e-01, -1.3775e-01,\n",
       "                       1.3329e-01,  4.0679e-02, -2.6505e-01,  1.8405e-02, -1.2554e-01,\n",
       "                       3.1920e-02, -1.4867e-01,  3.1728e-02])),\n",
       "             ('decisions.0.bn2.running_var',\n",
       "              tensor([0.4360, 0.6882, 0.1160, 0.7825, 0.3359, 0.7674, 0.3849, 0.2777, 0.7848,\n",
       "                      0.6374, 0.5748, 0.8370, 0.6381, 0.5391, 0.8528, 0.3252, 0.5589, 0.3654,\n",
       "                      0.3909, 0.5426, 0.5920, 0.3396, 0.7245, 0.3168, 0.3883, 0.3819, 0.4311,\n",
       "                      0.6129, 0.4691, 0.4393, 0.3506, 0.1220, 0.3462, 0.7048, 0.2542, 0.3326,\n",
       "                      0.2514, 0.4138, 0.7086, 0.7396, 0.0723, 0.4106, 0.6161, 0.8903, 0.3609,\n",
       "                      0.3606, 0.0921, 0.7930, 0.4302, 0.7655, 0.7381, 0.4756, 0.5583, 0.8117,\n",
       "                      0.9151, 0.4899, 0.8739, 0.2575, 0.6414, 0.0663, 0.5043, 0.6281, 0.7300,\n",
       "                      0.6849, 0.6238, 0.8412, 0.5209, 0.7139, 0.5731, 0.6685, 0.7828, 0.7482,\n",
       "                      0.7017, 0.5911, 0.4437, 0.0915, 0.6483, 0.8032, 0.4910, 0.6784, 0.4546,\n",
       "                      0.7485, 0.1629, 0.1466, 0.5335, 0.3369, 0.1830, 0.6635, 0.5508, 0.3218,\n",
       "                      0.8634, 0.3654, 0.6548, 0.6173, 0.7579, 0.8337, 0.5555, 0.2856, 0.6128,\n",
       "                      0.7769, 0.6725, 0.3019, 0.6062, 0.2144, 0.7338, 0.1682, 0.5564, 0.3119,\n",
       "                      0.7141, 0.5676, 0.5012, 0.6301, 0.3293, 0.4404, 0.8519, 0.6478, 0.5979,\n",
       "                      0.1927, 0.2011, 0.6548, 0.6262, 0.0643, 0.7783, 0.7344, 0.8907, 0.1667,\n",
       "                      0.4675, 0.2200])),\n",
       "             ('decisions.0.bn2.num_batches_tracked', tensor(906)),\n",
       "             ('decisions.0.dense3.weight',\n",
       "              tensor([[-1.6101e-02,  4.0463e-02, -1.1782e-04,  5.5459e-02,  7.8353e-03,\n",
       "                        5.8285e-02,  8.1604e-03, -7.2924e-04,  5.9269e-02, -3.8260e-02,\n",
       "                       -2.9655e-02, -7.2052e-02,  3.3277e-02, -1.8751e-02,  7.1717e-02,\n",
       "                       -4.5437e-03,  2.0886e-02, -7.4533e-02, -8.0009e-03,  2.8863e-02,\n",
       "                       -2.1550e-02, -5.3375e-03, -4.4451e-02,  1.0092e-03,  2.1674e-02,\n",
       "                        6.6981e-03, -9.9748e-03,  4.6919e-02,  2.1510e-02,  1.9961e-02,\n",
       "                       -2.5483e-03, -5.3310e-03,  4.4488e-03, -5.0020e-02, -7.5457e-03,\n",
       "                        2.5215e-03, -7.0441e-04,  1.6363e-02, -4.1545e-02, -5.6083e-02,\n",
       "                       -5.2621e-03,  2.3285e-02,  5.6246e-02,  9.9455e-02,  5.2710e-03,\n",
       "                        6.6639e-03, -4.5534e-04,  9.8029e-02,  2.3852e-02, -5.0964e-02,\n",
       "                       -5.6558e-02,  1.3354e-02, -2.2676e-02,  7.0932e-02,  8.9291e-02,\n",
       "                        2.9606e-02, -8.8280e-02, -7.7326e-04, -4.7153e-02, -3.0507e-04,\n",
       "                        1.8499e-02,  2.7093e-02,  7.3211e-02, -6.1320e-02, -4.7187e-02,\n",
       "                       -8.5682e-02, -4.9838e-02,  6.0861e-02,  4.0038e-02, -3.7388e-02,\n",
       "                       -5.1439e-02,  5.9607e-02, -3.9972e-02,  4.6439e-02, -1.1221e-02,\n",
       "                       -2.0010e-05, -3.2482e-02, -6.8051e-02, -1.5448e-02, -3.9418e-02,\n",
       "                       -3.1711e-02, -6.3820e-02, -2.8999e-03, -4.0825e-03, -1.8829e-02,\n",
       "                        1.8763e-03, -1.1238e-04, -4.5248e-02, -1.8253e-02, -2.4013e-03,\n",
       "                       -1.0140e-01, -9.7558e-03, -4.8376e-02,  3.9280e-02,  6.3052e-02,\n",
       "                        6.5249e-02,  4.2210e-02, -1.1451e-04, -5.1386e-02, -8.9768e-02,\n",
       "                       -4.7012e-02, -2.3066e-03,  4.0850e-02,  7.7229e-04, -4.0686e-02,\n",
       "                       -2.1524e-03, -4.0162e-02, -5.6146e-03,  5.7102e-02,  5.0010e-02,\n",
       "                        1.5807e-02,  7.9649e-02,  1.6986e-03, -2.1588e-02,  9.6456e-02,\n",
       "                       -3.1498e-02,  2.7044e-02,  2.5702e-04, -1.6684e-04,  4.7975e-02,\n",
       "                        5.6868e-02, -6.3051e-03, -7.3937e-02,  5.6633e-02,  6.9934e-02,\n",
       "                       -7.7153e-04, -1.8389e-02,  3.0565e-04]])),\n",
       "             ('decisions.0.dense3.bias', tensor([0.0553])),\n",
       "             ('decisions.1.dense1.weight',\n",
       "              tensor([[-5.9670e-02, -1.8693e-02,  8.5200e-02,  ...,  1.1202e-03,\n",
       "                       -7.4448e-02,  9.5994e-02],\n",
       "                      [-1.0113e-01,  3.8529e-02, -1.1931e-01,  ...,  1.0913e-01,\n",
       "                       -4.1572e-02,  6.5378e-03],\n",
       "                      [-4.5362e-02, -1.2267e-01, -1.3948e-01,  ..., -1.2851e-04,\n",
       "                       -4.6397e-02,  1.2770e-01],\n",
       "                      ...,\n",
       "                      [ 1.0426e-01, -4.7251e-02, -3.7308e-02,  ...,  3.3359e-03,\n",
       "                        1.0127e-02,  1.3968e-02],\n",
       "                      [-8.4202e-02, -6.1446e-04,  1.0643e-01,  ...,  1.7527e-02,\n",
       "                        5.4383e-02,  7.4186e-02],\n",
       "                      [ 1.2463e-01,  8.8144e-02,  1.3852e-01,  ..., -8.3630e-02,\n",
       "                       -4.7468e-04, -2.2052e-02]])),\n",
       "             ('decisions.1.dense2.weight',\n",
       "              tensor([[ 0.0233,  0.0438,  0.0595,  ..., -0.0021, -0.0781, -0.0109],\n",
       "                      [-0.0174, -0.0160, -0.0354,  ...,  0.0724, -0.0306, -0.0030],\n",
       "                      [ 0.0406,  0.0569,  0.0192,  ...,  0.0414, -0.0218, -0.0213],\n",
       "                      ...,\n",
       "                      [ 0.0817, -0.0476, -0.0377,  ...,  0.0486, -0.0364, -0.0004],\n",
       "                      [ 0.0231,  0.0064,  0.0042,  ..., -0.0313, -0.0578, -0.0246],\n",
       "                      [ 0.0282,  0.0097,  0.0440,  ...,  0.0663, -0.0108,  0.0557]])),\n",
       "             ('decisions.1.bn1.weight',\n",
       "              tensor([0.9075, 0.8897, 0.9068, 0.9150, 0.8250, 0.9161, 0.8623, 0.8225, 0.8062,\n",
       "                      0.9106, 0.8655, 0.9489, 0.8904, 0.7794, 0.8690, 0.8116, 0.8780, 0.8378,\n",
       "                      0.8553, 0.9053, 0.8329, 0.7835, 0.7980, 0.9225, 0.9195, 0.8159, 0.8713,\n",
       "                      0.8213, 0.8165, 0.7712, 0.9167, 0.9104, 0.8500, 0.8707, 0.8094, 0.8655,\n",
       "                      0.8015, 0.8432, 0.8090, 0.8472, 0.8572, 0.8487, 0.8906, 0.8135, 0.8688,\n",
       "                      0.9381, 0.8283, 0.9025, 0.8889, 0.8773, 0.8855, 0.8589, 0.8532, 0.8296,\n",
       "                      0.8218, 0.8301, 0.9106, 0.9123, 0.8181, 0.8721, 0.8108, 0.7779, 0.8412,\n",
       "                      0.8240, 0.7808, 0.8333, 0.8208, 0.8805, 0.7859, 0.8853, 0.8974, 0.8271,\n",
       "                      0.8401, 0.8179, 0.8719, 0.8100, 0.8975, 0.8934, 0.8004, 0.8935, 0.8154,\n",
       "                      0.9072, 0.8886, 0.8512, 0.9204, 0.9243, 0.9247, 0.9054, 0.8817, 0.8588,\n",
       "                      0.8420, 0.8965, 0.7882, 0.8915, 0.8889, 0.9407, 0.8379, 0.9038, 0.8317,\n",
       "                      0.8730, 0.9044, 0.8888, 0.8820, 0.7952, 0.8008, 0.8567, 0.8055, 0.8777,\n",
       "                      0.7882, 0.8098, 0.8699, 0.8133, 0.8507, 0.8200, 0.8298, 0.8733, 0.9289,\n",
       "                      0.7985, 0.7811, 0.8303, 0.7934, 0.8008, 0.8871, 0.9203, 0.7993, 0.9054,\n",
       "                      0.8258, 0.9507])),\n",
       "             ('decisions.1.bn1.bias',\n",
       "              tensor([-2.1327e-02, -3.2658e-02, -2.5482e-02, -4.9761e-03, -3.6149e-02,\n",
       "                      -4.2123e-03, -1.1622e-02, -2.8203e-05, -2.5323e-02,  2.3222e-05,\n",
       "                      -4.0044e-02,  2.8577e-02, -2.6338e-03, -4.3118e-02,  2.2894e-03,\n",
       "                      -4.0537e-03, -7.7293e-04, -1.7637e-02, -2.7364e-02,  1.0519e-02,\n",
       "                      -1.1461e-02, -2.7241e-02, -2.4849e-02, -3.6578e-03, -5.6023e-03,\n",
       "                      -1.3256e-02,  4.8436e-03, -1.7834e-02, -3.8669e-02, -4.4917e-02,\n",
       "                       1.1934e-02,  3.5524e-04, -6.6215e-05, -2.2995e-02, -5.2772e-03,\n",
       "                       9.7452e-03,  7.3036e-04, -7.3438e-04, -1.2374e-02, -2.2812e-02,\n",
       "                      -2.2626e-02,  1.5630e-02, -3.1566e-02, -1.1402e-02, -9.2805e-03,\n",
       "                       1.3765e-02, -7.5293e-03,  8.2907e-03, -1.6983e-02, -7.4719e-05,\n",
       "                      -9.8323e-04, -3.6087e-02, -1.7884e-02, -2.0665e-02, -6.6638e-03,\n",
       "                      -1.1985e-02, -2.4898e-03,  7.8223e-03, -1.4135e-02, -2.2599e-02,\n",
       "                      -1.7561e-02, -9.7550e-03, -1.4701e-02, -2.1727e-02, -2.8303e-02,\n",
       "                       1.3520e-03,  4.5105e-03,  4.7396e-03, -2.5604e-02, -1.2755e-03,\n",
       "                       4.3730e-03, -3.6422e-02, -4.7071e-02, -3.7179e-02, -8.8080e-03,\n",
       "                       6.8568e-04,  4.5546e-04, -2.2331e-02,  1.6851e-02, -1.2339e-02,\n",
       "                      -2.0181e-02,  2.2040e-02, -2.7498e-02, -3.6739e-04, -6.6270e-03,\n",
       "                      -2.1170e-02,  1.3146e-02,  3.0860e-03,  7.4464e-04,  8.9079e-04,\n",
       "                       5.7400e-04, -2.9935e-03, -1.6250e-02, -3.3774e-02, -1.4986e-03,\n",
       "                      -1.2136e-02, -2.3128e-02,  5.2653e-03, -7.6275e-03, -3.0040e-02,\n",
       "                       7.5098e-03,  2.1134e-03,  4.2755e-03, -5.6398e-03,  1.2369e-03,\n",
       "                      -2.5005e-02, -4.2286e-04,  7.6514e-03, -5.8842e-03, -4.9300e-02,\n",
       "                      -3.4725e-02, -3.9309e-02, -3.6267e-02, -4.6453e-04, -3.2566e-04,\n",
       "                      -1.1453e-02, -1.1039e-03,  7.0452e-03, -2.9225e-02, -4.6383e-02,\n",
       "                      -2.7632e-02, -7.4208e-04, -7.6546e-05,  1.2355e-04, -1.2304e-02,\n",
       "                       1.7859e-03, -3.3144e-02,  1.7438e-05])),\n",
       "             ('decisions.1.bn1.running_mean',\n",
       "              tensor([ 3.7985e-02,  1.4362e-01,  7.3199e-02,  3.6319e-02,  5.0650e-02,\n",
       "                       1.0573e-01,  8.4183e-02, -4.1606e-02,  1.7835e-03,  1.5689e-02,\n",
       "                       6.0412e-02, -5.3263e-02, -1.4108e-02,  1.5269e-03,  2.6777e-03,\n",
       "                       1.6780e-02, -6.3665e-02, -2.9598e-02, -8.9440e-02,  5.6904e-03,\n",
       "                       3.6532e-02,  4.2177e-02,  2.9987e-02, -3.1660e-03,  1.6706e-02,\n",
       "                      -5.9433e-02, -2.8719e-02, -8.0553e-02, -1.1178e-01, -2.2126e-04,\n",
       "                      -3.7127e-02,  1.4790e-02,  9.1884e-03, -3.9768e-02, -4.0157e-02,\n",
       "                      -1.2331e-01, -1.0068e-01,  1.0792e-01, -5.8706e-02,  1.3180e-02,\n",
       "                       5.6867e-02, -8.5224e-02, -3.4374e-02, -3.0606e-02,  1.1911e-01,\n",
       "                      -1.6656e-02,  1.2308e-01,  1.3367e-01,  6.9613e-02,  1.2304e-01,\n",
       "                       3.8822e-02, -1.1166e-01,  9.5196e-02,  1.7842e-02, -5.7120e-02,\n",
       "                       2.0267e-03, -1.0728e-01,  4.9904e-02, -6.2118e-02,  1.1896e-02,\n",
       "                      -1.4899e-01,  2.5466e-02,  1.0052e-01, -2.3290e-02,  1.4618e-01,\n",
       "                       9.2790e-02, -5.9517e-02,  1.9051e-02,  6.6417e-02, -1.5392e-02,\n",
       "                       3.3872e-03, -1.5916e-01,  5.2269e-02, -5.9129e-02, -4.0116e-02,\n",
       "                      -3.3550e-02,  1.5199e-01, -1.3075e-02, -4.6717e-02,  8.0056e-02,\n",
       "                       8.5232e-03,  1.0916e-02,  3.5111e-03, -8.9498e-02,  3.1670e-02,\n",
       "                      -4.6946e-02, -5.0982e-02,  8.6487e-02,  2.1534e-03, -4.4136e-02,\n",
       "                       2.0464e-02, -6.6641e-02,  7.8011e-02,  3.3995e-02, -5.7245e-02,\n",
       "                      -5.3277e-02, -1.0279e-02, -3.1458e-03,  1.6298e-01, -2.3250e-02,\n",
       "                      -7.9938e-02, -1.3076e-01, -1.5964e-02,  2.0482e-02,  3.8543e-02,\n",
       "                      -2.1936e-02, -8.8179e-02,  2.4750e-02, -2.8196e-02, -4.8161e-02,\n",
       "                       8.5426e-04,  3.8051e-02,  5.7709e-06,  5.4031e-02, -1.2673e-01,\n",
       "                       5.0558e-02,  1.5869e-01, -3.5445e-02, -3.7258e-02,  3.4541e-02,\n",
       "                      -5.0906e-02,  7.6810e-02, -7.0219e-02,  9.4017e-02,  5.0143e-02,\n",
       "                      -2.1371e-02, -7.4804e-03,  1.2601e-01])),\n",
       "             ('decisions.1.bn1.running_var',\n",
       "              tensor([0.1353, 0.2351, 0.1016, 0.1213, 0.0935, 0.1729, 0.0823, 0.4429, 0.2117,\n",
       "                      0.0952, 0.1079, 0.3491, 0.2094, 0.0930, 0.1999, 0.2984, 0.1313, 0.1416,\n",
       "                      0.0920, 0.1061, 0.1182, 0.2184, 0.0870, 0.1802, 0.1595, 0.0824, 0.1112,\n",
       "                      0.1209, 0.1684, 0.4130, 0.3140, 0.1804, 0.1569, 0.0908, 0.2835, 0.4876,\n",
       "                      0.0789, 0.1197, 0.1548, 0.1582, 0.1051, 0.6916, 0.1686, 0.0653, 0.0896,\n",
       "                      0.1534, 0.1177, 0.1208, 0.1568, 0.1937, 0.2016, 0.0996, 0.0935, 0.1280,\n",
       "                      0.2168, 0.2864, 0.1422, 0.1086, 0.1046, 0.1676, 0.1296, 0.1644, 0.0716,\n",
       "                      0.1129, 0.1121, 0.0893, 0.1004, 0.1163, 0.1403, 0.2001, 0.2179, 0.0836,\n",
       "                      0.0928, 0.1408, 0.2054, 0.0869, 0.1352, 0.1064, 0.2488, 0.0902, 0.2745,\n",
       "                      0.2136, 0.1336, 0.1769, 0.1469, 0.1658, 0.1022, 0.1366, 0.0934, 0.6003,\n",
       "                      0.1756, 0.2189, 0.1129, 0.2568, 0.2767, 0.1710, 0.1260, 0.1601, 0.1071,\n",
       "                      0.1553, 0.0872, 0.4050, 0.1756, 0.1050, 0.2207, 0.1539, 0.2571, 0.2654,\n",
       "                      0.1227, 0.0878, 0.1601, 0.1155, 0.1851, 0.1143, 0.1297, 0.1729, 0.1983,\n",
       "                      0.1150, 0.8895, 0.2488, 0.0958, 0.5113, 0.2991, 0.3564, 0.0992, 0.1196,\n",
       "                      0.4545, 0.1692])),\n",
       "             ('decisions.1.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.1.bn2.weight',\n",
       "              tensor([0.8859, 0.7245, 0.7719, 0.7101, 0.7085, 0.7609, 0.8790, 0.8520, 0.8357,\n",
       "                      0.8442, 0.8001, 0.7044, 0.7081, 0.7198, 0.7010, 0.7527, 0.7960, 0.6997,\n",
       "                      0.7038, 0.8244, 0.8626, 0.8231, 0.8660, 0.8744, 0.7901, 0.7035, 0.8664,\n",
       "                      0.7038, 0.8357, 0.7362, 0.8751, 0.8474, 0.7815, 0.8508, 0.8733, 0.7052,\n",
       "                      0.7017, 0.7036, 0.7157, 0.8431, 0.7508, 0.7039, 0.7046, 0.8547, 0.7143,\n",
       "                      0.8062, 0.8571, 0.8172, 0.8849, 0.7974, 0.8498, 0.7106, 0.8058, 0.8433,\n",
       "                      0.6981, 0.8575, 0.8584, 0.7969, 0.8366, 0.8171, 0.8736, 0.7655, 0.8432,\n",
       "                      0.7318, 0.8451, 0.8376, 0.8620, 0.7929, 0.8131, 0.7467, 0.8778, 0.7108,\n",
       "                      0.8488, 0.7172, 0.8050, 0.7836, 0.8721, 0.8361, 0.8573, 0.7155, 0.8776,\n",
       "                      0.7255, 0.7865, 0.8280, 0.8091, 0.8714, 0.7022, 0.7506, 0.8634, 0.8405,\n",
       "                      0.7334, 0.8397, 0.8514, 0.8302, 0.7693, 0.8091, 0.7740, 0.7846, 0.7519,\n",
       "                      0.8376, 0.8541, 0.7559, 0.8760, 0.8142, 0.8599, 0.6993, 0.8003, 0.8451,\n",
       "                      0.8567, 0.7917, 0.8578, 0.8595, 0.8180, 0.8451, 0.7745, 0.8333, 0.8644,\n",
       "                      0.8401, 0.7050, 0.6980, 0.7036, 0.7406, 0.8083, 0.7976, 0.8502, 0.8487,\n",
       "                      0.8558, 0.7596])),\n",
       "             ('decisions.1.bn2.bias',\n",
       "              tensor([ 1.3040e-02, -2.7883e-02, -2.8332e-02, -1.1761e-02, -2.0272e-02,\n",
       "                      -1.4630e-02, -8.4692e-03, -2.4369e-02, -3.0108e-05, -1.1538e-02,\n",
       "                      -1.0677e-02, -1.7162e-02, -3.7831e-02, -1.6352e-02, -2.6525e-02,\n",
       "                      -2.2529e-02, -2.3178e-03, -2.5951e-02, -2.5822e-02, -5.8991e-03,\n",
       "                      -3.8590e-03, -4.5700e-03,  2.2657e-04, -3.6597e-02, -6.5315e-04,\n",
       "                      -3.8471e-02, -2.4157e-02, -2.9209e-02, -5.5178e-03, -1.7097e-02,\n",
       "                       3.1182e-04,  3.4550e-03, -5.6440e-03, -1.1006e-02, -1.9152e-03,\n",
       "                      -2.0336e-02, -2.9881e-02, -3.3888e-02, -2.2598e-02, -6.8075e-04,\n",
       "                      -6.2512e-03, -2.8667e-02, -3.4499e-02,  4.8578e-03, -9.2281e-03,\n",
       "                      -5.1167e-03,  3.8658e-03,  1.2068e-03,  8.8116e-05, -5.0236e-03,\n",
       "                      -2.8036e-04, -1.2110e-02, -4.5525e-03, -1.8694e-02, -4.5610e-02,\n",
       "                      -5.9460e-03,  1.4213e-02,  3.4009e-04, -1.1788e-02, -3.9330e-03,\n",
       "                      -8.0520e-03, -1.6050e-02,  7.5443e-04, -2.8810e-02, -2.4648e-02,\n",
       "                       6.1214e-04, -4.3811e-03, -1.4877e-02, -1.3095e-02, -5.6864e-03,\n",
       "                      -2.3382e-02, -1.0182e-02, -1.2767e-02, -2.1277e-02, -9.2282e-03,\n",
       "                      -1.6229e-02,  3.0674e-03, -1.3678e-02,  4.8772e-04, -9.5012e-03,\n",
       "                      -1.3685e-03, -1.4158e-02, -1.3374e-02, -3.0083e-03, -9.7811e-03,\n",
       "                      -4.9157e-03, -2.2410e-02, -1.3623e-02, -2.3900e-02, -3.1041e-04,\n",
       "                      -1.8046e-02, -4.3265e-03, -1.9569e-02, -1.8755e-03, -1.4559e-02,\n",
       "                      -2.4773e-03, -2.1785e-02, -1.1481e-03, -1.2037e-02, -3.0578e-03,\n",
       "                      -7.7166e-04, -1.8187e-02, -7.6074e-03, -1.1780e-02,  3.4145e-03,\n",
       "                      -2.9779e-02, -5.2456e-03, -5.3024e-04, -1.6032e-02,  6.6516e-04,\n",
       "                      -5.0790e-03, -4.5906e-03,  2.9156e-03,  3.2625e-04,  8.2661e-05,\n",
       "                      -1.1679e-04, -1.5280e-02,  6.5621e-03, -2.2653e-02, -2.7729e-02,\n",
       "                      -3.5949e-02, -1.4453e-02, -1.6610e-02, -1.7692e-02, -7.8255e-03,\n",
       "                      -1.6446e-02, -6.1028e-04, -1.8472e-02])),\n",
       "             ('decisions.1.bn2.running_mean',\n",
       "              tensor([ 4.4502e-01,  1.1827e-01,  3.6245e-01, -2.0030e-01,  1.4904e-01,\n",
       "                       3.0352e-01,  4.1775e-01,  4.3216e-01, -4.4003e-01, -4.8979e-01,\n",
       "                      -3.1030e-01, -1.6987e-01, -2.2278e-01, -7.1512e-02,  6.9833e-02,\n",
       "                       2.5905e-01,  7.2172e-02, -1.2919e-01,  2.1685e-01, -3.1151e-01,\n",
       "                       2.6105e-01,  9.4480e-02,  3.8516e-01,  4.0879e-01, -4.2968e-01,\n",
       "                      -4.4958e-03,  4.0963e-01, -1.3963e-02,  1.3226e-01, -3.5674e-01,\n",
       "                      -4.6902e-01,  2.3880e-01,  4.2941e-01,  4.8387e-01,  5.1060e-01,\n",
       "                      -9.4885e-02, -9.2198e-02,  1.3804e-01,  1.0697e-01, -3.4634e-01,\n",
       "                       4.4108e-01, -2.2232e-01,  9.2133e-02, -3.5367e-01, -4.0277e-01,\n",
       "                       3.4872e-01, -4.7770e-01, -2.8101e-01,  5.3562e-01, -4.2889e-01,\n",
       "                       2.8208e-01, -4.9054e-03,  2.8822e-01, -2.4583e-01,  3.2511e-02,\n",
       "                       2.8027e-01, -6.0511e-01, -3.4320e-01, -3.6857e-01,  2.8020e-01,\n",
       "                       3.7972e-01,  9.3643e-02, -4.6919e-01, -1.6880e-01,  3.2365e-01,\n",
       "                      -5.4572e-01,  3.7876e-01,  3.2311e-01, -1.6507e-01,  2.7173e-01,\n",
       "                       3.7291e-01,  7.0116e-02,  3.3887e-01, -3.2393e-01,  2.7694e-01,\n",
       "                       2.2660e-01, -6.4799e-01,  4.4068e-01, -3.5800e-01, -1.1253e-01,\n",
       "                       3.3725e-01, -1.2133e-01,  5.1090e-01, -4.6499e-01,  3.0076e-01,\n",
       "                       2.5980e-01,  1.1112e-01,  2.4634e-01,  2.9676e-01, -4.9105e-01,\n",
       "                       2.1857e-01, -2.3426e-01,  3.0680e-01, -5.4866e-01,  3.3084e-01,\n",
       "                       1.7899e-01,  4.3623e-01, -3.6828e-01,  2.5219e-01, -2.8247e-01,\n",
       "                      -6.4802e-01,  1.5390e-01,  4.5968e-01, -3.4981e-01, -5.2701e-01,\n",
       "                      -6.3652e-02,  2.0659e-01,  1.9319e-01,  2.3112e-01, -2.9489e-01,\n",
       "                       3.8209e-01,  5.4462e-01, -5.1982e-01, -4.5318e-01, -4.9887e-01,\n",
       "                      -3.8582e-01,  3.4475e-01, -6.4752e-01,  7.6968e-02, -1.2045e-01,\n",
       "                       6.4343e-02, -2.0356e-01,  3.5173e-01,  4.3187e-01, -4.4304e-01,\n",
       "                       3.6541e-01, -4.5287e-01,  3.7975e-04])),\n",
       "             ('decisions.1.bn2.running_var',\n",
       "              tensor([0.1373, 0.0709, 0.1047, 0.0718, 0.1196, 0.1313, 0.1735, 0.1265, 0.2246,\n",
       "                      0.3210, 0.2118, 0.1038, 0.0971, 0.0602, 0.1707, 0.0810, 0.1519, 0.0886,\n",
       "                      0.0438, 0.4673, 0.2323, 0.3568, 0.1397, 0.1541, 0.1321, 0.0729, 0.1216,\n",
       "                      0.1369, 0.1827, 0.2312, 0.4116, 0.2370, 0.0835, 0.1152, 0.1525, 0.1790,\n",
       "                      0.0730, 0.1089, 0.0829, 0.5011, 0.1033, 0.1739, 0.0477, 0.4279, 0.1080,\n",
       "                      0.2154, 0.3548, 0.3532, 0.1598, 0.2819, 0.1822, 0.0836, 0.1572, 0.3927,\n",
       "                      0.2077, 0.1646, 0.4279, 0.3120, 0.3836, 0.1791, 0.1358, 0.1013, 0.4174,\n",
       "                      0.0728, 0.1680, 0.3091, 0.1465, 0.1157, 0.2030, 0.1549, 0.1533, 0.1102,\n",
       "                      0.1435, 0.2002, 0.1328, 0.1069, 0.2472, 0.1488, 0.4538, 0.0715, 0.1517,\n",
       "                      0.1004, 0.0799, 0.2665, 0.2093, 0.1995, 0.0677, 0.0724, 0.1732, 0.3758,\n",
       "                      0.0637, 0.3544, 0.2239, 0.2984, 0.1059, 0.1723, 0.0841, 0.2335, 0.0974,\n",
       "                      0.2940, 0.2714, 0.1345, 0.1526, 0.1685, 0.4899, 0.1039, 0.2142, 0.2587,\n",
       "                      0.1496, 0.2301, 0.1811, 0.1893, 0.2847, 0.2801, 0.1718, 0.2197, 0.1870,\n",
       "                      0.3038, 0.1538, 0.0746, 0.0613, 0.0793, 0.1304, 0.0985, 0.2250, 0.1721,\n",
       "                      0.2540, 0.1296])),\n",
       "             ('decisions.1.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.1.dense3.weight',\n",
       "              tensor([[ 6.2901e-02,  2.6779e-03,  6.8972e-03,  3.6288e-04,  3.8676e-03,\n",
       "                        9.1800e-03,  6.1873e-02,  3.8622e-02, -2.6395e-02, -3.4670e-02,\n",
       "                       -1.1970e-02, -7.6329e-04,  5.5464e-04,  7.6242e-04,  5.4955e-05,\n",
       "                        5.1227e-03,  1.0739e-02, -7.7326e-04,  2.6246e-04, -2.4127e-02,\n",
       "                        4.4667e-02,  1.8675e-02,  5.2601e-02,  5.2812e-02, -8.0960e-03,\n",
       "                        3.3918e-04,  4.5423e-02, -3.3860e-04,  2.9348e-02, -1.1126e-03,\n",
       "                       -5.8476e-02,  3.3830e-02,  1.2683e-02,  3.7080e-02,  5.3403e-02,\n",
       "                        7.7139e-04,  4.5114e-04,  4.0867e-03, -2.6964e-04, -3.0900e-02,\n",
       "                        5.2687e-03, -3.4595e-03,  4.5746e-04, -3.8048e-02, -3.4409e-03,\n",
       "                        1.7188e-02, -4.7814e-02, -1.8963e-02,  6.4262e-02, -1.9427e-02,\n",
       "                        3.5587e-02,  1.6489e-03,  1.9558e-02, -2.3822e-02,  6.9240e-04,\n",
       "                        4.0776e-02, -4.5474e-02, -1.0026e-02, -2.4160e-02,  1.5366e-02,\n",
       "                        5.0783e-02,  7.5209e-03, -3.3589e-02, -2.4178e-04,  3.2724e-02,\n",
       "                       -3.1427e-02,  4.5766e-02,  1.4633e-02, -3.3991e-03,  7.5378e-03,\n",
       "                        5.4857e-02,  1.3185e-04,  3.2975e-02, -1.3400e-03,  1.5439e-02,\n",
       "                        1.2272e-02, -5.5429e-02,  3.0946e-02, -4.7597e-02,  5.8722e-05,\n",
       "                        5.6431e-02, -7.5754e-04,  1.4795e-02, -1.9036e-02,  2.1025e-02,\n",
       "                        5.5541e-02,  8.3759e-04,  1.6687e-03,  4.6483e-02, -3.2384e-02,\n",
       "                        1.5300e-03, -2.9369e-02,  3.9184e-02, -2.8598e-02,  1.1496e-02,\n",
       "                        1.4798e-02,  1.0171e-02, -1.2850e-02,  8.2697e-04, -2.4857e-02,\n",
       "                       -4.1321e-02,  6.0444e-03,  5.4468e-02, -1.1026e-02, -4.5633e-02,\n",
       "                        7.5000e-04,  1.9165e-02,  3.2311e-02,  4.2353e-02, -1.1835e-02,\n",
       "                        4.1401e-02,  4.4930e-02, -2.1855e-02, -3.5592e-02, -1.1765e-02,\n",
       "                       -2.3441e-02,  4.6254e-02, -3.4925e-02, -7.5852e-04, -1.2693e-03,\n",
       "                       -2.4197e-04,  6.8845e-05,  1.8347e-02,  1.5119e-02, -4.3930e-02,\n",
       "                        4.0650e-02, -4.4570e-02,  1.0788e-03]])),\n",
       "             ('decisions.1.dense3.bias', tensor([-0.0240])),\n",
       "             ('decisions.2.dense1.weight',\n",
       "              tensor([[ 0.0197, -0.1469,  0.1476,  ...,  0.1020,  0.0995,  0.0019],\n",
       "                      [-0.1064,  0.0373, -0.0809,  ...,  0.1051, -0.1228, -0.0077],\n",
       "                      [ 0.1119,  0.1058,  0.1086,  ..., -0.0009,  0.0684,  0.0019],\n",
       "                      ...,\n",
       "                      [ 0.1739, -0.0180,  0.0014,  ...,  0.0290,  0.0169,  0.1198],\n",
       "                      [ 0.1101,  0.0926,  0.0620,  ...,  0.0530,  0.0281,  0.0155],\n",
       "                      [-0.0099,  0.0926, -0.0019,  ..., -0.0364,  0.0803,  0.0689]])),\n",
       "             ('decisions.2.dense2.weight',\n",
       "              tensor([[-0.0721, -0.0654, -0.0713,  ..., -0.0371, -0.0365, -0.0216],\n",
       "                      [-0.0749, -0.0221,  0.0010,  ...,  0.0274, -0.0564, -0.0051],\n",
       "                      [ 0.0173,  0.0546,  0.0142,  ...,  0.0040,  0.0264,  0.0266],\n",
       "                      ...,\n",
       "                      [-0.0235,  0.0042,  0.0163,  ...,  0.0063, -0.0146, -0.0433],\n",
       "                      [-0.0471, -0.0267, -0.0220,  ...,  0.0022, -0.0349,  0.0482],\n",
       "                      [-0.0671,  0.0478, -0.0164,  ..., -0.0694,  0.0072, -0.0806]])),\n",
       "             ('decisions.2.bn1.weight',\n",
       "              tensor([0.8116, 0.8849, 0.8681, 0.7980, 0.8313, 0.8674, 0.8861, 0.8690, 0.8869,\n",
       "                      0.8095, 0.9067, 0.8210, 0.8876, 0.8822, 0.9220, 0.8153, 0.8656, 0.8793,\n",
       "                      0.8867, 0.8902, 0.8854, 0.8642, 0.9229, 0.7889, 0.8862, 0.8011, 0.8582,\n",
       "                      0.8988, 0.8976, 0.9070, 0.8262, 0.8122, 0.8550, 0.9260, 0.8512, 0.8277,\n",
       "                      0.8642, 0.8846, 0.8292, 0.8870, 0.8829, 0.8014, 0.8262, 0.8896, 0.8445,\n",
       "                      0.8240, 0.9065, 0.8643, 0.7562, 0.9222, 0.8894, 0.8364, 0.8131, 0.8813,\n",
       "                      0.8637, 0.8636, 0.8704, 0.8703, 0.8978, 0.8557, 0.8713, 0.8552, 0.9242,\n",
       "                      0.9059, 0.8851, 0.8470, 0.8515, 0.8348, 0.8810, 0.8377, 0.8156, 0.8985,\n",
       "                      0.7770, 0.8837, 0.8076, 0.9205, 0.8392, 0.8097, 0.8546, 0.8281, 0.8490,\n",
       "                      0.8760, 0.8662, 0.8389, 0.7926, 0.9082, 0.9112, 0.8591, 0.8211, 0.8689,\n",
       "                      0.8562, 0.8740, 0.8095, 0.8810, 0.9112, 0.8710, 0.8762, 0.8264, 0.9104,\n",
       "                      0.8837, 0.8910, 0.8599, 0.9206, 0.8876, 0.8446, 0.8477, 0.8854, 0.8871,\n",
       "                      0.8029, 0.9038, 0.8907, 0.9153, 0.9101, 0.8121, 0.9034, 0.8350, 0.9034,\n",
       "                      0.7854, 0.8123, 0.9082, 0.8218, 0.7930, 0.8964, 0.8567, 0.8550, 0.9135,\n",
       "                      0.8560, 0.9058])),\n",
       "             ('decisions.2.bn1.bias',\n",
       "              tensor([-3.8211e-03, -1.2022e-02, -2.9548e-02,  1.8337e-03,  2.4667e-02,\n",
       "                      -1.9024e-02, -2.5539e-02, -2.8751e-02, -4.2933e-02,  1.3118e-03,\n",
       "                      -3.7343e-02, -3.3724e-02,  2.4730e-02, -3.2944e-04, -7.3195e-03,\n",
       "                       4.0306e-02, -3.0189e-02, -1.4381e-02, -3.0311e-02, -1.0898e-02,\n",
       "                      -4.4564e-02, -1.6813e-02,  6.7147e-03, -1.7218e-02, -6.1868e-03,\n",
       "                      -1.7615e-02, -2.0190e-02, -1.3896e-02, -6.4019e-04, -1.5144e-02,\n",
       "                      -1.3081e-03, -1.9500e-05, -2.0159e-02, -4.1738e-04, -4.6520e-02,\n",
       "                      -6.7805e-04, -1.3469e-03,  1.1001e-03, -1.2039e-02,  1.7543e-03,\n",
       "                      -6.4506e-03, -2.5337e-02,  2.5808e-02,  1.1944e-02, -2.4679e-02,\n",
       "                      -2.4000e-02, -2.3798e-02, -1.4842e-02, -3.6747e-02,  9.6801e-05,\n",
       "                      -2.2527e-02,  1.8615e-02,  3.7818e-03, -9.8746e-03,  7.4506e-04,\n",
       "                      -3.1724e-02, -4.3204e-03, -2.5270e-02,  1.9521e-02, -1.5694e-02,\n",
       "                      -2.3753e-02, -1.4966e-02, -9.2957e-03, -1.7173e-02, -1.9350e-02,\n",
       "                       5.5329e-03,  4.3360e-02, -1.7106e-02, -6.3137e-03, -4.5999e-02,\n",
       "                      -2.2162e-02,  4.2258e-03, -2.9269e-02, -3.4353e-03, -3.6327e-02,\n",
       "                       1.6336e-02, -3.4152e-02, -1.3005e-02, -3.2421e-02, -2.7388e-03,\n",
       "                      -3.5600e-02, -2.8620e-03, -9.3392e-03, -1.2982e-02, -4.6760e-03,\n",
       "                      -3.6273e-03,  1.5515e-03, -1.5348e-02, -4.4303e-02, -2.0413e-02,\n",
       "                      -2.0059e-02, -2.9187e-02, -1.6837e-04, -2.2307e-02, -2.0784e-04,\n",
       "                      -5.7109e-03,  2.2944e-02, -7.8767e-02,  1.8323e-02, -3.0018e-02,\n",
       "                      -2.1841e-02, -7.0637e-03,  4.4201e-03, -4.2675e-02, -6.9665e-03,\n",
       "                      -1.8094e-02, -1.3094e-04, -1.0919e-02,  1.5866e-03, -3.1513e-04,\n",
       "                      -8.4004e-03,  1.4532e-02, -1.7152e-02,  3.1555e-03,  7.1869e-05,\n",
       "                      -4.5891e-03,  3.3750e-06, -2.8023e-02, -2.4966e-02, -2.9111e-02,\n",
       "                      -2.7828e-02, -2.7506e-02, -8.0472e-03, -1.4990e-04, -1.9886e-02,\n",
       "                      -8.0868e-03, -3.9065e-02, -1.1685e-02])),\n",
       "             ('decisions.2.bn1.running_mean',\n",
       "              tensor([ 0.0940,  0.0854, -0.0084, -0.2113, -0.1533,  0.0830,  0.0581, -0.0816,\n",
       "                       0.0105, -0.1399, -0.0043, -0.0722,  0.1961, -0.0233, -0.0470, -0.2858,\n",
       "                       0.1120,  0.0892, -0.0902,  0.0223, -0.0046,  0.0519, -0.0205, -0.1217,\n",
       "                       0.0353, -0.0278, -0.0382,  0.0232, -0.0199,  0.0448, -0.0038, -0.1011,\n",
       "                       0.0353,  0.0139, -0.1060,  0.0916,  0.0180,  0.0055, -0.0875,  0.1293,\n",
       "                      -0.0481, -0.1691, -0.0536,  0.3442, -0.0585,  0.0331, -0.0323,  0.0334,\n",
       "                       0.0297,  0.1258,  0.0852,  0.1538, -0.2362,  0.0731, -0.0753, -0.0732,\n",
       "                       0.0389, -0.0840,  0.2133, -0.1006, -0.0743,  0.1468,  0.1015, -0.0851,\n",
       "                       0.0146,  0.0682,  0.1964,  0.0696,  0.0790, -0.0633, -0.0243, -0.0766,\n",
       "                      -0.1250, -0.0131,  0.1843, -0.0204, -0.0165,  0.0675, -0.1485, -0.0005,\n",
       "                      -0.1259, -0.0234,  0.1551, -0.0539, -0.0438, -0.0506,  0.0750, -0.0201,\n",
       "                       0.0789,  0.0502,  0.0243,  0.0438, -0.1696,  0.2212,  0.0050,  0.1759,\n",
       "                       0.0965, -0.0720,  0.0873,  0.1585, -0.1834,  0.1912, -0.0503,  0.1119,\n",
       "                      -0.0669, -0.1133,  0.1524,  0.0666, -0.1109,  0.1355,  0.0290,  0.1524,\n",
       "                      -0.0454, -0.1265,  0.0236, -0.0150, -0.0532,  0.1123, -0.0469,  0.0134,\n",
       "                       0.1581, -0.2068, -0.0189,  0.0107,  0.0270,  0.1104, -0.0412,  0.0227])),\n",
       "             ('decisions.2.bn1.running_var',\n",
       "              tensor([0.1151, 0.1026, 0.1043, 0.4638, 0.4103, 0.1516, 0.1079, 0.1286, 0.1078,\n",
       "                      0.2633, 0.0879, 0.0932, 0.2122, 0.0918, 0.0971, 0.6436, 0.1052, 0.1483,\n",
       "                      0.2004, 0.1055, 0.0781, 0.0990, 0.1732, 0.1763, 0.0924, 0.0735, 0.0811,\n",
       "                      0.0758, 0.1294, 0.1359, 0.1003, 0.1045, 0.1157, 0.1548, 0.1223, 0.1264,\n",
       "                      0.1115, 0.0879, 0.3128, 0.2089, 0.1128, 0.1906, 0.2113, 0.2992, 0.0975,\n",
       "                      0.1434, 0.1708, 0.1193, 0.1247, 0.1312, 0.1725, 0.1775, 0.4069, 0.1323,\n",
       "                      0.0962, 0.1518, 0.0767, 0.1069, 0.6048, 0.1047, 0.1438, 0.2509, 0.1290,\n",
       "                      0.1621, 0.1861, 0.1034, 0.2845, 0.1230, 0.1346, 0.1018, 0.2586, 0.1651,\n",
       "                      0.2089, 0.0834, 0.2103, 0.0864, 0.0841, 0.1002, 0.1165, 0.0642, 0.1509,\n",
       "                      0.1511, 0.1891, 0.0839, 0.0979, 0.0964, 0.1325, 0.1033, 0.1183, 0.0883,\n",
       "                      0.0874, 0.0867, 0.1856, 0.2252, 0.1278, 0.3644, 0.3113, 0.0984, 0.2378,\n",
       "                      0.1610, 0.4621, 0.2416, 0.1068, 0.3555, 0.2992, 0.3729, 0.2337, 0.1086,\n",
       "                      0.2634, 0.2309, 0.1268, 0.1655, 0.1192, 0.3035, 0.1306, 0.1100, 0.1102,\n",
       "                      0.0853, 0.0661, 0.1072, 0.2436, 0.1981, 0.1291, 0.1487, 0.1314, 0.1050,\n",
       "                      0.1230, 0.1512])),\n",
       "             ('decisions.2.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.2.bn2.weight',\n",
       "              tensor([0.8007, 0.8631, 0.8360, 0.7144, 0.6999, 0.8970, 0.7072, 0.8471, 0.8511,\n",
       "                      0.8589, 0.8416, 0.8501, 0.8456, 0.7748, 0.8887, 0.7217, 0.7180, 0.7629,\n",
       "                      0.7093, 0.8194, 0.8071, 0.7940, 0.7105, 0.6979, 0.8294, 0.8432, 0.8791,\n",
       "                      0.8674, 0.7011, 0.8142, 0.7013, 0.8128, 0.8835, 0.7079, 0.8298, 0.8749,\n",
       "                      0.8686, 0.8589, 0.8462, 0.8654, 0.8055, 0.6960, 0.7013, 0.8346, 0.8378,\n",
       "                      0.7670, 0.7509, 0.7622, 0.8370, 0.8355, 0.7021, 0.8755, 0.7133, 0.7869,\n",
       "                      0.8033, 0.6988, 0.6999, 0.8257, 0.7004, 0.8589, 0.6994, 0.8343, 0.8353,\n",
       "                      0.6990, 0.7284, 0.8466, 0.7574, 0.7638, 0.7063, 0.7039, 0.7637, 0.8585,\n",
       "                      0.8147, 0.8546, 0.8254, 0.8833, 0.8021, 0.8323, 0.7547, 0.8066, 0.7026,\n",
       "                      0.7314, 0.7848, 0.7408, 0.7045, 0.7592, 0.8430, 0.8556, 0.7115, 0.7029,\n",
       "                      0.8792, 0.8838, 0.7011, 0.8739, 0.8163, 0.7975, 0.8284, 0.8581, 0.8357,\n",
       "                      0.7042, 0.8621, 0.8381, 0.8150, 0.8579, 0.8188, 0.8873, 0.8305, 0.7651,\n",
       "                      0.8473, 0.8872, 0.7539, 0.8567, 0.6971, 0.8307, 0.7002, 0.7953, 0.7782,\n",
       "                      0.7853, 0.8656, 0.6996, 0.6976, 0.7735, 0.8234, 0.7188, 0.8641, 0.8226,\n",
       "                      0.8449, 0.8334])),\n",
       "             ('decisions.2.bn2.bias',\n",
       "              tensor([ 7.7036e-04,  9.7928e-03, -6.6647e-04, -1.9828e-02, -3.4248e-03,\n",
       "                       5.2140e-03, -1.2777e-02, -1.3437e-02, -7.6597e-04, -6.8238e-04,\n",
       "                      -5.0886e-04,  3.5051e-03, -1.6762e-02, -1.3448e-02, -1.4475e-02,\n",
       "                      -1.6746e-02, -2.1879e-02,  1.5598e-04, -2.4855e-02, -8.8203e-03,\n",
       "                      -5.8521e-03, -9.6460e-04, -9.0419e-03, -2.5555e-02, -3.5922e-03,\n",
       "                      -2.4742e-02, -1.2595e-02, -9.3528e-03, -3.0478e-02, -1.4598e-02,\n",
       "                      -4.2373e-02, -2.0143e-02, -1.6235e-03, -2.5083e-02, -1.0140e-02,\n",
       "                      -9.2716e-03, -1.4888e-02, -1.1624e-04, -3.5099e-03, -2.0957e-02,\n",
       "                       6.9734e-04, -3.8123e-02, -2.5110e-02, -5.4072e-03, -3.9616e-02,\n",
       "                      -1.6117e-02, -1.1734e-02, -1.0028e-02, -1.6884e-02, -7.3999e-03,\n",
       "                      -2.6117e-02, -1.4329e-02, -2.7334e-02, -1.8760e-04, -6.6189e-03,\n",
       "                      -3.0853e-02, -1.9342e-02, -1.6115e-02, -3.2282e-02, -1.4330e-02,\n",
       "                      -1.3926e-02, -2.2330e-03,  1.6281e-04, -1.3824e-02, -1.3050e-02,\n",
       "                       7.3745e-04,  3.8645e-04, -1.7572e-02, -2.2270e-02, -1.9854e-02,\n",
       "                      -1.6587e-02, -2.2665e-03, -2.0787e-02, -1.6181e-02, -4.6997e-03,\n",
       "                      -4.6017e-04, -1.3783e-02, -1.6132e-02,  4.1657e-03, -7.0693e-05,\n",
       "                      -3.9638e-02, -1.3209e-02, -2.9730e-03, -5.3895e-03, -1.9231e-02,\n",
       "                       7.6092e-04, -1.2118e-02, -1.3794e-02, -8.2894e-03, -2.7366e-02,\n",
       "                      -6.8269e-03, -9.1304e-03, -2.4869e-02,  5.1206e-04, -4.7061e-04,\n",
       "                      -3.1456e-03, -7.7084e-04,  5.8649e-04, -1.1007e-02, -2.4393e-02,\n",
       "                      -2.2604e-04, -1.3862e-02, -3.3638e-02, -7.3367e-03, -7.1532e-04,\n",
       "                      -2.9944e-03, -3.6601e-02, -3.7016e-03, -6.4454e-04,  1.7405e-03,\n",
       "                      -2.0687e-02, -1.5782e-04, -3.4231e-02, -2.6259e-02, -3.4360e-02,\n",
       "                      -1.1830e-02, -1.6415e-02, -2.6604e-02, -1.1953e-02, -1.4239e-02,\n",
       "                      -2.9260e-02, -6.3338e-03, -1.3664e-02, -1.8004e-02, -5.8814e-03,\n",
       "                      -3.4801e-04, -1.7418e-02, -1.0862e-02])),\n",
       "             ('decisions.2.bn2.running_mean',\n",
       "              tensor([-0.4360, -0.4187,  0.5627, -0.3199, -0.1434, -0.5990, -0.2275,  0.5115,\n",
       "                       0.2585, -0.5839, -0.3621, -0.5421, -0.5485,  0.2023,  0.5727, -0.2949,\n",
       "                       0.3952,  0.1117, -0.0900, -0.4195, -0.3604,  0.3817, -0.0730, -0.1032,\n",
       "                      -0.5176,  0.1201,  0.6043,  0.4825,  0.0621,  0.4050,  0.2504, -0.1962,\n",
       "                       0.3824,  0.0349,  0.3014,  0.5032,  0.4978, -0.2996,  0.4211,  0.4181,\n",
       "                      -0.3710, -0.0370, -0.0285,  0.3160,  0.3118,  0.1656, -0.1458, -0.3879,\n",
       "                      -0.3039,  0.4220,  0.0828,  0.4685,  0.2250, -0.2442, -0.4821, -0.0142,\n",
       "                       0.0262, -0.3731, -0.0781,  0.2234, -0.0794, -0.4744,  0.3836,  0.1135,\n",
       "                      -0.3176, -0.5753, -0.6019,  0.2575, -0.3598, -0.0629,  0.2843, -0.5111,\n",
       "                      -0.2951,  0.1733, -0.5281,  0.3568, -0.3980,  0.3392, -0.5808,  0.3151,\n",
       "                      -0.0401, -0.3885,  0.3877, -0.3501, -0.1286, -0.3124,  0.4762,  0.2340,\n",
       "                      -0.2615, -0.1143,  0.4415,  0.4545, -0.0108,  0.3762, -0.4753,  0.2784,\n",
       "                      -0.6815,  0.3120,  0.4705,  0.1605, -0.2996,  0.4261,  0.2095,  0.3141,\n",
       "                      -0.5133, -0.6485,  0.3868, -0.3143,  0.2075,  0.3526, -0.4248, -0.5542,\n",
       "                      -0.1466,  0.3474,  0.0477,  0.2202,  0.4469,  0.3188,  0.3698, -0.1008,\n",
       "                       0.1580,  0.3515, -0.4386,  0.3024,  0.4012, -0.3996,  0.3551, -0.3698])),\n",
       "             ('decisions.2.bn2.running_var',\n",
       "              tensor([0.3850, 0.5268, 0.1051, 0.0833, 0.0954, 0.4508, 0.0861, 0.0911, 0.3011,\n",
       "                      0.3307, 0.5222, 0.3451, 0.3260, 0.1020, 0.1672, 0.1170, 0.0535, 0.1458,\n",
       "                      0.0599, 0.2430, 0.2953, 0.1390, 0.1173, 0.0749, 0.2424, 0.2394, 0.1250,\n",
       "                      0.1604, 0.0856, 0.1054, 0.0579, 0.2756, 0.1376, 0.0435, 0.1411, 0.1311,\n",
       "                      0.1178, 0.5930, 0.1442, 0.1279, 0.3896, 0.0684, 0.0404, 0.1379, 0.1713,\n",
       "                      0.0892, 0.1147, 0.1099, 0.5581, 0.1814, 0.0659, 0.1114, 0.0754, 0.3334,\n",
       "                      0.2008, 0.1264, 0.0872, 0.3407, 0.0760, 0.1516, 0.0816, 0.3396, 0.1489,\n",
       "                      0.0521, 0.1410, 0.2599, 0.2017, 0.0987, 0.1949, 0.0692, 0.0709, 0.3917,\n",
       "                      0.1768, 0.1570, 0.3447, 0.2018, 0.1212, 0.1068, 0.0989, 0.1235, 0.0606,\n",
       "                      0.0742, 0.0837, 0.1371, 0.1169, 0.3031, 0.1300, 0.1373, 0.0742, 0.0781,\n",
       "                      0.1382, 0.1409, 0.0466, 0.2120, 0.3467, 0.1101, 0.2484, 0.1294, 0.1051,\n",
       "                      0.0751, 0.4628, 0.1259, 0.1293, 0.1630, 0.3725, 0.3360, 0.1293, 0.2073,\n",
       "                      0.2357, 0.1937, 0.1774, 0.4476, 0.0960, 0.1068, 0.0494, 0.1273, 0.1135,\n",
       "                      0.1031, 0.1617, 0.0537, 0.0479, 0.1274, 0.1645, 0.0430, 0.1226, 0.3197,\n",
       "                      0.1753, 0.2560])),\n",
       "             ('decisions.2.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions.2.dense3.weight',\n",
       "              tensor([[-1.7920e-02, -5.1827e-02,  2.9283e-02,  6.3245e-04,  4.8831e-04,\n",
       "                       -8.6011e-02,  5.3833e-04,  3.8820e-02,  3.7795e-02, -4.8380e-02,\n",
       "                       -3.0891e-02, -3.7693e-02, -4.0697e-02,  2.7053e-03,  7.1010e-02,\n",
       "                        4.1596e-04,  3.7575e-03,  8.6088e-03,  7.1771e-04, -1.8165e-02,\n",
       "                       -1.6745e-02,  1.5901e-02, -7.5442e-04, -6.6371e-04, -2.9158e-02,\n",
       "                        2.7446e-02,  6.0243e-02,  5.3568e-02, -2.3091e-04,  2.3151e-02,\n",
       "                       -5.7442e-04, -6.0473e-03,  5.9943e-02, -2.4683e-04,  2.5967e-02,\n",
       "                        5.3412e-02,  4.9751e-02, -4.1904e-02,  3.5249e-02,  4.4922e-02,\n",
       "                       -1.1959e-02, -5.0023e-04, -3.0894e-04,  2.4053e-02,  3.6289e-02,\n",
       "                        7.4286e-03, -8.6415e-05, -6.3292e-03, -2.4288e-02,  3.3687e-02,\n",
       "                       -2.5147e-04,  5.6806e-02, -3.3304e-04, -7.8909e-03, -1.8398e-02,\n",
       "                        5.1685e-06, -5.7271e-04, -1.9369e-02,  2.5508e-05,  5.1337e-02,\n",
       "                        7.0175e-04, -2.9605e-02,  2.9166e-02,  1.0987e-04,  4.8906e-04,\n",
       "                       -3.5428e-02, -7.9197e-03,  1.0474e-02, -1.5878e-03,  7.3441e-04,\n",
       "                        8.3244e-03, -4.3201e-02, -8.9654e-03,  4.0448e-02, -2.7313e-02,\n",
       "                        6.2110e-02, -9.3703e-03,  2.8556e-02, -1.0127e-02,  1.3499e-02,\n",
       "                        3.1087e-04,  1.3486e-04,  1.4973e-02, -8.0466e-04,  6.7907e-04,\n",
       "                       -2.9141e-03,  3.4104e-02,  4.1690e-02,  7.6334e-04,  1.9869e-03,\n",
       "                        6.8063e-02,  6.2703e-02, -6.9147e-04,  5.9589e-02, -1.6824e-02,\n",
       "                        1.0075e-02, -3.3910e-02,  4.5483e-02,  3.4053e-02, -6.8227e-04,\n",
       "                       -3.9554e-02,  3.3209e-02,  1.5086e-02,  4.9296e-02, -2.2511e-02,\n",
       "                       -6.9746e-02,  2.3660e-02, -6.5236e-04,  3.4370e-02,  6.9369e-02,\n",
       "                       -1.5964e-03, -4.6042e-02,  7.7161e-06,  2.2466e-02, -1.3497e-04,\n",
       "                        1.3919e-02,  1.5676e-02,  1.2375e-02,  4.8759e-02, -3.0094e-04,\n",
       "                       -2.1413e-04,  5.2820e-03, -2.0062e-02,  1.6750e-03,  5.0208e-02,\n",
       "                       -2.3498e-02,  3.3607e-02, -2.4204e-02]])),\n",
       "             ('decisions.2.dense3.bias', tensor([0.0641])),\n",
       "             ('decisions_q.0.dense1.weight',\n",
       "              tensor([[-0.0145,  0.0870,  0.0016,  ...,  0.0638, -0.0604, -0.0368],\n",
       "                      [ 0.0088,  0.0147, -0.0218,  ...,  0.0620, -0.0510,  0.0389],\n",
       "                      [-0.0940, -0.0005, -0.0659,  ...,  0.0595,  0.0731,  0.0212],\n",
       "                      ...,\n",
       "                      [-0.0095, -0.0708, -0.0323,  ..., -0.0856, -0.0186, -0.0130],\n",
       "                      [-0.0494, -0.0647, -0.0762,  ...,  0.0224,  0.0549, -0.0817],\n",
       "                      [ 0.0616, -0.0371,  0.0424,  ..., -0.0176,  0.0408, -0.0381]])),\n",
       "             ('decisions_q.0.dense2.weight',\n",
       "              tensor([[ 6.3592e-02,  7.1865e-02, -7.0638e-02,  ..., -7.8009e-02,\n",
       "                       -8.4963e-02, -4.9299e-03],\n",
       "                      [ 7.7665e-02, -8.5890e-02, -2.8607e-03,  ..., -5.6658e-02,\n",
       "                        1.0292e-01, -2.5401e-02],\n",
       "                      [ 7.8024e-02,  4.6985e-03,  3.2141e-02,  ...,  8.3373e-02,\n",
       "                        5.0240e-02,  7.4122e-02],\n",
       "                      ...,\n",
       "                      [ 3.8160e-02, -2.3192e-02, -8.2015e-02,  ...,  6.2456e-02,\n",
       "                        6.9692e-02, -5.8805e-02],\n",
       "                      [-7.8001e-02,  3.9478e-02, -3.3096e-02,  ..., -4.7302e-02,\n",
       "                       -6.1038e-05,  7.3150e-02],\n",
       "                      [-1.1989e-02, -3.4285e-02, -3.7390e-02,  ...,  6.4736e-02,\n",
       "                        6.1182e-02, -1.5920e-02]])),\n",
       "             ('decisions_q.0.bn1.weight',\n",
       "              tensor([0.9820, 0.9847, 0.9875, 1.0171, 1.0009, 0.9903, 0.9877, 0.9998, 1.0218,\n",
       "                      1.0126, 0.9773, 1.0056, 0.9743, 0.9861, 0.9969, 0.9834, 0.9870, 0.9853,\n",
       "                      1.0181, 1.0071, 0.9838, 1.0131, 0.9909, 0.9732, 1.0046, 1.0146, 1.0139,\n",
       "                      0.9853, 1.0107, 1.0111, 1.0183, 0.9847, 0.9958, 0.9859, 0.9916, 0.9827,\n",
       "                      0.9853, 1.0205, 1.0104, 1.0103, 1.0131, 1.0164, 1.0145, 0.9762, 0.9816,\n",
       "                      0.9965, 1.0080, 1.0171, 0.9805, 0.9887, 1.0122, 0.9848, 1.0141, 0.9824,\n",
       "                      1.0021, 1.0157, 0.9819, 0.9911, 1.0083, 1.0177, 0.9870, 1.0142, 0.9808,\n",
       "                      0.9850, 0.9789, 1.0193, 1.0021, 0.9833, 0.9864, 1.0109, 0.9930, 1.0206,\n",
       "                      0.9831, 1.0166, 0.9801, 0.9810, 1.0211, 1.0002, 1.0191, 0.9983, 1.0178,\n",
       "                      0.9891, 1.0020, 0.9886, 1.0172, 0.9907, 0.9827, 0.9776, 0.9949, 0.9937,\n",
       "                      0.9823, 0.9880, 1.0170, 0.9791, 0.9765, 1.0113, 0.9974, 0.9919, 0.9876,\n",
       "                      1.0311, 1.0195, 1.0014, 0.9925, 1.0152, 0.9832, 1.0202, 0.9918, 1.0143,\n",
       "                      0.9856, 0.9851, 1.0154, 0.9841, 1.0119, 1.0223, 1.0164, 0.9908, 0.9770,\n",
       "                      1.0033, 1.0387, 0.9981, 0.9927, 0.9823, 0.9828, 1.0165, 0.9979, 0.9825,\n",
       "                      1.0137, 0.9925])),\n",
       "             ('decisions_q.0.bn1.bias',\n",
       "              tensor([-0.0169,  0.0097,  0.0009,  0.0220,  0.0138, -0.0044,  0.0126,  0.0139,\n",
       "                       0.0201,  0.0216, -0.0156,  0.0122, -0.0218, -0.0117,  0.0061,  0.0054,\n",
       "                      -0.0115,  0.0112,  0.0175,  0.0125, -0.0134,  0.0188,  0.0010, -0.0157,\n",
       "                       0.0077,  0.0153,  0.0161,  0.0060,  0.0155,  0.0122,  0.0217,  0.0064,\n",
       "                       0.0023, -0.0137,  0.0078, -0.0029, -0.0190,  0.0223,  0.0136,  0.0213,\n",
       "                       0.0167,  0.0207,  0.0223, -0.0211, -0.0173,  0.0442,  0.0107,  0.0205,\n",
       "                      -0.0185, -0.0066,  0.0187, -0.0079,  0.0146, -0.0178,  0.0137,  0.0203,\n",
       "                      -0.0140,  0.0195,  0.0171,  0.0176,  0.0123,  0.0209, -0.0072, -0.0087,\n",
       "                      -0.0120,  0.0208,  0.0168, -0.0146,  0.0056,  0.0154,  0.0010,  0.0233,\n",
       "                      -0.0112,  0.0213,  0.0028, -0.0176,  0.0156,  0.0122,  0.0193,  0.0096,\n",
       "                       0.0202,  0.0125,  0.0196,  0.0021,  0.0201,  0.0101, -0.0137, -0.0213,\n",
       "                       0.0188,  0.0083, -0.0156, -0.0069,  0.0202, -0.0176, -0.0227,  0.0146,\n",
       "                       0.0378,  0.0200,  0.0039,  0.0305,  0.0220,  0.0091,  0.0099,  0.0211,\n",
       "                      -0.0043,  0.0189,  0.0142,  0.0169, -0.0083, -0.0034,  0.0117, -0.0143,\n",
       "                       0.0180,  0.0157,  0.0217,  0.0065, -0.0230,  0.0071,  0.0367,  0.0074,\n",
       "                       0.0085, -0.0151, -0.0157,  0.0174,  0.0083,  0.0147,  0.0170,  0.0087])),\n",
       "             ('decisions_q.0.bn1.running_mean',\n",
       "              tensor([ 5.5802e-02, -8.3281e-02,  2.4437e-02,  5.0876e-02,  8.8451e-02,\n",
       "                      -6.6053e-02, -2.4254e-02, -3.5990e-01, -1.2569e-01, -2.9325e-01,\n",
       "                       2.3717e-01, -3.8306e-01,  3.8665e-01, -8.2607e-02, -1.7148e-02,\n",
       "                      -2.4637e-02, -2.1656e-01, -1.2389e-01, -6.4305e-02,  1.9199e-03,\n",
       "                      -1.5847e-01, -3.4358e-02, -2.5828e-01,  1.8118e-01, -3.5705e-02,\n",
       "                      -1.0838e-01, -1.9955e-01,  1.4987e-01, -2.6022e-01,  1.3267e-02,\n",
       "                      -1.1666e-01,  4.8628e-02,  1.6525e-01, -1.8242e-02, -3.0250e-01,\n",
       "                      -1.5153e-01,  1.4310e-01,  1.6451e-01, -2.6014e-01, -2.8526e-01,\n",
       "                      -1.5896e-01, -4.3244e-02,  1.4280e-01, -2.6089e-01,  1.2012e-02,\n",
       "                      -2.0221e-01, -1.8704e-01,  2.5910e-02,  3.1824e-02, -3.1717e-01,\n",
       "                      -1.5388e-01, -2.3182e-02, -6.5116e-02, -3.9981e-01, -1.3050e-03,\n",
       "                      -4.5664e-02, -4.4625e-01, -1.4891e-01,  2.6558e-01, -2.9018e-01,\n",
       "                      -3.4553e-01,  9.2957e-02,  4.7864e-04, -4.8513e-02, -3.0625e-01,\n",
       "                      -1.6286e-01,  3.6443e-02,  7.7299e-02, -5.5647e-01, -3.8201e-01,\n",
       "                       2.2111e-01,  3.6318e-02, -3.3989e-01, -3.3482e-01,  1.2438e-01,\n",
       "                      -1.8451e-01, -2.4604e-01,  1.8045e-01, -5.8318e-02, -1.2011e-01,\n",
       "                       2.8306e-02, -1.8349e-01,  2.0772e-01, -2.4144e-01,  1.6078e-01,\n",
       "                      -3.2646e-01, -2.6481e-01, -4.7935e-02, -2.4160e-01, -1.0062e-01,\n",
       "                      -2.0921e-01, -1.5209e-01,  3.4384e-02,  5.4943e-02,  8.6880e-02,\n",
       "                      -2.8854e-01, -1.7442e-01,  8.8460e-03, -2.9231e-01, -1.3605e-01,\n",
       "                      -4.6271e-01, -9.3268e-02,  3.6874e-01, -9.0561e-02, -5.3971e-02,\n",
       "                      -2.3728e-01, -3.2832e-01, -8.8340e-03, -6.0456e-02,  2.6141e-01,\n",
       "                      -1.1144e-01, -1.2642e-01,  6.9147e-02, -4.9903e-01,  9.3083e-02,\n",
       "                      -8.9041e-02,  6.6563e-02,  6.0024e-02, -6.6323e-02,  1.7587e-01,\n",
       "                      -3.2778e-01, -3.7540e-02, -1.1327e-01, -1.2953e-01,  2.2839e-01,\n",
       "                      -2.0210e-01, -2.2767e-01, -3.0503e-01])),\n",
       "             ('decisions_q.0.bn1.running_var',\n",
       "              tensor([0.0488, 0.9688, 0.9737, 1.1383, 0.4807, 0.7862, 1.4935, 0.6620, 1.4402,\n",
       "                      1.5623, 0.1743, 1.8609, 0.1458, 0.6284, 1.0621, 0.8809, 1.0782, 0.8368,\n",
       "                      1.0540, 0.5255, 0.0778, 1.3024, 0.4553, 1.4471, 0.8544, 0.7566, 1.7236,\n",
       "                      1.1362, 1.3486, 0.4125, 0.6621, 0.6990, 0.9509, 0.9120, 0.0284, 0.5625,\n",
       "                      0.4202, 0.7429, 1.2654, 0.9045, 0.0208, 0.3835, 1.1469, 0.0295, 0.7378,\n",
       "                      0.3293, 1.5512, 0.6368, 0.6418, 1.0573, 1.2262, 0.9765, 1.0347, 1.0823,\n",
       "                      1.0396, 0.4601, 0.0629, 0.0282, 0.3454, 1.7431, 1.3637, 0.6189, 0.8843,\n",
       "                      1.2663, 0.2773, 0.1701, 1.2890, 0.6848, 0.1794, 1.2510, 0.6503, 1.0250,\n",
       "                      0.6516, 1.2982, 1.1369, 0.5528, 1.1655, 0.0233, 1.6465, 1.2697, 1.3860,\n",
       "                      0.5928, 0.5677, 0.5888, 1.0527, 0.7838, 0.5285, 0.0863, 0.5040, 0.6482,\n",
       "                      0.7859, 0.1832, 0.8314, 0.7142, 0.2890, 0.4646, 0.1794, 1.4453, 0.9767,\n",
       "                      0.1187, 1.1811, 0.6188, 1.0938, 1.3368, 0.6398, 0.7822, 0.8056, 0.4801,\n",
       "                      0.2904, 0.2768, 0.5508, 0.4754, 1.1870, 0.7468, 1.2560, 0.5605, 0.1564,\n",
       "                      1.2221, 0.0830, 0.3758, 0.7642, 0.3615, 1.0214, 0.7723, 0.8784, 0.9145,\n",
       "                      0.5628, 0.6673])),\n",
       "             ('decisions_q.0.bn1.num_batches_tracked', tensor(906)),\n",
       "             ('decisions_q.0.bn2.weight',\n",
       "              tensor([1.0588, 1.0773, 1.0676, 1.0823, 1.0701, 1.0600, 1.0700, 1.0654, 1.0611,\n",
       "                      1.1038, 1.0637, 1.0600, 1.1126, 1.0677, 1.0607, 1.0552, 1.0689, 1.0546,\n",
       "                      1.0580, 1.0953, 1.0765, 1.1047, 1.0558, 1.1172, 1.0665, 1.0518, 1.0569,\n",
       "                      1.0958, 1.0803, 1.0529, 1.0611, 1.0668, 1.1080, 1.0617, 1.0587, 1.0782,\n",
       "                      1.0542, 1.0991, 1.0501, 1.0600, 1.1277, 1.0638, 1.0760, 1.0552, 1.0748,\n",
       "                      1.1246, 1.0519, 1.0569, 1.0820, 1.0774, 1.0537, 1.0515, 1.0571, 1.1076,\n",
       "                      1.0524, 1.0776, 1.0785, 1.0581, 1.0684, 1.0849, 1.0505, 1.1160, 1.0563,\n",
       "                      1.0696, 1.0582, 1.1092, 1.0758, 1.0662, 1.0554, 1.0565, 1.0743, 1.1071,\n",
       "                      1.0765, 1.0611, 1.0496, 1.0504, 1.0633, 1.0565, 1.0745, 1.0674, 1.0571,\n",
       "                      1.1059, 1.0610, 1.0574, 1.0563, 1.0603, 1.0563, 1.0589, 1.0601, 1.0516,\n",
       "                      1.0629, 1.0830, 1.0567, 1.0522, 1.0602, 1.0586, 1.0591, 1.0550, 1.0498,\n",
       "                      1.1455, 1.0631, 1.0747, 1.2368, 1.0603, 1.1143, 1.0558, 1.0611, 1.0529,\n",
       "                      1.0620, 1.0725, 1.0728, 1.0585, 1.0569, 1.0532, 1.0668, 1.0517, 1.0544,\n",
       "                      1.0761, 1.1119, 1.0546, 1.0815, 1.0551, 1.0488, 1.0567, 1.0526, 1.0568,\n",
       "                      1.0692, 1.0611])),\n",
       "             ('decisions_q.0.bn2.bias',\n",
       "              tensor([0.0480, 0.0690, 0.0561, 0.0652, 0.0554, 0.0507, 0.0600, 0.0524, 0.0524,\n",
       "                      0.0812, 0.0524, 0.0511, 0.0956, 0.0484, 0.0497, 0.0405, 0.0596, 0.0421,\n",
       "                      0.0497, 0.0781, 0.0640, 0.0821, 0.0480, 0.0943, 0.0555, 0.0377, 0.0444,\n",
       "                      0.0768, 0.0664, 0.0420, 0.0532, 0.0568, 0.0909, 0.0513, 0.0442, 0.0644,\n",
       "                      0.0389, 0.0843, 0.0357, 0.0507, 0.1030, 0.0512, 0.0625, 0.0472, 0.0619,\n",
       "                      0.1014, 0.0382, 0.0453, 0.0622, 0.0654, 0.0396, 0.0396, 0.0430, 0.0921,\n",
       "                      0.0389, 0.0651, 0.0722, 0.0516, 0.0511, 0.0659, 0.0355, 0.0985, 0.0462,\n",
       "                      0.0530, 0.0431, 0.0908, 0.0622, 0.0485, 0.0402, 0.0428, 0.0571, 0.0885,\n",
       "                      0.0591, 0.0478, 0.0365, 0.0370, 0.0469, 0.0464, 0.0579, 0.0555, 0.0475,\n",
       "                      0.0873, 0.0472, 0.0450, 0.0481, 0.0449, 0.0483, 0.0492, 0.0435, 0.0384,\n",
       "                      0.0530, 0.0674, 0.0482, 0.0394, 0.0499, 0.0454, 0.0486, 0.0421, 0.0352,\n",
       "                      0.1150, 0.0541, 0.0613, 0.1957, 0.0511, 0.0921, 0.0473, 0.0473, 0.0398,\n",
       "                      0.0515, 0.0628, 0.0704, 0.0497, 0.0412, 0.0394, 0.0562, 0.0373, 0.0418,\n",
       "                      0.0612, 0.0759, 0.0409, 0.0547, 0.0413, 0.0368, 0.0441, 0.0391, 0.0487,\n",
       "                      0.0594, 0.0509])),\n",
       "             ('decisions_q.0.bn2.running_mean',\n",
       "              tensor([ 2.1450e-01,  2.8163e-01,  3.5052e-01,  2.9315e-01, -6.3161e-02,\n",
       "                       1.6886e-01,  1.9355e-01, -6.7907e-03,  2.6773e-02,  9.4740e-02,\n",
       "                       1.6306e-01,  3.4341e-01,  3.1056e-01,  6.1768e-02,  6.6035e-03,\n",
       "                      -1.5894e-01,  2.2870e-01, -2.6370e-01, -1.2151e-01, -1.6422e-01,\n",
       "                      -1.5760e-02,  2.0925e-02,  3.6804e-01,  1.2175e-02,  1.1174e-01,\n",
       "                      -1.1992e-01,  1.7174e-01, -3.8065e-02, -2.7380e-03,  6.5002e-02,\n",
       "                       2.9755e-01,  1.1178e-01,  1.5381e-01,  3.9759e-01, -6.5158e-02,\n",
       "                       1.5187e-01,  1.0495e-01,  2.7733e-05,  2.8241e-02,  5.0235e-01,\n",
       "                      -1.2713e-01,  3.6477e-02,  3.3076e-01,  2.0497e-01,  1.2834e-01,\n",
       "                       1.4554e-01, -4.3124e-02,  3.6338e-02,  2.0045e-02,  3.7569e-01,\n",
       "                      -1.4025e-02, -7.4970e-02,  2.0271e-01,  1.7133e-02, -7.5877e-02,\n",
       "                       2.1247e-01, -8.6214e-02,  9.0584e-02, -1.4617e-01,  1.4228e-01,\n",
       "                       3.9580e-02, -1.0585e-01,  2.3433e-01, -6.1954e-02, -2.0831e-01,\n",
       "                       2.7321e-01, -5.6268e-02,  1.3800e-01, -6.0890e-02, -2.4403e-01,\n",
       "                       1.6694e-01, -1.3962e-01,  1.1507e-01,  1.5642e-01,  8.9479e-03,\n",
       "                      -1.8275e-01, -9.4019e-02,  2.5845e-01, -6.3222e-02,  3.2281e-01,\n",
       "                       3.1934e-01,  2.5936e-01, -1.3656e-01,  4.8189e-02,  1.3154e-01,\n",
       "                       7.9656e-02,  1.2530e-01,  3.1788e-01, -2.3469e-02, -8.4010e-02,\n",
       "                       4.8004e-01,  1.1884e-01,  1.7870e-01,  2.3178e-01,  4.0376e-01,\n",
       "                      -2.3821e-01, -2.6826e-01,  3.8663e-01,  1.2620e-01, -4.8213e-02,\n",
       "                      -1.1291e-01,  6.8725e-02,  1.6926e-01,  2.1452e-01,  1.9589e-01,\n",
       "                       4.3697e-01, -1.3070e-01,  2.6355e-01,  2.2915e-01,  2.5214e-01,\n",
       "                      -1.9679e-01,  1.3798e-01,  3.3211e-01, -2.3011e-02, -1.3985e-01,\n",
       "                      -2.8720e-01,  1.0853e-01, -6.8087e-02,  2.2260e-01,  1.6092e-01,\n",
       "                       3.8265e-02, -2.9644e-01,  1.3006e-01, -2.7412e-01,  6.5652e-02,\n",
       "                       1.8541e-01,  4.3152e-01,  6.7828e-02])),\n",
       "             ('decisions_q.0.bn2.running_var',\n",
       "              tensor([1.1558, 1.1889, 1.4178, 1.2686, 1.8504, 0.9659, 1.1141, 1.5236, 0.8468,\n",
       "                      1.0005, 1.2117, 1.0265, 0.7901, 0.5221, 1.4125, 1.6895, 1.4998, 1.3530,\n",
       "                      0.9507, 1.3903, 1.2536, 1.2483, 0.6618, 0.9888, 1.0607, 1.3160, 0.9801,\n",
       "                      0.9376, 0.7564, 1.4137, 1.8343, 1.1549, 1.2030, 1.8833, 1.2168, 1.3021,\n",
       "                      1.7008, 0.7196, 1.0463, 1.2883, 1.5542, 0.8587, 1.1544, 1.2942, 1.3663,\n",
       "                      0.9619, 2.1041, 1.5183, 1.0575, 0.8938, 0.9782, 1.1313, 1.1370, 0.7445,\n",
       "                      0.9836, 0.6045, 1.2814, 1.4244, 0.8031, 1.3396, 1.0504, 1.0578, 1.8978,\n",
       "                      1.2414, 1.4391, 0.9943, 1.5737, 1.7138, 1.0660, 1.0855, 1.5649, 1.1445,\n",
       "                      0.7891, 1.4879, 1.2809, 1.8641, 1.1452, 1.3303, 0.9572, 1.1302, 1.6522,\n",
       "                      1.1972, 0.8768, 0.9744, 1.3760, 1.1111, 1.5115, 1.5499, 1.2126, 1.7778,\n",
       "                      1.1103, 1.8130, 0.7033, 0.9614, 0.8611, 0.7567, 0.8798, 1.6483, 1.6595,\n",
       "                      1.5214, 0.8613, 1.1605, 0.8004, 1.1155, 0.9522, 1.7485, 1.3176, 1.4026,\n",
       "                      0.8262, 0.9592, 1.0444, 1.1578, 1.7530, 1.5358, 1.2106, 1.6310, 1.6834,\n",
       "                      1.2080, 0.5140, 0.9892, 1.2121, 1.7313, 1.3362, 0.9373, 2.1335, 1.2261,\n",
       "                      0.8973, 1.4108])),\n",
       "             ('decisions_q.0.bn2.num_batches_tracked', tensor(906)),\n",
       "             ('decisions_q.0.dense3.weight',\n",
       "              tensor([[ 0.0936, -0.0732, -0.0711,  0.0563,  0.0673, -0.1081, -0.0712,  0.0792,\n",
       "                       -0.0999,  0.0690, -0.0947, -0.1016, -0.0610,  0.0393, -0.0953,  0.0861,\n",
       "                       -0.0897,  0.0982, -0.1050,  0.0561,  0.0603,  0.0552, -0.1003,  0.0599,\n",
       "                       -0.1200,  0.1183,  0.1052,  0.0617, -0.0725,  0.1324, -0.0853, -0.0719,\n",
       "                       -0.0598, -0.1071,  0.0736, -0.0714,  0.0987, -0.0628,  0.1223, -0.1317,\n",
       "                        0.0672,  0.1058, -0.0646, -0.1364, -0.0659,  0.0563,  0.1051,  0.1067,\n",
       "                        0.0574, -0.0625,  0.1091,  0.1004,  0.0889, -0.0581,  0.1165, -0.0649,\n",
       "                       -0.0589, -0.1034,  0.0639,  0.0576,  0.1188, -0.0673, -0.1214,  0.0801,\n",
       "                        0.1062,  0.0674, -0.0715,  0.0610,  0.1072,  0.1134,  0.0664,  0.0581,\n",
       "                        0.0716,  0.0820,  0.1311,  0.1309,  0.0830, -0.1249,  0.0610, -0.1358,\n",
       "                       -0.1338, -0.0528,  0.0738,  0.0998, -0.1108,  0.0695, -0.1031, -0.0983,\n",
       "                        0.0802,  0.1207, -0.1186,  0.0587, -0.1397,  0.0868, -0.1187,  0.0796,\n",
       "                        0.1066,  0.1286,  0.1210,  0.0547, -0.0963, -0.0751,  0.0588, -0.0936,\n",
       "                       -0.0516, -0.1301,  0.0773,  0.0938, -0.0889, -0.0814, -0.0496, -0.1036,\n",
       "                        0.0883,  0.1048, -0.1197,  0.1188,  0.0897,  0.0702,  0.0425,  0.1176,\n",
       "                        0.0629,  0.0953,  0.1108,  0.1246,  0.0996, -0.1377, -0.0882, -0.0929]])),\n",
       "             ('decisions_q.0.dense3.bias', tensor([-0.0539])),\n",
       "             ('decisions_q.1.dense1.weight',\n",
       "              tensor([[ 0.0715,  0.0353, -0.0132,  ...,  0.0805, -0.0219, -0.0823],\n",
       "                      [-0.0208, -0.0612, -0.0117,  ..., -0.0303, -0.0657,  0.0259],\n",
       "                      [ 0.0246, -0.0497, -0.0728,  ...,  0.0552, -0.0480,  0.0048],\n",
       "                      ...,\n",
       "                      [-0.0398, -0.0110, -0.0084,  ..., -0.0739, -0.0922, -0.0420],\n",
       "                      [ 0.1027,  0.0429,  0.0555,  ...,  0.0822,  0.0452, -0.0152],\n",
       "                      [-0.0322,  0.0708, -0.0427,  ..., -0.0314, -0.0740, -0.0149]])),\n",
       "             ('decisions_q.1.dense2.weight',\n",
       "              tensor([[-0.0744, -0.0529,  0.0259,  ...,  0.0552,  0.0141,  0.0373],\n",
       "                      [-0.0670,  0.0067,  0.0117,  ...,  0.0979, -0.0553,  0.0330],\n",
       "                      [-0.0633,  0.0700, -0.0408,  ..., -0.0487, -0.0060,  0.0597],\n",
       "                      ...,\n",
       "                      [-0.0322, -0.0424,  0.0245,  ..., -0.0500,  0.0684,  0.0963],\n",
       "                      [-0.0063, -0.0679,  0.0369,  ...,  0.0018,  0.0566,  0.0908],\n",
       "                      [-0.0225,  0.0417,  0.0635,  ...,  0.0552,  0.0010, -0.0565]])),\n",
       "             ('decisions_q.1.bn1.weight',\n",
       "              tensor([0.9988, 0.9828, 1.0127, 1.0050, 0.9809, 1.0046, 0.9767, 0.9879, 0.9838,\n",
       "                      0.9819, 1.0156, 0.9801, 0.9776, 1.0124, 1.0154, 0.9785, 0.9821, 1.0123,\n",
       "                      0.9935, 1.0081, 1.0068, 0.9984, 1.0071, 1.0006, 0.9968, 0.9820, 1.0098,\n",
       "                      1.0044, 0.9857, 0.9877, 1.0028, 0.9805, 0.9913, 0.9922, 1.0113, 1.0112,\n",
       "                      1.0055, 0.9913, 1.0064, 1.0032, 0.9849, 1.0083, 1.0136, 0.9813, 1.0158,\n",
       "                      1.0066, 1.0158, 0.9873, 0.9736, 0.9861, 1.0187, 1.0083, 0.9914, 1.0063,\n",
       "                      0.9969, 0.9915, 1.0102, 0.9967, 1.0019, 1.0099, 1.0205, 1.0171, 0.9804,\n",
       "                      1.0143, 0.9887, 0.9781, 0.9955, 1.0024, 1.0094, 1.0005, 1.0073, 0.9852,\n",
       "                      1.0192, 1.0171, 0.9869, 0.9928, 1.0019, 1.0163, 0.9940, 0.9783, 1.0231,\n",
       "                      0.9977, 1.0096, 0.9818, 0.9988, 1.0173, 0.9924, 0.9885, 1.0012, 1.0007,\n",
       "                      0.9803, 1.0039, 0.9921, 1.0028, 0.9903, 1.0197, 0.9845, 0.9860, 0.9808,\n",
       "                      1.0185, 1.0060, 1.0093, 1.0162, 1.0037, 1.0226, 1.0231, 1.0193, 0.9918,\n",
       "                      0.9937, 1.0047, 1.0097, 0.9960, 0.9992, 1.0122, 0.9930, 0.9990, 1.0153,\n",
       "                      0.9966, 0.9936, 1.0192, 0.9784, 1.0129, 0.9936, 1.0060, 0.9914, 1.0070,\n",
       "                      1.0077, 1.0050])),\n",
       "             ('decisions_q.1.bn1.bias',\n",
       "              tensor([ 8.1044e-03, -1.6603e-02,  2.5025e-02,  7.7261e-03, -1.8117e-02,\n",
       "                       2.9647e-02, -2.3732e-02,  8.1522e-04, -1.2272e-02, -3.3692e-03,\n",
       "                       2.7018e-02, -1.6579e-02, -2.2738e-02,  2.6301e-02,  1.5907e-02,\n",
       "                      -2.0828e-02, -1.2082e-02,  2.1536e-02,  8.4486e-03,  1.3588e-02,\n",
       "                       2.1786e-02, -9.5291e-03,  2.3479e-02,  2.3026e-02,  4.9961e-03,\n",
       "                      -1.7185e-02,  2.6297e-02,  2.5320e-02, -1.5497e-02, -5.6349e-03,\n",
       "                       1.3609e-02, -2.0873e-02,  1.5687e-03,  1.5920e-02,  2.1579e-02,\n",
       "                       1.5840e-02,  1.2002e-02,  1.8154e-02,  1.1803e-02,  1.5274e-02,\n",
       "                      -1.8813e-02,  2.4135e-02,  1.3298e-02, -1.7992e-02,  2.8480e-02,\n",
       "                       1.4159e-02,  2.0164e-02, -6.0427e-03, -1.6289e-02,  2.0946e-02,\n",
       "                       2.5423e-02,  1.5371e-02,  5.3798e-03,  2.6739e-02,  6.0273e-03,\n",
       "                      -1.5970e-03,  1.6994e-02,  1.1576e-02,  1.5726e-02,  1.1986e-02,\n",
       "                       2.4506e-02,  2.0855e-02,  1.3586e-03,  1.5802e-02, -5.4287e-03,\n",
       "                      -2.0591e-02,  1.1041e-02,  2.2930e-02,  1.8019e-02,  1.5744e-02,\n",
       "                       1.6619e-02, -1.5210e-02,  2.9446e-02,  2.2593e-02, -6.9949e-03,\n",
       "                      -5.0674e-03,  2.0554e-02,  1.8530e-02,  4.2935e-03, -2.0138e-02,\n",
       "                       2.7497e-02,  6.0717e-03,  2.9064e-02, -1.4068e-02,  2.0392e-02,\n",
       "                       2.1691e-02, -8.6200e-03, -1.2005e-02,  1.2104e-02,  1.2262e-02,\n",
       "                      -1.4262e-02,  2.0768e-02, -8.0972e-04,  2.7870e-02, -7.8043e-03,\n",
       "                       2.8382e-02, -1.0635e-02, -8.5220e-03, -1.7066e-02,  2.3732e-02,\n",
       "                       1.8445e-02,  2.4437e-02,  2.7740e-02,  2.3007e-02,  2.7183e-02,\n",
       "                       3.0079e-02,  2.5053e-02,  9.8462e-05,  1.2426e-02,  2.7976e-02,\n",
       "                       1.8713e-02,  1.3020e-02,  1.6317e-02,  1.7735e-02, -2.4710e-03,\n",
       "                       8.6474e-03,  1.8531e-02,  8.9452e-03,  2.3178e-02,  1.9951e-02,\n",
       "                      -1.6968e-02,  2.2824e-02,  7.3438e-03,  1.5630e-02,  9.0299e-03,\n",
       "                       2.1908e-02,  1.2444e-02,  1.2529e-02])),\n",
       "             ('decisions_q.1.bn1.running_mean',\n",
       "              tensor([-0.0936, -0.0880, -0.5714, -0.1026,  0.4156, -0.3970,  0.1653, -0.0041,\n",
       "                      -0.7333, -0.1000, -0.0745,  0.2184,  0.1504, -0.1052, -0.1068, -0.1026,\n",
       "                      -0.1046, -0.1784, -0.7805,  0.1141, -0.2236,  0.0090,  0.1198,  0.4333,\n",
       "                       0.6232, -0.4919, -0.5927, -0.0440,  0.3953, -0.2427, -0.1794,  0.1931,\n",
       "                       0.4116, -0.2879, -0.2427, -0.2915, -0.5197, -0.3381,  0.3686,  0.4411,\n",
       "                      -0.2738, -0.9704, -0.2632, -0.1145,  0.4643, -0.6077, -0.0603, -0.2397,\n",
       "                       0.1352, -0.5876,  0.4784,  0.1381, -0.1831, -0.3097, -0.0287, -0.4900,\n",
       "                      -0.2607, -0.1901,  0.0165, -0.1762,  0.4906, -0.4416, -0.1315,  0.3341,\n",
       "                      -0.3012,  0.1070, -0.0964, -0.4458,  0.0273, -0.0048,  0.0118,  0.3624,\n",
       "                      -0.4341, -0.6139, -0.5071, -0.5313, -0.1724, -0.0732, -0.3323, -0.3612,\n",
       "                      -0.0726, -0.6118, -0.0251, -0.1080, -0.1459,  0.4992,  0.1617,  0.0430,\n",
       "                      -0.2758, -0.4554,  0.2547, -0.1956,  0.2543, -0.2731, -0.3659, -0.3665,\n",
       "                       0.1276, -0.4043, -0.2546, -0.1341, -0.4176, -0.1641, -0.3861, -0.2374,\n",
       "                      -0.2866, -0.2717, -0.1274,  0.2205,  0.6147,  0.2079, -0.3799,  0.0751,\n",
       "                      -0.2926, -0.1216, -0.5413,  0.4308, -0.1682,  0.1255, -0.2737, -0.1867,\n",
       "                      -0.0236,  0.3433,  0.1326,  0.2132, -0.0025, -0.5405, -0.1799, -0.1402])),\n",
       "             ('decisions_q.1.bn1.running_var',\n",
       "              tensor([0.3337, 0.0188, 0.2060, 0.1122, 0.6730, 0.4889, 0.2672, 0.2828, 0.4909,\n",
       "                      0.0313, 0.0501, 0.3030, 0.2104, 0.3420, 0.0214, 0.3222, 0.1888, 0.0727,\n",
       "                      0.6698, 0.2537, 0.1595, 0.0209, 0.2093, 0.1792, 0.8057, 0.7199, 0.7334,\n",
       "                      0.2210, 0.5873, 0.2747, 0.4759, 0.3588, 0.2323, 0.2614, 0.3479, 0.2870,\n",
       "                      1.4666, 0.2205, 1.2507, 0.8399, 0.8894, 1.7946, 0.1379, 0.3854, 0.1380,\n",
       "                      0.2765, 0.3636, 0.3525, 0.3497, 0.5480, 1.0257, 0.4438, 0.2604, 0.4726,\n",
       "                      0.2771, 0.2249, 0.6545, 0.1448, 0.3366, 0.1845, 0.2294, 0.4146, 0.0479,\n",
       "                      0.1706, 0.3632, 0.2346, 0.1642, 0.5061, 0.0528, 0.1613, 0.2414, 1.1750,\n",
       "                      0.3493, 0.3635, 1.3203, 0.1636, 0.5009, 0.1789, 0.2153, 0.3166, 0.1944,\n",
       "                      0.8332, 0.1399, 0.7349, 0.3357, 0.6480, 0.6866, 0.3021, 0.0399, 0.8330,\n",
       "                      0.3691, 0.1611, 0.3135, 0.2259, 0.6932, 0.1424, 0.1808, 0.6172, 0.1112,\n",
       "                      0.0685, 0.2957, 0.1084, 0.1770, 0.5024, 0.0854, 0.2726, 0.1527, 0.2030,\n",
       "                      0.6426, 0.3969, 0.0230, 0.0546, 0.0909, 0.0725, 0.3582, 0.1630, 0.1847,\n",
       "                      0.0963, 0.7770, 0.2085, 0.1545, 0.1015, 0.0673, 0.1974, 0.0809, 0.2783,\n",
       "                      0.1587, 0.2045])),\n",
       "             ('decisions_q.1.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.1.bn2.weight',\n",
       "              tensor([1.0462, 1.0511, 1.0538, 1.0872, 1.0977, 1.0468, 1.0225, 1.0405, 1.0503,\n",
       "                      1.0214, 1.0871, 1.0666, 1.0460, 1.0517, 1.0478, 1.0441, 1.0464, 1.0478,\n",
       "                      1.0351, 1.1165, 1.0465, 1.0410, 1.0449, 1.0478, 1.0220, 1.0509, 1.0515,\n",
       "                      0.9902, 1.0510, 1.0442, 1.0621, 1.0455, 1.0477, 1.0563, 1.0383, 1.0475,\n",
       "                      1.0485, 1.0217, 1.0550, 1.0399, 1.0439, 1.0538, 1.0507, 1.0505, 1.0464,\n",
       "                      1.0528, 1.0283, 1.0432, 1.0503, 1.0479, 1.0496, 1.0574, 1.0429, 1.0524,\n",
       "                      1.0398, 1.0457, 1.0548, 1.0612, 1.0479, 1.0212, 1.0440, 1.0463, 1.0413,\n",
       "                      1.0058, 1.0026, 1.0459, 1.0197, 0.9981, 1.0059, 1.0403, 1.0275, 1.0578,\n",
       "                      1.0464, 1.0534, 1.0442, 1.0655, 1.0343, 1.0824, 1.0426, 1.0066, 1.0065,\n",
       "                      1.0501, 1.0532, 1.0514, 1.0434, 1.0473, 1.0536, 1.0401, 1.0494, 1.0534,\n",
       "                      0.9823, 1.0562, 1.0663, 1.0521, 1.0447, 1.0473, 1.0364, 1.0475, 1.0459,\n",
       "                      1.0388, 0.9927, 1.0463, 1.0008, 1.0527, 1.0613, 1.0416, 1.0062, 1.0470,\n",
       "                      1.0518, 1.0053, 0.9982, 1.0514, 1.0413, 1.0456, 1.0455, 1.0438, 1.0560,\n",
       "                      1.0567, 1.0511, 1.0460, 1.0533, 1.0462, 1.0569, 1.0603, 1.0894, 1.0480,\n",
       "                      1.0332, 1.0446])),\n",
       "             ('decisions_q.1.bn2.bias',\n",
       "              tensor([ 0.0377,  0.0439,  0.0447,  0.0686,  0.0601,  0.0388,  0.0116,  0.0345,\n",
       "                       0.0385,  0.0396,  0.0698,  0.0568,  0.0438,  0.0396,  0.0382,  0.0394,\n",
       "                       0.0423,  0.0389,  0.0424,  0.0836,  0.0387,  0.0554,  0.0384,  0.0382,\n",
       "                       0.0085,  0.0404,  0.0435, -0.0115,  0.0428,  0.0385,  0.0521,  0.0323,\n",
       "                       0.0362,  0.0503,  0.0258,  0.0410,  0.0384,  0.0102,  0.0475,  0.0354,\n",
       "                       0.0415,  0.0448,  0.0419,  0.0431,  0.0404,  0.0466,  0.0401,  0.0409,\n",
       "                       0.0382,  0.0416,  0.0348,  0.0468,  0.0308,  0.0419,  0.0378,  0.0383,\n",
       "                       0.0452,  0.0495,  0.0401,  0.0091,  0.0352,  0.0382,  0.0278,  0.0102,\n",
       "                       0.0128,  0.0383,  0.0351, -0.0010, -0.0032,  0.0380,  0.0119,  0.0484,\n",
       "                       0.0407,  0.0453,  0.0426,  0.0578,  0.0384,  0.0684,  0.0390,  0.0125,\n",
       "                      -0.0051,  0.0430,  0.0395,  0.0428,  0.0362,  0.0401,  0.0539,  0.0375,\n",
       "                       0.0407,  0.0428, -0.0158,  0.0403,  0.0613,  0.0478,  0.0404,  0.0417,\n",
       "                       0.0247,  0.0268,  0.0429,  0.0394, -0.0101,  0.0387, -0.0016,  0.0487,\n",
       "                       0.0575,  0.0389, -0.0042,  0.0380,  0.0355, -0.0030, -0.0055,  0.0403,\n",
       "                       0.0306,  0.0403,  0.0387,  0.0388,  0.0384,  0.0472,  0.0415,  0.0375,\n",
       "                       0.0411,  0.0383,  0.0475,  0.0494,  0.0669,  0.0388,  0.0252,  0.0396])),\n",
       "             ('decisions_q.1.bn2.running_mean',\n",
       "              tensor([ 0.1357,  0.1429,  0.1067, -0.1239, -0.5363,  0.0867, -0.0337,  0.1586,\n",
       "                      -0.1093,  0.3819,  0.2447, -0.1281,  0.3285,  0.0748, -0.2642,  0.0694,\n",
       "                       0.1424, -0.1406,  0.1357, -0.0633, -0.0819,  0.2780,  0.3358, -0.0212,\n",
       "                      -0.4272, -0.0490,  0.0818,  0.3570,  0.2968,  0.5530,  0.4225, -0.0945,\n",
       "                      -0.0360,  0.3067,  0.0627,  0.1475, -0.2458, -0.1877, -0.3439, -0.0099,\n",
       "                       0.1296,  0.0918,  0.0217,  0.1794,  0.1480,  0.1089, -0.1910, -0.0284,\n",
       "                      -0.0936, -0.1640, -0.2462,  0.0083, -0.0300,  0.1179, -0.1589,  0.2313,\n",
       "                       0.1501, -0.2271,  0.2346, -0.0422,  0.0159, -0.1940, -0.4357, -0.0289,\n",
       "                       0.1866, -0.1179,  0.0931,  0.1927,  0.0834,  0.2693, -0.1465,  0.1024,\n",
       "                       0.0854,  0.4222,  0.2368,  0.0993,  0.3319,  0.0901, -0.0084,  0.2720,\n",
       "                      -0.1046,  0.0926, -0.0619, -0.0198,  0.3979,  0.0344,  0.1612,  0.1841,\n",
       "                      -0.0676, -0.0674, -0.2779,  0.1292,  0.4606, -0.0072,  0.2435,  0.1612,\n",
       "                      -0.0695, -0.2073,  0.3351,  0.2403, -0.2971, -0.1530,  0.0813,  0.1940,\n",
       "                       0.1215, -0.0684, -0.1293,  0.0178, -0.1563, -0.1071, -0.3052, -0.0856,\n",
       "                      -0.0625,  0.2135, -0.2871,  0.2780, -0.1115, -0.1612, -0.0265, -0.0492,\n",
       "                      -0.2899, -0.0953,  0.1648,  0.0659, -0.2109, -0.2918, -0.2390, -0.2627])),\n",
       "             ('decisions_q.1.bn2.running_var',\n",
       "              tensor([1.2292, 0.5715, 1.2585, 0.7827, 0.8590, 0.8034, 0.8412, 0.6260, 0.8792,\n",
       "                      0.6155, 1.5397, 1.4618, 1.1048, 0.8451, 1.2504, 0.4898, 0.3973, 0.7839,\n",
       "                      0.6084, 0.4432, 0.8092, 0.6459, 0.6711, 1.3988, 0.8123, 0.7052, 1.2333,\n",
       "                      0.8049, 0.3337, 1.1857, 0.9773, 1.2403, 0.4827, 0.4611, 0.6346, 0.8027,\n",
       "                      0.5290, 0.7918, 0.6158, 0.3760, 0.6343, 0.8553, 0.9384, 0.5624, 0.5578,\n",
       "                      0.7951, 0.7581, 0.5160, 1.0178, 0.4255, 0.3690, 0.7713, 1.3008, 1.0174,\n",
       "                      0.4934, 0.5779, 0.6827, 1.4385, 0.6088, 0.5166, 0.5203, 0.5790, 0.9637,\n",
       "                      1.7948, 0.4133, 0.3675, 0.7606, 0.5711, 0.7129, 0.2608, 0.4674, 1.0288,\n",
       "                      0.6771, 0.8092, 0.4559, 0.4764, 0.7412, 0.4073, 0.8586, 0.6235, 1.0864,\n",
       "                      1.1306, 0.7086, 0.6882, 1.4619, 0.2699, 1.0567, 0.5381, 0.7401, 0.6695,\n",
       "                      0.4837, 0.6061, 1.0760, 0.7931, 0.8532, 0.6103, 1.1825, 0.6306, 1.0791,\n",
       "                      0.5038, 0.6596, 1.2118, 0.8928, 0.4665, 0.5357, 0.5974, 0.8223, 0.9478,\n",
       "                      0.9759, 0.9057, 0.8181, 1.7702, 0.9756, 1.0500, 0.7056, 0.6192, 0.6745,\n",
       "                      0.6941, 0.7214, 0.8377, 1.1845, 0.8072, 0.9713, 0.5189, 1.0255, 0.6772,\n",
       "                      0.1889, 0.5363])),\n",
       "             ('decisions_q.1.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.1.dense3.weight',\n",
       "              tensor([[-0.1192, -0.0633, -0.0841,  0.0467,  0.0384, -0.1096,  0.0645, -0.1214,\n",
       "                        0.1166, -0.0330,  0.0486,  0.0561, -0.0894,  0.1166,  0.1065, -0.0990,\n",
       "                       -0.0654,  0.1002, -0.0844,  0.0453, -0.1251, -0.0674, -0.1250,  0.1185,\n",
       "                        0.0299,  0.1110, -0.0795, -0.0527, -0.0668, -0.1278, -0.0520,  0.1261,\n",
       "                        0.0612, -0.0541,  0.0750, -0.0832,  0.1113,  0.0993,  0.0557, -0.1102,\n",
       "                       -0.0723, -0.0936,  0.1058, -0.0930, -0.1167, -0.0600, -0.0494, -0.0587,\n",
       "                        0.1104,  0.0728,  0.0914,  0.0914,  0.1078, -0.0963,  0.1080, -0.1126,\n",
       "                       -0.0726,  0.0735, -0.1204,  0.0947,  0.0917,  0.1056,  0.1117, -0.0831,\n",
       "                       -0.0178,  0.1221, -0.0483, -0.0463,  0.0702, -0.1130,  0.0462,  0.0693,\n",
       "                       -0.0981, -0.0857, -0.0687, -0.0422, -0.0975, -0.0438, -0.1120, -0.0591,\n",
       "                        0.0387, -0.0904,  0.0881,  0.0727, -0.1220,  0.0310, -0.0723, -0.1203,\n",
       "                       -0.0732,  0.0814,  0.0132,  0.0548, -0.0809, -0.0629, -0.1270, -0.0800,\n",
       "                        0.1053,  0.0461, -0.0553, -0.1147,  0.0124,  0.1148, -0.0880, -0.0859,\n",
       "                       -0.0484, -0.0879,  0.0706,  0.0933,  0.0796,  0.0897,  0.0231,  0.0885,\n",
       "                        0.0753, -0.0959,  0.1014, -0.1087,  0.0733,  0.0565,  0.0838,  0.1283,\n",
       "                        0.0809, -0.1117,  0.0782,  0.0529,  0.0479,  0.1107,  0.0975,  0.0915]])),\n",
       "             ('decisions_q.1.dense3.bias', tensor([0.0433])),\n",
       "             ('decisions_q.2.dense1.weight',\n",
       "              tensor([[-0.0089,  0.0321, -0.0420,  ...,  0.0633,  0.0694, -0.0871],\n",
       "                      [-0.0196, -0.0945,  0.0549,  ...,  0.0133,  0.0560, -0.0009],\n",
       "                      [-0.0627, -0.0416,  0.0451,  ...,  0.0114,  0.0918, -0.0211],\n",
       "                      ...,\n",
       "                      [-0.0363, -0.0641,  0.0577,  ...,  0.0865,  0.0192,  0.0858],\n",
       "                      [ 0.0718, -0.0026,  0.0035,  ..., -0.0634,  0.0534, -0.0641],\n",
       "                      [ 0.0078,  0.0721, -0.0516,  ...,  0.0217, -0.0349,  0.0595]])),\n",
       "             ('decisions_q.2.dense2.weight',\n",
       "              tensor([[-0.0224,  0.0312,  0.0018,  ..., -0.0549,  0.0214,  0.0137],\n",
       "                      [-0.0493,  0.0825, -0.0605,  ..., -0.0343,  0.0284, -0.0032],\n",
       "                      [ 0.0906, -0.0146, -0.0169,  ..., -0.0853,  0.0112, -0.0068],\n",
       "                      ...,\n",
       "                      [ 0.0653, -0.0342, -0.0307,  ...,  0.0713, -0.0290, -0.0049],\n",
       "                      [ 0.0518,  0.0486, -0.0663,  ...,  0.0102,  0.0391,  0.0315],\n",
       "                      [ 0.0552, -0.0166,  0.0122,  ..., -0.0488,  0.0008,  0.0527]])),\n",
       "             ('decisions_q.2.bn1.weight',\n",
       "              tensor([1.0012, 0.9818, 1.0097, 0.9772, 1.0257, 0.9969, 1.0064, 1.0103, 1.0024,\n",
       "                      1.0038, 0.9793, 1.0154, 0.9910, 1.0051, 0.9808, 0.9866, 1.0097, 1.0105,\n",
       "                      0.9910, 0.9886, 0.9955, 1.0210, 0.9897, 1.0176, 0.9801, 0.9883, 1.0145,\n",
       "                      1.0001, 0.9880, 1.0116, 0.9802, 0.9848, 1.0125, 1.0155, 1.0139, 0.9928,\n",
       "                      1.0150, 1.0045, 1.0107, 0.9903, 1.0218, 1.0121, 1.0048, 1.0164, 1.0219,\n",
       "                      1.0127, 0.9863, 1.0047, 1.0047, 1.0124, 0.9804, 1.0115, 1.0171, 0.9814,\n",
       "                      0.9861, 0.9865, 0.9819, 0.9802, 0.9876, 0.9923, 0.9957, 1.0204, 1.0180,\n",
       "                      1.0135, 0.9855, 1.0000, 0.9881, 0.9822, 1.0148, 1.0168, 0.9869, 1.0160,\n",
       "                      1.0000, 1.0093, 1.0148, 1.0097, 0.9884, 0.9843, 0.9838, 0.9845, 0.9833,\n",
       "                      1.0181, 1.0010, 0.9870, 0.9840, 0.9990, 0.9791, 0.9794, 1.0174, 0.9812,\n",
       "                      0.9832, 0.9936, 1.0131, 0.9903, 1.0158, 0.9875, 0.9991, 1.0205, 1.0185,\n",
       "                      0.9955, 0.9957, 0.9874, 0.9828, 0.9804, 0.9832, 1.0159, 1.0208, 1.0124,\n",
       "                      0.9898, 1.0151, 0.9857, 0.9848, 1.0073, 0.9791, 1.0166, 1.0132, 1.0148,\n",
       "                      1.0147, 0.9874, 1.0135, 0.9910, 1.0109, 0.9961, 1.0007, 0.9906, 0.9845,\n",
       "                      0.9928, 0.9996])),\n",
       "             ('decisions_q.2.bn1.bias',\n",
       "              tensor([ 0.0098, -0.0028,  0.0171, -0.0258,  0.0232,  0.0028,  0.0179,  0.0186,\n",
       "                       0.0229,  0.0196, -0.0122,  0.0178, -0.0028,  0.0250, -0.0124,  0.0112,\n",
       "                       0.0228,  0.0104, -0.0018,  0.0029, -0.0051,  0.0213, -0.0021,  0.0212,\n",
       "                      -0.0176, -0.0091,  0.0171,  0.0082,  0.0026,  0.0184, -0.0144, -0.0139,\n",
       "                       0.0207,  0.0220,  0.0213,  0.0188,  0.0208,  0.0097,  0.0190, -0.0028,\n",
       "                       0.0296,  0.0191,  0.0098,  0.0242,  0.0209,  0.0224, -0.0037,  0.0197,\n",
       "                       0.0095,  0.0086, -0.0184,  0.0126,  0.0182, -0.0183, -0.0079, -0.0085,\n",
       "                      -0.0152, -0.0179,  0.0022,  0.0008,  0.0187,  0.0214,  0.0255,  0.0169,\n",
       "                      -0.0100,  0.0099, -0.0091, -0.0174,  0.0179,  0.0199, -0.0102,  0.0255,\n",
       "                       0.0063,  0.0140,  0.0240,  0.0225,  0.0159, -0.0116, -0.0206, -0.0193,\n",
       "                      -0.0061,  0.0210,  0.0078, -0.0148, -0.0071,  0.0076, -0.0220, -0.0251,\n",
       "                       0.0224, -0.0150,  0.0169, -0.0064,  0.0152, -0.0029,  0.0233,  0.0031,\n",
       "                       0.0225,  0.0217,  0.0258, -0.0050,  0.0035, -0.0129, -0.0105, -0.0195,\n",
       "                      -0.0210,  0.0205,  0.0216,  0.0222, -0.0072,  0.0169, -0.0101, -0.0187,\n",
       "                       0.0280, -0.0139,  0.0213,  0.0196,  0.0199,  0.0207,  0.0007,  0.0212,\n",
       "                      -0.0140,  0.0069,  0.0079,  0.0129,  0.0141,  0.0081,  0.0155,  0.0147])),\n",
       "             ('decisions_q.2.bn1.running_mean',\n",
       "              tensor([-0.2040,  0.5908, -0.3112,  0.0238, -0.1801,  0.1662,  0.3533, -0.1464,\n",
       "                      -0.2359, -0.4201, -0.2945, -0.6633, -0.0803,  0.2070, -0.2445,  0.8706,\n",
       "                       0.1038,  0.0317,  0.2142,  0.0082, -0.5254, -0.0290, -0.3365, -0.3505,\n",
       "                       0.2848, -0.0385, -0.4929, -0.1243, -0.1434,  0.4389, -0.0237, -0.3376,\n",
       "                      -0.0827, -0.4442,  0.7410,  0.3173,  0.0103,  0.2269,  0.2427, -0.1418,\n",
       "                      -0.4804, -0.5503, -0.5086, -0.2238, -0.0891,  0.6117, -0.2430, -0.5307,\n",
       "                      -0.4154,  0.0952, -0.3391,  0.0657,  0.0701, -0.1702, -0.2503, -0.3540,\n",
       "                      -0.2821, -0.6735,  0.4238, -0.1514, -0.2420, -0.4103,  0.5795, -0.1648,\n",
       "                      -0.7194, -0.0968,  0.7472, -0.7687,  0.2203, -0.3958,  0.0924, -0.2120,\n",
       "                      -0.4457, -0.3819, -0.2326,  0.5325, -0.0354, -0.1934,  0.3767, -0.5764,\n",
       "                       0.2784,  0.2585, -0.2797, -0.1762, -0.2771, -0.4787,  0.1772, -0.4482,\n",
       "                      -0.1069,  0.1320,  0.4776, -0.1259, -0.2579,  0.2485, -0.2381,  0.5987,\n",
       "                       0.1069, -0.1284, -0.1019, -0.7890, -0.0324, -0.6111,  0.4447, -0.1121,\n",
       "                      -0.7702, -0.2388, -0.5167, -0.4886, -0.1246, -0.1573,  0.1439, -0.4552,\n",
       "                       0.1709,  0.1371,  0.1029, -0.0257,  0.1492, -0.2658,  0.1965,  0.1357,\n",
       "                       0.4604, -0.1993, -0.1904,  0.2114,  0.6230, -0.1363,  0.0999,  0.0842])),\n",
       "             ('decisions_q.2.bn1.running_var',\n",
       "              tensor([0.2354, 0.7403, 0.0978, 0.1022, 0.0674, 0.2887, 0.4381, 0.1120, 0.3570,\n",
       "                      0.4468, 0.3370, 0.2122, 0.0391, 0.3300, 0.3278, 1.4355, 0.3602, 0.0753,\n",
       "                      0.1122, 0.1350, 0.5884, 0.0906, 0.1861, 0.2406, 0.1768, 0.1216, 0.3843,\n",
       "                      0.4200, 0.2224, 0.7484, 0.1266, 0.7898, 0.1896, 0.1287, 1.6501, 0.2730,\n",
       "                      0.1273, 0.4852, 0.2011, 0.3382, 0.2274, 0.2240, 0.6955, 0.2291, 0.1247,\n",
       "                      0.5104, 0.4169, 0.8389, 0.3200, 0.1390, 0.9755, 0.1469, 0.0521, 0.2430,\n",
       "                      0.3450, 0.4623, 0.2031, 0.6858, 0.3925, 0.4392, 0.1138, 0.1424, 0.2131,\n",
       "                      0.1856, 0.5109, 0.0301, 1.2999, 0.8420, 0.3144, 0.2158, 0.0656, 0.1042,\n",
       "                      0.7646, 0.5404, 0.0534, 0.9213, 0.0331, 0.3431, 0.1837, 0.5920, 0.3803,\n",
       "                      0.0571, 0.0899, 0.6177, 0.3957, 0.3871, 0.3384, 0.7510, 0.0638, 0.1686,\n",
       "                      0.6604, 0.1848, 0.6378, 0.2702, 0.0590, 0.2430, 0.0704, 0.0222, 0.0889,\n",
       "                      1.0609, 0.8054, 0.2457, 0.3213, 0.3027, 0.3589, 0.1788, 0.3511, 0.4445,\n",
       "                      0.2764, 0.1244, 0.1932, 1.5016, 0.0693, 0.0582, 0.0657, 0.1356, 0.1327,\n",
       "                      0.2321, 0.3614, 0.1555, 0.7938, 0.1966, 0.5238, 0.4034, 0.3111, 0.0612,\n",
       "                      0.1058, 0.3815])),\n",
       "             ('decisions_q.2.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.2.bn2.weight',\n",
       "              tensor([1.0538, 1.0148, 1.0537, 1.0551, 1.0518, 1.0383, 1.0472, 0.9950, 1.0503,\n",
       "                      1.0213, 1.0569, 1.0515, 1.0478, 1.0582, 1.0067, 1.0490, 1.0534, 1.0457,\n",
       "                      1.0496, 1.0418, 1.0627, 1.0506, 1.0381, 1.0509, 1.0474, 1.0468, 1.0686,\n",
       "                      1.0442, 1.0373, 1.0496, 1.0332, 1.0595, 1.0476, 1.0389, 1.1075, 0.9933,\n",
       "                      0.9939, 1.0476, 1.0460, 1.0672, 1.0588, 1.0472, 1.0526, 1.0481, 1.0524,\n",
       "                      1.0683, 1.0501, 1.0501, 1.0460, 1.0468, 1.0703, 1.0634, 1.0612, 1.0472,\n",
       "                      1.0640, 1.0435, 1.0915, 1.0485, 1.0509, 0.9969, 1.0447, 1.0505, 1.0444,\n",
       "                      1.0446, 1.0561, 1.0507, 1.0653, 1.0180, 1.1837, 1.0609, 1.0459, 1.0452,\n",
       "                      1.1047, 1.0584, 1.0461, 0.9939, 1.0108, 1.0207, 1.0460, 1.0576, 1.0469,\n",
       "                      1.0455, 0.9989, 1.0884, 1.0695, 1.0396, 1.0475, 1.0685, 1.0502, 1.0593,\n",
       "                      1.0445, 1.0516, 1.0477, 1.0560, 1.0490, 1.0484, 1.0540, 1.0423, 1.0873,\n",
       "                      1.0972, 0.9976, 1.0450, 1.0563, 1.0983, 1.0503, 1.1368, 1.0462, 1.0466,\n",
       "                      1.0506, 1.0452, 1.0491, 1.0477, 1.0454, 1.0446, 1.0455, 1.0090, 1.0824,\n",
       "                      1.0468, 1.0453, 1.0449, 1.0602, 1.1035, 1.0468, 1.0741, 1.0121, 1.0481,\n",
       "                      1.0824, 1.0571])),\n",
       "             ('decisions_q.2.bn2.bias',\n",
       "              tensor([ 0.0492,  0.0006,  0.0472,  0.0523,  0.0521,  0.0237,  0.0319, -0.0138,\n",
       "                       0.0417,  0.0082,  0.0518,  0.0431,  0.0406,  0.0521,  0.0094,  0.0430,\n",
       "                       0.0460,  0.1064,  0.0426,  0.0336,  0.0551,  0.0359,  0.0225,  0.0382,\n",
       "                       0.0431,  0.0425,  0.0441,  0.0498,  0.0201,  0.0422,  0.0149,  0.0530,\n",
       "                       0.0353,  0.0240,  0.0976, -0.0017, -0.0170,  0.0342,  0.0443,  0.0477,\n",
       "                       0.0197,  0.0441,  0.0393,  0.0355,  0.0481,  0.0452,  0.0420,  0.0442,\n",
       "                       0.0332,  0.0345,  0.0389,  0.0572,  0.0350,  0.0334,  0.0446,  0.0331,\n",
       "                       0.0848,  0.0379,  0.0500, -0.0125,  0.0407,  0.0467,  0.0333,  0.0335,\n",
       "                       0.0420,  0.0367,  0.0712,  0.0037,  0.1373,  0.0395,  0.0423,  0.0418,\n",
       "                       0.1003,  0.0536,  0.0450, -0.0131,  0.0007,  0.0017,  0.0341,  0.0587,\n",
       "                       0.0342,  0.0339, -0.0110,  0.0881,  0.0614,  0.0264,  0.0354,  0.0453,\n",
       "                       0.0453,  0.0268,  0.0264,  0.0393,  0.0414,  0.0397,  0.0305,  0.0298,\n",
       "                       0.0341,  0.0431,  0.0641,  0.1003, -0.0114,  0.0234,  0.0485,  0.0898,\n",
       "                       0.0310,  0.1099,  0.0419,  0.0392,  0.0466,  0.0338,  0.0373,  0.0433,\n",
       "                       0.0393,  0.0351,  0.0342, -0.0038,  0.0566,  0.0460,  0.0332,  0.0423,\n",
       "                       0.0440,  0.0985,  0.0413,  0.0532, -0.0022,  0.0315,  0.0531,  0.0495])),\n",
       "             ('decisions_q.2.bn2.running_mean',\n",
       "              tensor([-0.2569, -0.1401,  0.1461,  0.0010, -0.2079, -0.1799, -0.0766,  0.1831,\n",
       "                      -0.0673,  0.0362, -0.0774, -0.0916,  0.3835,  0.0360,  0.0505,  0.3389,\n",
       "                       0.1385,  0.2292,  0.2598, -0.1378,  0.1267,  0.1790, -0.1940,  0.0023,\n",
       "                       0.1113,  0.1238, -0.1406,  0.0713,  0.1655, -0.2410, -0.1974,  0.4188,\n",
       "                       0.0074, -0.2130,  0.2551,  0.2812, -0.1858, -0.0370,  0.1363, -0.0276,\n",
       "                      -0.3591,  0.2727, -0.0505, -0.1080,  0.0257, -0.2115, -0.1118,  0.2287,\n",
       "                      -0.1222, -0.2739, -0.0850,  0.2773,  0.2878, -0.3203, -0.1021, -0.2041,\n",
       "                      -0.0809, -0.0373,  0.0081,  0.2161,  0.1774, -0.0396, -0.2929,  0.2629,\n",
       "                       0.0054,  0.2405, -0.1949,  0.2591, -0.0475,  0.0966,  0.0255,  0.1817,\n",
       "                       0.3047, -0.0937,  0.4296, -0.0658, -0.0775, -0.0693, -0.3726,  0.0422,\n",
       "                      -0.0936, -0.2035,  0.2430,  0.1026,  0.0284, -0.1405, -0.2204, -0.0609,\n",
       "                       0.1886,  0.0617,  0.0683, -0.1018,  0.3156,  0.1050,  0.2225, -0.1210,\n",
       "                       0.0020,  0.1242, -0.2070,  0.4443,  0.4436, -0.1902,  0.4156,  0.4899,\n",
       "                      -0.4136, -0.2367,  0.0713,  0.0656,  0.1339, -0.1099, -0.0697,  0.0593,\n",
       "                      -0.0074, -0.1702, -0.3777,  0.3517, -0.1716,  0.4276, -0.1461,  0.0962,\n",
       "                      -0.2336, -0.0537,  0.1271, -0.0845, -0.0202,  0.0931,  0.1716, -0.0281])),\n",
       "             ('decisions_q.2.bn2.running_var',\n",
       "              tensor([0.9853, 0.6614, 0.5756, 0.7134, 0.7924, 0.2263, 0.4164, 0.1394, 0.7488,\n",
       "                      0.8020, 0.5524, 0.7040, 0.4164, 0.4888, 0.7688, 0.3470, 1.1938, 0.5133,\n",
       "                      0.4567, 0.7369, 0.7460, 1.0688, 0.6804, 1.0135, 0.4032, 0.7933, 0.8799,\n",
       "                      0.8827, 0.3964, 0.8346, 0.5390, 0.4589, 0.5733, 0.3385, 0.2996, 1.2407,\n",
       "                      0.6726, 0.8870, 0.7544, 0.6105, 0.5707, 0.4714, 0.9675, 0.7475, 0.5277,\n",
       "                      0.4838, 0.8267, 0.3749, 0.6586, 0.5611, 0.5428, 0.1984, 0.7115, 0.8658,\n",
       "                      0.6469, 0.5098, 0.5355, 0.6613, 0.5736, 1.2475, 0.3368, 0.6347, 0.6574,\n",
       "                      1.8307, 0.6238, 0.9687, 0.9566, 0.8733, 0.2948, 1.7457, 0.7007, 0.6629,\n",
       "                      0.7690, 1.0055, 0.3623, 0.8068, 0.8400, 0.5596, 0.3872, 0.3861, 0.7720,\n",
       "                      0.6740, 0.9189, 0.5695, 2.1172, 0.3686, 0.3469, 0.9696, 0.5824, 0.9179,\n",
       "                      0.8654, 1.2832, 0.6840, 1.1062, 0.6282, 0.2657, 0.5006, 0.5673, 0.8546,\n",
       "                      1.1783, 0.8601, 0.5191, 0.4304, 0.6250, 0.4276, 0.7453, 0.4063, 0.5180,\n",
       "                      0.3959, 0.4973, 0.6365, 0.5032, 0.7280, 0.3364, 0.5301, 0.8290, 0.6621,\n",
       "                      0.3084, 0.7382, 0.4496, 0.9912, 1.7335, 0.2044, 0.5320, 0.5860, 0.7881,\n",
       "                      1.0443, 0.9114])),\n",
       "             ('decisions_q.2.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decisions_q.2.dense3.weight',\n",
       "              tensor([[-0.0921,  0.1018, -0.0799, -0.0871, -0.0764,  0.0955,  0.0766,  0.0137,\n",
       "                       -0.1197,  0.0975, -0.0858, -0.1074, -0.1309, -0.0584, -0.0311, -0.1022,\n",
       "                       -0.0840, -0.0353, -0.0965,  0.1087, -0.0526,  0.0689,  0.1178,  0.0632,\n",
       "                       -0.0852, -0.1062,  0.0481, -0.1186,  0.0778, -0.1327,  0.0905, -0.0551,\n",
       "                        0.1023,  0.1084, -0.0431, -0.0613,  0.0692,  0.0888, -0.0682,  0.0473,\n",
       "                        0.0433, -0.0702,  0.0770,  0.0879, -0.0655,  0.0504, -0.1020, -0.0786,\n",
       "                        0.1249,  0.0928,  0.0539, -0.0500,  0.0624,  0.1323,  0.0520,  0.1032,\n",
       "                       -0.0708,  0.0865, -0.0620,  0.0773, -0.1167, -0.0828,  0.1129,  0.1248,\n",
       "                        0.0550,  0.1198, -0.0620,  0.0914,  0.0445,  0.0504, -0.0891, -0.1210,\n",
       "                       -0.0406, -0.0720, -0.0707,  0.0432,  0.0371,  0.0533,  0.1057, -0.0577,\n",
       "                        0.1017,  0.1280,  0.0367, -0.0567, -0.0548,  0.1051,  0.0905,  0.0534,\n",
       "                       -0.0808,  0.0307,  0.1287,  0.0566, -0.1179,  0.0599,  0.1021,  0.0536,\n",
       "                        0.0498, -0.1159,  0.0416, -0.0479,  0.0253,  0.0779, -0.0681, -0.0381,\n",
       "                        0.0620,  0.0547, -0.1038, -0.1044, -0.0687,  0.1136,  0.0740, -0.0978,\n",
       "                       -0.1272,  0.0984,  0.0999,  0.0939,  0.0448, -0.0726,  0.1130, -0.0909,\n",
       "                        0.0508, -0.0491, -0.1091,  0.0460,  0.0440,  0.1128,  0.0483, -0.0621]])),\n",
       "             ('decisions_q.2.dense3.bias', tensor([-0.0511])),\n",
       "             ('decoders.3.dense1.weight',\n",
       "              tensor([[-0.1467,  0.0946,  0.1135,  ...,  0.1537,  0.0462, -0.1782],\n",
       "                      [-0.0054,  0.0177,  0.1177,  ..., -0.1505, -0.0175, -0.0133],\n",
       "                      [ 0.1013,  0.0242,  0.0475,  ...,  0.0532,  0.1581,  0.0034],\n",
       "                      ...,\n",
       "                      [-0.0334,  0.1788,  0.1623,  ...,  0.1268, -0.1691,  0.0647],\n",
       "                      [-0.0808, -0.1080, -0.0358,  ...,  0.0862, -0.0312, -0.0390],\n",
       "                      [ 0.0178, -0.0158,  0.1688,  ...,  0.0913,  0.0565,  0.0521]])),\n",
       "             ('decoders.3.bn1.weight',\n",
       "              tensor([1.0109, 1.0187, 0.9982, 0.9791, 0.9887, 1.0071, 0.9939, 0.9818, 0.9885,\n",
       "                      0.9804, 0.9887, 1.0029, 1.0101, 0.9838, 1.0245, 1.0144, 1.0037, 1.0070,\n",
       "                      0.9959, 0.9984, 1.0059, 1.0042, 1.0145, 1.0241, 1.0040, 0.9985, 0.9718,\n",
       "                      1.0000, 0.9948, 0.9850, 0.9909, 0.9974, 1.0033, 0.9924, 1.0230, 0.9935,\n",
       "                      0.9794, 1.0070, 0.9871, 0.9855, 0.9901, 0.9822, 1.0211, 1.0096, 0.9957,\n",
       "                      0.9825, 0.9900, 0.9880, 0.9960, 0.9927, 1.0116, 0.9941, 1.0133, 0.9881,\n",
       "                      1.0071, 0.9808, 1.0180, 0.9824, 1.0086, 0.9941, 1.0069, 0.9880, 0.9883,\n",
       "                      1.0075, 1.0175, 0.9915, 0.9879, 1.0006, 0.9787, 0.9898, 1.0151, 0.9860,\n",
       "                      0.9784, 1.0036, 0.9830, 0.9961, 1.0090, 1.0120, 0.9860, 0.9969, 0.9690,\n",
       "                      1.0304, 0.9988, 0.9952, 0.9869, 0.9923, 0.9986, 1.0031, 1.0052, 1.0073,\n",
       "                      1.0032, 1.0252, 1.0005, 0.9877, 0.9835, 0.9964, 1.0128, 1.0119, 1.0117,\n",
       "                      1.0122, 1.0108, 1.0076, 0.9860, 1.0006, 0.9946, 0.9960, 1.0137, 1.0029,\n",
       "                      1.0004, 0.9923, 1.0056, 0.9811, 0.9946, 1.0011, 1.0055, 0.9903, 0.9965,\n",
       "                      0.9906, 0.9878, 0.9988, 1.0063, 1.0212, 0.9959, 0.9813, 0.9958, 1.0075,\n",
       "                      1.0206, 0.9861])),\n",
       "             ('decoders.3.bn1.bias',\n",
       "              tensor([ 2.0251e-03,  2.1467e-02,  5.0430e-03,  5.0406e-04, -9.4834e-03,\n",
       "                       1.5173e-03,  1.7173e-02, -1.5031e-02,  4.2269e-03, -2.6889e-03,\n",
       "                      -4.3619e-06,  1.5879e-02,  1.6978e-02, -1.3906e-02, -2.7418e-03,\n",
       "                      -2.4608e-03,  1.8444e-02,  2.2607e-02, -4.8108e-03, -2.5738e-03,\n",
       "                       1.7357e-03, -8.9000e-03,  4.6789e-03,  3.1487e-03,  6.7012e-03,\n",
       "                       1.5435e-02, -3.0684e-02,  1.1225e-02,  6.1696e-05, -1.0280e-02,\n",
       "                      -5.2901e-03, -1.2969e-03,  3.2091e-02, -4.3612e-03,  1.1571e-03,\n",
       "                       5.8389e-04, -7.8831e-03,  1.0732e-02,  6.0840e-03, -8.4803e-03,\n",
       "                      -6.4439e-03, -1.0494e-02,  1.1305e-03, -7.0316e-03,  5.4779e-03,\n",
       "                      -1.1740e-02,  3.9275e-03, -4.7947e-03, -2.3895e-03,  3.9628e-03,\n",
       "                       1.0757e-03, -5.4026e-03,  1.4659e-02, -3.4141e-03,  1.8529e-02,\n",
       "                      -1.2742e-02, -4.2479e-03, -1.2929e-02,  1.2531e-02, -5.4230e-04,\n",
       "                       2.6811e-02, -9.7804e-03, -6.6949e-03,  4.7071e-03,  3.6981e-03,\n",
       "                       3.1832e-03, -1.1890e-02,  1.9711e-03, -3.4852e-03,  1.3780e-02,\n",
       "                       1.2443e-04, -7.5140e-03, -7.1943e-03,  1.3443e-02, -2.5038e-03,\n",
       "                       1.3136e-02,  1.1138e-02,  1.9612e-02, -1.1001e-02,  1.1881e-03,\n",
       "                      -1.9746e-02,  1.6172e-02,  1.0306e-02, -3.6599e-03,  5.4681e-03,\n",
       "                      -4.7947e-03,  2.5840e-02,  1.0749e-02,  1.3995e-02,  1.2472e-02,\n",
       "                       1.4901e-02,  2.0187e-02,  2.0324e-02, -6.6486e-03, -9.1851e-03,\n",
       "                       7.5053e-03,  4.9797e-04,  5.9197e-03,  1.6221e-02,  1.9343e-02,\n",
       "                       8.6264e-03,  9.9484e-03, -6.5500e-03,  1.2835e-03,  5.0367e-04,\n",
       "                       3.7905e-03,  1.7364e-03,  4.6372e-03,  1.2673e-03,  1.3126e-02,\n",
       "                       8.5964e-03, -4.8034e-03, -1.8199e-03,  9.3080e-03,  3.5406e-03,\n",
       "                      -1.5120e-02, -3.6198e-04, -1.0537e-02, -4.8379e-03,  6.9537e-03,\n",
       "                       8.0783e-03, -3.4326e-03,  6.4929e-03, -1.5143e-02,  2.5281e-03,\n",
       "                       1.1073e-02,  1.4479e-03, -1.0714e-03])),\n",
       "             ('decoders.3.bn1.running_mean',\n",
       "              tensor([-0.2514,  0.1394,  0.1519,  0.0532, -0.0639, -0.2354,  0.1457, -0.1746,\n",
       "                       0.1956, -0.2032, -0.0854,  0.3367, -0.1015,  0.1509, -0.3483, -0.3701,\n",
       "                       0.1435,  0.2756, -0.0668,  0.0378, -0.2195, -0.4464, -0.1679, -0.3534,\n",
       "                       0.0850, -0.3156,  0.1004,  0.2830, -0.1567, -0.1139, -0.0694,  0.2010,\n",
       "                       0.2074,  0.0493, -0.2507, -0.0083, -0.0066, -0.1198,  0.0530, -0.0421,\n",
       "                       0.0826,  0.0714, -0.2681, -0.6121,  0.1629, -0.1374, -0.0732,  0.0929,\n",
       "                       0.1018,  0.1435, -0.3578,  0.2116, -0.1487, -0.1078, -0.1874,  0.0780,\n",
       "                      -0.5612, -0.0025,  0.1134,  0.3284,  0.2242, -0.1908,  0.0087, -0.2822,\n",
       "                      -0.3113, -0.0160,  0.0655,  0.1024,  0.0330,  0.1039, -0.2882, -0.0816,\n",
       "                      -0.0159,  0.1742, -0.1607,  0.3713, -0.2752, -0.0439, -0.0318,  0.0606,\n",
       "                      -0.0184, -0.2139,  0.0892, -0.2023,  0.2223, -0.3334,  0.2242,  0.1194,\n",
       "                       0.3208, -0.1526,  0.2279, -0.2647,  0.1525, -0.0303, -0.1891, -0.0482,\n",
       "                      -0.2338, -0.1769, -0.1184, -0.1266, -0.0197, -0.2265,  0.2541, -0.1712,\n",
       "                       0.1033, -0.0860, -0.3027, -0.1517, -0.1326,  0.0118, -0.2381,  0.0799,\n",
       "                       0.1830,  0.2354, -0.2645, -0.0998,  0.0944, -0.0773, -0.0774, -0.1500,\n",
       "                      -0.2487, -0.3530, -0.1222,  0.0242,  0.1102,  0.0915, -0.4287, -0.1665])),\n",
       "             ('decoders.3.bn1.running_var',\n",
       "              tensor([0.3874, 0.3345, 0.1529, 0.1515, 0.1818, 0.6159, 0.3877, 0.1339, 0.4902,\n",
       "                      0.1345, 0.2877, 0.8322, 0.4628, 0.1247, 1.4054, 0.7508, 0.5320, 0.8861,\n",
       "                      0.1008, 0.1387, 0.3939, 0.9108, 0.5103, 0.9787, 0.1847, 0.7779, 0.1509,\n",
       "                      0.1881, 0.2226, 0.2162, 0.1604, 0.3092, 0.4161, 0.1326, 0.9575, 0.1437,\n",
       "                      0.1457, 0.7399, 0.1463, 0.1267, 0.1646, 0.1964, 1.1213, 1.3242, 0.3362,\n",
       "                      0.1236, 0.2644, 0.1713, 0.1375, 0.2205, 0.4781, 0.2156, 0.3850, 0.2224,\n",
       "                      0.3282, 0.0987, 1.0031, 0.1529, 0.3071, 0.4699, 0.3368, 0.2390, 0.1331,\n",
       "                      0.3803, 0.8633, 0.1500, 0.1285, 0.2046, 0.1712, 0.3496, 0.5976, 0.1886,\n",
       "                      0.1274, 0.2105, 0.3292, 0.5018, 0.5125, 0.4048, 0.1156, 0.1841, 0.1041,\n",
       "                      0.6345, 0.2224, 0.1559, 0.3080, 0.2968, 0.6689, 0.3352, 0.2766, 0.5735,\n",
       "                      0.4312, 0.5048, 0.4976, 0.1031, 0.0894, 0.3793, 0.6576, 0.3954, 0.3656,\n",
       "                      0.5245, 0.5666, 0.6239, 0.1704, 0.2120, 0.2792, 0.1243, 0.4105, 0.3355,\n",
       "                      0.3310, 0.3156, 0.5422, 0.2137, 0.2370, 0.4810, 0.3269, 0.1244, 0.2682,\n",
       "                      0.2073, 0.0993, 0.1650, 0.6031, 0.7652, 0.2877, 0.1137, 0.1473, 0.2400,\n",
       "                      0.6831, 0.2017])),\n",
       "             ('decoders.3.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense2.weight',\n",
       "              tensor([[-0.0676,  0.0037,  0.0474,  ..., -0.0071, -0.0627, -0.0288],\n",
       "                      [-0.0722, -0.0167, -0.0032,  ...,  0.0774,  0.0122,  0.0354],\n",
       "                      [ 0.0273, -0.0507,  0.0639,  ...,  0.0526,  0.0454, -0.0296],\n",
       "                      ...,\n",
       "                      [ 0.0034, -0.0232, -0.0668,  ...,  0.0097,  0.0686,  0.0846],\n",
       "                      [ 0.0332, -0.0449, -0.0761,  ...,  0.0167, -0.0686, -0.0749],\n",
       "                      [ 0.0262,  0.0405, -0.0792,  ..., -0.0809,  0.0520,  0.0651]])),\n",
       "             ('decoders.3.bn2.weight',\n",
       "              tensor([0.9885, 0.9951, 0.9883, 1.0002, 0.9954, 1.0053, 1.0141, 1.0191, 1.0058,\n",
       "                      0.9954, 1.0151, 1.0152, 1.0038, 0.9865, 0.9916, 1.0227, 0.9815, 1.0103,\n",
       "                      1.0124, 0.9929, 0.9834, 1.0068, 0.9891, 1.0197, 1.0101, 0.9969, 1.0003,\n",
       "                      0.9864, 0.9820, 1.0036, 1.0084, 0.9826, 0.9989, 1.0156, 0.9905, 1.0020,\n",
       "                      0.9859, 0.9951, 1.0173, 0.9922, 0.9908, 1.0077, 1.0029, 1.0043, 1.0004,\n",
       "                      1.0218, 0.9980, 0.9792, 0.9980, 0.9994, 0.9961, 0.9908, 0.9846, 1.0151,\n",
       "                      1.0116, 0.9926, 0.9911, 0.9949, 1.0088, 0.9951, 0.9880, 0.9970, 1.0039,\n",
       "                      1.0217, 1.0117, 0.9987, 1.0001, 1.0199, 0.9894, 1.0199, 1.0007, 0.9877,\n",
       "                      0.9969, 0.9927, 0.9914, 0.9906, 0.9914, 0.9817, 1.0135, 0.9919, 1.0045,\n",
       "                      0.9941, 0.9789, 1.0162, 0.9902, 0.9987, 1.0064, 0.9814, 0.9958, 1.0062,\n",
       "                      1.0207, 1.0141, 0.9954, 1.0041, 0.9792, 0.9906, 0.9912, 1.0074, 0.9955,\n",
       "                      1.0066, 1.0146, 1.0058, 0.9928, 1.0151, 0.9921, 0.9822, 1.0180, 1.0064,\n",
       "                      0.9972, 1.0074, 1.0126, 1.0108, 1.0118, 0.9995, 1.0061, 0.9952, 0.9863,\n",
       "                      1.0138, 0.9945, 0.9935, 1.0111, 1.0077, 1.0019, 0.9890, 0.9933, 0.9937,\n",
       "                      0.9954, 0.9837, 0.9928, 0.9850, 0.9992, 1.0161, 1.0121, 0.9930, 1.0075,\n",
       "                      1.0197, 1.0189, 0.9992, 1.0071, 1.0079, 0.9924, 0.9927, 0.9874, 1.0189,\n",
       "                      0.9944, 1.0051, 1.0054, 0.9955, 1.0056, 0.9972, 0.9910, 0.9934, 1.0186,\n",
       "                      0.9874, 0.9906, 0.9913, 0.9987, 1.0091, 0.9859, 0.9982, 0.9895, 0.9971,\n",
       "                      0.9978, 0.9961, 0.9868, 0.9962, 0.9920, 1.0012, 0.9947, 0.9933, 1.0139,\n",
       "                      1.0003, 0.9966, 0.9841, 0.9920, 0.9964, 0.9823, 0.9813, 1.0019, 0.9946,\n",
       "                      0.9914, 0.9947, 0.9824, 1.0042, 1.0142, 1.0181, 0.9960, 0.9982, 1.0039,\n",
       "                      0.9854, 0.9946, 0.9778, 1.0020, 1.0166, 0.9933, 0.9888, 0.9846, 0.9833,\n",
       "                      1.0119, 0.9998, 1.0036, 0.9884, 0.9860, 1.0075, 1.0106, 1.0096, 0.9937,\n",
       "                      1.0172, 0.9909, 1.0140, 0.9890, 1.0003, 1.0011, 0.9944, 0.9935, 0.9809,\n",
       "                      1.0042, 0.9974, 0.9958, 0.9804, 1.0019, 1.0134, 1.0270, 0.9898, 0.9987,\n",
       "                      1.0152, 1.0137, 0.9770, 0.9877, 1.0190, 0.9931, 0.9996, 1.0003, 0.9965,\n",
       "                      0.9905, 1.0098, 0.9899, 0.9963, 1.0015, 0.9900, 0.9959, 0.9898, 0.9796,\n",
       "                      0.9945, 0.9888, 0.9898, 0.9919, 1.0041, 1.0114, 0.9868, 1.0206, 1.0109,\n",
       "                      0.9845, 0.9987, 0.9827, 0.9865])),\n",
       "             ('decoders.3.bn2.bias',\n",
       "              tensor([ 4.1469e-03,  3.9828e-05,  1.0772e-02,  4.3801e-03,  7.6021e-04,\n",
       "                       2.3450e-02,  2.0546e-02,  1.5455e-02,  2.8800e-02,  3.0246e-03,\n",
       "                       7.0189e-03,  9.8910e-03,  4.2775e-03, -1.5118e-02, -1.1692e-03,\n",
       "                       2.1932e-02, -1.0631e-02, -1.0590e-03,  2.4859e-02, -3.1558e-03,\n",
       "                      -2.5464e-03,  1.7533e-02, -1.1473e-02, -5.1089e-03,  1.7626e-02,\n",
       "                      -4.2880e-03,  2.9593e-02, -1.6395e-02, -2.2973e-02,  4.9739e-03,\n",
       "                       1.5465e-02, -1.1240e-02,  3.8882e-03, -8.3216e-03,  2.6546e-03,\n",
       "                       3.1141e-02,  3.1952e-03,  1.7860e-03,  4.9594e-03, -1.3361e-02,\n",
       "                       3.3036e-02,  1.7007e-02,  1.5219e-03,  2.5197e-02,  7.6709e-03,\n",
       "                       5.8354e-03,  3.3734e-03, -1.4061e-02,  6.3645e-03,  1.0826e-02,\n",
       "                      -4.6906e-03,  1.5073e-02, -1.2354e-02,  2.2464e-02,  2.3804e-04,\n",
       "                      -2.0861e-03, -9.9332e-03, -1.6395e-03, -6.3836e-03,  2.0788e-02,\n",
       "                       3.9345e-03, -4.7698e-03,  1.1289e-02,  7.2868e-03,  9.6001e-03,\n",
       "                      -4.5389e-03,  7.7291e-03,  3.1215e-02,  1.2478e-02,  2.2298e-02,\n",
       "                       1.0396e-03, -6.8262e-03,  4.7660e-03, -7.5266e-04,  4.7872e-03,\n",
       "                      -1.1531e-02, -1.9019e-03,  3.8947e-04,  2.7940e-02, -9.2513e-03,\n",
       "                       7.1877e-03,  1.9982e-03, -1.6629e-02,  1.2388e-02,  4.7290e-03,\n",
       "                       5.7555e-03,  1.1127e-02, -1.6115e-02, -9.9262e-04, -8.8240e-04,\n",
       "                       4.2600e-03,  1.6448e-02, -6.1715e-03,  9.6528e-03, -7.9669e-03,\n",
       "                      -3.0585e-03,  8.4233e-03, -6.2985e-03,  3.5849e-03, -1.9665e-03,\n",
       "                       1.8744e-02,  2.2366e-02,  2.3575e-03,  6.4398e-03,  7.7562e-03,\n",
       "                      -5.5534e-03, -8.4690e-03,  1.3216e-02,  1.4662e-02,  6.1553e-03,\n",
       "                      -3.5032e-03,  5.5512e-03,  4.7026e-03, -3.5379e-03,  3.9397e-02,\n",
       "                       2.6054e-02, -9.1764e-03,  1.8138e-02, -4.5700e-03, -1.8091e-03,\n",
       "                       5.1796e-03,  1.3698e-02,  6.1041e-02,  2.2586e-02,  4.9488e-03,\n",
       "                      -1.0636e-02, -2.4441e-03,  2.4946e-03, -1.3817e-03, -9.1315e-03,\n",
       "                       2.5937e-02,  1.0884e-02, -3.0515e-04, -9.5494e-04, -2.1750e-03,\n",
       "                       1.9188e-03,  2.0528e-02,  2.1405e-02,  5.8954e-03,  1.2338e-02,\n",
       "                       2.2402e-02, -1.1048e-02, -2.4115e-03,  8.6846e-03, -2.2907e-03,\n",
       "                       1.1857e-02,  1.6544e-03,  1.0933e-02, -4.7678e-04,  1.1133e-02,\n",
       "                       1.1087e-02, -2.1139e-03,  3.5341e-03, -1.6124e-02, -1.2082e-02,\n",
       "                       1.1305e-02, -2.4816e-03, -2.1341e-03, -2.5978e-03,  3.5970e-03,\n",
       "                      -2.3087e-03,  2.1045e-03,  1.2254e-02, -1.6197e-03, -3.6437e-04,\n",
       "                       5.2905e-03, -5.0528e-03,  6.4940e-03,  1.8582e-02, -3.7143e-03,\n",
       "                       1.5447e-03,  1.4559e-02,  2.4258e-02,  9.4260e-03, -1.2955e-03,\n",
       "                      -5.1935e-03, -2.5776e-04, -8.0380e-03,  9.5960e-03,  6.5821e-03,\n",
       "                       1.6640e-02,  3.0305e-03, -4.7835e-03,  2.2187e-02, -4.5221e-03,\n",
       "                      -5.0498e-03,  9.7244e-03,  7.1991e-03,  1.6553e-02,  2.5504e-03,\n",
       "                      -4.1927e-03, -6.6158e-03,  3.0772e-02,  4.0553e-03,  4.8651e-03,\n",
       "                      -3.0569e-03, -9.8670e-03, -1.8959e-02,  5.7765e-03,  2.0110e-02,\n",
       "                      -3.5767e-03,  7.9156e-05,  3.9881e-04, -3.4934e-03,  2.4015e-02,\n",
       "                       1.3042e-02,  5.4584e-03,  4.0008e-03,  1.2561e-03,  2.7104e-02,\n",
       "                      -2.4168e-03,  6.3811e-03,  2.1300e-02,  9.2857e-04,  1.6750e-02,\n",
       "                      -1.3802e-02,  8.5930e-03,  2.4400e-02,  3.5361e-03, -3.9847e-03,\n",
       "                       7.1876e-03,  2.3361e-02,  1.6637e-02, -5.3302e-03,  3.9248e-03,\n",
       "                       4.9991e-02,  8.4482e-03,  6.4087e-04,  3.3086e-03,  1.4635e-03,\n",
       "                       8.4000e-03, -3.5336e-04,  3.3168e-03,  7.0688e-03,  5.8556e-03,\n",
       "                       8.4094e-04, -7.4517e-03, -7.3361e-03,  1.4468e-02, -1.0234e-02,\n",
       "                       1.4865e-02, -5.5181e-03, -8.9083e-03, -1.9498e-03, -1.4730e-03,\n",
       "                      -7.1573e-03, -8.6737e-03, -9.0567e-03, -4.6366e-03, -1.0085e-02,\n",
       "                       6.9700e-03,  2.4271e-02, -9.4246e-03, -2.7511e-03, -1.7860e-02,\n",
       "                      -1.3938e-02])),\n",
       "             ('decoders.3.bn2.running_mean',\n",
       "              tensor([-0.1031, -0.1400, -0.2933,  0.0588,  0.2769, -0.1647, -0.1908,  0.0776,\n",
       "                      -0.3260,  0.2192,  0.3756,  0.3357,  0.0964, -0.0546, -0.0700,  0.0519,\n",
       "                      -0.0790,  0.0388,  0.0971, -0.2588, -0.0090, -0.2225,  0.1913,  0.4065,\n",
       "                      -0.3635,  0.3646, -0.3403, -0.2501,  0.2074, -0.0468,  0.1034,  0.1214,\n",
       "                       0.0437, -0.0018,  0.1910, -0.3629, -0.0181,  0.0711, -0.0295, -0.0136,\n",
       "                      -0.2048,  0.0129,  0.1313, -0.2599, -0.0465,  0.3100,  0.0880,  0.0468,\n",
       "                       0.1154, -0.1778,  0.0362, -0.0573,  0.1325,  0.0408,  0.2933, -0.0197,\n",
       "                       0.1123, -0.0654, -0.1597, -0.2405, -0.3302, -0.0220, -0.2487,  0.3096,\n",
       "                       0.2053,  0.3181, -0.1680, -0.4063, -0.0192,  0.1651, -0.5307, -0.3398,\n",
       "                      -0.0133, -0.0196, -0.2478,  0.2678, -0.1008,  0.0103,  0.2641, -0.0217,\n",
       "                       0.0450, -0.2579, -0.0045,  0.0529, -0.0969, -0.1896,  0.1903,  0.1812,\n",
       "                      -0.0508,  0.2784,  0.1326,  0.3477,  0.0211,  0.1122,  0.0536, -0.0271,\n",
       "                      -0.4450,  0.0059, -0.1847, -0.1486, -0.1144, -0.5041,  0.0670, -0.0008,\n",
       "                      -0.0289, -0.2408, -0.1679, -0.3865, -0.0306, -0.2698,  0.0871,  0.4250,\n",
       "                       0.3233,  0.0229, -0.3071, -0.3256, -0.0906,  0.0355, -0.1291,  0.3219,\n",
       "                       0.3446,  0.2231, -0.3626, -0.2605, -0.1775, -0.0440,  0.1936, -0.2292,\n",
       "                       0.0630, -0.1899, -0.2918, -0.1424,  0.2823, -0.4713,  0.1417,  0.1773,\n",
       "                       0.1009, -0.2410, -0.2876,  0.2431, -0.5057,  0.3006,  0.2444,  0.2761,\n",
       "                      -0.3348,  0.2058, -0.1440,  0.0808, -0.0768, -0.1217,  0.0026, -0.0800,\n",
       "                       0.2995, -0.3569, -0.3633, -0.0283,  0.0109,  0.3325, -0.1956, -0.1545,\n",
       "                      -0.1420,  0.0537, -0.1746, -0.1294, -0.0877, -0.1303,  0.0928, -0.2340,\n",
       "                       0.1881, -0.0009,  0.4554, -0.1493, -0.3030, -0.1584, -0.0776,  0.1118,\n",
       "                      -0.1094,  0.1446, -0.2305, -0.1778, -0.4461, -0.1520,  0.0196, -0.1003,\n",
       "                       0.3478,  0.1438,  0.2227, -0.0512,  0.2124, -0.0211,  0.0163, -0.2151,\n",
       "                      -0.3079,  0.1113, -0.1165,  0.1511, -0.0450, -0.0235,  0.2015, -0.3862,\n",
       "                       0.4460,  0.3865, -0.0796,  0.1927, -0.1217,  0.2022, -0.1798,  0.1530,\n",
       "                      -0.0493, -0.0526, -0.3533, -0.1179, -0.0892,  0.1011, -0.2076,  0.1511,\n",
       "                      -0.5495, -0.4628, -0.2361, -0.1697,  0.2246,  0.1361,  0.0867,  0.4749,\n",
       "                       0.3349, -0.5120,  0.3255, -0.0693, -0.2045,  0.2602, -0.2108,  0.2778,\n",
       "                       0.5381, -0.0282, -0.1183,  0.0677,  0.3067,  0.2274, -0.2964,  0.1991,\n",
       "                      -0.0571,  0.0599,  0.1799, -0.1621, -0.2914, -0.2606, -0.3621, -0.0318,\n",
       "                       0.3438,  0.0478,  0.3367,  0.0827,  0.2750,  0.1469,  0.0363,  0.2363])),\n",
       "             ('decoders.3.bn2.running_var',\n",
       "              tensor([0.7944, 0.1746, 0.7211, 0.4461, 0.3415, 0.7806, 0.6200, 1.1844, 0.2317,\n",
       "                      0.0862, 0.4343, 0.5414, 0.5432, 0.3580, 0.1354, 1.0359, 0.0982, 0.4767,\n",
       "                      0.5410, 0.3965, 0.1083, 0.4124, 0.2091, 0.5205, 0.1115, 0.4638, 0.1715,\n",
       "                      0.1026, 0.1793, 0.2832, 0.3249, 0.1081, 0.3383, 1.0218, 0.2584, 0.3489,\n",
       "                      0.3562, 0.1949, 0.9123, 0.3151, 0.2626, 0.9929, 0.8420, 0.2605, 0.5851,\n",
       "                      0.6675, 0.2158, 0.2499, 0.2470, 0.2651, 0.4590, 0.3314, 0.2526, 0.8237,\n",
       "                      0.6438, 0.3480, 0.3211, 0.1249, 0.6536, 0.4281, 0.1654, 0.4401, 0.5858,\n",
       "                      1.0328, 0.2777, 0.3322, 0.3077, 0.0765, 0.3761, 0.4899, 0.1147, 0.1122,\n",
       "                      0.4137, 0.3178, 0.1935, 0.2431, 0.0848, 0.3297, 1.1964, 0.3134, 0.5281,\n",
       "                      0.1068, 0.2158, 0.7078, 0.1773, 0.1026, 0.4934, 0.2258, 0.1453, 0.4166,\n",
       "                      1.2578, 0.3498, 0.2610, 0.2558, 0.1321, 0.5092, 0.2553, 0.9037, 0.5430,\n",
       "                      0.8609, 0.7194, 0.1050, 0.3936, 0.6279, 0.6930, 0.1177, 1.1167, 0.1648,\n",
       "                      0.6338, 0.5527, 0.8555, 0.3633, 0.2030, 0.4356, 0.5145, 0.1099, 0.1369,\n",
       "                      0.4915, 0.1952, 0.1823, 0.5401, 0.7365, 0.5457, 0.3989, 0.2152, 0.1264,\n",
       "                      0.2804, 0.1998, 0.2113, 0.1982, 0.4502, 1.2874, 0.6045, 0.1377, 0.7383,\n",
       "                      0.5648, 0.6391, 0.4368, 0.2135, 0.3043, 0.2021, 0.4359, 0.2115, 0.9787,\n",
       "                      0.1059, 0.3310, 0.2451, 0.6403, 0.1216, 0.2437, 0.0683, 0.3119, 0.5764,\n",
       "                      0.0957, 0.1013, 0.4606, 0.3820, 0.2784, 0.1297, 0.1926, 0.2909, 0.3457,\n",
       "                      0.2261, 0.1651, 0.2851, 0.2310, 0.2627, 0.1186, 0.3594, 0.2571, 0.5589,\n",
       "                      0.5900, 0.3076, 0.4712, 0.2865, 0.2199, 0.3042, 0.1591, 0.4991, 0.2357,\n",
       "                      0.2444, 0.1000, 0.0849, 0.4868, 0.6513, 0.3086, 0.3967, 0.1614, 0.6894,\n",
       "                      0.2249, 0.1217, 0.1410, 0.2991, 1.0208, 0.2817, 0.1378, 0.1116, 0.0620,\n",
       "                      0.5804, 0.3480, 0.2540, 0.4225, 0.1649, 0.4930, 0.5580, 0.5393, 0.4349,\n",
       "                      0.6361, 0.0818, 1.0605, 0.0963, 0.3710, 0.4302, 0.1995, 0.3985, 0.1931,\n",
       "                      0.1080, 0.3554, 0.1392, 0.1051, 0.4127, 0.6349, 0.3302, 0.1662, 0.2782,\n",
       "                      0.2405, 0.6921, 0.3116, 0.0830, 1.0237, 0.2428, 0.2587, 0.1628, 0.3194,\n",
       "                      0.7500, 0.4565, 0.5763, 0.2097, 0.2062, 0.3097, 0.2855, 0.1757, 0.1507,\n",
       "                      0.3186, 0.1130, 0.2545, 0.0985, 0.7083, 0.6733, 0.0994, 0.5155, 0.5900,\n",
       "                      0.1308, 0.3349, 0.2343, 0.1233])),\n",
       "             ('decoders.3.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense3.weight',\n",
       "              tensor([[ 0.0310,  0.0212, -0.0593,  ...,  0.0243, -0.0123, -0.0463],\n",
       "                      [ 0.0202, -0.0384,  0.0235,  ..., -0.0453,  0.0187, -0.0201],\n",
       "                      [ 0.0071,  0.0423, -0.0287,  ..., -0.0502, -0.0218,  0.0144],\n",
       "                      ...,\n",
       "                      [ 0.0541,  0.0301, -0.0569,  ...,  0.0176,  0.0279,  0.0428],\n",
       "                      [-0.0008, -0.0601,  0.0535,  ..., -0.0340,  0.0609, -0.0104],\n",
       "                      [ 0.0145,  0.0001, -0.0056,  ...,  0.0267, -0.0274,  0.0575]])),\n",
       "             ('decoders.3.bn3.weight',\n",
       "              tensor([0.9962, 1.0106, 0.9996, 0.9986, 0.9941, 1.0037, 1.0053, 0.9947, 0.9997,\n",
       "                      0.9949, 1.0100, 0.9901, 0.9986, 0.9947, 1.0067, 1.0012, 0.9861, 0.9952,\n",
       "                      0.9924, 1.0054, 0.9886, 0.9842, 0.9893, 1.0143, 0.9749, 0.9969, 0.9823,\n",
       "                      0.9954, 1.0063, 1.0134, 1.0049, 0.9976, 0.9881, 1.0072, 1.0008, 1.0159,\n",
       "                      0.9951, 0.9969, 1.0147, 0.9942, 0.9875, 0.9889, 0.9987, 0.9986, 1.0101,\n",
       "                      0.9981, 0.9972, 1.0040, 0.9976, 0.9899, 1.0062, 1.0253, 0.9962, 0.9817,\n",
       "                      0.9949, 1.0045, 0.9903, 0.9976, 0.9921, 1.0174, 1.0051, 1.0149, 1.0067,\n",
       "                      1.0132, 1.0108, 0.9919, 1.0085, 1.0028, 0.9812, 0.9958, 1.0051, 1.0099,\n",
       "                      1.0025, 0.9974, 1.0025, 0.9965, 1.0110, 0.9930, 0.9971, 0.9991, 1.0038,\n",
       "                      1.0188, 1.0063, 1.0120, 0.9894, 0.9970, 0.9841, 0.9891, 1.0002, 0.9996,\n",
       "                      0.9927, 1.0117, 1.0127, 0.9985, 0.9943, 0.9902, 0.9779, 1.0156, 0.9994,\n",
       "                      1.0137, 0.9965, 0.9915, 1.0038, 0.9986, 1.0059, 0.9964, 0.9963, 0.9979,\n",
       "                      0.9937, 1.0023, 1.0147, 1.0028, 0.9961, 1.0034, 1.0088, 0.9910, 0.9947,\n",
       "                      0.9821, 0.9905, 0.9949, 0.9903, 0.9911, 1.0150, 0.9951, 1.0134, 0.9901,\n",
       "                      1.0080, 1.0117, 1.0083, 1.0151, 1.0035, 0.9962, 1.0066, 0.9949, 0.9809,\n",
       "                      1.0107, 1.0078, 1.0177, 0.9971, 0.9883, 0.9965, 0.9870, 0.9934, 0.9926,\n",
       "                      0.9902, 1.0088, 0.9954, 1.0067, 1.0209, 1.0085, 1.0145, 0.9959, 0.9892,\n",
       "                      0.9943, 1.0146, 0.9995, 1.0205, 1.0197, 1.0202, 0.9955, 1.0014, 0.9955,\n",
       "                      0.9964, 0.9986, 1.0003, 1.0084, 1.0095, 1.0089, 0.9956, 0.9988, 1.0033,\n",
       "                      1.0019, 1.0041, 0.9916, 1.0085, 1.0041, 0.9954, 0.9902, 1.0065, 1.0040,\n",
       "                      0.9849, 0.9926, 0.9952, 1.0171, 1.0112, 1.0109, 0.9877, 0.9990, 1.0068,\n",
       "                      0.9931, 1.0066, 1.0087, 0.9982, 1.0012, 1.0094, 1.0159, 0.9938, 1.0022,\n",
       "                      1.0097, 1.0020, 0.9934, 0.9871, 0.9976, 0.9942, 0.9855, 1.0007, 0.9947,\n",
       "                      1.0039, 0.9980, 0.9992, 1.0057, 0.9950, 0.9990, 0.9980, 0.9873, 1.0137,\n",
       "                      0.9884, 1.0097, 0.9919, 0.9991, 0.9970, 0.9965, 1.0068, 1.0154, 0.9984,\n",
       "                      0.9814, 0.9972, 0.9809, 1.0023, 1.0060, 0.9934, 1.0154, 1.0136, 0.9995,\n",
       "                      1.0053, 1.0019, 1.0160, 0.9981, 1.0001, 0.9792, 0.9956, 0.9859, 0.9999,\n",
       "                      0.9919, 0.9851, 0.9972, 1.0175, 1.0018, 0.9988, 0.9871, 0.9904, 0.9819,\n",
       "                      1.0131, 0.9877, 0.9901, 1.0038, 1.0087, 0.9958, 0.9971, 1.0058, 0.9949,\n",
       "                      1.0014, 1.0030, 1.0108, 1.0085, 0.9839, 1.0110, 0.9836, 0.9878, 1.0018,\n",
       "                      0.9971, 0.9904, 0.9910, 0.9901, 1.0036, 1.0029, 1.0168, 1.0123, 0.9792,\n",
       "                      1.0048, 1.0125, 0.9914, 0.9796, 1.0034, 0.9997, 0.9911, 1.0009, 0.9785,\n",
       "                      0.9943, 0.9812, 1.0149, 1.0094, 1.0016, 0.9985, 0.9942, 0.9951, 0.9829,\n",
       "                      1.0060, 1.0005, 1.0013, 0.9826, 0.9915, 0.9830, 1.0152, 0.9835, 1.0023,\n",
       "                      0.9987, 0.9912, 0.9944, 1.0063, 1.0171, 0.9833, 1.0112, 1.0083, 0.9879,\n",
       "                      1.0193, 0.9975, 0.9941, 0.9957, 0.9972, 0.9922, 1.0031, 1.0017, 1.0175,\n",
       "                      1.0119, 1.0023, 0.9786, 1.0000, 1.0020, 0.9980, 0.9958, 0.9928, 0.9872,\n",
       "                      0.9955, 0.9966, 0.9918, 0.9951, 0.9980, 1.0098, 1.0058, 1.0141, 0.9965,\n",
       "                      0.9964, 0.9976, 0.9984, 0.9976, 0.9948, 1.0006, 0.9951, 0.9860, 1.0120,\n",
       "                      1.0117, 0.9924, 1.0045, 0.9936, 0.9945, 1.0114, 1.0018, 1.0052, 1.0022,\n",
       "                      0.9981, 0.9990, 1.0217, 0.9897, 1.0096, 0.9990, 1.0031, 0.9917, 1.0088,\n",
       "                      1.0015, 0.9942, 1.0055, 1.0064, 1.0094, 1.0085, 0.9887, 1.0066, 1.0092,\n",
       "                      1.0015, 0.9887, 1.0167, 0.9963, 1.0082, 0.9897, 1.0117, 0.9934, 1.0045,\n",
       "                      1.0040, 0.9928, 1.0046, 0.9825, 0.9916, 0.9966, 0.9919, 0.9849, 1.0021,\n",
       "                      1.0025, 1.0046, 0.9841, 1.0114, 0.9989, 1.0100, 0.9904, 0.9933, 1.0076,\n",
       "                      0.9963, 0.9930, 1.0049, 0.9847, 1.0034, 1.0009, 0.9795, 0.9981, 0.9835,\n",
       "                      1.0081, 0.9902, 0.9881, 1.0034, 0.9905, 1.0030, 1.0009, 0.9899, 0.9933,\n",
       "                      0.9990, 0.9996, 0.9810, 1.0123, 0.9936, 1.0047, 0.9952, 1.0015, 0.9872,\n",
       "                      0.9930, 0.9914, 0.9867, 0.9935, 0.9959, 0.9954, 1.0036, 0.9957, 0.9979,\n",
       "                      0.9934, 1.0074, 1.0002, 1.0001, 0.9996, 1.0008, 1.0071, 1.0050, 1.0138,\n",
       "                      0.9931, 1.0016, 0.9885, 0.9963, 1.0038, 0.9902, 0.9984, 1.0071, 1.0043,\n",
       "                      1.0034, 0.9998, 0.9856, 0.9944, 1.0050, 1.0036, 1.0098, 1.0017, 0.9900,\n",
       "                      1.0033, 0.9931, 1.0019, 1.0003, 0.9920, 0.9945, 0.9950, 1.0166, 0.9902,\n",
       "                      0.9928, 1.0019, 0.9827, 1.0068, 1.0018, 1.0089, 0.9892, 1.0049, 0.9882,\n",
       "                      0.9899, 0.9964, 1.0001, 0.9984, 1.0082, 1.0117, 0.9903, 1.0097, 1.0127,\n",
       "                      0.9963, 1.0068, 1.0126, 1.0041, 1.0151, 0.9875, 0.9915, 1.0014, 1.0010,\n",
       "                      1.0052, 0.9954, 0.9964, 0.9995, 0.9899, 1.0092, 1.0019, 0.9941])),\n",
       "             ('decoders.3.bn3.bias',\n",
       "              tensor([ 9.3125e-03,  3.3310e-02,  2.0646e-02,  1.1585e-02, -6.0233e-03,\n",
       "                       7.7930e-03,  4.3385e-02,  3.6818e-03,  1.5246e-02, -8.9594e-03,\n",
       "                       2.6649e-02, -6.1741e-03,  3.6127e-03, -1.1412e-02,  5.3705e-03,\n",
       "                       1.7024e-02,  5.7304e-03,  2.5064e-02, -1.6327e-02,  3.3809e-02,\n",
       "                       3.6626e-03,  1.6195e-04, -5.1801e-05, -9.2117e-03, -1.5473e-02,\n",
       "                       1.0593e-03, -1.0430e-02, -4.6254e-03,  1.9648e-02, -1.4197e-02,\n",
       "                       2.9157e-02,  1.3999e-02, -9.4587e-03,  3.3642e-02, -3.0060e-03,\n",
       "                       2.1046e-03,  2.4253e-02,  5.6768e-03, -1.2518e-02,  4.8424e-03,\n",
       "                      -1.3216e-02,  7.3304e-03,  1.1810e-02,  9.7564e-03,  3.9778e-02,\n",
       "                       2.2421e-02,  2.3831e-02,  6.5827e-03,  1.0560e-02, -2.4035e-03,\n",
       "                       1.8407e-02,  4.1314e-02,  1.9748e-02,  3.1235e-03,  2.0694e-03,\n",
       "                       9.8469e-03,  1.0482e-02, -5.5696e-03,  3.8772e-02, -1.1484e-02,\n",
       "                      -7.4403e-03, -9.0260e-03, -2.6222e-03,  4.3542e-02,  3.3613e-02,\n",
       "                       1.5078e-02,  2.1647e-02,  2.4528e-04, -1.1682e-02,  3.1399e-02,\n",
       "                       4.7850e-02, -5.1492e-03,  2.4641e-02, -7.0469e-03,  1.7234e-02,\n",
       "                      -4.4292e-03, -1.2624e-02,  3.8181e-03, -1.6686e-02,  1.7410e-03,\n",
       "                       3.6289e-02,  3.4670e-02,  5.3217e-03, -3.5265e-03,  1.3310e-02,\n",
       "                      -6.6944e-03, -2.9408e-03,  3.2556e-03,  5.2211e-03,  9.7727e-03,\n",
       "                      -5.6591e-03,  3.3701e-02,  8.0345e-03, -4.1064e-03, -3.7045e-03,\n",
       "                      -4.2629e-03, -1.2486e-02, -5.4729e-03,  1.3838e-02,  4.5637e-02,\n",
       "                       4.0111e-02, -3.7927e-03,  1.5757e-02,  2.7075e-02, -7.3888e-03,\n",
       "                       3.8629e-03,  8.7996e-03, -1.1501e-02, -4.4356e-03, -1.1578e-02,\n",
       "                       4.7769e-02, -3.8696e-05, -6.7917e-03,  7.6934e-03,  4.2961e-03,\n",
       "                      -1.7184e-03,  2.3700e-03, -1.4531e-02,  2.0703e-03,  6.9778e-03,\n",
       "                       9.3018e-03, -6.1483e-03, -1.0968e-02, -3.5285e-03, -8.1840e-03,\n",
       "                       7.0115e-03,  2.4278e-02, -5.7627e-03, -2.2452e-02,  1.9160e-02,\n",
       "                       1.9687e-02,  6.9613e-04, -2.5527e-03,  1.7117e-02, -1.4309e-03,\n",
       "                       3.8544e-02, -7.3629e-03,  2.2398e-02,  1.5090e-02, -1.2438e-02,\n",
       "                       1.0391e-03,  5.2578e-03, -4.3260e-04,  4.8108e-04, -8.4034e-04,\n",
       "                       3.5961e-02,  1.7746e-03, -1.0061e-02,  9.6750e-03,  3.4712e-02,\n",
       "                      -8.8214e-03,  9.9320e-03,  1.1653e-03,  2.4189e-03, -3.9365e-03,\n",
       "                       5.4346e-03,  5.9543e-03,  8.9455e-03,  3.7356e-03,  5.7004e-03,\n",
       "                       4.3621e-03,  7.4343e-03,  1.9437e-02,  2.5543e-02,  1.0433e-02,\n",
       "                       2.9069e-02, -1.3164e-02, -6.0207e-03,  1.4286e-02,  1.9665e-02,\n",
       "                       1.1924e-02,  1.0922e-02,  1.6588e-02,  9.9200e-03, -5.2423e-03,\n",
       "                      -8.8547e-03,  5.3393e-03,  4.6220e-03,  2.6208e-02,  8.3014e-03,\n",
       "                      -1.5428e-02, -1.4183e-03,  1.9188e-03,  3.2696e-04, -1.5183e-02,\n",
       "                       2.0035e-03, -1.8703e-02,  1.1213e-02,  4.7310e-03,  5.4879e-03,\n",
       "                       1.4842e-04,  9.3712e-04,  8.8909e-03, -1.4895e-02,  7.5209e-03,\n",
       "                      -1.2172e-02,  1.1846e-02,  2.6711e-02,  1.7888e-02,  2.9983e-03,\n",
       "                       3.0405e-03, -1.5109e-02,  1.0816e-02,  3.9805e-03, -1.4702e-02,\n",
       "                      -1.2640e-02,  5.3719e-03,  4.1289e-03,  1.5994e-03, -1.8173e-03,\n",
       "                       4.8062e-03, -6.6898e-03,  9.6342e-03, -2.2137e-03,  7.1640e-04,\n",
       "                      -8.7787e-03, -1.2284e-02,  1.4840e-02,  1.1151e-02, -2.9715e-03,\n",
       "                      -1.7848e-04, -4.1148e-03,  2.3375e-02,  4.4793e-02,  2.6303e-02,\n",
       "                      -1.7254e-02,  2.2523e-03, -9.1999e-03,  2.6911e-02,  1.2145e-02,\n",
       "                       4.4636e-03, -2.7047e-03, -6.1314e-04,  8.8676e-03,  3.0253e-02,\n",
       "                      -1.0614e-03, -3.5591e-04,  1.5600e-02,  4.2163e-02, -1.0979e-02,\n",
       "                       1.6530e-03, -7.8992e-03,  2.5946e-02, -7.2154e-03,  6.5486e-03,\n",
       "                       3.2045e-04, -1.0347e-02,  1.3056e-03,  2.7699e-02,  1.8433e-02,\n",
       "                       1.2132e-04, -1.6952e-02, -5.5806e-03, -2.3120e-02, -1.2405e-03,\n",
       "                       4.8318e-03,  5.7733e-03, -1.2218e-03, -4.7119e-03, -2.3036e-03,\n",
       "                       6.7372e-03,  7.8562e-04,  2.3433e-02,  1.5852e-02, -1.1295e-02,\n",
       "                      -1.5074e-02,  1.6445e-02,  9.3711e-03, -6.3154e-03,  1.6210e-02,\n",
       "                      -1.1602e-04,  4.3959e-03, -4.0717e-03,  1.5029e-03,  3.2684e-02,\n",
       "                       7.5162e-03,  2.8172e-02, -6.7000e-03, -1.4207e-02,  1.3762e-02,\n",
       "                       4.3856e-02, -7.1048e-04, -1.5627e-02,  1.3646e-03,  5.4506e-03,\n",
       "                      -1.3567e-03,  1.1110e-02, -1.3362e-02,  8.7230e-03, -6.3912e-03,\n",
       "                      -1.7738e-02,  2.4850e-02,  7.6271e-03, -6.0709e-03,  4.6937e-03,\n",
       "                      -1.8255e-02,  2.9674e-03,  1.7597e-02,  1.5956e-02,  1.1330e-02,\n",
       "                      -1.0259e-02,  1.1224e-02, -1.9867e-02, -7.4270e-03,  8.3137e-03,\n",
       "                       1.5881e-02,  2.9193e-02, -6.3822e-03,  2.1198e-02,  3.9991e-02,\n",
       "                      -9.0701e-03, -4.5620e-03,  2.8811e-02,  1.2366e-02,  1.2469e-02,\n",
       "                       8.2937e-03, -7.6956e-03,  3.8672e-03,  4.7813e-03,  2.8319e-02,\n",
       "                      -5.6162e-03, -2.8754e-04,  3.1357e-02, -7.2541e-03, -2.9890e-04,\n",
       "                       2.3716e-02, -1.8779e-02,  1.3087e-02,  1.1255e-02,  8.9475e-04,\n",
       "                      -9.9710e-03, -8.8772e-04, -6.1476e-03,  3.9220e-03,  6.4830e-03,\n",
       "                       6.2359e-03,  9.1302e-03,  5.1764e-04,  1.5190e-02,  1.8259e-02,\n",
       "                       1.5265e-02,  1.7302e-02,  9.3746e-03,  4.4943e-04,  3.5591e-02,\n",
       "                       1.8307e-02,  8.4028e-03,  6.7216e-04,  3.6283e-03,  8.9207e-03,\n",
       "                       1.6148e-03, -1.7645e-02, -2.9023e-03,  5.2654e-03,  2.0251e-02,\n",
       "                      -1.7542e-03,  3.4459e-02,  9.8869e-03,  8.6733e-03,  1.5944e-02,\n",
       "                      -1.4976e-03, -9.7600e-04,  7.8225e-03,  7.8633e-03,  4.0448e-02,\n",
       "                       7.7242e-03,  2.9714e-03,  1.0842e-02,  2.8130e-04,  3.1077e-02,\n",
       "                       3.6317e-03, -4.2832e-03, -6.5701e-03, -3.5282e-03,  3.4612e-02,\n",
       "                      -7.8726e-03,  2.5447e-02,  2.2525e-02,  4.3772e-03, -4.1901e-03,\n",
       "                      -1.2466e-02,  1.7028e-02,  4.4696e-03, -2.9485e-04, -1.3029e-04,\n",
       "                      -5.8383e-03,  6.0140e-03,  3.3048e-02,  1.0878e-02,  2.6464e-02,\n",
       "                      -4.8419e-03,  8.4292e-03,  7.3242e-03, -1.6915e-04, -1.7472e-02,\n",
       "                      -3.3661e-03,  2.3374e-02, -1.0465e-02, -9.0062e-03, -8.4338e-03,\n",
       "                       9.3629e-03,  4.2526e-02,  2.6356e-03, -6.6380e-03,  1.9173e-03,\n",
       "                      -1.4020e-03, -8.2293e-04,  2.0207e-02, -2.9390e-03,  1.4594e-02,\n",
       "                       4.2720e-02, -1.2151e-02,  2.1521e-02,  1.9472e-02,  4.6044e-02,\n",
       "                      -3.8270e-03, -2.3740e-03,  8.2569e-03, -8.1687e-03,  1.1345e-03,\n",
       "                       1.7192e-03, -6.2746e-03, -1.4829e-03, -3.1430e-03,  2.1675e-03,\n",
       "                      -1.7156e-02,  4.3073e-02,  6.6343e-03, -1.4859e-02, -9.7583e-03,\n",
       "                       1.5981e-02, -7.2110e-03, -1.4681e-03,  7.2295e-04, -2.7952e-03,\n",
       "                       4.5814e-04,  1.7306e-02, -1.2386e-02,  1.8691e-02,  2.0999e-02,\n",
       "                      -1.9384e-03,  2.8157e-02,  8.3405e-03,  2.4925e-02,  9.3648e-03,\n",
       "                       1.7784e-02,  2.2627e-02,  3.1982e-02,  7.2117e-03,  3.2631e-02,\n",
       "                       2.6358e-03,  1.6877e-02, -5.2966e-03,  1.0959e-02, -8.2528e-03,\n",
       "                       9.1780e-03, -6.7086e-03,  8.7936e-04,  1.2549e-02,  7.7337e-03,\n",
       "                      -1.8227e-03, -9.9478e-03,  3.8144e-02,  1.5748e-02,  1.6309e-02,\n",
       "                       1.3233e-03,  1.4160e-02,  1.1612e-03, -1.0675e-02,  5.6161e-03,\n",
       "                       2.4975e-02,  3.5610e-02,  2.7813e-02,  6.9729e-03,  1.9799e-02,\n",
       "                       1.6983e-02, -1.6517e-03,  2.8085e-03, -4.0478e-03,  1.1278e-03,\n",
       "                       1.2413e-02,  1.2377e-02,  3.0535e-02,  1.1277e-02,  2.2998e-02,\n",
       "                      -2.0548e-03, -6.6545e-03,  6.0780e-03,  1.4506e-02,  3.8016e-02,\n",
       "                       3.5835e-02, -5.4233e-03, -8.6314e-03,  4.4335e-03,  1.2867e-02,\n",
       "                       1.5996e-02,  2.9568e-02,  2.8187e-02,  3.7404e-03,  3.6973e-02,\n",
       "                      -9.5178e-04,  9.3061e-03,  3.9468e-02, -1.0628e-03,  4.9677e-03,\n",
       "                       2.8057e-04,  9.0643e-03,  1.0406e-02, -1.2840e-02, -4.7258e-03,\n",
       "                       6.7705e-03,  6.5488e-03])),\n",
       "             ('decoders.3.bn3.running_mean',\n",
       "              tensor([-0.0076, -0.4061, -0.4275, -0.0322, -0.1623, -0.2989, -0.2610, -0.2933,\n",
       "                       0.0392,  0.1045,  0.0530, -0.1404,  0.0380,  0.3191,  0.0714, -0.2212,\n",
       "                      -0.0623, -0.5020, -0.0598, -0.2648,  0.0035, -0.3982, -0.0418,  0.5398,\n",
       "                      -0.3933,  0.1187,  0.6535, -0.1311, -0.0695,  0.2418, -0.1784,  0.1647,\n",
       "                      -0.0316, -0.2093,  0.1420,  0.1453, -0.1574, -0.1203,  0.6880, -0.0084,\n",
       "                       0.2202,  0.0382, -0.1228, -0.0849, -0.2354, -0.2299, -0.4033,  0.1043,\n",
       "                      -0.2505, -0.2719, -0.2376, -0.1824,  0.0883, -0.2259, -0.3378,  0.3340,\n",
       "                      -0.2705,  0.4965, -0.2303,  0.5029,  0.5133,  0.1515,  0.3546, -0.2628,\n",
       "                      -0.1651, -0.3352,  0.0185, -0.1126, -0.1519, -0.4128, -0.1764,  0.5095,\n",
       "                      -0.2116, -0.3790, -0.1848,  0.1012,  0.4511, -0.4032,  0.3298, -0.0085,\n",
       "                      -0.3545, -0.1073, -0.0686,  0.3533, -0.4023,  0.0196,  0.2292, -0.1422,\n",
       "                      -0.2068, -0.2296,  0.1491, -0.4385,  0.2320,  0.3496, -0.0187, -0.1183,\n",
       "                      -0.2290,  0.4263, -0.1960, -0.2791, -0.4752,  0.1063, -0.0333, -0.2875,\n",
       "                       0.4419,  0.3407, -0.1613, -0.0757, -0.1409,  0.2158, -0.4091, -0.0202,\n",
       "                      -0.3634, -0.0747,  0.3704,  0.0497,  0.2122,  0.2269, -0.1660, -0.4418,\n",
       "                       0.3126,  0.1482,  0.5312, -0.1392,  0.5238,  0.1563, -0.0783,  0.6692,\n",
       "                       0.4861,  0.2124, -0.2224, -0.1494,  0.3242, -0.1379, -0.0487, -0.4349,\n",
       "                       0.4664, -0.1118, -0.3520, -0.0094,  0.2052, -0.3819,  0.3027, -0.0740,\n",
       "                      -0.4394, -0.0258, -0.2101,  0.7129,  0.0811,  0.0407,  0.1899,  0.0530,\n",
       "                       0.2567, -0.0991,  0.2353,  0.1386,  0.4668,  0.2022,  0.2896, -0.1808,\n",
       "                      -0.2656, -0.0663,  0.3009, -0.1362,  0.4495,  0.1229,  0.4409,  0.2721,\n",
       "                       0.1364,  0.2032,  0.0274, -0.0506, -0.0215,  0.0199,  0.4464,  0.5473,\n",
       "                      -0.3968, -0.2138, -0.1209, -0.1029, -0.0995, -0.1682,  0.3541,  0.4098,\n",
       "                       0.4022,  0.2504,  0.2565, -0.1742,  0.4189, -0.1125,  0.0626,  0.6060,\n",
       "                       0.1698,  0.3326, -0.2560,  0.6563, -0.1500, -0.3590, -0.0068, -0.1050,\n",
       "                      -0.0154,  0.1644,  0.1167, -0.1568, -0.0440,  0.2726,  0.1180,  0.1687,\n",
       "                       0.1493,  0.0888,  0.1190,  0.4129, -0.1483,  0.4985, -0.1360,  0.1205,\n",
       "                      -0.1739, -0.0168, -0.3452,  0.1681, -0.1906, -0.1718, -0.5025, -0.4433,\n",
       "                      -0.3019,  0.1641, -0.2409,  0.2844, -0.3157,  0.2236, -0.2089,  0.2253,\n",
       "                       0.3162,  0.0599, -0.2980,  0.1052,  0.3157, -0.1166, -0.2183, -0.2394,\n",
       "                       0.0828,  0.2017,  0.1198,  0.2422, -0.1783, -0.1354,  0.6093,  0.3995,\n",
       "                      -0.5087, -0.3413, -0.2392,  0.0365,  0.6402,  0.0612, -0.1289,  0.3587,\n",
       "                      -0.2342, -0.0141,  0.2042,  0.3680, -0.0338,  0.5387, -0.1640, -0.3764,\n",
       "                       0.3969,  0.0080,  0.0796, -0.3056,  0.2931, -0.0134,  0.2010, -0.1431,\n",
       "                       0.1123, -0.1424, -0.3570,  0.0377,  0.0214,  0.1795,  0.0469, -0.1234,\n",
       "                      -0.1346, -0.2716, -0.2470,  0.0899, -0.1342, -0.2541, -0.3030, -0.2513,\n",
       "                       0.0329, -0.1980,  0.5202, -0.2543,  0.1183, -0.3412, -0.3067,  0.3349,\n",
       "                      -0.2541,  0.2335, -0.0121,  0.3904,  0.2407, -0.3200,  0.1906,  0.2717,\n",
       "                      -0.1121, -0.0334, -0.2430,  0.0980, -0.0705, -0.4620,  0.3537, -0.1577,\n",
       "                      -0.3924,  0.2788, -0.1840,  0.3049,  0.0822, -0.1435,  0.1176, -0.1940,\n",
       "                       0.0779,  0.3514, -0.3190,  0.5267,  0.3780,  0.1035, -0.1203, -0.1165,\n",
       "                       0.1571,  0.3473, -0.0386,  0.0712, -0.0806,  0.1855, -0.0666, -0.0941,\n",
       "                      -0.2350,  0.0482,  0.1987, -0.0771, -0.4178, -0.0878,  0.0132,  0.2458,\n",
       "                      -0.2170, -0.0403,  0.0328, -0.1184,  0.0345, -0.2056,  0.2855,  0.3543,\n",
       "                      -0.0426, -0.1410, -0.2062, -0.1284, -0.1716,  0.0107, -0.2984, -0.0090,\n",
       "                       0.0623,  0.1402,  0.5351, -0.1834,  0.1027, -0.0477,  0.0144, -0.3697,\n",
       "                       0.1426, -0.5100,  0.0744,  0.2468,  0.5730,  0.3277, -0.4406,  0.0406,\n",
       "                      -0.1273, -0.2573,  0.1188,  0.1356,  0.3002, -0.1671,  0.5189, -0.0388,\n",
       "                       0.2453,  0.2844, -0.0988, -0.2844, -0.0219,  0.1052, -0.3314, -0.2399,\n",
       "                      -0.1788, -0.2856, -0.1885,  0.4512, -0.2449,  0.0283,  0.1715,  0.1268,\n",
       "                       0.2869, -0.4949,  0.0909,  0.1349,  0.1805, -0.0743, -0.0738, -0.0422,\n",
       "                      -0.0595,  0.1960, -0.4487,  0.3669, -0.2891, -0.1797, -0.1879, -0.0194,\n",
       "                      -0.0412, -0.0354, -0.0122, -0.2062, -0.3064, -0.2943,  0.1498,  0.5612,\n",
       "                       0.2289, -0.1620, -0.2817,  0.2104,  0.3405,  0.0400, -0.2673, -0.1313,\n",
       "                      -0.1761, -0.1155, -0.0648,  0.3826, -0.1710,  0.3282, -0.3004, -0.1341,\n",
       "                       0.1770, -0.1420,  0.2635, -0.3800,  0.0267, -0.1483, -0.1572, -0.2712,\n",
       "                      -0.1007, -0.7691, -0.1010, -0.3480,  0.0925, -0.4083,  0.3736, -0.2550,\n",
       "                      -0.1197, -0.0133, -0.2345, -0.0260,  0.3556,  0.2928, -0.3752, -0.3666,\n",
       "                       0.0984,  0.1810,  0.0665, -0.1777,  0.5588, -0.0338, -0.1771, -0.2562,\n",
       "                      -0.3499, -0.2154, -0.0498, -0.0864, -0.0958, -0.1193,  0.3863, -0.4771,\n",
       "                      -0.0972, -0.1115, -0.1472,  0.3269,  0.0762, -0.0242,  0.4131,  0.0725,\n",
       "                      -0.2856, -0.0984, -0.4259,  0.5747,  0.0234,  0.2618,  0.2344,  0.0684,\n",
       "                      -0.3852,  0.0686,  0.0322, -0.5981,  0.0506, -0.2231, -0.2018, -0.0759,\n",
       "                       0.2051,  0.1766, -0.1882, -0.2192, -0.0997,  0.3436,  0.0218,  0.0276])),\n",
       "             ('decoders.3.bn3.running_var',\n",
       "              tensor([0.8034, 0.9857, 0.3351, 1.0243, 0.4659, 0.4012, 0.6024, 0.4871, 1.1798,\n",
       "                      0.2170, 0.8774, 1.0564, 1.2344, 0.3508, 0.9135, 0.6288, 0.4934, 0.5391,\n",
       "                      0.3289, 0.4614, 0.3785, 0.4163, 1.0578, 0.7510, 0.1799, 0.3513, 0.2676,\n",
       "                      0.2380, 0.9196, 0.9880, 0.7882, 1.4937, 0.4891, 0.6664, 0.4876, 1.4746,\n",
       "                      0.3710, 0.5319, 0.8512, 0.4461, 0.4173, 0.6974, 0.3577, 1.5511, 1.0759,\n",
       "                      1.0346, 0.5238, 0.4224, 1.1720, 0.1939, 0.4738, 0.9194, 0.7531, 0.4116,\n",
       "                      0.2796, 1.3520, 1.3300, 0.7516, 1.1782, 0.9969, 1.8007, 0.9936, 1.1015,\n",
       "                      0.7689, 0.5384, 0.4960, 1.1324, 0.4566, 0.2996, 0.8664, 0.9391, 0.6180,\n",
       "                      0.7365, 0.1563, 0.9299, 0.5213, 0.4569, 0.7072, 0.4962, 1.2130, 2.0338,\n",
       "                      0.8002, 1.1430, 0.9692, 0.5657, 0.3374, 0.3133, 1.3075, 0.5160, 0.2691,\n",
       "                      0.3473, 1.4562, 1.4154, 1.5440, 0.3854, 0.3176, 0.2469, 1.2644, 0.5312,\n",
       "                      0.5574, 0.4240, 0.7881, 0.5287, 1.6101, 1.6840, 0.9600, 1.5277, 0.7770,\n",
       "                      0.2019, 0.5503, 0.9903, 0.8421, 0.2550, 1.0831, 0.9832, 0.4390, 0.6861,\n",
       "                      0.4744, 0.4545, 0.4553, 0.8518, 0.4908, 1.4628, 0.4190, 1.4159, 0.7614,\n",
       "                      1.5300, 0.8832, 0.5392, 1.2146, 1.0289, 0.2458, 1.0405, 0.7532, 0.5748,\n",
       "                      0.6867, 0.9689, 0.8914, 0.8559, 0.3495, 0.6518, 0.8276, 0.4411, 0.2907,\n",
       "                      0.1819, 0.7302, 0.4145, 1.3021, 0.9637, 0.7627, 0.5577, 0.9077, 0.9141,\n",
       "                      0.3344, 0.5889, 1.4302, 1.2326, 1.3809, 0.7011, 0.9843, 0.8847, 0.6449,\n",
       "                      1.1993, 1.3764, 0.6747, 0.5783, 0.7856, 0.8632, 0.8427, 0.6625, 0.6899,\n",
       "                      0.6842, 0.5496, 0.2363, 2.0202, 1.0158, 0.7084, 0.3010, 0.7180, 0.2849,\n",
       "                      0.9191, 0.5543, 0.8532, 0.9765, 0.7006, 1.5818, 0.4446, 0.4729, 1.5120,\n",
       "                      0.2956, 0.9272, 0.6589, 0.8703, 1.5607, 0.9449, 0.8112, 0.4597, 0.7605,\n",
       "                      1.3524, 0.5193, 0.5557, 0.2219, 1.0873, 0.2806, 0.2805, 0.8633, 0.5060,\n",
       "                      0.6053, 0.7817, 0.9079, 0.5189, 0.4451, 0.6319, 0.2158, 0.1228, 1.5402,\n",
       "                      0.6617, 0.4238, 0.2311, 0.7463, 0.9050, 0.4234, 1.1633, 1.4208, 1.0848,\n",
       "                      0.3356, 0.1524, 0.1471, 1.1212, 0.7394, 0.2479, 1.1993, 0.7438, 1.0538,\n",
       "                      0.5211, 1.8781, 1.2339, 1.0033, 0.5868, 0.3086, 0.6294, 0.1446, 1.6660,\n",
       "                      0.7745, 0.5170, 0.6882, 0.9420, 0.4633, 0.9482, 0.7283, 0.5138, 0.4163,\n",
       "                      0.8042, 0.5105, 0.4481, 0.5828, 1.1558, 0.4118, 0.9177, 0.5217, 0.4697,\n",
       "                      0.6588, 0.6463, 0.3367, 0.9293, 0.2836, 1.5150, 0.5387, 0.3161, 0.5719,\n",
       "                      0.4433, 0.4927, 0.6844, 0.4835, 1.0502, 1.1936, 0.5527, 0.7826, 0.2657,\n",
       "                      0.6273, 0.5655, 0.1478, 0.1250, 0.4915, 0.9319, 0.4852, 0.5213, 0.2609,\n",
       "                      0.2632, 0.9193, 0.5818, 0.7788, 2.2047, 0.8043, 1.2323, 0.5618, 0.5728,\n",
       "                      0.4326, 0.4954, 0.8347, 0.2089, 1.0129, 0.2324, 0.8102, 0.5052, 0.4568,\n",
       "                      0.7942, 1.0895, 0.5762, 0.7673, 0.6958, 0.3547, 0.9439, 0.9388, 0.4214,\n",
       "                      0.9331, 0.5679, 0.5074, 0.3172, 1.4771, 0.2959, 1.0824, 0.3699, 1.2951,\n",
       "                      1.2990, 1.4983, 0.2144, 0.8854, 0.8581, 1.3602, 0.6956, 0.4386, 0.4391,\n",
       "                      0.5614, 0.7744, 0.6946, 0.3458, 1.2416, 1.0925, 0.5868, 0.6805, 0.5904,\n",
       "                      1.0998, 0.6955, 0.8420, 2.0483, 0.8622, 0.3826, 0.5452, 0.5141, 1.0624,\n",
       "                      0.5405, 0.1838, 1.0030, 1.0223, 0.4343, 1.2523, 1.4767, 0.4741, 0.9495,\n",
       "                      1.6237, 0.4564, 1.1678, 0.4655, 0.9878, 0.5720, 0.3906, 0.4612, 1.2966,\n",
       "                      0.7222, 0.2701, 1.1091, 0.6841, 1.9960, 0.8110, 0.5192, 0.7172, 1.1613,\n",
       "                      1.6399, 0.2409, 0.6941, 0.3023, 1.0001, 0.4353, 1.5803, 0.9165, 0.9057,\n",
       "                      0.6551, 1.1451, 1.3918, 0.6195, 0.7191, 0.3371, 0.3531, 0.4985, 0.7308,\n",
       "                      0.6204, 0.6266, 0.3612, 0.8018, 0.6840, 0.9489, 0.6924, 0.4774, 1.1289,\n",
       "                      0.5283, 0.3206, 0.7594, 1.7318, 0.7088, 0.7752, 0.4627, 1.2366, 0.9350,\n",
       "                      1.2088, 0.6326, 0.4078, 0.5245, 0.2565, 0.4575, 0.5537, 0.1804, 0.9693,\n",
       "                      0.2701, 0.4678, 0.3396, 1.6116, 0.5476, 0.5258, 0.4720, 0.6577, 0.6891,\n",
       "                      0.7391, 0.7354, 0.2875, 0.1643, 0.5241, 0.4811, 0.6977, 0.8965, 0.8067,\n",
       "                      0.8298, 1.8185, 0.6574, 0.8416, 1.1707, 1.0526, 0.5789, 0.9054, 0.4605,\n",
       "                      0.3622, 0.4525, 0.6398, 0.5315, 0.8472, 0.8462, 1.1424, 0.8254, 0.6809,\n",
       "                      1.1372, 0.5060, 0.4010, 1.8033, 0.6592, 0.8633, 1.3443, 0.7344, 0.3494,\n",
       "                      1.1492, 0.7211, 0.9889, 0.7576, 0.6682, 0.1448, 1.2397, 0.9278, 1.1182,\n",
       "                      0.2536, 0.6053, 0.9064, 0.9089, 0.6588, 1.8642, 0.6831, 1.2121, 0.5915,\n",
       "                      0.3676, 0.8396, 0.5591, 1.0424, 0.9861, 0.6517, 0.8379, 0.9792, 0.8513,\n",
       "                      0.6752, 0.8133, 0.6524, 0.9610, 0.4540, 1.0501, 0.4982, 0.6682, 0.4433,\n",
       "                      0.4726, 0.9656, 0.5077, 0.9888, 0.3612, 0.8851, 0.6983, 0.4115])),\n",
       "             ('decoders.3.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense4.weight',\n",
       "              tensor([[-0.0145,  0.0287, -0.0207,  ..., -0.0415,  0.0070, -0.0405],\n",
       "                      [ 0.0152,  0.0231, -0.0319,  ..., -0.0410,  0.0391,  0.0323],\n",
       "                      [ 0.0271, -0.0036, -0.0285,  ..., -0.0500,  0.0224, -0.0270],\n",
       "                      ...,\n",
       "                      [ 0.0426,  0.0012, -0.0245,  ...,  0.0454, -0.0248, -0.0031],\n",
       "                      [ 0.0303, -0.0293, -0.0054,  ...,  0.0117, -0.0370, -0.0343],\n",
       "                      [-0.0279,  0.0368,  0.0289,  ..., -0.0551, -0.0045,  0.0139]])),\n",
       "             ('decoders.3.bn4.weight',\n",
       "              tensor([1.0280, 1.0293, 1.0265, 1.0292, 1.0318, 1.0291, 1.0292, 1.0284, 1.0303,\n",
       "                      1.0296, 1.0313, 1.0323, 1.0300, 1.0306, 1.0327, 1.0312, 1.0289, 1.0286,\n",
       "                      1.0303, 1.0270, 1.0292, 1.0298, 1.0256, 1.0295, 1.0305, 1.0265, 1.0286,\n",
       "                      1.0305, 1.0277, 1.0291, 1.0292, 1.0289, 1.0302, 1.0303, 1.0268, 1.0296,\n",
       "                      1.0283, 1.0310, 1.0306, 1.0270, 1.0323, 1.0277, 1.0306, 1.0305, 1.0265,\n",
       "                      1.0301, 1.0290, 1.0292, 1.0315, 1.0221, 1.0330, 1.0314, 1.0328, 1.0287,\n",
       "                      1.0302, 1.0296, 1.0322, 1.0279, 1.0324, 1.0277, 1.0284, 1.0313, 1.0276,\n",
       "                      1.0250, 1.0247, 1.0262, 1.0312, 1.0270, 1.0314, 1.0287, 1.0330, 1.0279,\n",
       "                      1.0301, 1.0280, 1.0283, 1.0281, 1.0288, 1.0280, 1.0288, 1.0304, 1.0275,\n",
       "                      1.0348, 1.0307, 1.0251, 1.0316, 1.0294, 1.0251, 1.0315, 1.0274, 1.0305,\n",
       "                      1.0286, 1.0303, 1.0275, 1.0263, 1.0310, 1.0258, 1.0289, 1.0287, 1.0273,\n",
       "                      1.0305, 1.0233, 1.0303, 1.0302, 1.0290, 1.0281, 1.0303, 1.0275, 1.0314,\n",
       "                      1.0233, 1.0309, 1.0277, 1.0296, 1.0308, 1.0300, 1.0336, 1.0297, 1.0314,\n",
       "                      1.0302, 1.0319, 1.0286, 1.0305, 1.0276, 1.0304, 1.0326, 1.0302, 1.0280,\n",
       "                      1.0310, 1.0247, 1.0320, 1.0327, 1.0237, 1.0293, 1.0275, 1.0270, 1.0293,\n",
       "                      1.0313, 1.0316, 1.0270, 1.0309, 1.0277, 1.0284, 1.0299, 1.0305, 1.0289,\n",
       "                      1.0296, 1.0313, 1.0309, 1.0293, 1.0291, 1.0276, 1.0327, 1.0282, 1.0303,\n",
       "                      1.0299, 1.0310, 1.0265, 1.0295, 1.0262, 1.0299, 1.0291, 1.0300, 1.0284,\n",
       "                      1.0299, 1.0252, 1.0286, 1.0305, 1.0299, 1.0296, 1.0290, 1.0294, 1.0293,\n",
       "                      1.0296, 1.0257, 1.0303, 1.0300, 1.0286, 1.0313, 1.0311, 1.0309, 1.0323,\n",
       "                      1.0301, 1.0288, 1.0314, 1.0280, 1.0272, 1.0280, 1.0297, 1.0282, 1.0277,\n",
       "                      1.0289, 1.0255, 1.0291, 1.0262, 1.0273, 1.0264, 1.0267, 1.0293, 1.0311,\n",
       "                      1.0248, 1.0288, 1.0278, 1.0222, 1.0282, 1.0256, 1.0284, 1.0298, 1.0254,\n",
       "                      1.0271, 1.0261, 1.0287, 1.0302, 1.0259, 1.0269, 1.0316, 1.0299, 1.0269,\n",
       "                      1.0280, 1.0267, 1.0284, 1.0291, 1.0307, 1.0293, 1.0279, 1.0302, 1.0312,\n",
       "                      1.0298, 1.0286, 1.0308, 1.0302, 1.0288, 1.0301, 1.0271, 1.0293, 1.0316,\n",
       "                      1.0291, 1.0277, 1.0288, 1.0268, 1.0302, 1.0312, 1.0314, 1.0291, 1.0298,\n",
       "                      1.0301, 1.0265, 1.0284, 1.0292, 1.0282, 1.0266, 1.0317, 1.0279, 1.0309,\n",
       "                      1.0248, 1.0287, 1.0285, 1.0243, 1.0318, 1.0319, 1.0275, 1.0290, 1.0301,\n",
       "                      1.0285, 1.0297, 1.0285, 1.0309, 1.0303, 1.0298, 1.0264, 1.0275, 1.0306,\n",
       "                      1.0320, 1.0306, 1.0276, 1.0286, 1.0254, 1.0289, 1.0303, 1.0304, 1.0259,\n",
       "                      1.0327, 1.0295, 1.0293, 1.0287, 1.0305, 1.0278, 1.0333, 1.0280, 1.0228,\n",
       "                      1.0291, 1.0253, 1.0306, 1.0325, 1.0238, 1.0292, 1.0299, 1.0280, 1.0318,\n",
       "                      1.0270, 1.0289, 1.0330, 1.0267, 1.0302, 1.0267, 1.0311, 1.0284, 1.0273,\n",
       "                      1.0308, 1.0275, 1.0284, 1.0292, 1.0257, 1.0277, 1.0310, 1.0273, 1.0287,\n",
       "                      1.0325, 1.0289, 1.0301, 1.0316, 1.0311, 1.0288, 1.0280, 1.0302, 1.0289,\n",
       "                      1.0307, 1.0301, 1.0271, 1.0295, 1.0303, 1.0304, 1.0317, 1.0297, 1.0295,\n",
       "                      1.0319, 1.0292, 1.0292, 1.0288, 1.0308, 1.0320, 1.0282, 1.0264, 1.0273,\n",
       "                      1.0242, 1.0308, 1.0286, 1.0277, 1.0284, 1.0280, 1.0289, 1.0289, 1.0307,\n",
       "                      1.0296, 1.0309, 1.0265, 1.0242, 1.0275, 1.0290, 1.0257, 1.0307, 1.0285,\n",
       "                      1.0282, 1.0277, 1.0277, 1.0309, 1.0277, 1.0319, 1.0273, 1.0274, 1.0304,\n",
       "                      1.0324, 1.0267, 1.0303, 1.0300, 1.0302, 1.0314, 1.0280, 1.0308, 1.0285,\n",
       "                      1.0299, 1.0280, 1.0277, 1.0254, 1.0301, 1.0287, 1.0310, 1.0297, 1.0284,\n",
       "                      1.0260, 1.0288, 1.0302, 1.0288, 1.0290, 1.0307, 1.0290, 1.0307, 1.0313,\n",
       "                      1.0289, 1.0248, 1.0250, 1.0290, 1.0315, 1.0338, 1.0298, 1.0247, 1.0296,\n",
       "                      1.0304, 1.0279, 1.0260, 1.0279, 1.0273, 1.0272, 1.0295, 1.0306, 1.0296,\n",
       "                      1.0316, 1.0295, 1.0342, 1.0299, 1.0298, 1.0272, 1.0284, 1.0279, 1.0295,\n",
       "                      1.0267, 1.0285, 1.0288, 1.0312, 1.0293, 1.0246, 1.0308, 1.0297, 1.0248,\n",
       "                      1.0309, 1.0286, 1.0292, 1.0283, 1.0295, 1.0264, 1.0307, 1.0295, 1.0289,\n",
       "                      1.0283, 1.0311, 1.0271, 1.0289, 1.0277, 1.0313, 1.0305, 1.0272, 1.0313,\n",
       "                      1.0276, 1.0292, 1.0279, 1.0253, 1.0301, 1.0306, 1.0304, 1.0275, 1.0314,\n",
       "                      1.0279, 1.0316, 1.0292, 1.0271, 1.0307, 1.0293, 1.0326, 1.0254, 1.0281,\n",
       "                      1.0292, 1.0305, 1.0220, 1.0286, 1.0292, 1.0290, 1.0309, 1.0286, 1.0309,\n",
       "                      1.0277, 1.0292, 1.0325, 1.0286, 1.0279, 1.0300, 1.0286, 1.0288, 1.0258,\n",
       "                      1.0284, 1.0265, 1.0283, 1.0225, 1.0293, 1.0296, 1.0293, 1.0233, 1.0280,\n",
       "                      1.0303, 1.0313, 1.0262, 1.0327, 1.0240, 1.0280, 1.0271, 1.0252, 1.0299,\n",
       "                      1.0281, 1.0273, 1.0310, 1.0289, 1.0317, 1.0303, 1.0305, 1.0284])),\n",
       "             ('decoders.3.bn4.bias',\n",
       "              tensor([0.0336, 0.0352, 0.0345, 0.0355, 0.0369, 0.0324, 0.0370, 0.0352, 0.0364,\n",
       "                      0.0346, 0.0358, 0.0374, 0.0339, 0.0349, 0.0368, 0.0373, 0.0343, 0.0353,\n",
       "                      0.0367, 0.0355, 0.0352, 0.0321, 0.0320, 0.0362, 0.0358, 0.0349, 0.0357,\n",
       "                      0.0354, 0.0316, 0.0380, 0.0347, 0.0354, 0.0358, 0.0348, 0.0352, 0.0321,\n",
       "                      0.0328, 0.0383, 0.0360, 0.0327, 0.0364, 0.0356, 0.0355, 0.0353, 0.0317,\n",
       "                      0.0345, 0.0335, 0.0325, 0.0358, 0.0306, 0.0377, 0.0364, 0.0363, 0.0337,\n",
       "                      0.0371, 0.0370, 0.0371, 0.0323, 0.0376, 0.0336, 0.0341, 0.0380, 0.0342,\n",
       "                      0.0307, 0.0326, 0.0347, 0.0367, 0.0346, 0.0367, 0.0331, 0.0363, 0.0349,\n",
       "                      0.0363, 0.0340, 0.0329, 0.0354, 0.0362, 0.0352, 0.0353, 0.0371, 0.0321,\n",
       "                      0.0372, 0.0351, 0.0332, 0.0367, 0.0355, 0.0349, 0.0352, 0.0338, 0.0347,\n",
       "                      0.0344, 0.0347, 0.0342, 0.0312, 0.0364, 0.0323, 0.0355, 0.0345, 0.0312,\n",
       "                      0.0384, 0.0303, 0.0333, 0.0350, 0.0349, 0.0320, 0.0359, 0.0345, 0.0375,\n",
       "                      0.0304, 0.0335, 0.0338, 0.0356, 0.0377, 0.0363, 0.0364, 0.0353, 0.0376,\n",
       "                      0.0355, 0.0348, 0.0343, 0.0353, 0.0326, 0.0363, 0.0373, 0.0353, 0.0361,\n",
       "                      0.0341, 0.0302, 0.0375, 0.0364, 0.0282, 0.0337, 0.0351, 0.0341, 0.0359,\n",
       "                      0.0366, 0.0365, 0.0355, 0.0350, 0.0358, 0.0331, 0.0356, 0.0350, 0.0362,\n",
       "                      0.0362, 0.0371, 0.0367, 0.0382, 0.0358, 0.0345, 0.0356, 0.0338, 0.0345,\n",
       "                      0.0351, 0.0348, 0.0321, 0.0373, 0.0349, 0.0363, 0.0359, 0.0356, 0.0332,\n",
       "                      0.0369, 0.0328, 0.0356, 0.0356, 0.0353, 0.0356, 0.0365, 0.0338, 0.0371,\n",
       "                      0.0344, 0.0283, 0.0354, 0.0366, 0.0327, 0.0365, 0.0356, 0.0367, 0.0366,\n",
       "                      0.0361, 0.0341, 0.0358, 0.0352, 0.0353, 0.0324, 0.0366, 0.0310, 0.0345,\n",
       "                      0.0348, 0.0358, 0.0346, 0.0332, 0.0323, 0.0360, 0.0333, 0.0350, 0.0372,\n",
       "                      0.0349, 0.0347, 0.0352, 0.0330, 0.0345, 0.0345, 0.0342, 0.0336, 0.0333,\n",
       "                      0.0325, 0.0318, 0.0350, 0.0374, 0.0319, 0.0335, 0.0364, 0.0347, 0.0332,\n",
       "                      0.0321, 0.0344, 0.0345, 0.0325, 0.0354, 0.0348, 0.0315, 0.0373, 0.0364,\n",
       "                      0.0317, 0.0351, 0.0359, 0.0360, 0.0351, 0.0381, 0.0342, 0.0345, 0.0382,\n",
       "                      0.0374, 0.0333, 0.0359, 0.0354, 0.0370, 0.0370, 0.0360, 0.0346, 0.0362,\n",
       "                      0.0380, 0.0323, 0.0345, 0.0355, 0.0371, 0.0314, 0.0364, 0.0340, 0.0348,\n",
       "                      0.0329, 0.0377, 0.0343, 0.0315, 0.0359, 0.0360, 0.0355, 0.0354, 0.0381,\n",
       "                      0.0348, 0.0352, 0.0338, 0.0350, 0.0347, 0.0361, 0.0349, 0.0375, 0.0372,\n",
       "                      0.0352, 0.0368, 0.0321, 0.0348, 0.0319, 0.0344, 0.0356, 0.0370, 0.0344,\n",
       "                      0.0355, 0.0360, 0.0347, 0.0364, 0.0351, 0.0343, 0.0367, 0.0349, 0.0342,\n",
       "                      0.0357, 0.0365, 0.0353, 0.0358, 0.0374, 0.0372, 0.0367, 0.0355, 0.0377,\n",
       "                      0.0352, 0.0316, 0.0364, 0.0317, 0.0367, 0.0309, 0.0382, 0.0320, 0.0318,\n",
       "                      0.0353, 0.0337, 0.0322, 0.0361, 0.0301, 0.0327, 0.0373, 0.0317, 0.0327,\n",
       "                      0.0374, 0.0364, 0.0353, 0.0341, 0.0362, 0.0325, 0.0349, 0.0374, 0.0336,\n",
       "                      0.0377, 0.0366, 0.0323, 0.0362, 0.0377, 0.0353, 0.0374, 0.0361, 0.0358,\n",
       "                      0.0367, 0.0352, 0.0348, 0.0355, 0.0382, 0.0364, 0.0343, 0.0317, 0.0330,\n",
       "                      0.0325, 0.0348, 0.0339, 0.0319, 0.0350, 0.0339, 0.0347, 0.0348, 0.0354,\n",
       "                      0.0371, 0.0370, 0.0334, 0.0327, 0.0340, 0.0364, 0.0341, 0.0359, 0.0367,\n",
       "                      0.0340, 0.0349, 0.0327, 0.0353, 0.0339, 0.0377, 0.0334, 0.0356, 0.0366,\n",
       "                      0.0374, 0.0373, 0.0363, 0.0334, 0.0352, 0.0367, 0.0322, 0.0353, 0.0348,\n",
       "                      0.0344, 0.0347, 0.0327, 0.0300, 0.0360, 0.0350, 0.0370, 0.0357, 0.0340,\n",
       "                      0.0309, 0.0322, 0.0351, 0.0357, 0.0347, 0.0344, 0.0372, 0.0352, 0.0343,\n",
       "                      0.0327, 0.0328, 0.0326, 0.0365, 0.0358, 0.0364, 0.0360, 0.0301, 0.0344,\n",
       "                      0.0367, 0.0352, 0.0324, 0.0324, 0.0340, 0.0319, 0.0360, 0.0350, 0.0347,\n",
       "                      0.0374, 0.0358, 0.0361, 0.0358, 0.0351, 0.0335, 0.0347, 0.0318, 0.0321,\n",
       "                      0.0352, 0.0360, 0.0323, 0.0369, 0.0353, 0.0333, 0.0366, 0.0370, 0.0328,\n",
       "                      0.0378, 0.0347, 0.0379, 0.0337, 0.0352, 0.0351, 0.0358, 0.0349, 0.0360,\n",
       "                      0.0352, 0.0344, 0.0327, 0.0345, 0.0346, 0.0366, 0.0368, 0.0349, 0.0343,\n",
       "                      0.0343, 0.0374, 0.0360, 0.0321, 0.0365, 0.0330, 0.0329, 0.0350, 0.0366,\n",
       "                      0.0315, 0.0352, 0.0345, 0.0310, 0.0359, 0.0348, 0.0358, 0.0330, 0.0342,\n",
       "                      0.0363, 0.0353, 0.0343, 0.0336, 0.0347, 0.0324, 0.0352, 0.0350, 0.0355,\n",
       "                      0.0327, 0.0324, 0.0366, 0.0315, 0.0345, 0.0345, 0.0361, 0.0332, 0.0338,\n",
       "                      0.0353, 0.0332, 0.0356, 0.0351, 0.0370, 0.0344, 0.0384, 0.0322, 0.0341,\n",
       "                      0.0355, 0.0370, 0.0341, 0.0363, 0.0304, 0.0323, 0.0338, 0.0335, 0.0372,\n",
       "                      0.0337, 0.0314, 0.0370, 0.0375, 0.0360, 0.0355, 0.0373, 0.0352])),\n",
       "             ('decoders.3.bn4.running_mean',\n",
       "              tensor([-0.8285, -0.4891, -0.6804, -0.6890, -0.5629, -0.3013, -0.6149, -0.6096,\n",
       "                      -0.6642, -0.5420, -0.7092, -0.4886, -0.2999, -0.3650, -0.0276, -0.6306,\n",
       "                      -0.5489, -0.8701, -0.3674, -0.7743, -0.4355, -0.1142, -0.1323, -0.5609,\n",
       "                      -0.6925, -0.7572, -0.6431, -0.5816, -0.0966, -0.8007, -0.5793, -0.7613,\n",
       "                      -0.6102, -0.3255, -0.6097, -0.3155, -0.3217, -0.7675, -0.5455, -0.2431,\n",
       "                      -0.3580, -0.7086, -0.5248, -0.6380, -0.2870, -0.5522, -0.1910,  0.0264,\n",
       "                      -0.7157, -0.8512, -0.3762, -0.3774, -0.3515, -0.3031, -0.3071, -0.7365,\n",
       "                      -0.5285, -0.2869, -0.8382, -0.4437, -0.5219, -0.6474, -0.8283, -0.1489,\n",
       "                      -0.4645, -0.9039, -0.4559, -0.4580, -0.8114, -0.3167, -0.4621, -0.9022,\n",
       "                      -0.2924, -0.8249, -0.4363, -1.0448, -0.8743, -0.6714, -0.5423, -0.7064,\n",
       "                      -0.4374, -0.2821, -0.5468, -0.4805, -0.6241, -0.7054, -0.8014, -0.4914,\n",
       "                      -0.5110, -0.8143, -0.4627, -0.7787, -0.5158, -0.1853, -0.5629, -0.3937,\n",
       "                      -0.8316, -0.6287, -0.3085, -0.8571, -0.4418, -0.0282, -0.7208, -0.8701,\n",
       "                      -0.3992, -0.6264, -0.4433, -0.4488, -0.1235, -0.4101, -0.5462, -0.5070,\n",
       "                      -0.7281, -0.7284, -0.5028, -0.8862, -0.8734, -0.9450, -0.3898, -0.5471,\n",
       "                      -0.8635, -0.2595, -0.7032, -0.4091, -0.1276, -0.9995, -0.2442, -0.2548,\n",
       "                      -0.5178, -0.5781, -0.3528, -0.5953, -0.8430, -0.8377, -0.4767, -0.7027,\n",
       "                      -0.7513, -1.0648, -0.3417, -0.6142, -0.2275, -0.6228, -0.5540, -0.6836,\n",
       "                      -0.5701, -0.6209, -0.5507, -0.8121, -0.7103, -0.2485, -0.8461, -0.2740,\n",
       "                      -0.2314, -0.4262, -0.4933, -0.4563, -0.6136, -0.8803, -0.7767, -0.5636,\n",
       "                      -0.6425, -0.2035, -0.5132, -0.2262, -0.7013, -0.4278, -0.7264, -0.7218,\n",
       "                      -0.5673, -0.2874, -0.6068, -0.3932, -0.1032, -0.4943, -0.5348, -0.3079,\n",
       "                      -0.7952, -0.5368, -0.6432, -0.3922, -0.5125, -0.1643, -0.6777, -0.4324,\n",
       "                      -0.5618, -0.5414, -0.7279, -0.5537, -0.7631, -0.5142, -0.8084, -0.5056,\n",
       "                      -0.7012, -0.2309, -0.7951, -0.2444, -0.8612, -0.5254, -0.4027, -0.7126,\n",
       "                      -0.4131, -0.9369, -0.2762, -0.6938, -0.3452, -0.5717, -0.2565, -0.4084,\n",
       "                      -0.5515, -0.1787, -0.6496, -0.3939, -0.3034, -0.8268, -0.3888, -0.4526,\n",
       "                      -0.2676, -0.6011, -0.4460, -0.2620, -0.5153, -0.2802, -0.3085, -0.6583,\n",
       "                      -0.5215, -0.1324, -0.7799, -0.4665, -0.5805, -0.6161, -0.7123, -0.7938,\n",
       "                      -0.5938, -0.4942, -0.9065, -0.4828, -0.6292, -1.0060, -0.7944, -0.7855,\n",
       "                      -0.2956, -0.4627, -0.6307, -0.8173, -0.6383, -0.8069, -0.5717, -0.5110,\n",
       "                      -0.3331, -0.5171, -0.6829, -0.4884, -0.3084, -0.7786, -0.1751, -0.4201,\n",
       "                      -0.5390, -0.6400, -0.3351, -0.7535, -0.7566, -0.5846, -0.6275, -0.5434,\n",
       "                      -0.4883, -0.5368, -0.5461, -0.5700, -0.8320, -0.4192, -0.4182, -0.7119,\n",
       "                      -0.4049, -0.6272, -0.4143, -0.4628, -0.6988, -0.6415, -0.5504, -0.3167,\n",
       "                      -0.7233, -0.2508, -0.6336, -0.7661, -0.7495, -0.3716, -0.9112, -0.6857,\n",
       "                      -0.7334, -0.9031, -0.4328, -0.8054, -1.0045, -0.5843, -0.8508, -0.9336,\n",
       "                      -0.6619, -0.4570, -0.4206, -0.4876, -0.5190, -0.5791, -0.0475, -0.5652,\n",
       "                      -0.3731, -0.4535, -0.5919, -0.3900, -0.1606, -0.7229, -0.2021, -0.1257,\n",
       "                      -0.9541, -0.4631, -0.1684, -0.4883, -0.5517, -0.3498, -0.1011, -0.8053,\n",
       "                      -0.3493, -0.4941, -0.6200, -0.2436, -0.7634, -0.7928, -0.4724, -0.6513,\n",
       "                      -0.5303, -0.4784, -0.4110, -0.4031, -0.5462, -0.6573, -0.7654, -0.3293,\n",
       "                      -0.6772, -0.7884, -0.6885, -0.6574, -0.5209, -0.2546, -0.4985, -0.3717,\n",
       "                      -0.1464, -0.2387, -0.3894, -0.5852, -0.9618, -0.6893, -0.7124, -0.8090,\n",
       "                      -0.4982, -0.3386, -0.9121, -0.6847, -0.7555, -0.6877, -0.5376, -0.4961,\n",
       "                      -0.7331, -0.4915, -0.5905, -0.5387, -0.2548, -0.6392, -0.4864, -0.6475,\n",
       "                      -0.4547, -0.4441, -0.6934, -0.5931, -0.2607, -0.5298, -0.4912, -0.1917,\n",
       "                      -0.7792, -0.7711, -0.3403, -0.7703, -0.0054, -0.0545, -0.6142, -0.1755,\n",
       "                      -0.6767, -0.6264, -0.3478, -0.2408, -0.0649, -0.6299, -0.4463, -0.6710,\n",
       "                      -0.2594, -0.7686, -0.5812, -0.0756, -0.4769, -0.3040, -0.7463, -0.4590,\n",
       "                      -0.4315, -0.3198, -0.7861, -0.2853, -0.4800, -0.5733, -0.4081, -0.1924,\n",
       "                      -0.4029, -0.3681, -0.1867, -0.6594, -0.4834, -0.7965, -0.5279, -0.5822,\n",
       "                      -0.4489, -0.5034, -0.6862, -0.1506, -0.6351, -0.4288,  0.2153, -0.6111,\n",
       "                      -0.6969, -0.0400, -0.5403, -0.6076, -0.5420, -0.3387, -1.0094, -0.7339,\n",
       "                      -0.7131, -0.4121, -0.6837, -0.4185, -0.7867, -0.4188, -0.6133, -0.7974,\n",
       "                      -0.8653, -0.2809, -0.2074, -0.3140, -0.8210, -0.6430, -0.6586, -0.7911,\n",
       "                      -0.5328,  0.0221, -0.4643, -0.6162, -0.7745, -0.6810, -0.7191, -0.5252,\n",
       "                      -0.1903, -0.6171, -0.2907, -0.2619, -0.3597, -0.6131, -0.4827, -0.7017,\n",
       "                      -0.8358, -0.4266, -0.7334, -0.7606, -0.2966, -0.4516, -0.7747, -0.5209,\n",
       "                      -0.4948, -0.5831, -0.2106, -0.6838, -0.3553, -0.3567, -0.0793, -0.5531,\n",
       "                      -0.0230, -0.5564, -0.3558, -0.7058, -0.2447, -0.7165, -0.1786, -0.7814,\n",
       "                      -0.8007, -0.7678, -0.7810, -0.2289, -0.8234, -0.9902, -0.7072, -0.9479,\n",
       "                      -0.7756, -0.7506, -0.2325, -0.4715, -0.1849, -0.3973, -0.4343, -0.6125,\n",
       "                      -0.7172, -0.4378, -0.4461, -0.6930, -0.4838, -0.7043, -0.5616, -0.7976])),\n",
       "             ('decoders.3.bn4.running_var',\n",
       "              tensor([3.8463, 2.6762, 1.9733, 2.1616, 2.5785, 1.0031, 2.9929, 2.3699, 5.4681,\n",
       "                      4.2966, 2.5618, 3.9667, 0.8783, 2.8676, 3.6679, 2.9267, 4.5437, 3.1901,\n",
       "                      3.0750, 0.4908, 1.8015, 1.0052, 0.7487, 3.2418, 4.0643, 0.3661, 1.2567,\n",
       "                      3.2640, 0.6196, 2.2774, 5.0190, 2.9170, 3.2417, 1.6860, 0.3520, 1.0742,\n",
       "                      0.9294, 1.9778, 4.1072, 0.8408, 2.5889, 1.7790, 6.0413, 2.9641, 0.7441,\n",
       "                      0.8915, 1.1382, 1.0810, 3.3537, 0.3612, 3.6600, 4.0086, 2.8725, 0.7830,\n",
       "                      2.5411, 3.6086, 4.8970, 0.8030, 2.2526, 0.8786, 5.1512, 2.1030, 3.8534,\n",
       "                      0.6905, 2.4602, 2.0024, 3.0590, 1.7761, 1.3066, 0.7113, 3.1225, 3.6186,\n",
       "                      4.2425, 4.6897, 1.4583, 0.4386, 1.5893, 2.7784, 3.6299, 3.4964, 0.4313,\n",
       "                      3.7698, 2.9579, 0.7252, 2.0119, 1.6538, 1.3907, 3.5918, 3.9470, 5.4147,\n",
       "                      4.2658, 4.3478, 4.3437, 2.1946, 3.3640, 0.7592, 2.9475, 4.1626, 0.9358,\n",
       "                      1.9061, 0.7355, 2.0686, 2.9405, 4.2290, 0.6489, 2.6346, 3.6947, 3.1502,\n",
       "                      0.7317, 1.0556, 0.6548, 2.5887, 3.1150, 1.8121, 2.4411, 3.6458, 2.0212,\n",
       "                      3.1069, 0.4192, 2.9973, 3.4466, 0.7995, 2.8656, 3.3159, 2.0456, 1.3387,\n",
       "                      0.6759, 0.5989, 4.0796, 2.2211, 0.7183, 0.7375, 3.1352, 3.0969, 4.1895,\n",
       "                      4.2759, 2.9163, 0.3162, 5.4414, 2.4264, 0.8391, 2.9226, 3.2549, 4.7233,\n",
       "                      3.9800, 4.2545, 3.7574, 1.6786, 2.3734, 0.8804, 2.4869, 1.2263, 1.3618,\n",
       "                      2.6425, 4.6612, 0.5709, 2.6343, 1.9391, 1.5518, 2.7488, 2.4579, 0.8243,\n",
       "                      1.9249, 0.9861, 2.2032, 2.8520, 3.7629, 2.9042, 2.3450, 1.4721, 2.9562,\n",
       "                      4.8567, 3.5444, 3.4835, 3.1487, 0.6769, 2.8101, 2.8442, 2.2310, 2.9247,\n",
       "                      2.6377, 1.8403, 4.0070, 2.6500, 2.2220, 0.3773, 5.1195, 0.9186, 3.7150,\n",
       "                      0.9889, 0.9082, 0.6386, 3.8280, 0.9925, 0.6259, 0.8642, 3.4613, 3.2245,\n",
       "                      1.5826, 3.4520, 1.7976, 2.0024, 0.7575, 2.5489, 4.4657, 1.1375, 1.9639,\n",
       "                      1.8501, 0.7059, 0.9377, 1.9313, 0.6136, 0.6808, 3.7570, 0.6217, 0.7782,\n",
       "                      1.3929, 2.3635, 2.6037, 0.7491, 3.4086, 1.2392, 1.8666, 1.4400, 2.2102,\n",
       "                      0.9710, 3.3998, 2.8134, 2.7936, 0.8526, 2.2029, 2.0496, 3.7164, 2.6397,\n",
       "                      1.5305, 0.9880, 2.1917, 1.4480, 3.5757, 3.2934, 3.0468, 3.8863, 1.9041,\n",
       "                      2.5943, 0.4068, 3.4015, 3.5192, 2.5241, 1.9508, 2.6218, 1.8936, 3.0585,\n",
       "                      0.8824, 1.3003, 3.1319, 0.7258, 2.9803, 3.6458, 1.0875, 2.3890, 1.3670,\n",
       "                      3.2685, 4.4690, 0.7134, 0.7859, 3.6928, 2.4755, 0.4492, 1.2296, 2.5939,\n",
       "                      4.6885, 1.6396, 1.0440, 2.6762, 0.9818, 3.0281, 3.2480, 2.7485, 0.3727,\n",
       "                      3.4561, 2.4465, 3.4103, 2.3224, 4.6653, 4.4432, 4.8549, 2.3941, 0.5974,\n",
       "                      3.2638, 1.0741, 3.8361, 3.3137, 0.9535, 2.7948, 3.6814, 2.4927, 2.8932,\n",
       "                      0.5013, 1.3726, 4.0979, 0.6169, 3.2339, 2.0341, 1.5968, 1.4928, 0.4658,\n",
       "                      3.6948, 0.7419, 2.3552, 4.3706, 1.2635, 1.4838, 2.3331, 0.8720, 1.0065,\n",
       "                      2.5178, 2.8442, 2.8807, 1.3069, 2.1153, 0.7340, 1.9349, 2.9831, 2.7277,\n",
       "                      1.8910, 2.4963, 0.6264, 3.0546, 2.4622, 2.4018, 2.2963, 2.9335, 2.9491,\n",
       "                      1.8803, 3.1841, 1.7391, 1.5441, 1.5264, 3.1040, 0.3820, 0.6189, 0.8275,\n",
       "                      0.6727, 4.3745, 1.8266, 0.8303, 2.3182, 0.7133, 3.9760, 2.7738, 2.3653,\n",
       "                      3.7260, 1.9136, 0.6649, 0.3691, 2.6006, 2.2508, 2.2901, 1.6979, 3.1865,\n",
       "                      4.4632, 1.9375, 0.9118, 3.3215, 0.7591, 2.2815, 0.7851, 1.4144, 2.7428,\n",
       "                      3.0485, 0.8448, 1.8595, 1.3702, 5.0364, 5.4786, 0.7238, 4.0023, 3.0154,\n",
       "                      5.4673, 1.8056, 1.0264, 1.6999, 2.5347, 1.0888, 3.7970, 4.1798, 2.8710,\n",
       "                      1.1857, 1.1902, 2.4303, 4.3671, 3.2287, 0.7761, 2.2998, 3.2328, 0.6980,\n",
       "                      0.7195, 0.8425, 2.0873, 3.0119, 3.5855, 4.0507, 2.7263, 1.0648, 2.8414,\n",
       "                      3.4156, 2.0934, 0.6627, 1.9506, 2.7724, 0.7037, 3.5724, 0.5182, 5.2652,\n",
       "                      2.4816, 2.1104, 3.5784, 2.5890, 3.5153, 1.3018, 3.2474, 1.1917, 1.2477,\n",
       "                      1.5538, 0.3599, 1.1100, 4.2628, 2.2962, 0.3444, 3.7190, 1.1767, 3.4413,\n",
       "                      2.1740, 0.8238, 1.8557, 0.9569, 3.2160, 1.9826, 1.9854, 5.4314, 2.0202,\n",
       "                      2.4600, 1.2118, 0.7266, 4.0625, 3.2504, 2.6083, 3.8987, 2.1120, 0.6970,\n",
       "                      2.7197, 2.0582, 0.4754, 0.7243, 5.6105, 1.6273, 0.6968, 1.9554, 1.7970,\n",
       "                      1.1232, 0.9372, 4.9656, 1.3175, 2.3331, 4.7769, 4.3168, 4.4057, 2.7938,\n",
       "                      1.6736, 3.0440, 1.5866, 1.1514, 3.3049, 0.8027, 4.3205, 2.8048, 3.8972,\n",
       "                      0.5394, 0.9823, 2.8089, 4.3332, 2.4358, 1.9094, 3.3786, 1.0334, 2.7429,\n",
       "                      1.0596, 0.6057, 2.4469, 0.9718, 1.8189, 0.4963, 1.7267, 0.4225, 2.7658,\n",
       "                      3.2497, 4.1801, 2.2395, 3.0636, 0.5370, 0.8498, 0.6009, 0.6524, 2.6691,\n",
       "                      3.8190, 1.1385, 5.0799, 1.6374, 2.2729, 2.8016, 2.7778, 3.0271])),\n",
       "             ('decoders.3.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.3.dense5.weight',\n",
       "              tensor([[-0.0172, -0.0487, -0.0596,  ..., -0.0433, -0.0391, -0.0402],\n",
       "                      [-0.0398, -0.0701, -0.0129,  ...,  0.0144, -0.0559, -0.0291],\n",
       "                      [-0.0157, -0.0604, -0.0669,  ..., -0.0537,  0.0044, -0.0695],\n",
       "                      ...,\n",
       "                      [ 0.0099, -0.0275,  0.0100,  ..., -0.0425, -0.0506, -0.0118],\n",
       "                      [-0.0347,  0.0113, -0.0430,  ..., -0.0516, -0.0248, -0.0317],\n",
       "                      [-0.0491, -0.0045, -0.0045,  ...,  0.0043,  0.0269,  0.0167]])),\n",
       "             ('decoders.3.dense5.bias',\n",
       "              tensor([-0.0417, -0.0581, -0.0647,  ...,  0.0034, -0.0381,  0.0132])),\n",
       "             ('decoders.4.dense1.weight',\n",
       "              tensor([[ 0.0038,  0.0266,  0.1591,  ...,  0.0917,  0.1890,  0.1054],\n",
       "                      [-0.1255, -0.0469, -0.0373,  ..., -0.0106,  0.1211,  0.0783],\n",
       "                      [-0.0772,  0.1008,  0.0720,  ...,  0.0997, -0.1479, -0.1033],\n",
       "                      ...,\n",
       "                      [ 0.0801, -0.1334,  0.0041,  ..., -0.0914,  0.1553,  0.0491],\n",
       "                      [ 0.0380, -0.1082,  0.1028,  ...,  0.0809, -0.0725,  0.0061],\n",
       "                      [-0.0270,  0.0398, -0.0999,  ..., -0.0909, -0.1687,  0.0955]])),\n",
       "             ('decoders.4.bn1.weight',\n",
       "              tensor([0.9959, 0.9890, 0.9951, 1.0143, 0.9950, 0.9977, 0.9952, 1.0008, 1.0087,\n",
       "                      1.0075, 0.9958, 1.0023, 0.9943, 1.0137, 1.0093, 1.0070, 0.9927, 0.9825,\n",
       "                      0.9920, 1.0139, 0.9822, 0.9884, 0.9955, 1.0005, 0.9806, 1.0090, 0.9839,\n",
       "                      0.9986, 1.0084, 1.0016, 1.0033, 0.9926, 1.0098, 0.9874, 1.0017, 1.0174,\n",
       "                      1.0011, 0.9848, 1.0095, 0.9917, 0.9865, 1.0154, 0.9973, 0.9839, 1.0017,\n",
       "                      0.9832, 1.0225, 0.9986, 0.9924, 1.0137, 1.0099, 1.0075, 0.9852, 1.0217,\n",
       "                      1.0035, 1.0082, 0.9962, 1.0022, 1.0103, 0.9894, 1.0076, 1.0085, 1.0142,\n",
       "                      0.9969, 1.0278, 0.9940, 0.9916, 0.9894, 1.0277, 0.9962, 0.9955, 0.9955,\n",
       "                      0.9954, 1.0029, 0.9903, 0.9774, 0.9891, 0.9896, 1.0128, 1.0043, 1.0074,\n",
       "                      1.0018, 1.0051, 1.0055, 1.0137, 1.0187, 0.9775, 0.9952, 0.9829, 0.9985,\n",
       "                      1.0042, 0.9839, 1.0033, 0.9915, 0.9959, 0.9953, 1.0259, 1.0011, 0.9979,\n",
       "                      0.9987, 0.9930, 0.9820, 0.9842, 0.9815, 0.9945, 0.9979, 0.9921, 0.9845,\n",
       "                      0.9940, 0.9786, 1.0173, 1.0007, 0.9926, 0.9998, 0.9872, 1.0009, 1.0045,\n",
       "                      1.0087, 0.9979, 0.9894, 1.0042, 1.0127, 0.9974, 1.0020, 0.9786, 1.0236,\n",
       "                      1.0068, 1.0002])),\n",
       "             ('decoders.4.bn1.bias',\n",
       "              tensor([ 0.0042,  0.0003,  0.0070, -0.0057,  0.0024, -0.0020,  0.0123,  0.0109,\n",
       "                       0.0256,  0.0080,  0.0115,  0.0038,  0.0255,  0.0085,  0.0159,  0.0084,\n",
       "                      -0.0052, -0.0068, -0.0066,  0.0293, -0.0024, -0.0102,  0.0107,  0.0126,\n",
       "                      -0.0054,  0.0175,  0.0019,  0.0033,  0.0048,  0.0168,  0.0075,  0.0188,\n",
       "                       0.0345,  0.0003,  0.0051,  0.0212, -0.0095, -0.0030,  0.0071, -0.0033,\n",
       "                      -0.0088,  0.0145, -0.0055, -0.0131,  0.0072,  0.0019,  0.0237, -0.0056,\n",
       "                      -0.0075,  0.0153,  0.0323,  0.0242, -0.0051,  0.0432,  0.0045, -0.0003,\n",
       "                       0.0076,  0.0249,  0.0092, -0.0004,  0.0111,  0.0350,  0.0322,  0.0188,\n",
       "                       0.0251, -0.0072,  0.0019, -0.0199,  0.0425,  0.0041,  0.0045,  0.0040,\n",
       "                       0.0060,  0.0252,  0.0044, -0.0118, -0.0003, -0.0069,  0.0155,  0.0137,\n",
       "                       0.0018,  0.0030,  0.0096,  0.0158,  0.0173,  0.0184, -0.0122,  0.0014,\n",
       "                      -0.0130,  0.0019,  0.0152, -0.0107,  0.0059,  0.0110,  0.0035,  0.0176,\n",
       "                       0.0235,  0.0054,  0.0007,  0.0064,  0.0006, -0.0042, -0.0094, -0.0088,\n",
       "                      -0.0101,  0.0057,  0.0026, -0.0128, -0.0025, -0.0213,  0.0210,  0.0065,\n",
       "                       0.0073,  0.0097, -0.0112,  0.0410,  0.0107,  0.0129,  0.0069, -0.0113,\n",
       "                       0.0100,  0.0104,  0.0093,  0.0118, -0.0009,  0.0147,  0.0102,  0.0108])),\n",
       "             ('decoders.4.bn1.running_mean',\n",
       "              tensor([-0.2888, -0.1521,  0.2059,  0.2681,  0.3669, -0.0461, -0.1908, -0.1146,\n",
       "                      -0.4405,  0.1939, -0.3277,  0.2412, -0.2528,  0.5418,  0.4297,  0.4594,\n",
       "                      -0.2447, -0.3653,  0.2913, -0.5605, -0.1266,  0.2781, -0.2801, -0.4271,\n",
       "                      -0.1436,  0.1790, -0.2735, -0.0505,  0.2645, -0.3735, -0.2059, -0.5873,\n",
       "                      -0.2903, -0.0676,  0.2186,  0.5301,  0.4041,  0.0630,  0.1651, -0.0308,\n",
       "                       0.3426,  0.6361,  0.2219, -0.2503,  0.2608, -0.1672,  0.4037,  0.2472,\n",
       "                       0.2132,  0.3135, -0.5070,  0.3694,  0.0416, -0.5145,  0.1158,  0.5511,\n",
       "                       0.4238, -0.4213,  0.6039, -0.2951,  0.3669, -0.3538, -0.6420,  0.4117,\n",
       "                       0.3785,  0.2725, -0.2113,  0.1346, -0.5527, -0.0273, -0.4163,  0.0759,\n",
       "                       0.2492, -0.3028, -0.1267, -0.0330,  0.2163,  0.0841,  0.7903,  0.2691,\n",
       "                       0.5326,  0.1502, -0.4302, -0.4396,  0.6293,  0.3716, -0.1097,  0.2123,\n",
       "                      -0.3351,  0.0519,  0.2287,  0.0399, -0.0039, -0.2283, -0.1902,  0.1795,\n",
       "                       0.7404,  0.2270,  0.4491, -0.2333,  0.1354,  0.0443, -0.0706,  0.1391,\n",
       "                       0.2609, -0.1660, -0.3834,  0.0178,  0.0030,  0.0444,  0.7998, -0.2458,\n",
       "                       0.2353,  0.0009,  0.4188, -0.7865,  0.4022,  0.2064, -0.2407,  0.3126,\n",
       "                       0.2680,  0.3133, -0.1093, -0.2990, -0.1241,  0.6787,  0.3804,  0.2893])),\n",
       "             ('decoders.4.bn1.running_var',\n",
       "              tensor([0.1819, 0.1634, 0.3662, 0.3637, 0.5565, 0.1678, 0.3337, 0.2304, 0.6760,\n",
       "                      0.2538, 0.3869, 0.1957, 0.2327, 1.0791, 0.5727, 0.5717, 0.2791, 0.2074,\n",
       "                      0.2030, 1.0551, 0.1729, 0.3234, 0.2506, 0.6935, 0.1158, 0.4111, 0.3451,\n",
       "                      0.0869, 0.3127, 0.2425, 0.1531, 1.4045, 0.3901, 0.2181, 0.3928, 0.8225,\n",
       "                      0.6718, 0.1892, 0.2245, 0.1424, 0.3124, 1.0408, 0.1505, 0.2595, 0.2987,\n",
       "                      0.2507, 0.4743, 0.2245, 0.1055, 0.7086, 0.9629, 0.7220, 0.1746, 0.6171,\n",
       "                      0.1937, 1.0044, 0.5263, 0.5887, 0.8876, 0.2774, 0.2282, 0.6805, 1.1455,\n",
       "                      0.3916, 0.7184, 0.1766, 0.2737, 0.1985, 0.6961, 0.1905, 0.4033, 0.2498,\n",
       "                      0.0924, 0.4922, 0.2368, 0.1953, 0.2916, 0.1621, 1.7164, 0.2540, 0.4817,\n",
       "                      0.1760, 0.4506, 0.5591, 0.6688, 0.4836, 0.1227, 0.1505, 0.2889, 0.0944,\n",
       "                      0.2650, 0.1371, 0.3142, 0.3510, 0.2238, 0.1642, 1.4811, 0.1672, 0.3108,\n",
       "                      0.2362, 0.1617, 0.1191, 0.1114, 0.1484, 0.4105, 0.1956, 0.2467, 0.1622,\n",
       "                      0.1395, 0.1456, 1.7663, 0.2518, 0.3519, 0.2661, 0.3046, 1.0610, 0.3705,\n",
       "                      0.2450, 0.2220, 0.4507, 0.4153, 0.3932, 0.1576, 0.3309, 0.3139, 1.1600,\n",
       "                      0.2616, 0.1509])),\n",
       "             ('decoders.4.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense2.weight',\n",
       "              tensor([[ 0.0373, -0.0747,  0.0793,  ..., -0.0755,  0.0158,  0.0933],\n",
       "                      [ 0.0116, -0.0606,  0.0567,  ..., -0.0376,  0.0600, -0.0074],\n",
       "                      [-0.0505, -0.0607,  0.0713,  ...,  0.0421, -0.0276,  0.0784],\n",
       "                      ...,\n",
       "                      [-0.0640, -0.0772,  0.0604,  ...,  0.0084, -0.0140, -0.0249],\n",
       "                      [-0.0600, -0.0225, -0.0503,  ..., -0.0238, -0.0774,  0.0002],\n",
       "                      [-0.0119,  0.0526, -0.0394,  ..., -0.0516,  0.0469, -0.0233]])),\n",
       "             ('decoders.4.bn2.weight',\n",
       "              tensor([0.9904, 0.9949, 1.0168, 0.9968, 1.0038, 0.9974, 0.9841, 0.9989, 0.9938,\n",
       "                      0.9873, 1.0033, 0.9846, 0.9955, 0.9899, 0.9984, 0.9905, 0.9908, 1.0066,\n",
       "                      1.0075, 0.9905, 1.0060, 1.0120, 1.0159, 0.9895, 0.9990, 1.0194, 0.9962,\n",
       "                      0.9869, 0.9869, 0.9834, 0.9858, 1.0035, 1.0018, 1.0107, 0.9921, 1.0049,\n",
       "                      0.9807, 1.0085, 1.0113, 1.0120, 1.0057, 0.9910, 0.9868, 0.9958, 0.9982,\n",
       "                      0.9912, 0.9905, 0.9974, 0.9999, 1.0025, 1.0018, 0.9900, 1.0130, 1.0261,\n",
       "                      0.9934, 1.0052, 0.9971, 0.9985, 0.9920, 0.9938, 1.0113, 0.9834, 0.9962,\n",
       "                      0.9981, 0.9939, 0.9995, 0.9909, 1.0058, 0.9925, 1.0017, 1.0160, 1.0101,\n",
       "                      0.9956, 0.9942, 0.9803, 1.0017, 0.9806, 0.9967, 1.0093, 1.0091, 1.0114,\n",
       "                      0.9964, 1.0044, 1.0215, 0.9919, 1.0227, 1.0068, 0.9966, 1.0132, 0.9898,\n",
       "                      1.0033, 0.9876, 1.0068, 1.0004, 0.9945, 1.0079, 0.9943, 1.0020, 1.0192,\n",
       "                      1.0001, 1.0096, 1.0151, 0.9990, 0.9996, 0.9851, 0.9878, 1.0015, 1.0121,\n",
       "                      1.0017, 0.9985, 0.9991, 0.9970, 0.9870, 0.9915, 1.0090, 1.0090, 1.0106,\n",
       "                      1.0242, 1.0035, 0.9984, 1.0024, 0.9898, 0.9988, 0.9901, 0.9954, 1.0050,\n",
       "                      0.9956, 0.9988, 0.9926, 0.9928, 0.9956, 1.0096, 0.9964, 1.0073, 0.9995,\n",
       "                      0.9896, 1.0286, 0.9936, 0.9897, 0.9954, 1.0017, 1.0183, 0.9923, 1.0042,\n",
       "                      1.0050, 1.0085, 1.0061, 0.9964, 1.0044, 0.9846, 1.0128, 0.9928, 1.0104,\n",
       "                      1.0070, 1.0157, 0.9939, 1.0275, 0.9849, 1.0123, 1.0060, 0.9939, 1.0180,\n",
       "                      0.9989, 1.0102, 1.0157, 1.0069, 0.9933, 1.0012, 0.9861, 0.9981, 1.0051,\n",
       "                      0.9922, 1.0129, 1.0031, 0.9950, 1.0098, 0.9959, 1.0065, 0.9863, 0.9935,\n",
       "                      1.0013, 1.0117, 1.0034, 1.0190, 1.0172, 0.9852, 0.9975, 0.9873, 1.0178,\n",
       "                      0.9957, 0.9838, 0.9934, 1.0133, 1.0025, 1.0007, 1.0116, 1.0110, 0.9879,\n",
       "                      1.0102, 0.9900, 1.0070, 1.0030, 0.9916, 1.0029, 0.9997, 1.0059, 1.0136,\n",
       "                      1.0028, 0.9926, 1.0207, 0.9899, 1.0001, 1.0109, 1.0040, 0.9862, 1.0077,\n",
       "                      1.0144, 0.9957, 0.9945, 1.0270, 0.9909, 1.0166, 0.9868, 0.9833, 0.9888,\n",
       "                      0.9907, 0.9828, 1.0026, 0.9884, 1.0087, 0.9880, 0.9916, 1.0183, 0.9949,\n",
       "                      0.9918, 0.9941, 0.9891, 0.9932, 1.0009, 1.0098, 0.9952, 0.9866, 1.0201,\n",
       "                      0.9996, 1.0045, 1.0019, 0.9929, 1.0070, 0.9943, 0.9910, 1.0150, 1.0101,\n",
       "                      0.9916, 1.0253, 1.0041, 1.0124])),\n",
       "             ('decoders.4.bn2.bias',\n",
       "              tensor([-7.3589e-03,  1.4635e-02,  1.4605e-02,  2.6159e-02, -5.4760e-04,\n",
       "                       6.1311e-03, -1.6513e-03, -2.6865e-03,  5.9158e-03, -6.7075e-03,\n",
       "                       6.4391e-03, -9.5045e-03,  1.2406e-02, -7.8787e-03, -5.2882e-03,\n",
       "                      -7.5183e-04, -4.5003e-03,  2.3170e-03,  7.9990e-03, -3.8712e-03,\n",
       "                       3.8260e-02,  1.9840e-02,  6.9724e-03,  8.3306e-03, -9.0740e-04,\n",
       "                       1.5456e-02,  5.9834e-03, -1.1166e-02, -5.9146e-03, -7.5825e-03,\n",
       "                       1.9387e-03,  9.7201e-03,  1.0277e-02,  2.3977e-03, -1.1461e-02,\n",
       "                       2.8839e-02, -1.0072e-02,  2.2141e-02,  2.2866e-02,  2.7674e-02,\n",
       "                       1.2016e-02, -2.4769e-04, -1.1277e-03,  1.4453e-02,  1.1044e-02,\n",
       "                      -2.1515e-04, -1.1859e-03,  4.0294e-03,  2.0060e-02,  1.1245e-02,\n",
       "                       7.4575e-03, -9.0812e-03,  3.8375e-02,  8.7477e-03, -1.2346e-03,\n",
       "                       2.4405e-02, -1.9010e-03,  1.0545e-02,  1.3114e-02, -1.6714e-03,\n",
       "                       1.4413e-02, -1.6867e-02,  2.2154e-02,  3.2493e-03,  2.7848e-04,\n",
       "                      -6.3036e-04,  2.7084e-04,  2.2732e-02, -5.3780e-03,  2.7702e-03,\n",
       "                       1.8378e-02,  1.4010e-02, -7.0728e-04,  7.2606e-03, -2.2156e-02,\n",
       "                       9.0751e-03, -1.8606e-02,  1.4953e-02,  5.0225e-02,  1.5161e-02,\n",
       "                       1.2007e-02,  3.6756e-03,  2.6926e-02,  3.8711e-02,  1.8304e-02,\n",
       "                       4.0726e-02, -5.7026e-03,  5.8165e-03,  8.0208e-03, -8.5790e-04,\n",
       "                      -4.7209e-03, -2.0173e-03,  4.8581e-02,  4.2945e-03,  3.6864e-02,\n",
       "                       2.2437e-02, -4.2987e-03,  2.0631e-02,  2.7018e-02,  1.4694e-02,\n",
       "                       2.3186e-02,  2.3882e-02, -2.8977e-03,  1.6296e-02, -4.2895e-03,\n",
       "                      -1.2533e-02,  7.0148e-03,  5.3974e-03,  3.1815e-03, -5.8862e-03,\n",
       "                       2.8759e-03, -6.4979e-06, -1.7164e-02,  4.1468e-03,  9.5027e-03,\n",
       "                       3.1010e-02,  1.1337e-02,  2.6099e-02, -4.4353e-04,  3.2090e-02,\n",
       "                       9.9803e-03,  1.2943e-02,  8.5284e-03,  4.0890e-03,  5.1589e-04,\n",
       "                      -4.0259e-03,  2.0779e-02,  2.2081e-02,  1.5508e-02, -1.9961e-03,\n",
       "                       3.6720e-03,  4.5532e-02,  1.0284e-04,  3.0644e-02,  3.4047e-03,\n",
       "                      -4.0466e-04,  2.8783e-02, -2.7587e-03, -1.3944e-02,  1.0539e-02,\n",
       "                       9.1203e-03,  2.6499e-02,  3.8988e-03,  5.2357e-03, -2.5308e-03,\n",
       "                       2.2194e-02,  8.2299e-03,  2.3044e-02,  2.4592e-03, -2.5180e-03,\n",
       "                       2.8716e-02,  3.2471e-03,  1.3487e-02,  1.4972e-02,  1.1358e-02,\n",
       "                      -5.3129e-05,  2.8692e-02,  2.8025e-04,  1.1869e-02,  2.1430e-02,\n",
       "                       6.1986e-03,  2.7689e-02,  1.3264e-02,  3.0200e-03,  2.6328e-02,\n",
       "                       1.1809e-02,  2.1020e-03,  4.2948e-03, -1.3928e-02, -6.1648e-03,\n",
       "                       2.8085e-02,  1.8971e-02,  3.3818e-02,  2.6783e-02,  1.8743e-03,\n",
       "                       2.7147e-02, -3.4246e-03,  1.3523e-02, -6.6371e-03, -7.8172e-03,\n",
       "                       1.4853e-03,  6.8736e-03,  3.3645e-02,  3.5351e-02,  2.5339e-02,\n",
       "                      -5.6773e-03,  3.7026e-03,  6.8230e-03,  1.0992e-02,  2.9345e-03,\n",
       "                      -3.1991e-03, -8.5955e-03,  8.9978e-03,  1.0202e-02, -2.3004e-03,\n",
       "                      -3.1485e-04,  1.7102e-02, -3.1357e-03,  2.2274e-02,  3.6369e-03,\n",
       "                       8.1855e-03,  5.2534e-03,  1.0567e-02, -4.1563e-04, -1.0080e-03,\n",
       "                       2.5627e-02, -1.0181e-03,  2.6328e-02,  5.5541e-03,  2.5995e-02,\n",
       "                       2.2404e-03,  2.0239e-02,  1.4355e-02,  3.3835e-02, -1.4455e-03,\n",
       "                       2.0680e-02,  8.8063e-03, -2.6336e-04,  5.8370e-04,  4.6549e-02,\n",
       "                       3.4074e-03,  1.1656e-02, -5.1661e-03,  5.4111e-03, -7.3985e-03,\n",
       "                       5.6234e-04, -1.3035e-02,  7.4280e-03,  1.5630e-02,  2.2979e-02,\n",
       "                      -9.7871e-03,  1.9903e-02,  2.5002e-02,  9.2844e-03, -3.3126e-03,\n",
       "                       1.5751e-02,  1.8788e-03,  3.1830e-03,  2.9356e-02,  7.9836e-03,\n",
       "                       6.7346e-03, -9.1937e-03,  3.8386e-03,  1.1996e-02,  1.1577e-02,\n",
       "                       1.3511e-02,  2.9781e-03, -3.9225e-03, -7.7628e-03,  3.9013e-03,\n",
       "                       1.3970e-02,  1.3868e-02,  8.9659e-03,  2.0351e-02,  1.7827e-02,\n",
       "                       2.6097e-02])),\n",
       "             ('decoders.4.bn2.running_mean',\n",
       "              tensor([ 1.6080e-01, -4.7835e-02, -1.7529e-01, -1.9785e-02,  1.6923e-01,\n",
       "                       3.2440e-01,  2.1612e-01,  1.4879e-02,  6.6256e-02, -2.3706e-03,\n",
       "                      -3.9025e-02,  6.7937e-02,  2.3712e-01, -4.0553e-01,  1.1264e-01,\n",
       "                       3.1836e-02, -1.5376e-01,  1.1547e-01,  4.7979e-01,  2.2512e-01,\n",
       "                      -2.1423e-01, -1.8854e-01,  6.1518e-02, -4.6157e-02,  1.1563e-01,\n",
       "                       3.3656e-01, -1.3137e-01, -2.7103e-01,  1.8352e-01, -1.5616e-01,\n",
       "                      -1.3964e-01,  6.3818e-02, -2.2908e-01,  1.1873e-01,  4.0857e-01,\n",
       "                       1.7332e-01,  8.8786e-02, -2.0432e-01, -2.2274e-01, -1.1105e-01,\n",
       "                      -4.9675e-02, -9.7838e-02, -1.4524e-01,  6.7510e-02, -2.6466e-01,\n",
       "                      -1.7938e-01, -1.0202e-01, -8.9869e-02, -1.6553e-01, -1.7579e-01,\n",
       "                      -2.4592e-01,  1.2484e-01, -3.2174e-01,  2.8032e-01, -2.2498e-01,\n",
       "                       4.7319e-02,  1.5923e-01, -6.7960e-01, -8.5962e-02,  1.9922e-01,\n",
       "                       4.7838e-03, -2.4425e-01, -8.4904e-02,  5.4074e-02, -2.8553e-01,\n",
       "                      -7.8051e-02,  3.5965e-01,  2.5545e-01,  2.8084e-02, -3.2523e-01,\n",
       "                       2.0032e-01,  5.3240e-02,  2.9629e-01, -2.2547e-02,  3.2399e-02,\n",
       "                       3.4084e-01, -1.9527e-01, -3.2227e-01, -1.4001e-01,  1.1889e-01,\n",
       "                       3.6197e-01,  1.8353e-02, -1.7831e-01,  4.9238e-02, -1.5768e-01,\n",
       "                      -3.0351e-01,  2.9755e-01,  2.7383e-02, -3.3413e-01,  1.1216e-01,\n",
       "                       2.0848e-01, -3.7499e-01, -3.8182e-01, -3.1015e-01, -1.3888e-01,\n",
       "                      -3.1975e-01,  1.2826e-01, -1.7967e-01,  4.2596e-02, -2.1597e-01,\n",
       "                      -1.1482e-01, -3.9950e-03, -1.7576e-02, -4.2902e-01, -1.3791e-01,\n",
       "                       1.4076e-01,  1.2513e-01,  8.3961e-02, -1.1708e-01,  3.0649e-01,\n",
       "                      -2.9857e-01, -1.7193e-01,  1.9907e-01, -7.1465e-02,  1.4393e-01,\n",
       "                      -7.8823e-01,  1.9335e-02,  3.1736e-01,  2.1470e-01, -8.7526e-02,\n",
       "                      -2.5909e-01,  1.0190e-01, -1.3434e-01, -7.9067e-02, -4.6868e-01,\n",
       "                       2.9810e-01, -2.6046e-02, -1.6308e-01, -1.6323e-01, -1.0154e-01,\n",
       "                      -7.5999e-02, -3.2003e-01,  1.6000e-01, -1.3680e-01, -3.1130e-01,\n",
       "                      -1.2029e-01, -1.5637e-01, -1.1240e-01,  1.6907e-01, -6.1659e-02,\n",
       "                      -1.0833e-01, -3.6292e-01, -2.6944e-01, -6.1030e-02, -1.4712e-01,\n",
       "                      -4.7838e-01,  2.1957e-01,  2.0907e-01,  6.5019e-03,  1.3622e-01,\n",
       "                       1.8667e-02,  7.7419e-02,  3.6621e-01,  1.3222e-01, -1.3466e-02,\n",
       "                      -2.8909e-02, -1.4667e-01, -9.7106e-02, -3.5530e-02,  2.7581e-01,\n",
       "                       1.2258e-01,  4.4931e-02, -3.6584e-01,  9.0570e-02, -2.5152e-01,\n",
       "                      -1.5507e-02,  2.6215e-01,  1.1324e-01,  1.1645e-01, -1.5791e-01,\n",
       "                      -2.5140e-01, -3.7908e-01, -1.6344e-01, -7.5952e-02, -2.6459e-01,\n",
       "                      -1.2917e-01, -4.3063e-02,  2.0160e-01, -1.0527e-01, -1.9518e-01,\n",
       "                      -4.4570e-02,  4.1992e-02, -4.4064e-01,  9.6600e-02,  4.6269e-01,\n",
       "                       5.1903e-02,  1.8393e-01,  2.9981e-02, -1.0487e-01, -8.4759e-02,\n",
       "                      -3.4078e-02,  4.7489e-01,  3.7761e-01, -2.6597e-02,  1.5209e-01,\n",
       "                       1.2268e-01, -1.1989e-01, -1.7936e-01,  5.5899e-03, -4.2813e-01,\n",
       "                       2.6958e-02, -2.2547e-01, -8.9387e-02,  3.5103e-01, -4.3608e-02,\n",
       "                       5.4199e-02,  2.7926e-01,  1.3109e-04, -1.7962e-01, -2.4364e-01,\n",
       "                      -6.1071e-02,  1.1857e-01, -2.6313e-01, -1.0652e-01, -2.2828e-01,\n",
       "                      -4.7635e-02, -1.5472e-01, -2.9859e-01,  2.0281e-01, -1.4248e-01,\n",
       "                      -1.0626e-01,  2.6036e-02,  6.8178e-02,  1.7227e-02, -2.6456e-01,\n",
       "                       3.1210e-02, -4.5670e-01, -2.6501e-01, -1.9566e-01, -1.6941e-01,\n",
       "                      -2.0311e-01, -2.2418e-01,  3.0927e-01, -2.0424e-01, -2.6749e-01,\n",
       "                       1.1249e-01,  1.1167e-01, -2.5381e-03, -1.8129e-01, -5.0995e-01,\n",
       "                      -7.8258e-03,  7.0737e-02,  2.7864e-01,  4.3897e-01,  1.1976e-03,\n",
       "                       1.2612e-01, -3.8010e-01,  4.3206e-01,  2.8066e-01, -4.7771e-02,\n",
       "                       7.7901e-02, -2.8422e-01,  1.1975e-01,  3.3347e-01, -1.0259e-01,\n",
       "                      -2.4910e-01])),\n",
       "             ('decoders.4.bn2.running_var',\n",
       "              tensor([0.1801, 0.3802, 0.3839, 0.4443, 0.0883, 0.5342, 0.1368, 0.2397, 0.2278,\n",
       "                      0.2475, 0.1579, 0.1019, 0.2982, 0.1539, 0.3890, 0.6082, 0.0812, 0.9275,\n",
       "                      0.3613, 0.1742, 0.3322, 0.6392, 1.0292, 0.6092, 0.2412, 0.7299, 0.1410,\n",
       "                      0.1532, 0.1697, 0.1157, 0.2906, 0.1983, 0.0496, 0.2836, 0.3631, 0.6174,\n",
       "                      0.1829, 0.3185, 0.4090, 0.4976, 0.1130, 0.2373, 0.2588, 0.5280, 0.3770,\n",
       "                      0.1136, 0.1755, 0.1146, 1.0673, 0.1967, 0.4436, 0.2226, 0.5652, 0.6762,\n",
       "                      0.0971, 0.2765, 0.3613, 0.2614, 0.4062, 0.3035, 0.4865, 0.2597, 0.4600,\n",
       "                      0.3477, 0.1132, 0.1966, 0.3907, 0.5552, 0.3875, 0.1312, 0.3360, 0.4070,\n",
       "                      0.1016, 0.3298, 0.2908, 0.4151, 0.0842, 0.2608, 0.5346, 0.3132, 0.2716,\n",
       "                      0.2222, 0.2136, 0.8604, 0.8179, 0.8712, 0.3316, 0.4404, 0.1687, 0.2512,\n",
       "                      0.7244, 0.1474, 0.4368, 0.0873, 0.5572, 0.2291, 0.2467, 0.3194, 0.5926,\n",
       "                      0.1657, 0.1738, 0.8362, 0.9392, 0.2593, 0.1259, 0.1658, 0.4390, 0.9757,\n",
       "                      0.4129, 0.5173, 0.0809, 0.0975, 0.1314, 0.1726, 0.4470, 0.6749, 0.4149,\n",
       "                      0.5291, 0.6968, 0.7789, 0.2539, 0.5134, 0.1323, 0.2973, 0.1199, 0.4052,\n",
       "                      0.4590, 0.5163, 0.4827, 0.5481, 0.2076, 0.6133, 0.6241, 0.6569, 0.0674,\n",
       "                      0.1125, 0.3193, 0.3439, 0.2181, 0.1368, 0.1513, 0.3559, 0.1322, 0.4250,\n",
       "                      0.1774, 0.1418, 0.7796, 0.2524, 0.1113, 0.2396, 0.1984, 0.2021, 0.5722,\n",
       "                      0.2790, 0.8234, 0.3409, 0.2118, 0.2340, 0.3135, 0.4427, 0.4168, 0.7626,\n",
       "                      0.3181, 0.6719, 0.3294, 0.3559, 0.1173, 0.2201, 0.4353, 0.1027, 0.8632,\n",
       "                      0.4213, 0.4319, 0.6623, 0.1259, 0.3975, 0.3511, 0.5009, 0.1838, 0.1046,\n",
       "                      0.2228, 0.4470, 0.8008, 1.1438, 0.4380, 0.2106, 0.2192, 0.2269, 0.9314,\n",
       "                      0.2115, 0.2280, 0.2276, 0.4003, 0.7756, 0.2015, 0.8575, 0.2869, 0.3575,\n",
       "                      0.7709, 0.2051, 0.4147, 0.4091, 0.3322, 0.4909, 0.3135, 0.5448, 0.7269,\n",
       "                      0.4389, 0.1862, 0.2597, 0.2741, 0.2734, 0.3887, 0.4608, 0.4425, 0.6384,\n",
       "                      0.2389, 0.1557, 0.6219, 0.9533, 0.2659, 0.6453, 0.1447, 0.0964, 0.1675,\n",
       "                      0.2269, 0.0895, 0.2900, 0.5706, 0.2775, 0.1126, 0.2294, 0.9639, 0.3603,\n",
       "                      0.1047, 0.2483, 0.2250, 0.4918, 1.3946, 0.1932, 0.1668, 0.1362, 1.1037,\n",
       "                      0.6362, 0.0820, 0.4661, 0.0900, 0.0917, 0.3484, 0.1948, 0.5127, 0.1734,\n",
       "                      0.3877, 0.5122, 0.3419, 0.2559])),\n",
       "             ('decoders.4.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense3.weight',\n",
       "              tensor([[ 0.0584, -0.0260, -0.0545,  ..., -0.0527,  0.0116,  0.0106],\n",
       "                      [-0.0619, -0.0316,  0.0226,  ...,  0.0664, -0.0045, -0.0275],\n",
       "                      [-0.0530,  0.0048, -0.0582,  ...,  0.0602,  0.0114,  0.0597],\n",
       "                      ...,\n",
       "                      [-0.0077,  0.0143, -0.0500,  ...,  0.0278, -0.0288, -0.0022],\n",
       "                      [-0.0407, -0.0056,  0.0336,  ..., -0.0165, -0.0479, -0.0666],\n",
       "                      [-0.0248, -0.0187,  0.0447,  ..., -0.0450, -0.0128,  0.0149]])),\n",
       "             ('decoders.4.bn3.weight',\n",
       "              tensor([0.9894, 0.9898, 1.0002, 1.0078, 1.0090, 1.0102, 0.9968, 0.9947, 0.9967,\n",
       "                      1.0019, 0.9809, 0.9948, 0.9986, 1.0006, 0.9950, 1.0073, 1.0062, 0.9897,\n",
       "                      1.0045, 0.9973, 1.0011, 0.9910, 1.0008, 0.9913, 1.0074, 1.0035, 1.0016,\n",
       "                      1.0016, 0.9918, 1.0105, 0.9902, 0.9915, 1.0073, 0.9988, 0.9880, 1.0042,\n",
       "                      1.0143, 1.0090, 0.9943, 1.0015, 1.0067, 0.9947, 0.9934, 0.9897, 0.9987,\n",
       "                      1.0057, 0.9944, 1.0139, 0.9895, 0.9881, 1.0010, 0.9879, 0.9866, 0.9921,\n",
       "                      1.0006, 1.0080, 1.0127, 1.0078, 1.0204, 0.9927, 0.9907, 0.9955, 1.0175,\n",
       "                      1.0008, 0.9900, 0.9944, 0.9955, 0.9895, 1.0021, 0.9956, 1.0042, 0.9880,\n",
       "                      1.0018, 0.9973, 1.0055, 0.9969, 0.9946, 1.0024, 0.9899, 0.9925, 0.9784,\n",
       "                      0.9982, 0.9892, 0.9753, 1.0073, 1.0036, 1.0015, 1.0083, 1.0060, 1.0145,\n",
       "                      0.9959, 0.9988, 0.9894, 1.0046, 0.9988, 1.0142, 1.0058, 1.0088, 0.9801,\n",
       "                      0.9985, 0.9883, 0.9906, 1.0046, 0.9925, 0.9911, 1.0069, 0.9889, 1.0023,\n",
       "                      0.9991, 1.0179, 0.9872, 0.9778, 1.0121, 1.0034, 1.0190, 1.0028, 0.9868,\n",
       "                      0.9915, 0.9848, 0.9953, 0.9950, 1.0004, 1.0029, 1.0131, 1.0122, 0.9920,\n",
       "                      1.0073, 0.9970, 0.9886, 1.0078, 0.9837, 0.9965, 1.0010, 0.9973, 1.0039,\n",
       "                      0.9987, 1.0095, 0.9926, 1.0211, 0.9876, 1.0108, 0.9952, 1.0018, 0.9964,\n",
       "                      1.0037, 0.9910, 1.0052, 0.9998, 1.0116, 0.9879, 1.0059, 1.0198, 1.0049,\n",
       "                      1.0129, 1.0080, 0.9954, 0.9890, 0.9954, 1.0103, 1.0115, 1.0048, 1.0085,\n",
       "                      1.0098, 1.0115, 0.9926, 1.0039, 1.0072, 0.9983, 0.9921, 1.0236, 0.9950,\n",
       "                      0.9900, 1.0211, 1.0129, 1.0002, 0.9851, 1.0138, 1.0028, 0.9954, 1.0090,\n",
       "                      0.9918, 1.0171, 0.9929, 0.9941, 1.0130, 1.0186, 1.0070, 1.0003, 0.9976,\n",
       "                      0.9993, 1.0131, 0.9963, 0.9953, 0.9979, 1.0105, 1.0024, 0.9971, 1.0012,\n",
       "                      1.0049, 1.0143, 0.9966, 1.0044, 1.0001, 1.0007, 0.9884, 0.9958, 0.9937,\n",
       "                      1.0153, 1.0101, 1.0005, 0.9891, 0.9989, 1.0114, 0.9807, 0.9975, 0.9921,\n",
       "                      1.0108, 0.9985, 0.9826, 1.0022, 1.0043, 0.9921, 0.9962, 0.9921, 1.0088,\n",
       "                      1.0100, 1.0165, 0.9897, 1.0159, 1.0057, 1.0146, 0.9969, 0.9843, 0.9853,\n",
       "                      0.9991, 0.9981, 0.9953, 0.9987, 1.0105, 1.0041, 1.0059, 0.9906, 0.9968,\n",
       "                      1.0021, 1.0094, 0.9917, 1.0110, 1.0047, 1.0060, 1.0035, 0.9956, 0.9944,\n",
       "                      0.9924, 0.9960, 0.9972, 1.0006, 1.0019, 0.9968, 0.9919, 1.0056, 0.9999,\n",
       "                      0.9999, 1.0003, 0.9954, 1.0037, 1.0005, 1.0014, 0.9908, 1.0007, 0.9925,\n",
       "                      1.0095, 1.0049, 0.9970, 1.0164, 0.9981, 1.0039, 0.9953, 1.0008, 1.0014,\n",
       "                      1.0039, 0.9917, 0.9871, 1.0185, 1.0009, 0.9926, 1.0014, 0.9987, 0.9935,\n",
       "                      1.0017, 1.0000, 1.0003, 0.9933, 1.0092, 0.9905, 1.0053, 1.0028, 1.0052,\n",
       "                      0.9915, 0.9989, 1.0089, 1.0062, 0.9949, 1.0026, 0.9930, 0.9927, 0.9966,\n",
       "                      1.0039, 1.0055, 1.0036, 1.0078, 1.0175, 1.0112, 1.0026, 1.0138, 0.9977,\n",
       "                      1.0059, 1.0007, 0.9997, 1.0037, 1.0025, 0.9938, 1.0060, 0.9987, 1.0100,\n",
       "                      1.0099, 1.0016, 0.9998, 1.0122, 0.9960, 0.9948, 1.0048, 0.9881, 0.9949,\n",
       "                      0.9846, 1.0153, 1.0068, 0.9936, 0.9991, 0.9951, 1.0020, 0.9989, 1.0003,\n",
       "                      0.9945, 1.0019, 0.9937, 0.9988, 0.9949, 1.0023, 0.9907, 0.9941, 0.9953,\n",
       "                      1.0012, 0.9960, 0.9952, 0.9941, 0.9984, 1.0085, 1.0023, 0.9933, 1.0033,\n",
       "                      1.0248, 0.9929, 1.0019, 0.9942, 0.9968, 0.9947, 0.9972, 0.9926, 1.0010,\n",
       "                      0.9968, 0.9986, 0.9855, 1.0070, 1.0192, 1.0128, 1.0094, 1.0021, 0.9877,\n",
       "                      1.0216, 0.9921, 1.0026, 0.9999, 0.9878, 0.9971, 1.0204, 1.0191, 0.9910,\n",
       "                      1.0008, 0.9890, 1.0088, 0.9945, 1.0091, 0.9944, 1.0012, 0.9962, 1.0153,\n",
       "                      0.9877, 0.9891, 1.0097, 1.0029, 1.0008, 1.0010, 1.0169, 1.0110, 0.9857,\n",
       "                      1.0014, 0.9948, 0.9937, 0.9985, 1.0055, 1.0115, 1.0052, 1.0024, 1.0127,\n",
       "                      1.0121, 0.9926, 0.9862, 1.0066, 0.9994, 1.0089, 0.9899, 0.9963, 0.9856,\n",
       "                      0.9655, 0.9883, 1.0082, 1.0036, 0.9924, 0.9997, 0.9988, 0.9974, 0.9994,\n",
       "                      1.0081, 0.9831, 0.9907, 1.0114, 0.9833, 1.0191, 0.9990, 0.9973, 0.9994,\n",
       "                      1.0069, 1.0043, 0.9958, 0.9952, 0.9993, 1.0061, 0.9847, 0.9972, 0.9944,\n",
       "                      0.9917, 1.0143, 1.0019, 1.0147, 1.0012, 1.0240, 1.0054, 1.0141, 0.9953,\n",
       "                      1.0004, 0.9988, 1.0061, 1.0102, 0.9962, 1.0021, 1.0045, 1.0166, 1.0088,\n",
       "                      0.9960, 1.0020, 0.9812, 0.9974, 1.0014, 1.0072, 0.9953, 0.9886, 1.0076,\n",
       "                      1.0061, 1.0021, 0.9916, 0.9903, 0.9795, 1.0004, 0.9894, 0.9996, 0.9994,\n",
       "                      0.9927, 0.9916, 0.9862, 0.9916, 1.0007, 1.0083, 1.0212, 1.0148, 1.0017,\n",
       "                      0.9857, 1.0258, 1.0137, 1.0190, 0.9972, 1.0064, 1.0049, 0.9958, 0.9952,\n",
       "                      0.9936, 0.9841, 0.9923, 1.0015, 0.9884, 0.9974, 0.9924, 0.9982])),\n",
       "             ('decoders.4.bn3.bias',\n",
       "              tensor([ 1.6980e-03,  4.4761e-03, -5.4943e-03,  1.2991e-02,  4.3177e-03,\n",
       "                       3.0169e-02,  1.1454e-02,  1.7698e-02, -5.1390e-03,  2.9803e-02,\n",
       "                      -2.1717e-02,  8.4417e-03, -1.1919e-03, -1.6670e-03,  1.7271e-02,\n",
       "                       3.5401e-02,  1.3056e-02,  3.5280e-03, -6.2686e-03,  1.1874e-02,\n",
       "                       2.9276e-03, -5.6565e-03,  1.9646e-02, -8.1479e-03,  1.4378e-02,\n",
       "                       1.0322e-02,  5.7736e-03,  8.8967e-03,  6.2993e-03,  2.0688e-03,\n",
       "                      -6.7735e-04, -1.7041e-03,  2.4798e-02,  1.2357e-02, -8.5686e-03,\n",
       "                       2.1065e-02,  2.6477e-02,  3.7031e-02,  5.3923e-03,  1.8767e-02,\n",
       "                       1.8989e-02,  1.1259e-02,  1.1241e-02, -3.2102e-03,  2.1292e-02,\n",
       "                      -5.8811e-03, -4.6935e-03,  2.7552e-02, -5.5402e-03,  1.2050e-02,\n",
       "                      -5.1707e-03,  1.6166e-03, -2.3501e-02, -2.2040e-03,  1.9787e-02,\n",
       "                       1.2419e-02,  8.8290e-03,  3.3383e-03,  3.7745e-03,  1.2274e-02,\n",
       "                       5.6480e-03,  7.9526e-03,  1.7893e-02,  1.5977e-02, -1.1391e-04,\n",
       "                      -5.6857e-04,  1.5113e-02,  4.5266e-03,  6.2575e-03, -3.7517e-03,\n",
       "                       1.5060e-02,  3.0429e-03,  1.8136e-03, -3.7193e-03,  2.1977e-03,\n",
       "                       4.1435e-03,  3.6684e-03,  1.3276e-02, -5.2754e-03,  8.5783e-04,\n",
       "                      -1.2794e-02,  5.0148e-03,  1.0957e-02, -2.0721e-02,  4.1010e-02,\n",
       "                       6.1659e-03, -5.1095e-03,  1.8317e-02,  1.6847e-02,  7.1610e-03,\n",
       "                       1.3379e-02, -6.7912e-03,  1.0245e-02,  2.0482e-02,  2.3590e-03,\n",
       "                      -5.6277e-03,  1.4533e-02,  3.8558e-03, -6.9356e-03,  1.3965e-02,\n",
       "                      -5.6320e-04,  1.5700e-02,  3.3458e-03,  1.2667e-02, -8.5356e-03,\n",
       "                      -9.9250e-03,  2.8856e-03,  5.9156e-03, -7.9461e-04,  2.9710e-02,\n",
       "                       3.8516e-03, -1.4464e-02,  1.6956e-02,  3.2405e-03,  1.2341e-02,\n",
       "                       8.1001e-03, -1.0433e-02,  6.4180e-03, -1.1212e-02, -3.8739e-03,\n",
       "                      -8.3427e-03,  1.0157e-02,  1.6650e-03,  4.3950e-02,  2.8242e-02,\n",
       "                      -4.8950e-03,  1.7220e-02,  4.9780e-03,  3.1281e-03,  1.7194e-02,\n",
       "                       9.5287e-03,  9.1442e-03, -1.3032e-03,  1.5976e-02,  1.8562e-02,\n",
       "                       6.6875e-03,  1.6777e-02,  8.0277e-03,  2.0374e-02, -2.4762e-03,\n",
       "                       3.1202e-02,  7.4750e-03,  2.0059e-02,  1.2846e-03,  1.5982e-02,\n",
       "                       2.2342e-03,  3.2663e-02, -6.1921e-04,  3.2644e-03, -4.7524e-03,\n",
       "                       2.2520e-03,  8.7570e-03,  1.6589e-02,  7.2015e-03,  1.4389e-02,\n",
       "                       2.0833e-02, -1.2359e-02,  6.5772e-03,  1.7639e-02,  3.2607e-02,\n",
       "                       1.2650e-02,  3.9732e-02,  2.0856e-02,  1.1612e-02, -4.7338e-04,\n",
       "                       1.6525e-02,  3.6552e-02,  2.2687e-02,  2.0539e-02,  5.6411e-03,\n",
       "                       1.3324e-02,  2.4344e-03,  2.6835e-02, -3.0389e-03,  1.2211e-02,\n",
       "                      -1.3218e-02,  1.7645e-02,  1.5740e-02,  1.6401e-02,  1.2182e-02,\n",
       "                       1.8909e-03,  8.0065e-03, -8.9011e-03,  4.6959e-03, -1.1061e-02,\n",
       "                       2.5369e-02,  2.4741e-03,  1.1283e-02,  5.0946e-03, -3.4500e-03,\n",
       "                       2.1700e-03, -2.4406e-03, -1.1814e-03,  9.6930e-05,  3.1023e-04,\n",
       "                       5.9392e-03,  4.5169e-03,  1.3264e-02,  2.0077e-02,  2.7333e-02,\n",
       "                       8.4692e-03,  7.0138e-03,  1.0034e-02,  4.5678e-03, -4.0638e-03,\n",
       "                      -1.3715e-04, -6.0665e-04, -6.7535e-03,  1.5484e-03, -6.8629e-03,\n",
       "                       5.8177e-03, -6.3523e-04,  4.5685e-03, -1.0321e-02, -1.0827e-03,\n",
       "                      -1.2047e-03,  2.9627e-02,  6.0745e-03,  1.7293e-03,  1.6707e-02,\n",
       "                       7.6158e-03,  1.1257e-02,  1.4052e-02, -3.9463e-03,  9.2639e-03,\n",
       "                       1.3239e-02,  5.5749e-03, -6.3185e-03,  4.3529e-03,  4.2585e-03,\n",
       "                       4.1210e-02, -7.6064e-03,  1.0869e-02,  1.5599e-02,  7.5907e-03,\n",
       "                       2.4818e-03,  3.5379e-03,  1.6630e-02,  2.8117e-02, -1.9044e-04,\n",
       "                       3.3125e-03,  1.0222e-02,  1.6570e-02,  8.4659e-03,  1.1330e-03,\n",
       "                      -7.1726e-03,  2.4262e-02, -6.6694e-03,  8.1148e-03,  6.4460e-03,\n",
       "                       5.7469e-03,  9.7523e-04,  1.5417e-02,  1.8459e-03,  3.5842e-02,\n",
       "                       1.5666e-02,  7.9886e-03, -3.5673e-03,  3.9326e-03,  1.5332e-02,\n",
       "                       7.2039e-03,  2.0818e-02,  1.3804e-02, -2.8333e-04,  4.5211e-03,\n",
       "                       9.5744e-03, -9.2955e-03,  3.8979e-03,  1.3980e-02,  1.3203e-02,\n",
       "                       1.1740e-02,  1.3640e-02, -3.2755e-04,  3.3723e-02,  1.1590e-02,\n",
       "                       1.5323e-02, -2.4490e-03,  2.3590e-02,  1.3012e-02,  2.3432e-02,\n",
       "                       2.8956e-02,  1.3822e-02, -5.4958e-03,  1.6390e-02,  1.2960e-02,\n",
       "                       2.1935e-02,  2.6823e-02,  1.7077e-03,  6.0558e-03,  1.3324e-02,\n",
       "                       9.0048e-03,  8.0097e-03,  1.0207e-02,  2.6930e-03, -3.6016e-03,\n",
       "                       2.2265e-02,  1.9517e-02, -6.2498e-03,  8.7799e-03,  2.7582e-02,\n",
       "                       2.1516e-02, -6.5515e-03,  4.6486e-03,  1.0148e-02, -5.1606e-03,\n",
       "                       1.3658e-02,  2.0596e-02,  9.0444e-03,  1.8288e-02, -1.2036e-02,\n",
       "                       3.5810e-03,  2.5577e-02,  3.6079e-02,  2.7708e-02,  1.7243e-02,\n",
       "                       3.8240e-03, -4.6031e-04,  1.7549e-02,  5.2920e-03,  2.4021e-02,\n",
       "                      -1.3727e-02, -6.3969e-03,  1.0538e-02,  8.5330e-03,  2.2308e-02,\n",
       "                      -4.8366e-03, -6.5500e-03,  3.8299e-03,  4.0205e-03,  2.2857e-02,\n",
       "                       8.4390e-03, -9.4892e-03,  3.2147e-03, -3.1294e-03,  3.2653e-02,\n",
       "                      -4.7518e-03,  9.6909e-03,  4.8285e-03,  1.9958e-02,  1.7805e-02,\n",
       "                      -4.8378e-03,  1.6535e-02,  7.1882e-03,  1.1308e-02,  2.7975e-03,\n",
       "                       7.0754e-03,  3.4423e-03,  1.5778e-02,  6.2914e-03,  8.7777e-03,\n",
       "                       1.0205e-03,  7.2850e-03,  1.2508e-02,  7.5883e-03,  6.5232e-03,\n",
       "                       8.4164e-03,  9.1724e-03,  1.3230e-02,  4.4041e-03,  1.1725e-02,\n",
       "                       3.6550e-02, -3.0778e-03,  8.1594e-03,  1.1066e-03,  6.3764e-03,\n",
       "                       2.2313e-03,  1.5472e-02, -2.2242e-04,  7.4380e-03,  1.5084e-02,\n",
       "                       5.1816e-03,  9.9341e-03,  2.0595e-02,  2.8867e-02,  7.0810e-03,\n",
       "                       3.5439e-02,  6.8371e-03, -3.5376e-03,  8.7481e-03,  3.9922e-03,\n",
       "                       1.8361e-02,  1.9143e-02,  3.3920e-04,  7.4971e-03,  3.4776e-02,\n",
       "                      -1.8286e-03,  4.5463e-03,  1.2928e-02, -2.8748e-03, -6.6579e-03,\n",
       "                      -9.1148e-03,  1.7259e-02, -7.9252e-03,  8.0446e-03,  1.1052e-02,\n",
       "                       3.0972e-02, -7.0245e-03, -2.6238e-03,  1.9524e-02,  8.9695e-03,\n",
       "                       1.8091e-02,  1.8023e-02,  4.2950e-03,  8.6955e-03, -3.0037e-03,\n",
       "                       1.9211e-02,  6.3362e-03, -5.4773e-03, -4.7597e-03, -1.4657e-02,\n",
       "                       2.8083e-02,  3.7537e-03,  3.1457e-02,  3.2420e-02,  1.5944e-02,\n",
       "                       1.0303e-02, -1.6789e-02,  2.8329e-03,  7.1731e-03,  1.5633e-02,\n",
       "                      -1.0392e-04,  2.8573e-02, -3.5313e-03, -2.0450e-02, -8.1463e-03,\n",
       "                       1.2755e-02,  1.7547e-02, -9.4285e-04, -2.6275e-03,  3.1227e-02,\n",
       "                      -2.7366e-04,  2.7166e-02,  1.6604e-02, -2.3792e-03,  1.3761e-02,\n",
       "                       1.6380e-02, -6.5109e-03,  2.9812e-02,  1.2938e-02,  1.5514e-03,\n",
       "                       1.9345e-02,  1.4277e-02,  2.2608e-02, -6.1459e-03, -1.1084e-02,\n",
       "                       8.0503e-03,  8.5128e-04,  6.7071e-03,  1.4243e-03,  7.3426e-03,\n",
       "                      -5.2609e-04,  1.8505e-02,  4.3964e-03,  4.3262e-02,  3.2547e-03,\n",
       "                       1.6201e-02,  1.5407e-02,  1.9765e-03, -8.5043e-04,  9.5522e-03,\n",
       "                       6.7482e-03,  1.9549e-02,  6.6928e-03,  1.2816e-02, -4.2358e-03,\n",
       "                       1.7020e-02,  2.4144e-02,  2.5901e-02,  1.4634e-02,  1.4931e-03,\n",
       "                      -1.0056e-02,  1.2204e-02,  6.0033e-03,  2.6287e-02, -3.8207e-03,\n",
       "                      -5.2938e-03,  1.8594e-02,  2.8054e-02,  6.3522e-03, -1.4047e-03,\n",
       "                       1.8881e-02, -9.3242e-03,  4.5256e-03,  8.7391e-03,  7.9931e-03,\n",
       "                       4.8320e-03, -3.4344e-03, -2.2357e-03, -8.2007e-03, -2.8103e-04,\n",
       "                       3.0191e-03,  2.7681e-02,  1.4826e-02,  1.4573e-02,  6.4704e-03,\n",
       "                      -1.0456e-02,  4.8931e-02,  2.6368e-02,  1.2184e-02, -6.7456e-04,\n",
       "                      -6.9535e-03,  9.1383e-03,  2.3284e-02,  2.0260e-03, -3.4482e-03,\n",
       "                      -8.5473e-03, -9.7217e-03,  5.4748e-03, -4.4213e-03,  8.1092e-03,\n",
       "                       7.6962e-04,  8.6095e-03])),\n",
       "             ('decoders.4.bn3.running_mean',\n",
       "              tensor([ 2.4256e-04,  3.5387e-01,  1.6763e-01, -1.2014e-01,  6.3953e-02,\n",
       "                      -3.9141e-01, -3.8800e-01, -2.9508e-02, -7.6600e-02,  7.1984e-02,\n",
       "                       2.5174e-02, -2.0204e-01, -3.7989e-01, -2.8957e-01,  1.9007e-02,\n",
       "                       4.7943e-02, -3.2967e-01, -2.7908e-01,  6.9229e-01,  1.9514e-01,\n",
       "                       1.2567e-01,  1.5159e-01, -3.3101e-01,  1.9659e-01, -6.0692e-02,\n",
       "                       5.7541e-03, -2.2759e-01,  1.8563e-01, -1.7005e-01,  1.3386e-01,\n",
       "                      -7.1037e-01, -5.4060e-01,  3.5768e-02,  5.1221e-02, -1.8742e-01,\n",
       "                      -1.0986e-02,  3.0554e-02, -3.0048e-01, -4.7852e-01, -1.2288e-01,\n",
       "                      -8.7152e-02, -4.5393e-01, -3.0588e-01,  4.3324e-02, -7.6763e-02,\n",
       "                       5.7004e-01, -6.0693e-02, -4.4632e-01,  2.5756e-02, -2.2414e-02,\n",
       "                       1.2519e-01, -1.4940e-01,  1.1423e-01,  2.5616e-01, -3.0379e-01,\n",
       "                      -7.6032e-02,  3.5299e-01, -4.8770e-01, -1.5506e-01, -4.7388e-01,\n",
       "                      -1.8151e-01, -2.2492e-01, -5.8936e-01, -2.9949e-01, -2.6643e-01,\n",
       "                      -4.7657e-02, -3.8835e-01, -1.2264e-01, -3.3527e-01,  2.3054e-01,\n",
       "                      -2.1488e-01, -1.9546e-01, -1.7525e-01, -1.9645e-01, -3.8651e-02,\n",
       "                      -1.5403e-01,  1.3374e-02, -1.9910e-01,  4.6227e-01, -1.4731e-01,\n",
       "                       9.8671e-02, -1.6145e-01, -2.9192e-01, -2.7058e-01, -1.9170e-01,\n",
       "                      -7.4823e-03, -6.3456e-02, -1.4517e-01, -2.2981e-01,  8.9065e-02,\n",
       "                       1.8712e-01,  1.2520e-01, -2.3678e-02, -1.7411e-01, -3.5382e-01,\n",
       "                       2.0791e-01, -3.9756e-02,  3.0509e-01, -3.1605e-01, -8.7954e-02,\n",
       "                      -1.0980e-01, -2.6286e-01,  1.2950e-01,  3.9432e-02,  4.5108e-01,\n",
       "                       4.3985e-01, -4.5830e-01, -1.8975e-01,  7.2121e-02, -2.2234e-01,\n",
       "                      -6.0039e-02, -2.1621e-01, -1.8644e-01, -4.7780e-01,  5.5356e-02,\n",
       "                      -2.0066e-01, -2.7799e-01, -1.9776e-01, -1.7624e-01,  7.6527e-02,\n",
       "                      -2.4830e-01, -5.9599e-01,  1.1589e-01, -2.9754e-01, -3.4429e-02,\n",
       "                      -1.1413e-01, -8.7312e-02, -1.3636e-01,  9.6233e-02, -3.0787e-02,\n",
       "                      -3.4402e-01,  1.0300e-01,  6.3744e-02, -2.5777e-01, -4.2888e-01,\n",
       "                      -2.3222e-01,  1.7446e-02,  1.9624e-01,  1.5632e-01,  3.8569e-01,\n",
       "                      -1.7350e-01,  9.8481e-02, -1.4108e-01,  3.6671e-02, -4.6842e-01,\n",
       "                      -2.3872e-01,  2.2964e-01,  3.0316e-01,  2.5015e-01, -3.6333e-01,\n",
       "                       2.9609e-01,  2.1420e-01, -9.0205e-02,  3.1018e-01, -2.3348e-01,\n",
       "                       2.3059e-01, -2.6939e-01, -7.9562e-02, -2.4695e-01, -2.6869e-01,\n",
       "                       4.8183e-02, -3.5296e-01,  4.2091e-02,  2.2302e-01,  5.1396e-02,\n",
       "                       1.5180e-01,  7.9330e-03, -2.7472e-01, -5.9230e-02,  3.0005e-01,\n",
       "                      -1.6931e-02, -1.4501e-01, -2.8045e-01,  5.2407e-01, -1.9663e-01,\n",
       "                      -2.0025e-02,  2.9766e-01,  1.7882e-01, -3.3712e-01, -2.0629e-01,\n",
       "                       2.3504e-01,  4.9127e-01,  5.5563e-02, -4.9003e-01,  6.1908e-02,\n",
       "                      -3.1236e-01,  8.5998e-02,  1.3387e-01,  2.6726e-02,  3.4376e-01,\n",
       "                       2.6437e-01,  2.7761e-02, -4.3410e-02, -5.0857e-01,  2.2277e-01,\n",
       "                       2.7173e-01,  2.2205e-01,  1.2916e-01, -2.5270e-01, -7.2149e-02,\n",
       "                      -3.2308e-02, -4.8576e-01, -5.7932e-02,  2.1446e-01,  1.2317e-01,\n",
       "                      -4.8909e-02,  5.6316e-02,  2.8204e-01,  2.7601e-01,  4.3024e-01,\n",
       "                       5.0887e-02,  1.8876e-01, -1.0700e-01,  4.8495e-02,  4.8441e-01,\n",
       "                      -2.8627e-01, -1.5589e-01, -3.8853e-02, -2.9659e-01, -2.6309e-02,\n",
       "                       6.3167e-02, -8.8556e-02, -1.3774e-01, -1.4516e-01,  5.6955e-01,\n",
       "                       1.3244e-01,  5.4235e-01, -2.4989e-01,  4.3381e-01, -1.2497e-01,\n",
       "                      -3.6263e-01,  1.6187e-01, -9.4345e-02, -3.3823e-02, -2.6129e-02,\n",
       "                      -1.1287e-01, -2.7721e-02,  8.0532e-02, -1.9933e-01,  2.2254e-01,\n",
       "                       3.5318e-01, -1.0805e-01, -8.7052e-02,  2.4833e-01,  1.8177e-01,\n",
       "                       6.7585e-02,  1.4882e-01,  3.9264e-01,  8.3346e-02, -2.3047e-01,\n",
       "                       1.8180e-02, -1.3301e-01, -4.9078e-01,  4.1417e-02, -1.0212e-01,\n",
       "                      -2.6816e-01, -2.7421e-01,  2.8652e-01, -5.9787e-02,  1.4986e-01,\n",
       "                      -2.0287e-01, -1.9532e-01, -2.0556e-01, -1.0923e-01,  9.2440e-02,\n",
       "                      -3.4907e-01,  3.4335e-01, -6.8713e-02,  9.2644e-02, -1.6492e-01,\n",
       "                       2.6233e-01,  1.7182e-01,  1.7984e-01, -2.9274e-01, -1.9461e-01,\n",
       "                      -3.4537e-01, -1.2345e-02, -2.5176e-01, -1.7271e-01,  1.3867e-01,\n",
       "                      -4.4561e-01, -4.0014e-01,  2.8655e-01,  1.0018e-01, -1.6113e-01,\n",
       "                      -9.9796e-02, -1.6284e-01, -1.0733e-01,  1.9495e-01, -5.1119e-01,\n",
       "                       5.0556e-02, -1.5139e-01,  3.2032e-01, -1.8338e-01,  1.7517e-01,\n",
       "                      -1.7357e-01,  1.0791e-01, -1.2420e-01, -1.3008e-01, -5.2370e-01,\n",
       "                      -5.4102e-01,  1.1076e-01, -4.5593e-02, -2.2827e-02,  3.3648e-01,\n",
       "                      -3.4273e-01, -1.4401e-02,  3.2361e-01, -2.6163e-01,  1.1896e-01,\n",
       "                       4.2812e-01,  5.0119e-02, -2.7204e-01,  2.4421e-01,  1.8092e-01,\n",
       "                      -3.6269e-01,  2.4180e-01, -1.2772e-02,  6.1278e-01, -3.5211e-02,\n",
       "                       3.0002e-01,  1.6397e-01, -4.5236e-02,  2.8598e-01,  7.0843e-02,\n",
       "                      -3.9470e-01,  3.3837e-01,  1.8175e-01, -1.7691e-01, -3.4167e-01,\n",
       "                       3.4874e-01, -2.3113e-01, -3.1103e-01, -1.3351e-01, -1.6084e-02,\n",
       "                      -1.2137e-01, -3.5906e-01,  6.9907e-02,  5.4440e-02,  6.0645e-03,\n",
       "                       3.8641e-01, -9.0085e-02, -4.2379e-01, -3.5663e-01, -3.2522e-01,\n",
       "                       6.9117e-02, -1.4249e-01, -3.4776e-01, -3.5446e-01, -2.8475e-01,\n",
       "                      -9.1215e-02, -4.5802e-02, -2.8840e-01, -2.1512e-01,  6.5206e-02,\n",
       "                      -2.3636e-01, -1.2913e-01, -2.4675e-01, -3.8708e-01, -3.6997e-01,\n",
       "                      -2.0889e-01, -4.1028e-01, -1.6422e-01,  2.2169e-01, -2.1078e-01,\n",
       "                      -5.8657e-02, -2.6676e-01,  7.1384e-03, -1.2414e-01,  4.6544e-02,\n",
       "                      -1.6119e-01, -7.1694e-02, -4.5445e-03,  1.3275e-01,  1.5346e-01,\n",
       "                      -4.2141e-01, -9.0436e-02,  1.9721e-01,  1.7806e-01, -2.7514e-02,\n",
       "                      -4.9017e-01, -4.2208e-01, -1.0886e-01, -2.9087e-01, -4.5425e-01,\n",
       "                       1.9006e-01, -5.1307e-01, -3.4395e-01, -1.7685e-01, -5.4684e-02,\n",
       "                      -3.6632e-01, -8.7109e-02,  7.1558e-02, -3.0354e-02,  4.6074e-02,\n",
       "                      -2.3889e-01, -1.7401e-03, -6.2013e-01, -1.5925e-01,  1.6290e-01,\n",
       "                      -2.8787e-01,  8.3800e-02,  2.4714e-01,  2.0905e-01, -1.1000e-01,\n",
       "                      -3.0800e-02, -1.0418e-01,  5.1589e-01,  1.7551e-01,  2.3111e-01,\n",
       "                      -2.8442e-01,  7.9565e-02,  9.9991e-02, -1.2311e-01,  1.0399e-01,\n",
       "                      -8.9535e-02, -3.7900e-02, -6.6981e-02, -3.8411e-01, -1.0950e-01,\n",
       "                       8.0835e-02, -6.2917e-02,  8.3234e-02,  2.9039e-01,  1.1017e-01,\n",
       "                      -4.7097e-01, -2.0201e-01,  2.0320e-01,  3.9876e-01,  3.5007e-01,\n",
       "                      -6.3979e-02, -1.1024e-01,  1.2167e-02,  1.4680e-01, -8.8172e-02,\n",
       "                      -5.4854e-02,  6.1038e-02, -1.7536e-01, -1.4651e-01, -1.0227e-01,\n",
       "                      -1.9653e-01, -1.9355e-01, -1.9467e-01,  1.7308e-01,  1.1922e-01,\n",
       "                      -9.8940e-02,  3.7440e-01, -3.7635e-01, -5.0501e-02,  2.9416e-01,\n",
       "                      -3.6606e-01, -1.1052e-01,  3.2407e-02,  3.8962e-02,  3.3230e-01,\n",
       "                       4.7547e-01, -1.0235e-01, -3.3552e-02,  2.1590e-02, -3.0829e-01,\n",
       "                       6.1069e-02,  1.0223e-01,  6.6503e-02, -1.2487e-01,  5.6353e-02,\n",
       "                      -1.4095e-01,  2.2103e-01, -1.4260e-02, -4.3365e-01,  5.6684e-01,\n",
       "                       9.9371e-03, -3.2676e-01, -1.6557e-01, -4.1267e-01, -1.0054e-01,\n",
       "                      -9.6334e-04, -5.6405e-02,  8.3928e-02, -2.1271e-01, -3.6966e-01,\n",
       "                      -2.9905e-01,  2.8404e-02, -2.9878e-01, -1.8492e-01,  5.5040e-01,\n",
       "                      -1.7848e-01, -1.2763e-01,  3.1584e-02,  1.0535e-01, -2.3312e-01,\n",
       "                      -1.3523e-01, -1.0411e-01, -2.2335e-02,  3.9840e-01,  6.8015e-02,\n",
       "                      -4.6642e-01, -1.5700e-01, -1.7112e-01, -3.9533e-01,  7.6810e-02,\n",
       "                       4.3098e-01, -1.9191e-02, -4.4266e-02, -2.0597e-01, -6.8898e-02,\n",
       "                      -1.6590e-01,  1.5910e-01,  2.8131e-02,  2.4735e-01,  1.0923e-01,\n",
       "                      -3.1877e-01, -2.7383e-01])),\n",
       "             ('decoders.4.bn3.running_var',\n",
       "              tensor([0.6767, 0.3183, 0.4779, 0.4573, 0.7616, 1.1225, 0.1546, 1.3553, 0.3922,\n",
       "                      0.4105, 0.2983, 0.4525, 0.1581, 0.2268, 0.9418, 0.9583, 0.3115, 0.6467,\n",
       "                      0.2899, 0.8227, 0.6276, 0.5720, 0.5376, 0.3613, 1.0083, 0.7737, 0.2597,\n",
       "                      0.7303, 1.8556, 2.2735, 0.2239, 0.3752, 0.1213, 0.4560, 0.2172, 0.7570,\n",
       "                      1.3272, 0.8643, 0.2154, 1.1371, 0.2557, 0.2581, 0.3966, 0.1841, 0.7234,\n",
       "                      0.3532, 0.3135, 0.4550, 0.4080, 0.8812, 0.3564, 0.2696, 0.7139, 0.8512,\n",
       "                      0.5462, 1.2904, 1.0609, 0.1769, 1.1458, 0.5708, 0.3022, 0.2316, 0.2333,\n",
       "                      0.5574, 0.4883, 1.1428, 0.4497, 0.4635, 0.2783, 0.4293, 0.5708, 0.5670,\n",
       "                      0.2670, 0.1591, 1.5894, 0.7754, 0.9226, 0.7529, 0.2649, 0.1638, 0.3075,\n",
       "                      0.5556, 0.8496, 0.1375, 0.8384, 1.6471, 0.1607, 0.6399, 0.5386, 0.3812,\n",
       "                      0.5432, 0.4257, 0.9436, 0.7450, 0.1467, 0.9518, 0.4656, 0.5332, 0.2160,\n",
       "                      0.5913, 0.2765, 1.1176, 1.5356, 0.9344, 0.3214, 0.9265, 0.2766, 0.1471,\n",
       "                      0.2518, 0.5482, 0.3167, 0.3713, 1.1139, 0.2211, 1.1721, 1.3489, 0.2525,\n",
       "                      0.4525, 0.2048, 0.1322, 0.6621, 0.1616, 1.3048, 1.0443, 0.3473, 0.7652,\n",
       "                      0.5532, 0.2366, 0.4230, 1.1418, 1.0743, 0.2842, 0.9037, 0.2651, 0.7906,\n",
       "                      1.2722, 1.6531, 0.6136, 1.2736, 0.1348, 0.3197, 0.9900, 0.4576, 0.5564,\n",
       "                      0.2730, 0.3727, 0.9672, 0.4465, 0.9088, 0.1360, 0.4926, 0.6958, 2.0259,\n",
       "                      0.9160, 0.4923, 0.6315, 0.2517, 1.1555, 0.8372, 0.6874, 0.3137, 1.1536,\n",
       "                      0.4519, 0.6965, 0.5594, 0.6973, 0.5044, 0.9172, 0.3927, 1.5522, 0.7625,\n",
       "                      0.6612, 0.3431, 2.3318, 0.2302, 0.7087, 1.0935, 0.5806, 0.3094, 0.5379,\n",
       "                      0.4033, 0.6653, 0.4980, 0.1454, 0.9489, 0.7152, 0.9908, 0.6643, 1.0120,\n",
       "                      0.7716, 0.9157, 0.7213, 0.3491, 0.3191, 1.6233, 0.7707, 0.5127, 0.4851,\n",
       "                      0.4344, 0.6593, 0.7216, 0.1250, 0.4677, 0.6074, 0.2432, 0.6275, 0.8872,\n",
       "                      0.6949, 1.2953, 0.5988, 0.7988, 0.5459, 0.5980, 0.1963, 0.5437, 0.4367,\n",
       "                      0.6738, 1.8041, 0.2779, 0.6689, 1.4268, 0.7388, 0.5554, 0.1515, 0.3873,\n",
       "                      1.2471, 0.2987, 0.1862, 0.2637, 0.5717, 0.8294, 0.4013, 0.3225, 0.8239,\n",
       "                      0.1457, 0.1896, 0.3824, 0.7557, 0.6260, 0.8502, 0.5385, 0.9289, 0.3909,\n",
       "                      1.1558, 1.0863, 0.7017, 1.4538, 0.7777, 0.4680, 0.5208, 0.6009, 0.5007,\n",
       "                      0.3437, 0.9970, 1.5762, 0.1822, 0.1928, 0.3947, 1.0686, 1.0849, 0.2594,\n",
       "                      0.4872, 0.6870, 0.3657, 0.2085, 1.6998, 0.7201, 0.4672, 1.1116, 0.4120,\n",
       "                      0.6220, 1.1314, 0.6119, 0.8826, 0.3881, 0.4298, 0.2600, 0.8357, 0.2500,\n",
       "                      0.8158, 0.8410, 0.7324, 0.8933, 0.7274, 1.2107, 0.5298, 0.8627, 0.2387,\n",
       "                      0.9399, 0.5235, 0.4680, 0.5834, 0.6935, 0.4063, 1.3271, 0.5762, 1.1484,\n",
       "                      0.8003, 0.5884, 0.4223, 0.2062, 0.3820, 0.5147, 0.2716, 0.8976, 0.5918,\n",
       "                      0.4885, 0.9199, 0.3800, 0.5028, 0.6832, 1.2167, 0.9212, 0.3877, 0.6506,\n",
       "                      0.7732, 0.6336, 0.9198, 1.3848, 1.3587, 0.3979, 0.4031, 0.4677, 0.3628,\n",
       "                      1.1017, 0.1486, 0.7720, 1.0491, 0.5013, 0.5495, 0.3343, 0.1678, 0.1851,\n",
       "                      0.3538, 0.6673, 1.4837, 0.1697, 1.7546, 1.0244, 0.8044, 0.9516, 0.4937,\n",
       "                      0.2278, 0.2757, 0.8294, 0.7647, 0.9756, 0.4312, 0.7326, 0.1594, 0.5857,\n",
       "                      0.2818, 0.4974, 0.4929, 0.5543, 0.4702, 1.0320, 0.7014, 0.1795, 0.2070,\n",
       "                      0.4189, 0.1337, 0.1080, 0.5246, 0.3322, 0.1654, 0.5543, 0.2547, 0.4662,\n",
       "                      0.9460, 0.2473, 0.2968, 0.4298, 0.5379, 0.3031, 1.0424, 0.1999, 0.4926,\n",
       "                      1.9051, 0.3146, 0.6178, 0.5751, 0.8982, 0.3241, 0.4249, 0.7939, 0.1355,\n",
       "                      0.2564, 0.3389, 0.7296, 0.1219, 0.4966, 0.6972, 0.6774, 0.8317, 0.7248,\n",
       "                      0.9686, 0.4295, 0.5953, 0.8670, 1.0602, 0.6140, 0.8809, 0.9252, 0.8400,\n",
       "                      1.1749, 0.3946, 0.2483, 1.8231, 1.1171, 0.4013, 0.3154, 1.0989, 0.5633,\n",
       "                      1.0136, 0.5485, 0.6700, 0.7078, 0.1043, 0.1663, 0.5181, 0.2650, 0.3785,\n",
       "                      0.1823, 0.4436, 0.2757, 0.4608, 0.5184, 0.5074, 1.2083, 0.3416, 0.8235,\n",
       "                      0.6833, 0.2876, 0.4717, 0.4705, 0.3698, 0.5782, 0.3952, 0.7439, 1.2113,\n",
       "                      0.4080, 0.7553, 0.4537, 1.0550, 0.5323, 0.4209, 0.5196, 0.4369, 1.3130,\n",
       "                      0.1635, 0.6922, 0.2557, 0.6986, 0.6895, 1.3416, 0.3317, 1.5703, 0.2652,\n",
       "                      0.5457, 0.4577, 0.9663, 0.6543, 0.6592, 0.4501, 0.3069, 0.6689, 0.8842,\n",
       "                      0.4939, 0.3746, 0.3131, 1.2740, 0.2281, 0.2414, 0.3314, 0.6544, 0.3584,\n",
       "                      1.2997, 0.6627, 0.1675, 0.6104, 0.4621, 0.1704, 1.7032, 0.2173, 0.6928,\n",
       "                      0.1426, 0.1912, 0.3741, 0.1526, 0.1628, 0.5328, 0.9272, 0.3210, 0.1666,\n",
       "                      0.1368, 0.3805, 0.7656, 0.1790, 0.5215, 0.7837, 0.6021, 0.6853, 0.3344,\n",
       "                      0.1186, 0.2546, 0.4695, 0.3712, 0.1613, 0.6990, 0.2544, 0.6601])),\n",
       "             ('decoders.4.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense4.weight',\n",
       "              tensor([[-0.0420,  0.0104,  0.0353,  ..., -0.0274, -0.0183, -0.0143],\n",
       "                      [ 0.0348, -0.0321,  0.0219,  ..., -0.0089,  0.0050, -0.0279],\n",
       "                      [-0.0170,  0.0207,  0.0167,  ..., -0.0167,  0.0429,  0.0412],\n",
       "                      ...,\n",
       "                      [-0.0234, -0.0039, -0.0009,  ...,  0.0159, -0.0027,  0.0353],\n",
       "                      [-0.0197, -0.0312,  0.0226,  ..., -0.0322,  0.0272, -0.0316],\n",
       "                      [ 0.0273,  0.0372,  0.0129,  ..., -0.0457, -0.0394, -0.0609]])),\n",
       "             ('decoders.4.bn4.weight',\n",
       "              tensor([1.0304, 1.0230, 1.0244, 1.0219, 1.0282, 1.0264, 1.0267, 1.0266, 1.0245,\n",
       "                      1.0249, 1.0226, 1.0310, 1.0296, 1.0241, 1.0239, 1.0204, 1.0254, 1.0236,\n",
       "                      1.0253, 1.0270, 1.0288, 1.0250, 1.0271, 1.0268, 1.0267, 1.0282, 1.0256,\n",
       "                      1.0219, 1.0222, 1.0265, 1.0281, 1.0253, 1.0251, 1.0249, 1.0255, 1.0285,\n",
       "                      1.0269, 1.0247, 1.0303, 1.0290, 1.0288, 1.0304, 1.0246, 1.0263, 1.0267,\n",
       "                      1.0248, 1.0239, 1.0249, 1.0247, 1.0275, 1.0266, 1.0271, 1.0253, 1.0231,\n",
       "                      1.0274, 1.0264, 1.0315, 1.0260, 1.0211, 1.0225, 1.0238, 1.0292, 1.0259,\n",
       "                      1.0256, 1.0244, 1.0235, 1.0261, 1.0231, 1.0267, 1.0241, 1.0261, 1.0247,\n",
       "                      1.0256, 1.0284, 1.0220, 1.0268, 1.0264, 1.0211, 1.0226, 1.0249, 1.0288,\n",
       "                      1.0279, 1.0245, 1.0270, 1.0280, 1.0303, 1.0248, 1.0220, 1.0286, 1.0260,\n",
       "                      1.0253, 1.0218, 1.0243, 1.0234, 1.0259, 1.0285, 1.0249, 1.0274, 1.0253,\n",
       "                      1.0258, 1.0302, 1.0264, 1.0201, 1.0263, 1.0235, 1.0226, 1.0244, 1.0285,\n",
       "                      1.0324, 1.0284, 1.0274, 1.0261, 1.0253, 1.0258, 1.0246, 1.0238, 1.0210,\n",
       "                      1.0216, 1.0256, 1.0261, 1.0234, 1.0282, 1.0245, 1.0251, 1.0256, 1.0299,\n",
       "                      1.0268, 1.0198, 1.0255, 1.0274, 1.0257, 1.0249, 1.0226, 1.0233, 1.0223,\n",
       "                      1.0256, 1.0233, 1.0237, 1.0268, 1.0250, 1.0265, 1.0254, 1.0260, 1.0277,\n",
       "                      1.0275, 1.0258, 1.0247, 1.0269, 1.0186, 1.0258, 1.0245, 1.0319, 1.0257,\n",
       "                      1.0208, 1.0303, 1.0259, 1.0262, 1.0259, 1.0298, 1.0214, 1.0237, 1.0271,\n",
       "                      1.0278, 1.0213, 1.0244, 1.0255, 1.0259, 1.0270, 1.0290, 1.0246, 1.0258,\n",
       "                      1.0253, 1.0211, 1.0244, 1.0289, 1.0247, 1.0235, 1.0242, 1.0308, 1.0315,\n",
       "                      1.0230, 1.0247, 1.0212, 1.0294, 1.0209, 1.0249, 1.0285, 1.0214, 1.0302,\n",
       "                      1.0217, 1.0246, 1.0226, 1.0239, 1.0253, 1.0248, 1.0231, 1.0232, 1.0251,\n",
       "                      1.0256, 1.0261, 1.0272, 1.0268, 1.0238, 1.0277, 1.0261, 1.0300, 1.0268,\n",
       "                      1.0262, 1.0257, 1.0291, 1.0267, 1.0246, 1.0255, 1.0209, 1.0276, 1.0274,\n",
       "                      1.0278, 1.0309, 1.0263, 1.0221, 1.0281, 1.0256, 1.0265, 1.0249, 1.0264,\n",
       "                      1.0244, 1.0243, 1.0261, 1.0252, 1.0245, 1.0254, 1.0249, 1.0280, 1.0245,\n",
       "                      1.0300, 1.0184, 1.0258, 1.0249, 1.0270, 1.0258, 1.0302, 1.0232, 1.0255,\n",
       "                      1.0289, 1.0215, 1.0245, 1.0299, 1.0243, 1.0271, 1.0265, 1.0223, 1.0248,\n",
       "                      1.0262, 1.0278, 1.0238, 1.0297, 1.0228, 1.0262, 1.0204, 1.0255, 1.0258,\n",
       "                      1.0247, 1.0241, 1.0250, 1.0233, 1.0241, 1.0278, 1.0273, 1.0262, 1.0267,\n",
       "                      1.0253, 1.0243, 1.0230, 1.0239, 1.0256, 1.0256, 1.0275, 1.0254, 1.0287,\n",
       "                      1.0238, 1.0255, 1.0275, 1.0299, 1.0256, 1.0221, 1.0249, 1.0264, 1.0307,\n",
       "                      1.0253, 1.0308, 1.0267, 1.0258, 1.0294, 1.0258, 1.0258, 1.0242, 1.0291,\n",
       "                      1.0250, 1.0254, 1.0283, 1.0236, 1.0258, 1.0287, 1.0282, 1.0273, 1.0290,\n",
       "                      1.0299, 1.0275, 1.0250, 1.0308, 1.0240, 1.0260, 1.0272, 1.0269, 1.0264,\n",
       "                      1.0301, 1.0268, 1.0309, 1.0220, 1.0221, 1.0275, 1.0271, 1.0249, 1.0286,\n",
       "                      1.0253, 1.0271, 1.0263, 1.0224, 1.0279, 1.0278, 1.0257, 1.0280, 1.0287,\n",
       "                      1.0283, 1.0229, 1.0252, 1.0293, 1.0258, 1.0265, 1.0261, 1.0247, 1.0223,\n",
       "                      1.0242, 1.0237, 1.0293, 1.0253, 1.0270, 1.0265, 1.0213, 1.0246, 1.0253,\n",
       "                      1.0223, 1.0226, 1.0272, 1.0285, 1.0256, 1.0248, 1.0234, 1.0261, 1.0254,\n",
       "                      1.0249, 1.0270, 1.0242, 1.0252, 1.0272, 1.0270, 1.0259, 1.0260, 1.0265,\n",
       "                      1.0261, 1.0227, 1.0217, 1.0242, 1.0273, 1.0261, 1.0229, 1.0260, 1.0281,\n",
       "                      1.0277, 1.0281, 1.0236, 1.0261, 1.0217, 1.0256, 1.0251, 1.0292, 1.0238,\n",
       "                      1.0275, 1.0285, 1.0270, 1.0244, 1.0228, 1.0251, 1.0254, 1.0246, 1.0240,\n",
       "                      1.0268, 1.0266, 1.0272, 1.0262, 1.0256, 1.0248, 1.0217, 1.0274, 1.0191,\n",
       "                      1.0253, 1.0228, 1.0227, 1.0246, 1.0235, 1.0273, 1.0287, 1.0298, 1.0246,\n",
       "                      1.0200, 1.0240, 1.0231, 1.0258, 1.0292, 1.0246, 1.0249, 1.0239, 1.0256,\n",
       "                      1.0244, 1.0230, 1.0266, 1.0224, 1.0221, 1.0199, 1.0280, 1.0238, 1.0275,\n",
       "                      1.0244, 1.0262, 1.0248, 1.0294, 1.0259, 1.0256, 1.0258, 1.0245, 1.0252,\n",
       "                      1.0238, 1.0220, 1.0224, 1.0295, 1.0236, 1.0259, 1.0251, 1.0260, 1.0229,\n",
       "                      1.0234, 1.0229, 1.0262, 1.0251, 1.0275, 1.0275, 1.0249, 1.0250, 1.0255,\n",
       "                      1.0321, 1.0243, 1.0236, 1.0271, 1.0274, 1.0292, 1.0232, 1.0233, 1.0300,\n",
       "                      1.0235, 1.0265, 1.0305, 1.0245, 1.0277, 1.0274, 1.0230, 1.0272, 1.0227,\n",
       "                      1.0207, 1.0246, 1.0272, 1.0295, 1.0268, 1.0235, 1.0241, 1.0255, 1.0275,\n",
       "                      1.0249, 1.0264, 1.0245, 1.0272, 1.0236, 1.0268, 1.0259, 1.0250, 1.0301,\n",
       "                      1.0255, 1.0238, 1.0271, 1.0239, 1.0236, 1.0247, 1.0236, 1.0281, 1.0286,\n",
       "                      1.0277, 1.0226, 1.0262, 1.0252, 1.0268, 1.0258, 1.0284, 1.0227])),\n",
       "             ('decoders.4.bn4.bias',\n",
       "              tensor([0.0345, 0.0310, 0.0312, 0.0311, 0.0341, 0.0349, 0.0336, 0.0326, 0.0316,\n",
       "                      0.0317, 0.0296, 0.0340, 0.0343, 0.0308, 0.0308, 0.0276, 0.0317, 0.0302,\n",
       "                      0.0302, 0.0309, 0.0333, 0.0327, 0.0316, 0.0342, 0.0332, 0.0335, 0.0327,\n",
       "                      0.0275, 0.0308, 0.0350, 0.0353, 0.0323, 0.0320, 0.0301, 0.0352, 0.0335,\n",
       "                      0.0332, 0.0318, 0.0345, 0.0355, 0.0344, 0.0345, 0.0305, 0.0325, 0.0329,\n",
       "                      0.0317, 0.0317, 0.0326, 0.0328, 0.0350, 0.0349, 0.0324, 0.0349, 0.0288,\n",
       "                      0.0333, 0.0326, 0.0334, 0.0298, 0.0295, 0.0310, 0.0323, 0.0340, 0.0324,\n",
       "                      0.0330, 0.0301, 0.0313, 0.0327, 0.0316, 0.0331, 0.0301, 0.0325, 0.0307,\n",
       "                      0.0323, 0.0346, 0.0305, 0.0328, 0.0306, 0.0304, 0.0289, 0.0316, 0.0346,\n",
       "                      0.0349, 0.0296, 0.0348, 0.0351, 0.0353, 0.0323, 0.0303, 0.0345, 0.0324,\n",
       "                      0.0325, 0.0295, 0.0318, 0.0316, 0.0315, 0.0347, 0.0324, 0.0346, 0.0322,\n",
       "                      0.0305, 0.0326, 0.0305, 0.0301, 0.0326, 0.0304, 0.0305, 0.0313, 0.0335,\n",
       "                      0.0350, 0.0355, 0.0328, 0.0339, 0.0321, 0.0313, 0.0287, 0.0317, 0.0300,\n",
       "                      0.0305, 0.0324, 0.0330, 0.0330, 0.0347, 0.0339, 0.0322, 0.0319, 0.0343,\n",
       "                      0.0341, 0.0291, 0.0306, 0.0334, 0.0326, 0.0330, 0.0329, 0.0292, 0.0268,\n",
       "                      0.0328, 0.0313, 0.0329, 0.0339, 0.0326, 0.0326, 0.0303, 0.0304, 0.0327,\n",
       "                      0.0309, 0.0339, 0.0311, 0.0327, 0.0280, 0.0329, 0.0327, 0.0348, 0.0331,\n",
       "                      0.0289, 0.0360, 0.0349, 0.0334, 0.0322, 0.0362, 0.0305, 0.0292, 0.0305,\n",
       "                      0.0345, 0.0301, 0.0315, 0.0324, 0.0301, 0.0342, 0.0339, 0.0306, 0.0328,\n",
       "                      0.0310, 0.0302, 0.0309, 0.0341, 0.0317, 0.0301, 0.0299, 0.0341, 0.0349,\n",
       "                      0.0305, 0.0317, 0.0271, 0.0353, 0.0299, 0.0322, 0.0335, 0.0307, 0.0345,\n",
       "                      0.0302, 0.0300, 0.0290, 0.0322, 0.0324, 0.0336, 0.0284, 0.0313, 0.0308,\n",
       "                      0.0299, 0.0331, 0.0345, 0.0330, 0.0305, 0.0332, 0.0343, 0.0336, 0.0307,\n",
       "                      0.0325, 0.0314, 0.0342, 0.0307, 0.0308, 0.0309, 0.0273, 0.0347, 0.0345,\n",
       "                      0.0346, 0.0333, 0.0351, 0.0288, 0.0330, 0.0327, 0.0351, 0.0329, 0.0326,\n",
       "                      0.0325, 0.0316, 0.0304, 0.0309, 0.0316, 0.0304, 0.0302, 0.0336, 0.0314,\n",
       "                      0.0341, 0.0265, 0.0325, 0.0321, 0.0312, 0.0329, 0.0356, 0.0308, 0.0316,\n",
       "                      0.0352, 0.0298, 0.0290, 0.0346, 0.0322, 0.0306, 0.0326, 0.0310, 0.0329,\n",
       "                      0.0345, 0.0327, 0.0311, 0.0334, 0.0312, 0.0351, 0.0297, 0.0324, 0.0324,\n",
       "                      0.0305, 0.0322, 0.0311, 0.0327, 0.0321, 0.0333, 0.0326, 0.0328, 0.0330,\n",
       "                      0.0326, 0.0322, 0.0292, 0.0312, 0.0327, 0.0325, 0.0356, 0.0329, 0.0361,\n",
       "                      0.0296, 0.0321, 0.0330, 0.0338, 0.0318, 0.0272, 0.0318, 0.0313, 0.0351,\n",
       "                      0.0298, 0.0345, 0.0315, 0.0303, 0.0352, 0.0334, 0.0335, 0.0324, 0.0363,\n",
       "                      0.0328, 0.0324, 0.0348, 0.0313, 0.0342, 0.0345, 0.0360, 0.0329, 0.0337,\n",
       "                      0.0344, 0.0355, 0.0312, 0.0346, 0.0296, 0.0344, 0.0331, 0.0333, 0.0349,\n",
       "                      0.0339, 0.0312, 0.0350, 0.0299, 0.0304, 0.0315, 0.0345, 0.0307, 0.0311,\n",
       "                      0.0298, 0.0345, 0.0344, 0.0282, 0.0347, 0.0347, 0.0347, 0.0340, 0.0342,\n",
       "                      0.0356, 0.0286, 0.0328, 0.0340, 0.0328, 0.0340, 0.0323, 0.0328, 0.0283,\n",
       "                      0.0314, 0.0317, 0.0345, 0.0325, 0.0330, 0.0329, 0.0301, 0.0328, 0.0321,\n",
       "                      0.0302, 0.0305, 0.0326, 0.0336, 0.0310, 0.0298, 0.0284, 0.0327, 0.0299,\n",
       "                      0.0324, 0.0333, 0.0315, 0.0312, 0.0334, 0.0343, 0.0323, 0.0321, 0.0332,\n",
       "                      0.0346, 0.0309, 0.0308, 0.0315, 0.0357, 0.0342, 0.0314, 0.0346, 0.0340,\n",
       "                      0.0345, 0.0334, 0.0321, 0.0350, 0.0294, 0.0329, 0.0334, 0.0337, 0.0308,\n",
       "                      0.0335, 0.0339, 0.0351, 0.0323, 0.0284, 0.0343, 0.0327, 0.0326, 0.0325,\n",
       "                      0.0309, 0.0350, 0.0323, 0.0332, 0.0325, 0.0324, 0.0307, 0.0348, 0.0267,\n",
       "                      0.0324, 0.0305, 0.0286, 0.0318, 0.0314, 0.0344, 0.0356, 0.0349, 0.0326,\n",
       "                      0.0289, 0.0301, 0.0315, 0.0325, 0.0341, 0.0313, 0.0328, 0.0313, 0.0338,\n",
       "                      0.0314, 0.0298, 0.0330, 0.0281, 0.0284, 0.0266, 0.0332, 0.0304, 0.0348,\n",
       "                      0.0304, 0.0343, 0.0318, 0.0351, 0.0326, 0.0323, 0.0331, 0.0315, 0.0326,\n",
       "                      0.0305, 0.0308, 0.0314, 0.0339, 0.0320, 0.0325, 0.0296, 0.0327, 0.0300,\n",
       "                      0.0288, 0.0314, 0.0340, 0.0322, 0.0347, 0.0343, 0.0327, 0.0336, 0.0344,\n",
       "                      0.0334, 0.0289, 0.0283, 0.0336, 0.0339, 0.0336, 0.0306, 0.0307, 0.0341,\n",
       "                      0.0309, 0.0326, 0.0348, 0.0315, 0.0333, 0.0358, 0.0320, 0.0332, 0.0309,\n",
       "                      0.0300, 0.0322, 0.0330, 0.0342, 0.0337, 0.0295, 0.0313, 0.0322, 0.0310,\n",
       "                      0.0320, 0.0346, 0.0307, 0.0336, 0.0292, 0.0346, 0.0325, 0.0310, 0.0343,\n",
       "                      0.0336, 0.0301, 0.0342, 0.0318, 0.0317, 0.0318, 0.0294, 0.0337, 0.0362,\n",
       "                      0.0331, 0.0310, 0.0340, 0.0323, 0.0344, 0.0337, 0.0352, 0.0294])),\n",
       "             ('decoders.4.bn4.running_mean',\n",
       "              tensor([-0.4599, -0.3463, -0.1353, -0.7742, -0.3869, -0.4076, -0.7419, -0.4473,\n",
       "                      -0.3526, -0.5989, -0.3710, -0.3412, -0.4392, -0.4547, -0.0180, -0.4059,\n",
       "                      -0.0412, -0.5316, -0.5500, -0.3605, -0.4673, -0.4593, -0.3493, -0.4052,\n",
       "                      -0.0484, -0.4390, -0.8220, -0.3860, -0.8073, -0.6167, -0.4347, -0.5057,\n",
       "                      -0.7139, -0.2729, -0.3986, -0.3622, -0.7019, -0.6127, -0.4011, -0.4105,\n",
       "                      -0.3926, -0.4485, -0.4026, -0.6813, -0.0440, -0.5406, -0.4332, -0.7142,\n",
       "                      -0.3851, -0.5420, -0.3211, -0.4481, -0.4903, -0.1742, -0.3984, -0.3684,\n",
       "                      -0.6341, -0.3181, -0.6475, -0.4860, -0.6249, -0.4286, -0.5920, -0.7447,\n",
       "                      -0.4549, -0.4088, -0.3538, -0.5705, -0.4192, -0.3174, -0.6422, -0.2751,\n",
       "                      -0.6650, -0.0222, -0.6475, -0.3060, -0.3366, -0.6543, -0.3963, -0.3689,\n",
       "                      -0.6760, -0.4695, -0.4463, -0.5570, -0.4481, -0.7040, -0.4413, -0.8272,\n",
       "                      -0.2627, -0.6209, -0.6236, -0.2723, -0.6026, -0.3330, -0.4459, -0.3233,\n",
       "                      -0.2957, -0.6948, -0.1818, -0.5455, -0.1565, -0.3783, -0.6497, -0.3918,\n",
       "                      -0.2806, -0.2368, -0.2193, -0.5367, -0.5579, -0.4928, -0.4369, -0.8140,\n",
       "                      -0.5824, -0.2947, -0.2096, -0.6776, -0.4909, -0.7168, -0.3887, -0.6320,\n",
       "                      -0.4853, -0.2238, -0.5123, -0.1608, -0.4570, -0.4197, -0.5342, -0.5657,\n",
       "                      -0.4428, -0.3411, -0.4937, -0.4533, -0.5143, -0.5816, -0.3694, -0.6716,\n",
       "                      -0.5220, -0.3704, -0.6617, -0.2749, -0.3737, -0.3086, -0.3956, -0.2198,\n",
       "                      -0.0109, -0.4054, -0.1302, -0.5531, -0.4275, -0.7393, -0.3819, -0.3990,\n",
       "                      -0.4652, -0.4034, -0.5573, -0.6837, -0.3795, -0.4939, -0.3921, -0.6466,\n",
       "                      -0.4856, -0.3684, -0.4467, -0.4111, -0.5824, -0.5388, -0.1720, -0.3325,\n",
       "                      -0.4554, -0.4313, -0.4300, -0.5975, -0.7713, -0.6088, -0.5581, -0.4925,\n",
       "                      -0.4057,  0.0679, -0.4091, -0.6457, -0.7316, -0.4808, -0.5012, -0.3074,\n",
       "                      -0.5872, -0.2008, -0.2236, -0.7556, -0.5531, -0.4805, -0.6681, -0.4897,\n",
       "                      -0.3967, -0.4098, -0.5510, -0.4713, -0.4020, -0.0951, -0.4287, -0.6997,\n",
       "                      -0.3220, -0.1390, -0.2059, -0.2704, -0.8017, -0.2199, -0.1987, -0.2116,\n",
       "                       0.0279, -0.6266, -0.1958, -0.1644, -0.3265, -0.2860, -0.4047, -0.3739,\n",
       "                      -0.5212, -0.2163, -0.4073, -0.4008, -0.2886, -0.3809, -0.6754, -0.5947,\n",
       "                      -0.3598, -0.3027, -0.4001, -0.4145,  0.0340, -0.3602, -0.7770, -0.4366,\n",
       "                      -0.5533, -0.4999, -0.2788, -0.2171, -0.4818, -0.5563, -0.2308, -0.6296,\n",
       "                      -0.3445, -0.4507, -0.8213, -0.4924, -0.3297, -0.3168, -0.6821, -0.6287,\n",
       "                      -0.5253, -0.5340, -0.5304, -0.1830, -0.5001, -0.4328, -0.3147, -0.2638,\n",
       "                      -0.7378, -0.4521, -0.4039, -0.6212, -0.5479, -0.5553, -0.7126, -0.6471,\n",
       "                      -0.4305, -0.7252, -0.2699, -0.6380, -0.7926, -0.2296, -0.6116, -0.5624,\n",
       "                      -0.3357, -0.1068, -0.3121, -0.4689, -0.4798, -0.5744, -0.4814, -0.7673,\n",
       "                      -0.5476, -0.5003, -0.6707, -0.5144, -0.3724, -0.4096, -0.1486, -0.5014,\n",
       "                      -0.3973, -0.5304,  0.1272, -0.4714, -0.1484, -0.6374, -0.4420, -0.6405,\n",
       "                      -0.1985, -0.6132, -0.2230, -0.6744, -0.3727, -0.9254, -0.6708, -0.7457,\n",
       "                      -0.2327, -0.6597, -0.6051, -0.4394, -0.5213, -0.1901, -0.3639, -0.4924,\n",
       "                      -0.2219, -0.4612, -0.4210, -0.7611, -0.1938, -0.1451, -0.4806, -0.5271,\n",
       "                      -0.3189, -0.4710, -0.2104, -0.5367, -0.5105, -0.5449, -0.4281, -0.4014,\n",
       "                      -0.4805, -0.4305, -0.4278, -0.6229, -0.5969, -0.5763, -0.1784, -0.3124,\n",
       "                      -0.2830, -0.2106, -0.1149, -0.4243, -0.5827, -0.3359, -0.5558, -0.2975,\n",
       "                      -0.3240, -0.7325, -0.3646, -0.4282, -0.4949, -0.2952, -0.3223, -0.4632,\n",
       "                      -0.2898, -0.5001, -0.1695, -0.2378, -0.2546, -0.1966, -0.4905, -0.2152,\n",
       "                      -0.3241, -0.1774, -0.3988, -0.2503, -0.3522, -0.4492, -0.3272, -0.1731,\n",
       "                      -0.6059, -0.4461, -0.7170, -0.4673, -0.5510, -0.5399, -0.4866, -0.3501,\n",
       "                      -0.4562, -0.4930, -0.2605, -0.1821, -0.3444, -0.7515, -0.5848, -0.5138,\n",
       "                      -0.0304, -0.4448, -0.2296, -0.5752, -0.3574, -0.5057, -0.3761, -0.3977,\n",
       "                      -0.5759, -0.5207, -0.4244, -0.1940, -0.4354, -0.6410, -0.3865, -0.4211,\n",
       "                      -0.5568, -0.5980, -0.4494, -0.3110, -0.5500, -0.5666, -0.4645, -0.0499,\n",
       "                      -0.3787, -0.4966, -0.4075, -0.8049, -0.4168, -0.2689, -0.4432, -0.0193,\n",
       "                      -0.5110, -0.7787, -0.5208, -0.5272, -0.5174, -0.6100, -0.5707, -0.4608,\n",
       "                      -0.3681, -0.4916, -0.4265, -0.3974, -0.3689, -0.3086, -0.1539, -0.7440,\n",
       "                      -0.4216, -0.5137, -0.7435, -0.4911, -0.4497, -0.3075, -0.3761, -0.0676,\n",
       "                      -0.2648, -0.6589, -0.4746, -0.3202, -0.3897, -0.5339, -0.6371, -0.2062,\n",
       "                      -0.3309, -0.0260, -0.2071, -0.4869, -0.2374, -0.6863, -0.4843, -0.6646,\n",
       "                      -0.6134, -0.6642, -0.6492, -0.6658, -0.3181, -0.2875, -0.6759, -0.3332,\n",
       "                      -0.2782, -0.4436, -0.3555, -0.5018, -0.3798, -0.3019, -0.5923, -0.4710,\n",
       "                      -0.3658, -0.4397, -0.5775, -0.6323, -0.3389, -0.7225, -0.5233, -0.0513,\n",
       "                      -0.0261, -0.4631, -0.2056, -0.3510, -0.3559, -0.3448, -0.5598, -0.4283,\n",
       "                      -0.3151, -0.5810, -0.6881, -0.2360, -0.5252, -0.1747, -0.4983, -0.3681,\n",
       "                      -0.4526, -0.4364, -0.4193, -0.5607, -0.6296, -0.2393, -0.7255, -0.4472,\n",
       "                      -0.4477, -0.8105, -0.5605, -0.6076, -0.4735, -0.3184, -0.6320, -0.2855])),\n",
       "             ('decoders.4.bn4.running_var',\n",
       "              tensor([2.2610, 1.3428, 0.3317, 1.6342, 2.1354, 2.0434, 0.4003, 3.2553, 1.2435,\n",
       "                      1.0910, 0.3227, 2.3482, 2.6336, 2.3432, 0.6744, 0.4370, 2.8857, 0.3474,\n",
       "                      0.3692, 0.7762, 0.2894, 1.8352, 0.3197, 1.5500, 0.4522, 3.7335, 1.8161,\n",
       "                      0.3692, 1.4706, 1.9118, 1.7658, 1.8855, 3.1378, 0.7445, 1.8473, 2.5477,\n",
       "                      1.2365, 1.1741, 1.6987, 3.3025, 1.6760, 3.2588, 0.2028, 1.5878, 0.6700,\n",
       "                      1.3534, 1.6718, 1.9916, 2.2783, 1.5966, 1.9273, 0.5374, 1.3377, 1.3157,\n",
       "                      0.3623, 1.7412, 0.3313, 0.4867, 2.3501, 0.8343, 3.1425, 1.5818, 1.4136,\n",
       "                      1.6609, 0.5145, 3.0482, 2.0025, 1.2521, 0.3413, 0.6291, 2.2687, 0.3800,\n",
       "                      1.7151, 2.0451, 0.7967, 2.6424, 0.4702, 1.2238, 0.6450, 0.6518, 0.9784,\n",
       "                      1.2780, 0.5564, 2.1926, 2.3673, 1.3514, 1.6775, 1.5755, 2.1486, 1.4608,\n",
       "                      1.4844, 0.4506, 1.6651, 1.1631, 0.3310, 1.9297, 1.0631, 2.0335, 2.6307,\n",
       "                      0.4802, 0.6371, 0.3259, 1.0730, 1.8889, 0.2148, 3.0026, 0.5077, 1.1501,\n",
       "                      3.3046, 2.0698, 0.1872, 2.1590, 1.8115, 0.5274, 0.8650, 1.3445, 0.8762,\n",
       "                      1.5905, 1.3314, 1.5485, 0.4735, 2.5807, 1.2976, 1.2532, 1.3524, 1.4648,\n",
       "                      1.6806, 1.4732, 0.1932, 3.7749, 2.4901, 1.6038, 0.8218, 0.3939, 0.7157,\n",
       "                      2.0990, 1.8442, 0.6943, 2.2796, 2.0698, 1.8309, 0.4416, 0.2806, 0.7925,\n",
       "                      0.6488, 1.1253, 0.3975, 0.2919, 1.3057, 1.7272, 2.2371, 1.5949, 1.8019,\n",
       "                      0.5211, 2.1357, 1.2120, 1.6887, 1.4101, 2.0149, 1.1733, 0.2801, 0.4552,\n",
       "                      2.0306, 1.8698, 0.5145, 2.4168, 0.5939, 2.1226, 0.7014, 0.4617, 2.3922,\n",
       "                      0.2575, 1.3719, 0.2894, 1.7025, 1.6444, 1.4345, 1.0367, 2.5262, 2.7558,\n",
       "                      0.4360, 3.1349, 0.4657, 2.0838, 0.4673, 2.3199, 0.3016, 1.0465, 1.1275,\n",
       "                      0.5313, 0.3286, 0.1999, 1.8825, 1.8814, 1.1253, 0.2879, 0.5261, 0.6518,\n",
       "                      0.9789, 1.7118, 2.5295, 1.5191, 0.6896, 0.4951, 2.1691, 0.4111, 0.7191,\n",
       "                      1.4740, 0.4842, 1.8835, 1.2578, 0.3882, 0.4752, 0.5801, 2.6556, 2.5701,\n",
       "                      2.3797, 0.5716, 2.0122, 0.5486, 0.3624, 1.6434, 2.2375, 1.5798, 1.7689,\n",
       "                      2.1443, 1.4276, 0.6684, 0.6737, 1.9793, 0.2788, 0.4311, 1.3520, 2.5147,\n",
       "                      1.5364, 0.4764, 2.2850, 1.6791, 0.5163, 1.9048, 1.3597, 0.3031, 0.6314,\n",
       "                      1.4159, 1.2027, 0.8323, 2.2569, 1.3272, 0.9399, 2.1386, 1.5310, 1.9463,\n",
       "                      2.8760, 0.5881, 1.7643, 0.3161, 0.9442, 1.5619, 0.5715, 2.3854, 1.4524,\n",
       "                      0.3680, 2.8837, 0.4421, 0.8877, 1.0575, 1.6285, 3.2444, 1.7883, 0.8352,\n",
       "                      2.3282, 0.9631, 0.4006, 1.8639, 1.2314, 1.5044, 1.6419, 1.4070, 1.7925,\n",
       "                      0.2670, 1.4423, 1.4825, 1.3525, 0.5263, 0.7311, 2.3658, 0.3412, 1.6449,\n",
       "                      1.7615, 2.5478, 0.6233, 0.3105, 1.9797, 1.3586, 0.3279, 0.6822, 1.8944,\n",
       "                      1.7805, 1.7452, 1.6923, 1.7312, 0.9771, 0.4404, 2.1534, 0.5190, 0.4408,\n",
       "                      2.5733, 1.9827, 0.4287, 2.5592, 0.5488, 2.2702, 1.4279, 1.6967, 2.3948,\n",
       "                      3.2687, 0.6287, 2.5626, 2.5124, 2.4594, 0.4492, 2.4545, 0.5532, 0.3595,\n",
       "                      0.2743, 1.1938, 1.4070, 0.4739, 2.5470, 1.6342, 2.2370, 1.9175, 2.0352,\n",
       "                      1.9014, 0.2581, 0.4708, 1.7403, 0.3758, 2.2628, 2.4039, 1.7458, 0.7097,\n",
       "                      1.6663, 2.2431, 1.7706, 1.9800, 2.1147, 1.7897, 1.7194, 0.4764, 1.6200,\n",
       "                      1.7985, 2.2172, 3.1509, 0.2719, 0.5863, 0.8475, 0.6619, 1.6426, 0.5491,\n",
       "                      1.3484, 0.5224, 2.7352, 0.4308, 2.3295, 2.0021, 1.4862, 2.9602, 1.7181,\n",
       "                      1.6208, 2.1627, 1.7938, 1.5556, 1.5708, 1.3944, 1.3708, 0.8971, 1.7208,\n",
       "                      1.9571, 1.5938, 1.7921, 1.6372, 0.3723, 2.2887, 0.3802, 1.0893, 0.4141,\n",
       "                      1.0530, 1.1920, 1.2626, 1.2549, 0.3275, 1.6434, 1.4877, 2.0557, 1.5407,\n",
       "                      0.4472, 2.1004, 1.6245, 2.0843, 1.8676, 1.0079, 1.9198, 1.4085, 0.3213,\n",
       "                      2.0162, 0.7442, 0.5869, 1.7263, 1.6024, 2.2266, 1.9153, 2.1569, 1.2866,\n",
       "                      1.5360, 1.1655, 2.1391, 1.7998, 1.9361, 0.7112, 1.7605, 2.1510, 0.2129,\n",
       "                      0.4505, 0.4321, 3.1347, 0.6113, 0.5184, 0.2511, 0.5908, 0.4300, 1.3779,\n",
       "                      0.3195, 2.2171, 1.4736, 3.0215, 2.1612, 2.6496, 1.7766, 1.2201, 2.3313,\n",
       "                      2.7756, 1.8337, 1.7150, 1.7528, 1.3899, 1.3712, 1.1904, 1.7994, 0.6344,\n",
       "                      0.5551, 1.7344, 1.2761, 1.4682, 1.5153, 2.0375, 1.2344, 1.0839, 2.3865,\n",
       "                      0.5281, 0.6015, 0.5210, 0.9136, 2.4447, 1.9006, 2.5763, 1.6266, 1.7091,\n",
       "                      2.3670, 0.2957, 1.9776, 2.3065, 2.2745, 2.0170, 1.2349, 0.2895, 1.0341,\n",
       "                      0.8096, 1.2628, 0.9680, 1.8476, 0.5910, 0.6734, 2.3909, 1.6645, 0.9118,\n",
       "                      0.5671, 2.3038, 0.2633, 2.2347, 0.3748, 1.6291, 2.3056, 0.3235, 1.6742,\n",
       "                      1.5485, 0.4326, 2.1303, 1.2446, 1.6787, 1.9898, 0.6486, 1.0664, 1.9184,\n",
       "                      2.1018, 0.7912, 0.6958, 2.7687, 2.0561, 1.7897, 2.2271, 0.4328])),\n",
       "             ('decoders.4.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.4.dense5.weight',\n",
       "              tensor([[-0.0674, -0.0552,  0.0106,  ..., -0.0362, -0.0126, -0.0254],\n",
       "                      [-0.0099,  0.0022, -0.0286,  ...,  0.0031, -0.0292, -0.0440],\n",
       "                      [-0.0535, -0.0616, -0.0592,  ...,  0.0008, -0.0572, -0.0453],\n",
       "                      ...,\n",
       "                      [-0.0355, -0.0261,  0.0141,  ...,  0.0114, -0.0018, -0.0692],\n",
       "                      [-0.0595, -0.0425, -0.0537,  ..., -0.0301, -0.0366, -0.0426],\n",
       "                      [-0.0246,  0.0174, -0.0402,  ...,  0.0279, -0.0425, -0.0467]])),\n",
       "             ('decoders.4.dense5.bias',\n",
       "              tensor([-0.0440, -0.0708, -0.0256,  ..., -0.0031, -0.0107, -0.0462])),\n",
       "             ('decoders.5.dense1.weight',\n",
       "              tensor([[-0.0279,  0.1500, -0.0904,  ...,  0.1508,  0.0742, -0.1315],\n",
       "                      [-0.0939, -0.1725,  0.0010,  ...,  0.1625,  0.1615,  0.0868],\n",
       "                      [-0.0223,  0.1317,  0.0965,  ...,  0.0352, -0.0446,  0.1367],\n",
       "                      ...,\n",
       "                      [-0.0611, -0.0078, -0.1699,  ..., -0.1317, -0.0316,  0.1569],\n",
       "                      [-0.1524,  0.0218,  0.0944,  ..., -0.0666, -0.1028,  0.1486],\n",
       "                      [ 0.0640, -0.0127,  0.1230,  ...,  0.0553,  0.0797, -0.1276]])),\n",
       "             ('decoders.5.bn1.weight',\n",
       "              tensor([1.0013, 0.9956, 1.0027, 0.9916, 0.9898, 0.9871, 0.9842, 0.9948, 1.0100,\n",
       "                      1.0028, 1.0006, 0.9898, 1.0251, 0.9940, 0.9867, 1.0138, 0.9880, 0.9946,\n",
       "                      0.9862, 1.0033, 1.0248, 0.9888, 1.0030, 0.9916, 0.9858, 1.0085, 0.9907,\n",
       "                      1.0002, 0.9798, 1.0030, 1.0092, 1.0172, 0.9864, 0.9995, 0.9963, 1.0010,\n",
       "                      0.9869, 1.0002, 1.0041, 0.9849, 1.0179, 0.9823, 0.9978, 0.9851, 1.0064,\n",
       "                      0.9871, 1.0016, 1.0052, 1.0034, 0.9970, 1.0095, 1.0022, 1.0131, 0.9874,\n",
       "                      1.0178, 1.0271, 0.9968, 0.9884, 0.9973, 0.9896, 0.9864, 0.9882, 0.9891,\n",
       "                      1.0091, 0.9983, 1.0122, 1.0082, 1.0236, 0.9852, 1.0040, 0.9870, 0.9898,\n",
       "                      0.9906, 0.9896, 0.9895, 1.0194, 1.0215, 0.9886, 0.9949, 1.0062, 0.9921,\n",
       "                      0.9963, 1.0059, 0.9943, 1.0021, 0.9809, 1.0106, 0.9781, 0.9932, 0.9923,\n",
       "                      0.9925, 0.9901, 1.0186, 1.0113, 1.0249, 0.9912, 1.0072, 0.9982, 0.9900,\n",
       "                      1.0284, 1.0025, 1.0130, 1.0033, 0.9903, 0.9965, 0.9813, 0.9818, 0.9904,\n",
       "                      0.9978, 0.9966, 1.0120, 0.9837, 0.9821, 0.9932, 0.9914, 1.0006, 1.0153,\n",
       "                      0.9801, 0.9958, 1.0201, 1.0118, 0.9955, 0.9893, 0.9892, 1.0142, 0.9914,\n",
       "                      1.0187, 0.9870])),\n",
       "             ('decoders.5.bn1.bias',\n",
       "              tensor([-1.3758e-03, -7.9267e-03, -9.0775e-03, -9.4095e-03, -1.2470e-03,\n",
       "                      -1.5992e-02, -1.1331e-02, -9.7924e-03,  6.7403e-03,  2.1178e-03,\n",
       "                      -7.5096e-03, -6.2369e-03, -5.7253e-04,  2.7811e-03, -9.3582e-03,\n",
       "                      -3.4667e-03,  2.3450e-03,  1.2011e-02, -1.3840e-02,  7.3362e-03,\n",
       "                       1.3580e-03,  7.4121e-03, -3.0855e-04, -9.7295e-04, -1.5128e-02,\n",
       "                       4.0201e-03, -3.2793e-03,  3.7736e-03, -9.3557e-03, -3.5944e-03,\n",
       "                      -3.6493e-03,  8.8581e-03, -1.2373e-02,  1.0790e-02,  3.7589e-03,\n",
       "                      -3.0631e-03, -7.7809e-03,  4.8194e-03,  2.1680e-02, -4.2476e-03,\n",
       "                       1.0116e-03, -1.1150e-02,  7.8750e-03, -1.1521e-02, -2.6453e-03,\n",
       "                      -3.5226e-03,  1.0554e-02, -1.0116e-02, -8.8895e-03,  3.8080e-03,\n",
       "                      -9.7994e-04, -2.4356e-03,  1.9310e-03,  7.2122e-03,  1.1256e-03,\n",
       "                      -9.6949e-03,  4.8269e-03, -1.1167e-02,  1.5105e-03, -2.5716e-03,\n",
       "                      -1.4664e-03, -1.1201e-02, -1.7147e-02,  8.6221e-05, -1.5861e-03,\n",
       "                      -8.3418e-03, -4.4500e-03, -2.8287e-03, -1.4001e-02, -1.2586e-03,\n",
       "                      -7.7036e-03, -4.0233e-03, -6.4055e-03, -5.6650e-03, -3.5092e-03,\n",
       "                      -7.7343e-03,  2.5349e-03, -7.2647e-03, -3.1054e-04,  1.3453e-02,\n",
       "                      -1.3900e-02,  9.1944e-03,  2.2380e-02,  1.3617e-02,  1.5071e-02,\n",
       "                      -1.7385e-02,  1.2372e-02, -1.5069e-02,  8.0061e-05,  3.2149e-03,\n",
       "                      -8.6786e-03, -1.2525e-02, -5.7170e-03,  2.3009e-02, -2.2599e-03,\n",
       "                      -7.3974e-03,  2.1575e-02, -3.4853e-04, -4.9641e-04,  1.9317e-03,\n",
       "                       2.8845e-03,  2.5074e-02,  9.1278e-04,  1.0561e-02,  1.2272e-02,\n",
       "                      -1.0104e-02, -1.5675e-02, -1.4976e-02,  9.4418e-03,  2.1609e-03,\n",
       "                       7.5694e-03,  9.8941e-03, -1.7778e-02, -6.5518e-03, -1.2069e-02,\n",
       "                       1.5242e-04,  2.5877e-03, -1.2665e-02, -2.3622e-03, -2.5509e-03,\n",
       "                      -1.2146e-02,  1.2445e-03, -4.6610e-03,  1.5177e-03,  2.3214e-03,\n",
       "                      -4.6638e-03, -2.0804e-02,  2.3466e-03])),\n",
       "             ('decoders.5.bn1.running_mean',\n",
       "              tensor([-2.7414e-01, -1.9667e-01, -3.1660e-01, -1.1592e-01,  3.2323e-01,\n",
       "                       9.5814e-03,  3.7886e-02, -2.2151e-01, -7.1385e-02, -1.0132e-01,\n",
       "                      -1.3530e-01, -3.9732e-02, -4.2731e-01,  1.4492e-01, -2.6660e-02,\n",
       "                      -3.5513e-01,  1.4684e-01,  5.2667e-02, -7.8526e-02, -7.0769e-02,\n",
       "                      -1.6069e-01,  2.5214e-03, -1.2923e-01, -1.6518e-01,  4.9540e-02,\n",
       "                      -2.4744e-01, -6.4379e-02,  4.1699e-02,  7.3586e-02, -1.6073e-01,\n",
       "                      -4.1168e-02, -3.2677e-01, -3.2045e-03,  1.1198e-01,  6.8366e-02,\n",
       "                      -4.3838e-02,  3.0472e-02,  6.4628e-02,  6.6786e-03,  2.0680e-01,\n",
       "                      -2.3013e-01,  3.1878e-02,  2.8733e-01, -1.4892e-01, -2.8588e-01,\n",
       "                       2.1027e-01,  1.8204e-01, -9.9741e-02, -1.1798e-01, -1.0105e-01,\n",
       "                      -1.5150e-01, -3.6942e-01, -2.1381e-01,  1.1981e-01, -2.5067e-01,\n",
       "                      -3.7103e-01, -7.8270e-03, -3.8553e-02,  1.8921e-02, -2.8339e-02,\n",
       "                       1.4190e-01, -1.7193e-02, -1.8631e-01, -1.9564e-01, -1.4183e-01,\n",
       "                      -2.1287e-01, -3.1200e-01, -2.7199e-01, -1.0171e-01, -3.2799e-01,\n",
       "                      -7.4905e-02,  8.2323e-02, -8.5315e-02, -2.4007e-01, -2.1759e-01,\n",
       "                      -2.0987e-01, -3.0613e-01, -2.9522e-01,  1.1326e-01,  8.7763e-02,\n",
       "                      -1.0680e-02,  9.6634e-02,  1.6345e-01,  2.0559e-01,  1.8499e-01,\n",
       "                      -6.3226e-02,  1.9315e-01, -7.0684e-02,  5.8677e-02,  1.5369e-01,\n",
       "                      -1.7873e-01, -1.1700e-01, -1.5617e-01,  2.9998e-01, -3.4599e-01,\n",
       "                      -1.1772e-01,  2.6999e-01, -5.9711e-02,  1.5594e-01, -2.6148e-01,\n",
       "                      -1.0254e-01,  3.5686e-01, -2.5815e-01,  3.2695e-01,  2.6639e-01,\n",
       "                      -3.7575e-03,  1.2083e-05, -1.9838e-01,  1.8844e-01,  2.0383e-01,\n",
       "                      -2.6753e-01,  6.0387e-02,  1.7480e-01, -9.7237e-02, -1.4144e-01,\n",
       "                      -1.3943e-01, -3.3497e-01, -1.1149e-01,  6.9261e-02, -1.2554e-01,\n",
       "                      -3.1601e-01, -2.2927e-01, -1.5843e-01, -3.2844e-02, -2.9825e-01,\n",
       "                      -6.5559e-02, -3.1468e-01,  1.7363e-01])),\n",
       "             ('decoders.5.bn1.running_var',\n",
       "              tensor([0.5574, 0.3165, 0.4877, 0.3718, 0.5013, 0.1244, 0.0986, 0.3156, 0.5712,\n",
       "                      0.2590, 0.6484, 0.2510, 1.7735, 0.2483, 0.1724, 0.7373, 0.3124, 0.4355,\n",
       "                      0.2299, 0.2339, 0.7679, 0.1571, 0.5551, 0.2697, 0.1855, 0.4090, 0.1771,\n",
       "                      0.1697, 0.0845, 0.4252, 0.5989, 0.6679, 0.1275, 0.3064, 0.1765, 0.2194,\n",
       "                      0.1387, 0.3262, 0.2280, 0.2233, 0.5980, 0.1394, 0.3385, 0.1736, 0.7444,\n",
       "                      0.4090, 0.4787, 0.2240, 0.2585, 0.2219, 0.4075, 0.5465, 0.4212, 0.2803,\n",
       "                      0.6515, 0.9270, 0.3090, 0.1561, 0.1184, 0.1387, 0.2901, 0.1035, 0.2864,\n",
       "                      0.5502, 0.2823, 0.5851, 0.4939, 1.1194, 0.2066, 0.5689, 0.1414, 0.1364,\n",
       "                      0.1485, 0.2390, 0.2466, 0.5327, 0.7985, 0.2518, 0.2174, 0.2793, 0.2153,\n",
       "                      0.4153, 0.4669, 0.4251, 0.6248, 0.2362, 0.7019, 0.1267, 0.0936, 0.1280,\n",
       "                      0.1647, 0.1732, 0.4332, 0.3806, 1.2002, 0.1817, 0.6237, 0.2422, 0.1043,\n",
       "                      0.5650, 0.1717, 0.7197, 0.3315, 0.6489, 0.5352, 0.1298, 0.1164, 0.3309,\n",
       "                      0.2695, 0.2290, 0.7600, 0.2190, 0.2218, 0.1493, 0.3857, 0.1815, 0.5876,\n",
       "                      0.1909, 0.1494, 0.4617, 0.4765, 0.2664, 0.1687, 0.1277, 0.5637, 0.1692,\n",
       "                      0.6381, 0.3043])),\n",
       "             ('decoders.5.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense2.weight',\n",
       "              tensor([[ 0.0125,  0.0411,  0.0150,  ...,  0.0102,  0.0765, -0.0014],\n",
       "                      [ 0.0714, -0.0232, -0.0463,  ...,  0.0906, -0.0627,  0.0099],\n",
       "                      [ 0.0049, -0.0827, -0.0167,  ..., -0.0238,  0.0164,  0.0153],\n",
       "                      ...,\n",
       "                      [ 0.0330,  0.0816, -0.0543,  ..., -0.0282, -0.0955, -0.0288],\n",
       "                      [-0.0029,  0.0652,  0.0503,  ..., -0.0253, -0.0380, -0.0809],\n",
       "                      [-0.0807, -0.0150,  0.0232,  ...,  0.0148,  0.0775,  0.0612]])),\n",
       "             ('decoders.5.bn2.weight',\n",
       "              tensor([1.0097, 0.9928, 0.9729, 0.9842, 0.9973, 0.9955, 0.9953, 0.9851, 0.9983,\n",
       "                      1.0081, 0.9847, 1.0067, 0.9967, 1.0148, 1.0131, 1.0116, 0.9910, 0.9847,\n",
       "                      0.9972, 0.9880, 0.9921, 0.9963, 1.0223, 1.0066, 0.9803, 1.0042, 1.0025,\n",
       "                      0.9989, 1.0067, 0.9922, 0.9862, 0.9918, 0.9936, 1.0190, 1.0022, 0.9790,\n",
       "                      0.9968, 0.9997, 0.9968, 1.0203, 1.0039, 0.9910, 1.0002, 0.9925, 0.9877,\n",
       "                      1.0125, 0.9937, 0.9927, 0.9953, 1.0097, 1.0227, 1.0024, 1.0087, 0.9934,\n",
       "                      1.0060, 1.0041, 0.9938, 1.0073, 0.9910, 0.9939, 1.0038, 0.9830, 0.9887,\n",
       "                      0.9947, 1.0048, 1.0100, 1.0092, 0.9792, 0.9824, 0.9872, 1.0059, 1.0131,\n",
       "                      0.9932, 0.9921, 1.0230, 1.0119, 0.9923, 0.9964, 0.9953, 0.9896, 0.9907,\n",
       "                      0.9988, 0.9869, 0.9892, 1.0141, 0.9923, 0.9910, 0.9925, 1.0184, 0.9914,\n",
       "                      0.9986, 1.0196, 1.0214, 1.0255, 0.9894, 0.9850, 0.9790, 1.0139, 1.0022,\n",
       "                      0.9958, 1.0200, 1.0152, 1.0194, 1.0162, 0.9838, 1.0309, 1.0250, 1.0013,\n",
       "                      1.0143, 1.0144, 1.0032, 1.0259, 0.9889, 0.9866, 0.9920, 0.9658, 0.9890,\n",
       "                      0.9925, 1.0024, 1.0233, 0.9995, 0.9834, 0.9870, 0.9948, 0.9976, 0.9831,\n",
       "                      0.9781, 0.9943, 0.9842, 1.0010, 0.9721, 0.9909, 1.0016, 1.0040, 1.0016,\n",
       "                      1.0016, 0.9990, 0.9843, 1.0223, 0.9882, 1.0212, 0.9838, 1.0115, 0.9952,\n",
       "                      1.0015, 0.9783, 0.9910, 1.0020, 0.9870, 1.0038, 0.9962, 0.9931, 1.0069,\n",
       "                      1.0202, 0.9995, 1.0024, 1.0037, 0.9876, 0.9920, 0.9866, 0.9996, 1.0178,\n",
       "                      1.0125, 1.0194, 0.9980, 0.9754, 0.9956, 0.9939, 0.9944, 0.9939, 0.9920,\n",
       "                      1.0228, 1.0011, 0.9922, 1.0005, 0.9956, 1.0130, 0.9844, 1.0039, 0.9930,\n",
       "                      0.9816, 0.9928, 0.9883, 0.9972, 1.0314, 0.9962, 0.9968, 1.0067, 0.9931,\n",
       "                      0.9947, 1.0044, 0.9997, 0.9924, 0.9969, 0.9923, 0.9858, 1.0078, 0.9841,\n",
       "                      1.0021, 0.9837, 1.0109, 1.0157, 1.0022, 0.9928, 0.9869, 0.9923, 1.0156,\n",
       "                      0.9687, 0.9816, 0.9938, 0.9797, 1.0004, 0.9805, 1.0020, 1.0211, 0.9987,\n",
       "                      0.9806, 1.0044, 1.0016, 0.9856, 0.9748, 0.9960, 1.0058, 0.9956, 0.9873,\n",
       "                      0.9900, 1.0025, 0.9871, 0.9970, 0.9991, 0.9813, 1.0160, 0.9941, 1.0218,\n",
       "                      0.9972, 1.0037, 1.0010, 0.9992, 0.9914, 0.9804, 0.9949, 0.9815, 1.0275,\n",
       "                      0.9877, 0.9935, 0.9888, 1.0201, 1.0173, 1.0075, 0.9907, 1.0060, 1.0254,\n",
       "                      0.9911, 0.9810, 0.9925, 1.0099])),\n",
       "             ('decoders.5.bn2.bias',\n",
       "              tensor([-1.7198e-02, -1.9155e-03, -2.3836e-02, -6.8982e-03, -7.9292e-03,\n",
       "                      -3.8902e-03, -1.1865e-02, -1.0086e-02, -9.6468e-03, -5.9182e-04,\n",
       "                      -7.8040e-03, -9.1464e-03,  6.6775e-03,  3.5389e-03,  5.6748e-03,\n",
       "                       2.1567e-03, -2.1171e-03, -7.8750e-03,  1.2697e-02, -1.0893e-02,\n",
       "                      -6.5256e-03, -5.0471e-03, -1.4381e-03, -6.5345e-03, -1.9374e-02,\n",
       "                       1.5499e-02, -2.3679e-03, -1.0221e-05,  4.3302e-03, -5.1386e-03,\n",
       "                       1.9809e-02, -7.6553e-03, -1.7698e-03,  2.0611e-02,  1.4792e-03,\n",
       "                      -8.6067e-03, -1.4142e-03,  3.3675e-03,  9.2338e-03, -5.1358e-03,\n",
       "                       2.2144e-02, -2.6787e-05, -2.9822e-03,  2.4793e-04, -3.9442e-03,\n",
       "                      -3.4348e-03,  6.7967e-03,  3.3452e-03, -7.1947e-03,  1.1012e-03,\n",
       "                       1.1485e-03, -8.1003e-03,  2.4821e-02, -1.5545e-02,  1.2984e-02,\n",
       "                       8.9881e-03, -1.3505e-02,  2.9938e-02, -3.8230e-03,  4.3303e-03,\n",
       "                      -2.2484e-03,  6.8245e-03, -1.4812e-02,  1.9684e-03,  1.9774e-02,\n",
       "                      -1.6412e-02, -7.2952e-03, -2.3979e-02, -1.2050e-02, -1.3431e-02,\n",
       "                       1.7014e-02,  1.9515e-02, -7.5006e-04, -6.2452e-03,  4.5930e-03,\n",
       "                      -4.9950e-03,  5.5499e-03, -3.7520e-03,  1.9935e-02,  1.8800e-03,\n",
       "                      -7.8176e-03, -3.5463e-03, -9.9530e-03, -6.9270e-03,  5.9675e-03,\n",
       "                       3.9053e-04, -8.5350e-03,  8.9174e-03, -7.9921e-04,  4.1918e-03,\n",
       "                       1.0523e-03,  1.1954e-02,  2.2417e-03,  3.1108e-03, -5.9474e-03,\n",
       "                      -1.3807e-02, -1.7121e-02, -4.9154e-03,  4.4474e-04,  5.7176e-03,\n",
       "                       7.4610e-03,  8.8695e-03,  5.4137e-03,  1.6873e-02, -1.0702e-02,\n",
       "                      -5.5185e-03, -6.5127e-03,  1.2857e-02,  6.8811e-03,  4.4629e-04,\n",
       "                       9.2244e-03, -7.4803e-03,  3.1181e-02, -7.5012e-03, -7.3289e-03,\n",
       "                      -2.3837e-02,  4.5486e-03,  1.0054e-02,  2.8594e-02,  2.3624e-03,\n",
       "                       4.1554e-03, -3.1611e-03, -1.4782e-02,  1.4545e-02, -1.4102e-03,\n",
       "                      -1.2852e-02, -1.8467e-02,  2.2229e-02, -2.0605e-04,  1.8937e-02,\n",
       "                      -2.5808e-02, -1.1940e-02,  1.3755e-02,  3.4983e-03,  1.0653e-02,\n",
       "                       1.7130e-03,  1.5788e-03,  1.3834e-03,  2.3415e-03, -4.4510e-03,\n",
       "                       4.6176e-03, -1.1676e-02, -5.6795e-03, -1.0296e-03,  1.2238e-02,\n",
       "                      -1.7352e-02, -3.4617e-03,  2.6746e-03,  1.0165e-02,  1.5900e-02,\n",
       "                      -6.0548e-03,  1.0325e-02, -2.4700e-03, -5.9575e-03,  2.3346e-02,\n",
       "                       8.2121e-03,  9.7556e-03,  1.8765e-04, -4.3717e-03,  2.9604e-03,\n",
       "                      -1.6807e-02,  5.0313e-03, -2.1227e-03, -1.8067e-03,  3.1264e-03,\n",
       "                      -2.1670e-02, -4.7815e-03, -2.5062e-03,  1.1455e-02, -9.2547e-03,\n",
       "                      -7.2906e-04, -5.0487e-03, -6.8774e-03, -6.1758e-03,  2.7072e-02,\n",
       "                       1.0913e-02,  1.3691e-02, -7.0558e-03,  2.6569e-02, -3.9963e-03,\n",
       "                      -7.9030e-04, -1.0252e-02, -6.2005e-04, -1.0518e-03, -1.8133e-03,\n",
       "                       2.2991e-02, -5.4410e-03, -1.0099e-02,  1.0591e-02, -2.8200e-03,\n",
       "                      -3.2416e-03, -3.1627e-03, -4.1668e-03,  4.6608e-03,  8.8093e-04,\n",
       "                       6.3921e-03,  1.6416e-02, -1.4047e-02, -6.6064e-03,  7.3338e-03,\n",
       "                      -7.7266e-03,  7.4836e-03, -7.8517e-03,  1.1664e-02, -7.8374e-03,\n",
       "                      -1.4340e-02,  1.6145e-02, -1.9885e-02, -6.3264e-03,  1.2937e-02,\n",
       "                      -2.0783e-02,  1.4849e-02, -4.3911e-03,  2.2018e-02, -6.0546e-03,\n",
       "                      -1.6684e-03, -5.8245e-03,  1.0804e-03, -1.0801e-02, -9.8808e-03,\n",
       "                      -1.5679e-02, -1.4640e-03, -6.9074e-03, -2.1327e-03, -1.8169e-02,\n",
       "                       5.3880e-03,  1.8278e-02, -2.3176e-02,  1.7232e-02, -1.1117e-02,\n",
       "                      -8.6722e-03, -5.3551e-03,  1.9688e-04, -5.3372e-03,  3.0524e-02,\n",
       "                       5.2019e-03, -9.7744e-03, -7.5875e-03, -6.0846e-03, -1.4734e-02,\n",
       "                       4.8019e-03, -1.0134e-02, -2.7676e-03, -9.8442e-03, -1.7543e-02,\n",
       "                      -1.2001e-02, -1.1534e-03,  3.4600e-03,  3.3398e-02, -4.9753e-04,\n",
       "                      -9.8324e-03,  7.5321e-03,  5.7564e-03, -8.4156e-03, -8.6951e-03,\n",
       "                      -6.3345e-04])),\n",
       "             ('decoders.5.bn2.running_mean',\n",
       "              tensor([ 0.4385,  0.1174, -0.0756, -0.1397,  0.1579,  0.1315,  0.2104,  0.2327,\n",
       "                       0.3822,  0.3423,  0.0144,  0.0277, -0.3020,  0.3513, -0.1536,  0.0294,\n",
       "                      -0.0844, -0.3157,  0.0008,  0.0372, -0.0544, -0.2884,  0.4129,  0.2700,\n",
       "                       0.2043, -0.1275,  0.1595,  0.5228, -0.0286,  0.0326, -0.2032,  0.1290,\n",
       "                       0.0827,  0.4028, -0.3002,  0.1964,  0.1400, -0.1972,  0.1042,  0.1071,\n",
       "                      -0.3094, -0.1557, -0.0454,  0.0479, -0.0514,  0.2511, -0.0825, -0.0902,\n",
       "                      -0.2079,  0.3000,  0.1280, -0.0012, -0.1830,  0.1682, -0.0376,  0.2999,\n",
       "                      -0.0060, -0.2921,  0.1893,  0.1526,  0.1906, -0.1463,  0.0471, -0.2318,\n",
       "                       0.0068,  0.3301,  0.2593, -0.0510,  0.1292, -0.0095, -0.0592,  0.4563,\n",
       "                      -0.2196,  0.3001,  0.4235,  0.0178,  0.0570, -0.1085, -0.1611, -0.3594,\n",
       "                      -0.0931, -0.2708,  0.2232, -0.0070,  0.3581, -0.0801, -0.1857, -0.1809,\n",
       "                       0.4186, -0.3320, -0.2791,  0.3172,  0.0536,  0.4406,  0.0541,  0.0870,\n",
       "                      -0.1104,  0.0502,  0.0926, -0.0532,  0.3507,  0.2515,  0.1645,  0.0112,\n",
       "                       0.0539,  0.5694,  0.5790, -0.2125,  0.3420,  0.3205,  0.0012,  0.2828,\n",
       "                      -0.1749,  0.1636, -0.2101, -0.0152, -0.1955, -0.1745, -0.2970,  0.3659,\n",
       "                       0.0661,  0.1291,  0.1753, -0.3467,  0.1180,  0.2234, -0.0679, -0.4889,\n",
       "                      -0.0079, -0.2861, -0.0485,  0.3505, -0.0968,  0.2348, -0.1774,  0.0458,\n",
       "                       0.0031, -0.2440,  0.3416, -0.1428,  0.2502,  0.1916,  0.0641, -0.1703,\n",
       "                      -0.2467,  0.0671, -0.1990,  0.2374, -0.3958, -0.0677,  0.3112,  0.3033,\n",
       "                       0.0620,  0.2511, -0.1068,  0.2029, -0.0200, -0.2400, -0.3161, -0.1327,\n",
       "                       0.0653,  0.3524,  0.3048,  0.1494, -0.2079,  0.0511,  0.0225,  0.0196,\n",
       "                      -0.4128,  0.1153, -0.0812,  0.3478,  0.3402,  0.2726,  0.2108, -0.1154,\n",
       "                       0.0848, -0.4114, -0.2900,  0.1565, -0.4120, -0.0656, -0.1859, -0.4513,\n",
       "                       0.5567, -0.3011, -0.0817,  0.1096, -0.4076,  0.0819, -0.0817, -0.2969,\n",
       "                       0.0320,  0.2973, -0.0011, -0.0397,  0.1768, -0.0247,  0.0769, -0.1320,\n",
       "                       0.3704,  0.2182,  0.0514, -0.4021, -0.2744,  0.3729,  0.0631, -0.1990,\n",
       "                       0.0074, -0.1083,  0.1046, -0.1943, -0.3098, -0.5147,  0.4622,  0.2228,\n",
       "                      -0.1477,  0.2011,  0.3754, -0.1838, -0.1112, -0.2509,  0.0831,  0.2324,\n",
       "                       0.3639, -0.2720,  0.0300,  0.1892,  0.0712,  0.1943, -0.2141,  0.0777,\n",
       "                      -0.3954,  0.5561, -0.2740,  0.3023,  0.3352, -0.3142,  0.1947,  0.1050,\n",
       "                       0.0550, -0.1619,  0.5422, -0.2576,  0.4880, -0.0624,  0.1445,  0.1864,\n",
       "                      -0.0553, -0.0636,  0.1862,  0.4807, -0.3097,  0.0313, -0.1026,  0.5389])),\n",
       "             ('decoders.5.bn2.running_var',\n",
       "              tensor([0.4491, 0.4781, 0.1146, 0.3717, 0.5459, 0.5806, 0.0646, 0.0884, 0.5743,\n",
       "                      0.2927, 0.2453, 0.6578, 0.1580, 0.8453, 0.8528, 0.7496, 0.2332, 0.2310,\n",
       "                      0.7687, 0.2734, 0.0980, 0.0980, 0.3143, 0.2588, 0.1268, 0.0773, 0.3579,\n",
       "                      0.3704, 0.2992, 0.0851, 0.4512, 0.2947, 0.1814, 0.3675, 0.1081, 0.3342,\n",
       "                      0.2006, 0.1026, 0.5984, 0.6308, 0.1935, 0.2361, 0.1394, 0.2339, 0.1067,\n",
       "                      1.1776, 0.0787, 0.4095, 0.1301, 0.3604, 0.5502, 0.4745, 0.6761, 0.3691,\n",
       "                      0.4385, 0.3889, 0.7864, 0.2068, 0.3472, 0.4820, 0.3769, 0.1851, 0.2474,\n",
       "                      0.8922, 0.3870, 0.7440, 0.8495, 0.1044, 0.2694, 0.1172, 0.6483, 0.6810,\n",
       "                      0.1379, 0.3640, 1.1396, 0.9561, 0.5877, 0.1047, 0.1979, 0.1476, 0.1123,\n",
       "                      0.1171, 0.1009, 0.2247, 0.6482, 0.3506, 0.1976, 0.2800, 0.8650, 0.2727,\n",
       "                      0.1157, 0.6552, 1.0696, 1.3402, 0.5711, 0.1768, 0.6988, 1.2466, 0.4065,\n",
       "                      0.0792, 0.5228, 0.2526, 0.6256, 0.7508, 0.4424, 0.3125, 0.2678, 0.1602,\n",
       "                      0.8894, 0.5075, 0.7047, 0.8787, 0.9333, 0.6537, 0.3145, 0.1408, 0.3626,\n",
       "                      0.6435, 0.4156, 0.4336, 0.5620, 0.0797, 0.0979, 0.5662, 0.3879, 0.1989,\n",
       "                      0.0681, 0.3669, 0.3452, 0.0635, 0.1808, 0.4919, 0.3858, 0.2761, 0.7308,\n",
       "                      0.2452, 0.4504, 0.4545, 0.4296, 0.1110, 0.4049, 0.2361, 0.6269, 0.0787,\n",
       "                      0.0955, 0.0774, 0.1851, 1.2027, 0.3230, 0.4091, 1.1362, 0.3425, 0.7016,\n",
       "                      0.5262, 0.5107, 0.4625, 0.5117, 0.4519, 0.2249, 0.3704, 0.2903, 0.5650,\n",
       "                      0.3525, 0.7763, 0.1266, 0.1610, 0.3500, 0.1824, 0.0886, 0.3107, 0.1545,\n",
       "                      1.1660, 0.6875, 0.3293, 0.4917, 0.5816, 0.6606, 0.7206, 0.3822, 0.3923,\n",
       "                      0.4554, 0.5362, 0.3554, 0.1274, 0.2903, 0.3800, 0.7058, 1.0405, 0.7209,\n",
       "                      0.7299, 0.9611, 0.1636, 0.3185, 0.1483, 0.3328, 0.2552, 0.4520, 0.2331,\n",
       "                      0.7718, 0.4328, 0.9994, 0.9217, 0.3054, 0.2410, 0.1148, 0.3828, 0.5125,\n",
       "                      0.0861, 0.4770, 0.4288, 0.3344, 0.4602, 0.5633, 0.5905, 1.0460, 0.1541,\n",
       "                      0.3400, 0.3585, 0.7641, 0.0843, 0.3220, 0.3427, 0.7179, 0.2134, 0.1526,\n",
       "                      0.3730, 0.4615, 0.3652, 0.6733, 0.4289, 0.2986, 0.9851, 0.0932, 0.7900,\n",
       "                      0.5238, 0.2612, 0.8783, 0.1187, 0.2728, 0.1946, 0.6329, 0.0807, 0.6666,\n",
       "                      0.1814, 0.3687, 0.0871, 1.5071, 0.7268, 0.7743, 0.1680, 0.7383, 0.5635,\n",
       "                      0.1605, 0.2492, 0.0881, 0.2342])),\n",
       "             ('decoders.5.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense3.weight',\n",
       "              tensor([[-1.0105e-02,  4.1738e-02, -4.8000e-02,  ..., -3.2582e-02,\n",
       "                        2.9555e-02,  3.8374e-02],\n",
       "                      [ 4.0911e-02,  1.0352e-02,  3.7416e-06,  ..., -4.4214e-02,\n",
       "                       -2.9099e-02, -7.3477e-02],\n",
       "                      [-3.3703e-02,  5.5077e-02, -6.1769e-04,  ..., -2.8061e-02,\n",
       "                       -3.1354e-02, -1.0894e-02],\n",
       "                      ...,\n",
       "                      [ 2.0748e-02, -4.2594e-02,  4.9783e-02,  ..., -6.0732e-02,\n",
       "                       -3.7396e-02, -6.4938e-02],\n",
       "                      [ 1.5201e-02,  3.5560e-03, -2.1185e-02,  ..., -2.1501e-02,\n",
       "                       -4.9993e-02, -8.7404e-03],\n",
       "                      [ 4.7450e-02, -4.4045e-02,  3.2170e-02,  ...,  3.6208e-02,\n",
       "                       -2.9964e-02,  4.7497e-02]])),\n",
       "             ('decoders.5.bn3.weight',\n",
       "              tensor([0.9983, 0.9993, 0.9950, 0.9953, 0.9716, 0.9979, 0.9993, 0.9841, 1.0031,\n",
       "                      0.9971, 1.0076, 0.9926, 1.0133, 0.9926, 1.0160, 0.9915, 1.0118, 0.9899,\n",
       "                      0.9923, 1.0069, 1.0046, 1.0070, 1.0154, 0.9942, 0.9745, 1.0075, 0.9914,\n",
       "                      0.9890, 0.9877, 0.9919, 0.9881, 0.9889, 0.9944, 1.0013, 0.9898, 0.9957,\n",
       "                      0.9862, 1.0056, 1.0010, 0.9937, 0.9882, 0.9952, 1.0182, 1.0048, 1.0032,\n",
       "                      0.9811, 1.0162, 1.0216, 1.0004, 0.9925, 0.9910, 1.0296, 0.9978, 0.9909,\n",
       "                      1.0058, 1.0215, 1.0177, 0.9969, 1.0159, 1.0075, 0.9858, 0.9912, 1.0034,\n",
       "                      1.0010, 0.9841, 0.9961, 0.9959, 1.0136, 1.0040, 0.9905, 0.9882, 0.9964,\n",
       "                      0.9951, 0.9862, 1.0224, 1.0159, 0.9949, 0.9922, 0.9892, 1.0095, 0.9981,\n",
       "                      0.9924, 0.9899, 1.0063, 0.9827, 1.0111, 1.0103, 0.9954, 1.0014, 0.9757,\n",
       "                      0.9862, 0.9914, 1.0058, 0.9920, 0.9915, 1.0026, 0.9921, 0.9913, 0.9998,\n",
       "                      1.0159, 1.0170, 0.9802, 1.0000, 1.0052, 0.9954, 1.0199, 1.0197, 0.9928,\n",
       "                      1.0027, 1.0153, 0.9901, 0.9985, 0.9904, 0.9909, 1.0066, 1.0171, 0.9895,\n",
       "                      0.9969, 1.0188, 0.9815, 1.0171, 0.9914, 1.0177, 0.9959, 0.9916, 1.0056,\n",
       "                      1.0011, 1.0160, 0.9891, 0.9897, 0.9926, 1.0150, 0.9943, 0.9993, 0.9841,\n",
       "                      0.9840, 1.0134, 0.9999, 0.9840, 1.0101, 1.0063, 0.9973, 0.9930, 1.0004,\n",
       "                      0.9892, 0.9886, 1.0044, 1.0040, 0.9881, 0.9865, 1.0008, 1.0168, 1.0033,\n",
       "                      0.9946, 1.0060, 0.9924, 0.9805, 1.0013, 1.0031, 0.9929, 0.9922, 0.9890,\n",
       "                      0.9973, 0.9872, 1.0197, 0.9950, 0.9954, 0.9756, 1.0085, 0.9984, 1.0033,\n",
       "                      0.9657, 1.0006, 0.9839, 0.9854, 1.0132, 1.0077, 0.9809, 0.9950, 0.9924,\n",
       "                      1.0250, 0.9730, 1.0010, 1.0006, 0.9995, 0.9939, 0.9868, 0.9760, 0.9992,\n",
       "                      1.0073, 1.0193, 0.9890, 0.9851, 0.9885, 0.9884, 1.0029, 0.9963, 1.0216,\n",
       "                      0.9943, 1.0073, 1.0213, 0.9986, 0.9959, 0.9858, 0.9886, 0.9986, 0.9985,\n",
       "                      0.9994, 0.9985, 1.0240, 0.9965, 0.9862, 1.0008, 1.0193, 1.0212, 1.0030,\n",
       "                      0.9956, 0.9985, 0.9935, 1.0171, 1.0154, 1.0010, 1.0065, 0.9987, 0.9932,\n",
       "                      1.0004, 1.0116, 0.9985, 0.9912, 1.0022, 0.9913, 1.0003, 0.9998, 1.0020,\n",
       "                      0.9960, 1.0102, 1.0060, 1.0029, 0.9974, 0.9923, 0.9788, 0.9803, 0.9900,\n",
       "                      0.9893, 1.0152, 0.9853, 1.0020, 1.0039, 1.0023, 1.0143, 0.9917, 1.0066,\n",
       "                      1.0188, 1.0047, 0.9834, 0.9833, 1.0086, 1.0193, 1.0073, 1.0136, 0.9924,\n",
       "                      1.0115, 0.9816, 0.9988, 1.0207, 0.9908, 0.9699, 0.9820, 0.9965, 1.0099,\n",
       "                      0.9991, 0.9931, 1.0024, 0.9828, 0.9976, 1.0060, 0.9921, 1.0024, 0.9968,\n",
       "                      0.9917, 0.9866, 0.9992, 0.9840, 1.0164, 0.9934, 1.0014, 1.0073, 1.0111,\n",
       "                      0.9937, 0.9955, 0.9977, 0.9994, 0.9999, 0.9955, 0.9845, 0.9876, 1.0087,\n",
       "                      1.0001, 0.9955, 0.9905, 1.0166, 0.9898, 0.9975, 0.9993, 1.0184, 0.9855,\n",
       "                      0.9942, 0.9830, 0.9942, 0.9896, 0.9979, 0.9890, 1.0203, 0.9984, 0.9933,\n",
       "                      1.0151, 0.9926, 0.9792, 0.9863, 0.9907, 1.0130, 0.9825, 1.0182, 1.0147,\n",
       "                      0.9939, 1.0075, 1.0161, 0.9969, 1.0213, 0.9848, 1.0231, 0.9870, 1.0124,\n",
       "                      1.0191, 1.0148, 0.9909, 0.9712, 0.9969, 1.0198, 1.0092, 0.9950, 0.9971,\n",
       "                      0.9879, 1.0032, 0.9935, 0.9866, 0.9891, 0.9968, 1.0181, 1.0118, 1.0037,\n",
       "                      1.0207, 0.9892, 0.9919, 1.0176, 0.9857, 0.9887, 1.0204, 0.9985, 0.9981,\n",
       "                      1.0019, 0.9964, 1.0220, 1.0009, 0.9879, 1.0009, 1.0150, 1.0003, 1.0028,\n",
       "                      0.9951, 0.9974, 0.9921, 1.0259, 1.0125, 1.0167, 0.9968, 0.9885, 1.0173,\n",
       "                      0.9944, 0.9964, 0.9855, 1.0068, 0.9949, 1.0265, 1.0020, 1.0026, 0.9864,\n",
       "                      1.0063, 0.9915, 1.0044, 0.9880, 0.9872, 0.9821, 1.0028, 0.9997, 1.0055,\n",
       "                      0.9942, 0.9976, 0.9918, 0.9802, 1.0050, 0.9990, 1.0013, 0.9939, 0.9857,\n",
       "                      1.0088, 0.9993, 0.9924, 0.9877, 0.9722, 1.0077, 0.9915, 0.9846, 0.9770,\n",
       "                      1.0083, 1.0026, 0.9916, 0.9909, 0.9985, 1.0239, 1.0054, 0.9920, 1.0176,\n",
       "                      1.0076, 1.0212, 1.0069, 0.9895, 1.0000, 1.0133, 0.9787, 1.0191, 0.9894,\n",
       "                      0.9805, 0.9944, 0.9985, 0.9842, 1.0014, 0.9960, 0.9957, 0.9972, 0.9815,\n",
       "                      0.9891, 0.9963, 1.0017, 0.9978, 1.0173, 1.0290, 0.9988, 0.9978, 0.9982,\n",
       "                      1.0151, 1.0053, 1.0020, 1.0152, 1.0129, 0.9983, 0.9944, 0.9758, 0.9964,\n",
       "                      0.9905, 0.9956, 1.0003, 1.0020, 0.9952, 1.0013, 0.9809, 0.9958, 0.9854,\n",
       "                      0.9947, 0.9915, 0.9769, 0.9761, 1.0019, 0.9814, 0.9985, 0.9912, 1.0214,\n",
       "                      0.9921, 0.9992, 1.0140, 0.9993, 1.0120, 0.9956, 1.0052, 1.0151, 0.9951,\n",
       "                      0.9940, 0.9959, 0.9942, 1.0067, 0.9978, 0.9934, 1.0155, 0.9909, 0.9983,\n",
       "                      1.0088, 0.9942, 0.9996, 1.0276, 1.0118, 1.0035, 0.9898, 0.9987, 1.0060,\n",
       "                      1.0175, 0.9889, 0.9988, 0.9837, 0.9935, 0.9961, 0.9870, 1.0113])),\n",
       "             ('decoders.5.bn3.bias',\n",
       "              tensor([ 4.3096e-02,  5.1177e-02, -3.4495e-03, -1.0173e-02, -2.1961e-02,\n",
       "                      -1.0896e-02, -4.1433e-03, -8.8929e-03,  3.3395e-02,  2.0755e-02,\n",
       "                      -3.1689e-02,  3.8654e-03, -2.7752e-02,  3.6254e-02, -3.1330e-02,\n",
       "                      -4.8856e-03,  2.5464e-02,  2.8721e-02,  5.3567e-02, -4.5186e-03,\n",
       "                       2.1083e-02, -1.3760e-02, -2.0651e-02, -6.2560e-03, -1.3588e-02,\n",
       "                      -1.6299e-03,  1.7529e-02,  9.6761e-03,  4.4655e-02, -1.3779e-02,\n",
       "                       1.6192e-02,  2.3846e-03,  1.7868e-02, -2.3336e-02,  3.3548e-02,\n",
       "                       4.4769e-02, -1.5048e-02,  2.0716e-02, -1.4731e-03,  1.1525e-02,\n",
       "                      -1.3768e-02, -7.3725e-03, -2.9254e-02,  3.5192e-02,  8.4301e-05,\n",
       "                      -1.1334e-02, -1.7556e-02, -1.7712e-02, -8.0888e-04, -1.6033e-02,\n",
       "                      -7.0585e-03,  1.3001e-02,  1.9998e-02,  1.4953e-02,  2.4732e-02,\n",
       "                      -2.5967e-03, -1.6166e-02,  1.7216e-02, -1.3814e-02,  1.6315e-02,\n",
       "                      -1.3883e-02,  2.9530e-03, -2.2439e-03, -9.1592e-03, -1.5889e-02,\n",
       "                       3.5020e-02,  2.3844e-02, -1.9253e-02, -7.1030e-03, -1.6368e-02,\n",
       "                       2.8308e-02, -7.4569e-03, -4.7051e-03, -8.4507e-03, -8.3573e-03,\n",
       "                      -4.8559e-03,  1.8792e-04,  3.7952e-02,  1.6395e-03,  4.6881e-03,\n",
       "                       1.1777e-02,  6.6050e-03, -1.3938e-02,  3.1634e-03, -1.0532e-02,\n",
       "                      -4.6340e-03, -4.1868e-03,  1.3437e-02,  1.7064e-02, -1.2935e-02,\n",
       "                      -9.8320e-03,  1.0409e-02,  9.3121e-03, -1.1930e-02, -1.3610e-02,\n",
       "                       1.3471e-02,  1.5419e-02,  2.4288e-03, -2.2560e-02,  5.7591e-04,\n",
       "                       2.0047e-02, -1.5181e-02, -1.7498e-02,  3.7460e-02, -9.6781e-03,\n",
       "                       7.5558e-03,  2.7834e-02, -2.5208e-03,  4.9027e-02,  8.6672e-03,\n",
       "                       1.4825e-02,  3.2528e-02, -2.7039e-03,  3.5985e-02,  3.0491e-03,\n",
       "                      -2.3000e-02,  5.9194e-03,  1.5835e-02, -1.3411e-02, -1.5697e-02,\n",
       "                       1.4109e-02,  3.7506e-02, -1.3463e-02,  6.9457e-03, -8.5042e-03,\n",
       "                       2.5692e-02, -1.5057e-02, -1.1156e-02, -7.3206e-03,  2.2346e-02,\n",
       "                      -9.1019e-04, -8.5028e-03, -4.3274e-04,  4.4182e-02, -1.4136e-02,\n",
       "                       1.4203e-02,  1.4073e-02,  6.9559e-02,  3.0449e-02, -1.5097e-02,\n",
       "                      -2.0134e-02,  2.4175e-02,  1.7476e-02,  1.1789e-03, -7.7540e-04,\n",
       "                       1.9098e-02, -5.9607e-03, -2.4473e-02,  2.8654e-02,  3.1590e-02,\n",
       "                       3.8863e-02,  3.7753e-02, -2.2430e-03,  4.7564e-04,  6.0184e-02,\n",
       "                      -5.4284e-03, -1.8952e-02,  1.3586e-02,  5.3098e-02, -5.7046e-03,\n",
       "                       4.0236e-04, -1.0756e-02,  5.6629e-03, -7.3459e-03, -1.1649e-02,\n",
       "                       2.3356e-02,  5.8034e-03, -2.1277e-02,  2.4867e-02,  5.7073e-03,\n",
       "                       4.9282e-03, -1.1583e-03,  2.1136e-02,  3.7184e-03, -3.7538e-03,\n",
       "                      -5.8942e-03,  1.1836e-02, -1.3427e-02,  3.9951e-03,  1.3682e-02,\n",
       "                      -1.8869e-02,  3.4465e-03, -3.6444e-03, -8.3127e-03,  3.1139e-02,\n",
       "                       7.6356e-03, -7.3289e-04, -1.0418e-02,  2.0280e-03,  4.9626e-02,\n",
       "                       1.6158e-03, -1.0473e-02, -2.4627e-02, -1.0546e-02, -9.3836e-03,\n",
       "                       1.6500e-02,  2.5155e-02, -2.4816e-02, -7.1852e-03,  3.3768e-02,\n",
       "                      -1.4789e-02,  4.7965e-02,  5.9874e-03, -2.8444e-03, -7.8709e-03,\n",
       "                       7.0580e-03,  1.9800e-02,  2.5446e-02,  3.7398e-02, -1.9891e-02,\n",
       "                       4.1530e-02, -1.1225e-02,  9.7796e-03, -5.4438e-03, -8.2284e-03,\n",
       "                      -1.0346e-03,  3.8295e-03,  1.0574e-02,  3.4940e-02, -1.0836e-02,\n",
       "                      -9.0888e-03,  5.4241e-03, -2.4758e-02, -6.4009e-03, -2.1830e-02,\n",
       "                       4.2653e-02, -2.3434e-02, -8.5146e-03, -6.2827e-03,  1.3096e-03,\n",
       "                       4.2390e-03,  2.3788e-02,  1.2408e-02,  4.9017e-02, -2.3193e-02,\n",
       "                       2.3018e-02, -2.6701e-02,  3.2681e-02,  5.6325e-02, -9.7016e-03,\n",
       "                      -1.8239e-02,  5.4440e-03, -9.1087e-03,  1.2428e-02, -2.2785e-02,\n",
       "                      -1.3451e-02,  2.9574e-03, -1.3529e-02, -9.6644e-03, -2.6066e-02,\n",
       "                       8.8054e-03, -3.4252e-02, -2.4343e-03, -1.2173e-02, -1.3764e-02,\n",
       "                      -1.7026e-02, -2.2258e-02, -1.9310e-02, -4.0478e-03, -4.8107e-03,\n",
       "                      -9.9184e-03, -2.5202e-02, -1.6296e-02, -5.0110e-03, -2.0567e-02,\n",
       "                      -5.2864e-03, -1.1516e-02, -9.6346e-03,  2.0907e-02,  2.0479e-02,\n",
       "                      -3.7337e-03,  1.9210e-02,  3.0730e-02, -4.5141e-03,  1.7783e-02,\n",
       "                       2.7653e-02, -1.9894e-03,  2.7544e-02,  8.4372e-03,  4.0973e-02,\n",
       "                       2.1189e-02,  5.0419e-02, -9.2048e-03, -1.8605e-02, -7.2585e-03,\n",
       "                       3.6466e-03,  7.9803e-03, -3.2919e-02,  2.3036e-03,  3.0618e-02,\n",
       "                       7.3918e-03,  3.5264e-02,  4.2276e-02,  3.8805e-02, -1.1310e-02,\n",
       "                       1.5531e-03,  6.3397e-02, -3.8074e-03,  2.2817e-02,  8.3264e-03,\n",
       "                       2.2673e-05,  1.4985e-02, -4.2213e-03,  1.3258e-02, -5.8194e-03,\n",
       "                      -2.0840e-02, -7.0227e-03, -8.2994e-03,  2.4676e-02, -1.2728e-02,\n",
       "                       4.0723e-03,  2.3806e-02, -1.9875e-02,  3.3958e-02,  1.4848e-02,\n",
       "                       7.5334e-03, -5.2426e-03, -1.5827e-02, -1.7902e-02, -3.5405e-02,\n",
       "                      -2.7308e-03,  1.9697e-02, -1.8652e-02, -4.0545e-03,  6.1840e-03,\n",
       "                      -1.6629e-02, -2.9695e-02, -1.0946e-02, -1.6009e-02, -1.1082e-02,\n",
       "                      -1.6736e-02, -8.4851e-03, -3.6290e-03, -1.4757e-02,  1.0448e-02,\n",
       "                       3.8537e-03, -1.2832e-02,  1.8220e-02, -3.0275e-03, -1.8345e-02,\n",
       "                       3.9205e-02,  3.5701e-04, -9.0391e-03,  1.9376e-02, -1.3383e-03,\n",
       "                       8.2460e-03, -3.5796e-03,  2.7261e-02, -1.2388e-02,  1.7720e-02,\n",
       "                       1.2077e-02, -7.8527e-03,  1.7781e-02,  2.4748e-02, -1.3516e-02,\n",
       "                       1.2932e-02,  2.2736e-03, -8.1801e-03,  8.7299e-03,  1.3478e-02,\n",
       "                       1.1618e-02,  8.9455e-03, -1.7313e-02, -1.1720e-02,  3.4427e-02,\n",
       "                       1.2964e-02,  4.2455e-03,  6.1682e-04, -1.0768e-03,  1.3205e-02,\n",
       "                       4.8744e-03,  1.6922e-02, -2.6958e-02,  3.7414e-04, -1.4819e-02,\n",
       "                       9.0150e-03,  9.2343e-03, -1.3787e-02, -9.5221e-04,  3.4241e-03,\n",
       "                      -6.2894e-03,  3.4945e-02,  1.8722e-02, -3.2633e-02,  1.8604e-02,\n",
       "                       1.8735e-03,  1.7458e-02,  6.2340e-03, -1.5774e-02,  2.1396e-03,\n",
       "                       1.0887e-02,  6.3361e-03, -4.6106e-03,  1.1236e-02, -1.3895e-04,\n",
       "                      -3.0886e-03,  5.8803e-03,  3.7215e-04,  3.3309e-04,  1.4970e-03,\n",
       "                      -1.1657e-02, -1.8988e-02,  3.7192e-02,  3.1035e-02,  1.7810e-02,\n",
       "                       4.4764e-02,  6.8361e-03, -2.6284e-02,  1.0164e-02, -2.1386e-02,\n",
       "                       4.8333e-02,  1.5552e-03,  1.6003e-03, -2.0254e-02, -1.6260e-02,\n",
       "                       8.8278e-03,  1.6272e-02, -1.0529e-02,  2.9972e-02, -9.0156e-03,\n",
       "                      -1.7953e-02, -1.0162e-02,  3.5057e-02,  6.3483e-03, -1.7410e-02,\n",
       "                       4.5457e-02,  3.8696e-04,  4.4183e-02, -2.2212e-02, -2.0869e-02,\n",
       "                      -8.5879e-03, -3.5181e-03, -9.9537e-03, -1.7171e-03,  6.9903e-03,\n",
       "                      -6.0519e-03,  9.5161e-03, -5.0649e-03, -2.1493e-03,  1.0143e-02,\n",
       "                       1.3932e-02, -4.3142e-03,  4.3947e-02,  5.3835e-02, -5.0062e-03,\n",
       "                      -2.1481e-02, -1.8815e-02,  2.0140e-02,  3.2186e-03,  1.1551e-03,\n",
       "                      -2.4795e-03,  1.5570e-02, -7.1874e-03,  7.6443e-03, -2.0115e-03,\n",
       "                      -5.0737e-03,  4.7906e-03, -1.5969e-02, -3.7778e-03,  9.7793e-03,\n",
       "                       1.1140e-04,  1.5146e-02,  1.8701e-03,  1.7707e-03, -1.2221e-02,\n",
       "                       1.6999e-03,  3.9722e-02,  2.3684e-02,  1.2334e-02, -1.8321e-03,\n",
       "                      -1.2815e-02, -2.1752e-02, -4.7323e-03, -3.7400e-03,  3.0770e-02,\n",
       "                       3.5652e-02, -2.5625e-02,  1.3287e-02,  5.4390e-02, -2.3167e-03,\n",
       "                      -2.8043e-03,  1.8891e-02, -3.0666e-03,  5.5142e-02, -3.3856e-02,\n",
       "                       4.4635e-03,  1.6058e-02,  1.1195e-02,  4.9356e-03,  1.9848e-02,\n",
       "                       5.6559e-03,  3.5828e-02, -3.8309e-03,  1.6349e-03,  2.1838e-02,\n",
       "                      -2.3593e-02,  1.2291e-02,  3.7768e-03, -2.1966e-02,  2.5164e-02,\n",
       "                       8.2151e-03,  4.2111e-03,  2.3717e-02,  1.1649e-04, -1.4595e-02,\n",
       "                       3.5618e-03, -4.1089e-03,  1.8054e-02,  1.1044e-02,  1.2571e-02,\n",
       "                      -5.4906e-03, -1.2855e-02])),\n",
       "             ('decoders.5.bn3.running_mean',\n",
       "              tensor([-0.2286, -0.6630, -0.0996, -0.2367, -0.1540, -0.3355, -0.4589,  0.4061,\n",
       "                      -0.3206, -0.5141,  0.2174, -0.2459,  0.6811, -0.2114,  0.6482, -0.0403,\n",
       "                      -0.1351, -0.1268, -0.2299,  0.1551,  0.3802,  0.2911,  0.5399, -0.3428,\n",
       "                      -0.0940,  0.1976, -0.2470, -0.4877, -0.3302,  0.1624, -0.2954, -0.3064,\n",
       "                       0.2280,  0.4032, -0.1560, -0.4814,  0.2122, -0.1029, -0.2356,  0.4519,\n",
       "                      -0.0379, -0.2599,  0.6131, -0.2187, -0.4356,  0.2265,  0.5433,  0.6891,\n",
       "                       0.4291, -0.2844,  0.1391,  0.2191, -0.6002, -0.2805,  0.0719,  0.4431,\n",
       "                       0.4974, -0.6107,  0.1412, -0.0816,  0.1350, -0.2271,  0.1767,  0.3451,\n",
       "                      -0.0080, -0.2933, -0.3238,  0.3766,  0.5195,  0.1413, -0.3814, -0.2454,\n",
       "                      -0.1099,  0.1477,  0.5138,  0.5556, -0.0130, -0.4038, -0.3284,  0.2696,\n",
       "                       0.0726,  0.1915, -0.3288,  0.5129,  0.0915,  0.1864,  0.5557, -0.3140,\n",
       "                      -0.2980,  0.3067, -0.2985, -0.2502,  0.2860,  0.3258,  0.2346,  0.1484,\n",
       "                      -0.4570, -0.4005,  0.4720,  0.3745,  0.1015,  0.0605,  0.3649, -0.4777,\n",
       "                      -0.3318,  0.1661, -0.1018,  0.0453, -0.5400, -0.4915, -0.4940, -0.2475,\n",
       "                      -0.1194, -0.5543,  0.3202,  0.4447,  0.0305, -0.1187,  0.2675,  0.1834,\n",
       "                       0.2752, -0.4598,  0.5027,  0.0963, -0.0901, -0.5584,  0.1242,  0.3720,\n",
       "                       0.1521, -0.1627,  0.3901,  0.4484,  0.0275, -0.3860, -0.0543, -0.4197,\n",
       "                       0.0631, -0.4233, -0.3587,  0.6252,  0.3220,  0.0364, -0.5364, -0.0907,\n",
       "                      -0.2363, -0.2462,  0.4722,  0.2535, -0.6159, -0.3866, -0.3433,  0.2377,\n",
       "                       0.1908,  0.2765, -0.4187, -0.0410,  0.1825, -0.1151, -0.2584,  0.0431,\n",
       "                      -0.2825, -0.2516,  0.4191,  0.0055,  0.4196, -0.2008,  0.1909,  0.4059,\n",
       "                       0.2661, -0.2632, -0.0688, -0.3310,  0.1546, -0.2098, -0.4537,  0.3835,\n",
       "                      -0.1341, -0.2298, -0.0580, -0.1822,  0.9374, -0.4635, -0.0409,  0.3599,\n",
       "                      -0.2637, -0.0515,  0.0370, -0.1329, -0.1554, -0.4969,  0.2787, -0.1355,\n",
       "                       0.0623,  0.0728, -0.1384, -0.2837, -0.1984,  0.5214,  0.2067, -0.1561,\n",
       "                       0.5040, -0.3203,  0.2814, -0.0498, -0.4498, -0.0612,  0.2368, -0.4006,\n",
       "                      -0.3164,  0.2579, -0.4850,  0.0710, -0.1083,  0.3785,  0.4421,  0.2136,\n",
       "                       0.0524, -0.1401, -0.3532,  0.6703,  0.4000,  0.3541,  0.3823,  0.2345,\n",
       "                       0.4776, -0.1827,  0.2259,  0.3642,  0.0242, -0.0944, -0.1231, -0.0396,\n",
       "                      -0.3079, -0.3109,  0.3536, -0.0079,  0.3458, -0.3590, -0.1997, -0.0128,\n",
       "                      -0.1736, -0.4288, -0.3299, -0.3010,  0.6267, -0.1986, -0.1739,  0.3724,\n",
       "                       0.3282,  0.6056,  0.4425,  0.2806,  0.3132,  0.3910, -0.2408,  0.0831,\n",
       "                       0.5652,  0.5492,  0.5978, -0.0155,  0.1771,  0.4235,  0.4430,  0.0869,\n",
       "                       0.4059, -0.0139, -0.2506,  0.1864, -0.2247,  0.1311, -0.1959,  0.0453,\n",
       "                      -0.4093, -0.2056,  0.1584,  0.1105,  0.1986,  0.2165, -0.1546, -0.2514,\n",
       "                      -0.3728, -0.3635, -0.4037,  0.6429,  0.2505,  0.1691, -0.0244,  0.5448,\n",
       "                      -0.0106, -0.4931,  0.1261, -0.4357, -0.2803, -0.5418, -0.2086,  0.1491,\n",
       "                      -0.3196,  0.3263, -0.2596, -0.2511,  0.1130, -0.2612,  0.4502, -0.4028,\n",
       "                       0.3635, -0.3117,  0.5541, -0.1901, -0.4314,  0.0707, -0.0126, -0.6379,\n",
       "                       0.3031, -0.0976, -0.3116, -0.0470,  0.0356, -0.1842,  0.3918,  0.2651,\n",
       "                       0.1523, -0.2710,  0.4461,  0.3142, -0.2157,  0.2355,  0.6769, -0.0250,\n",
       "                       0.3747, -0.1467,  0.5355, -0.6428,  0.1701,  0.6438,  0.2490, -0.0774,\n",
       "                      -0.0554, -0.2597,  0.5182,  0.6053, -0.5619, -0.2203,  0.0908,  0.2676,\n",
       "                      -0.0230, -0.2960,  0.0290, -0.3579,  0.4088,  0.0995,  0.1774,  0.6988,\n",
       "                      -0.3289, -0.2671,  0.2693,  0.1569,  0.2350,  0.0719,  0.1623,  0.0123,\n",
       "                      -0.0548,  0.2566,  0.5933,  0.3923, -0.3002,  0.0291,  0.4492,  0.1068,\n",
       "                       0.2238,  0.0622, -0.0609,  0.2487,  0.5285,  0.3482,  0.4970, -0.1299,\n",
       "                       0.1549,  0.6552, -0.0603,  0.1448,  0.1895, -0.1918,  0.0463,  0.7151,\n",
       "                       0.3069, -0.0639,  0.0450,  0.0141, -0.0078,  0.3257, -0.3511,  0.1072,\n",
       "                      -0.0550,  0.2175, -0.2669, -0.2079, -0.4172, -0.1686,  0.1328, -0.2362,\n",
       "                       0.5323,  0.5063, -0.3605, -0.2767, -0.1827, -0.2550,  0.4738,  0.5308,\n",
       "                      -0.3060,  0.1571, -0.5043,  0.1666, -0.1795, -0.0148,  0.4852,  0.3504,\n",
       "                      -0.4363, -0.0275, -0.5597,  0.9120,  0.7056,  0.0604,  0.1629,  0.0281,\n",
       "                       0.5551, -0.2850, -0.0094, -0.5149,  0.6485,  0.1952,  0.4856, -0.4029,\n",
       "                      -0.1606, -0.2149, -0.2029, -0.2780,  0.3958, -0.2131,  0.1985, -0.0250,\n",
       "                      -0.2965,  0.1174, -0.4099, -0.5148, -0.5303,  0.4037,  0.6754, -0.3687,\n",
       "                      -0.1386, -0.0695,  0.2436, -0.4480,  0.0192,  0.3545,  0.1892,  0.1732,\n",
       "                      -0.0063, -0.1037,  0.1307, -0.3415,  0.0205, -0.3090, -0.2387,  0.0047,\n",
       "                      -0.2380,  0.0114, -0.5646, -0.3489,  0.2329, -0.4182, -0.1520, -0.1210,\n",
       "                       0.2966, -0.1484, -0.3140, -0.4240,  0.5445, -0.4026, -0.4257,  0.2344,\n",
       "                       0.2657, -0.3101, -0.0954, -0.5669,  0.7895,  0.2784, -0.1007,  0.1255,\n",
       "                      -0.1053, -0.4448, -0.1904, -0.2321,  0.1937, -0.1437,  0.4573,  0.3097,\n",
       "                      -0.1441, -0.0824,  0.7405,  0.2078,  0.3677,  0.1065, -0.2065,  0.1980,\n",
       "                       0.4685, -0.1701, -0.0084, -0.5783, -0.2271, -0.1441,  0.0902,  0.2164])),\n",
       "             ('decoders.5.bn3.running_var',\n",
       "              tensor([1.7938, 1.0681, 0.2845, 1.4630, 0.4742, 1.5002, 0.2718, 0.4746, 0.5340,\n",
       "                      0.9983, 0.6875, 0.6095, 0.8650, 0.4879, 0.7990, 0.6683, 1.0751, 0.6053,\n",
       "                      1.1876, 2.1446, 0.9992, 1.4996, 1.2699, 0.5421, 0.8546, 1.9770, 1.1363,\n",
       "                      0.2650, 1.2298, 0.3098, 0.4982, 1.0503, 0.6863, 1.2851, 1.1080, 1.2476,\n",
       "                      0.5020, 0.7704, 0.3428, 1.0622, 0.7032, 0.8375, 1.1293, 0.6284, 0.8030,\n",
       "                      0.3687, 1.0056, 1.3111, 0.8857, 0.6870, 0.4654, 2.1540, 0.5330, 0.2970,\n",
       "                      1.2300, 1.0474, 1.6444, 0.4950, 1.5287, 1.4415, 0.7276, 1.2467, 1.6510,\n",
       "                      1.0979, 0.4837, 0.6718, 1.0718, 0.9953, 1.3104, 0.4772, 0.7955, 0.2677,\n",
       "                      0.4679, 0.4339, 1.5399, 1.5162, 0.2593, 1.3821, 0.3065, 2.1392, 1.1804,\n",
       "                      1.0807, 0.3141, 0.5886, 0.5998, 1.1145, 1.0238, 1.5403, 0.7067, 0.5531,\n",
       "                      1.0719, 1.0224, 0.9763, 0.4818, 0.4093, 1.0535, 1.2207, 0.3479, 1.9095,\n",
       "                      2.0551, 0.8677, 0.3902, 0.7057, 1.4103, 0.5580, 1.7994, 1.8468, 0.6834,\n",
       "                      0.8040, 1.8207, 1.3307, 0.4510, 1.2249, 0.5405, 2.1071, 1.0317, 0.7263,\n",
       "                      0.4841, 1.6514, 0.5448, 1.4639, 0.3502, 1.0500, 0.9524, 0.6978, 0.4361,\n",
       "                      1.8168, 1.5826, 0.1305, 1.0506, 0.8529, 1.4099, 1.3427, 0.9122, 0.4095,\n",
       "                      0.8183, 2.6125, 1.1362, 1.2916, 1.2727, 0.8639, 1.0904, 0.4303, 1.3108,\n",
       "                      0.9489, 1.2718, 1.7715, 0.9341, 0.7055, 0.6848, 0.4460, 1.7135, 1.5960,\n",
       "                      1.1278, 0.6628, 0.7692, 0.2798, 0.6046, 0.7215, 0.7028, 0.4282, 0.2649,\n",
       "                      0.7854, 0.8398, 1.1841, 0.4486, 1.0278, 0.3043, 1.0067, 0.6965, 0.8821,\n",
       "                      0.9420, 1.1703, 0.2345, 0.3738, 1.3848, 0.6968, 0.3714, 0.5234, 0.6861,\n",
       "                      2.3369, 0.9349, 0.2988, 1.4029, 0.4440, 0.5223, 0.6834, 0.2015, 0.8010,\n",
       "                      1.0935, 1.5205, 1.0073, 0.3345, 0.2439, 0.8810, 0.5007, 1.0291, 0.9764,\n",
       "                      0.7757, 1.2239, 1.2787, 0.4199, 1.0374, 0.9191, 0.3074, 2.2354, 0.9472,\n",
       "                      0.6309, 0.4479, 1.4452, 1.0615, 1.0126, 0.7814, 1.2513, 1.9633, 1.3415,\n",
       "                      0.6561, 0.7047, 0.9427, 1.5181, 1.5612, 1.5377, 0.8638, 1.1122, 0.5506,\n",
       "                      1.5330, 0.7810, 0.5348, 0.4811, 0.4024, 1.1079, 1.2290, 0.8767, 0.7061,\n",
       "                      0.8436, 0.8703, 1.7743, 0.2996, 0.6646, 0.6209, 0.1331, 0.3689, 0.1890,\n",
       "                      1.3966, 1.1998, 0.2437, 0.4820, 1.6545, 0.9529, 1.2692, 0.9982, 0.7689,\n",
       "                      1.8512, 1.5103, 1.1140, 0.2969, 1.9039, 0.8406, 0.8040, 1.4032, 1.5520,\n",
       "                      0.7617, 0.7226, 1.4383, 1.3916, 0.6740, 0.9838, 0.5355, 0.8225, 1.6417,\n",
       "                      0.5591, 0.4905, 0.8587, 1.1922, 1.5869, 0.8136, 1.0039, 1.3667, 2.1073,\n",
       "                      0.6047, 1.7651, 1.0625, 0.1892, 0.7699, 0.4248, 1.4742, 1.5081, 0.6816,\n",
       "                      0.8695, 1.6410, 0.6627, 0.4708, 2.1052, 0.9690, 0.2097, 0.9096, 0.7050,\n",
       "                      0.9243, 0.7524, 0.9024, 1.3125, 0.9436, 1.5332, 0.2779, 2.6819, 0.5012,\n",
       "                      0.9749, 0.2659, 0.5117, 0.4517, 0.8357, 1.4409, 1.5631, 1.1080, 0.5833,\n",
       "                      2.4623, 0.7860, 0.7008, 0.3234, 0.6681, 2.3477, 1.0912, 1.0666, 0.7349,\n",
       "                      1.6909, 1.5094, 0.6847, 0.5122, 0.6627, 0.4330, 0.8059, 0.1805, 1.3899,\n",
       "                      1.2943, 2.4715, 0.3268, 0.3398, 0.4717, 2.5746, 0.6181, 0.6569, 0.7899,\n",
       "                      1.1029, 1.3428, 0.5475, 0.5015, 1.0840, 0.6126, 1.4797, 0.9898, 0.8240,\n",
       "                      2.0266, 1.2133, 0.6172, 1.0779, 0.7191, 0.7862, 1.1252, 1.4517, 1.4766,\n",
       "                      0.3215, 0.8493, 0.9920, 1.4013, 0.6969, 0.7728, 2.0778, 0.7123, 1.6291,\n",
       "                      1.1665, 0.7306, 1.0575, 0.9182, 1.4118, 1.5211, 0.4634, 1.3724, 2.1379,\n",
       "                      0.6849, 1.5397, 1.0611, 1.0359, 1.3705, 0.9561, 1.5029, 1.3176, 0.8849,\n",
       "                      0.3832, 0.6946, 2.1148, 0.3189, 0.5340, 0.4275, 1.4812, 0.3598, 1.2250,\n",
       "                      0.2424, 0.7778, 0.3906, 0.5397, 1.3284, 0.5255, 1.2654, 0.8246, 0.5192,\n",
       "                      0.7773, 1.3285, 0.6596, 0.6252, 0.0966, 0.5304, 0.4410, 0.4161, 0.2595,\n",
       "                      1.1885, 1.9386, 0.5520, 0.8372, 0.4105, 0.8286, 1.7058, 0.4689, 2.3470,\n",
       "                      2.3701, 1.1958, 0.7845, 0.4302, 1.2186, 0.9996, 0.3594, 1.2158, 0.3450,\n",
       "                      0.4830, 0.6728, 0.6587, 0.6746, 2.4899, 0.3347, 1.3486, 1.2424, 0.9599,\n",
       "                      0.3723, 2.1298, 0.7858, 0.3960, 0.7580, 1.2114, 0.5202, 1.0065, 0.6559,\n",
       "                      1.1560, 0.4294, 1.0967, 2.1824, 2.3320, 0.8686, 0.9364, 0.3578, 1.6604,\n",
       "                      0.1392, 1.3378, 0.3580, 1.1010, 0.7698, 0.7042, 0.7329, 0.5460, 0.9952,\n",
       "                      1.2010, 0.3119, 0.3959, 0.4487, 0.7277, 0.7913, 0.3477, 0.8602, 0.7901,\n",
       "                      0.5681, 0.7412, 1.8651, 1.4936, 0.4888, 0.2685, 1.5388, 1.0515, 0.6797,\n",
       "                      1.5493, 0.7371, 0.7771, 0.2308, 0.5880, 0.3702, 1.8203, 0.4783, 1.5803,\n",
       "                      0.8659, 0.6626, 0.3098, 0.8903, 1.1679, 0.9907, 1.6146, 0.2954, 0.9302,\n",
       "                      1.4195, 0.9805, 0.4701, 1.0896, 1.1241, 1.7552, 0.9533, 0.7364])),\n",
       "             ('decoders.5.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense4.weight',\n",
       "              tensor([[ 0.0028, -0.0426,  0.0197,  ..., -0.0051,  0.0203, -0.0030],\n",
       "                      [ 0.0397, -0.0123, -0.0108,  ..., -0.0258,  0.0224,  0.0102],\n",
       "                      [ 0.0150, -0.0204,  0.0381,  ...,  0.0249, -0.0133, -0.0215],\n",
       "                      ...,\n",
       "                      [-0.0114, -0.0381, -0.0125,  ..., -0.0312,  0.0268, -0.0337],\n",
       "                      [-0.0075,  0.0265, -0.0148,  ...,  0.0277,  0.0120,  0.0053],\n",
       "                      [-0.0283,  0.0165, -0.0253,  ..., -0.0418, -0.0066,  0.0095]])),\n",
       "             ('decoders.5.bn4.weight',\n",
       "              tensor([1.0334, 1.0305, 1.0314, 1.0341, 1.0296, 1.0380, 1.0307, 1.0359, 1.0303,\n",
       "                      1.0283, 1.0298, 1.0299, 1.0320, 1.0332, 1.0359, 1.0331, 1.0300, 1.0326,\n",
       "                      1.0329, 1.0310, 1.0284, 1.0291, 1.0305, 1.0253, 1.0306, 1.0352, 1.0286,\n",
       "                      1.0300, 1.0304, 1.0283, 1.0355, 1.0302, 1.0311, 1.0381, 1.0303, 1.0277,\n",
       "                      1.0293, 1.0317, 1.0302, 1.0296, 1.0289, 1.0297, 1.0265, 1.0307, 1.0347,\n",
       "                      1.0291, 1.0268, 1.0280, 1.0352, 1.0312, 1.0299, 1.0311, 1.0370, 1.0307,\n",
       "                      1.0291, 1.0275, 1.0307, 1.0313, 1.0373, 1.0258, 1.0295, 1.0314, 1.0283,\n",
       "                      1.0370, 1.0340, 1.0296, 1.0355, 1.0303, 1.0293, 1.0296, 1.0311, 1.0304,\n",
       "                      1.0303, 1.0300, 1.0299, 1.0302, 1.0309, 1.0303, 1.0296, 1.0296, 1.0297,\n",
       "                      1.0302, 1.0307, 1.0287, 1.0333, 1.0307, 1.0302, 1.0302, 1.0342, 1.0290,\n",
       "                      1.0316, 1.0309, 1.0285, 1.0400, 1.0292, 1.0297, 1.0307, 1.0285, 1.0361,\n",
       "                      1.0275, 1.0321, 1.0290, 1.0310, 1.0279, 1.0296, 1.0367, 1.0301, 1.0338,\n",
       "                      1.0314, 1.0304, 1.0290, 1.0342, 1.0313, 1.0308, 1.0289, 1.0307, 1.0292,\n",
       "                      1.0316, 1.0288, 1.0294, 1.0323, 1.0278, 1.0282, 1.0305, 1.0374, 1.0357,\n",
       "                      1.0293, 1.0348, 1.0284, 1.0340, 1.0303, 1.0296, 1.0344, 1.0390, 1.0287,\n",
       "                      1.0304, 1.0293, 1.0372, 1.0265, 1.0329, 1.0322, 1.0316, 1.0294, 1.0308,\n",
       "                      1.0355, 1.0375, 1.0306, 1.0309, 1.0309, 1.0352, 1.0371, 1.0293, 1.0286,\n",
       "                      1.0309, 1.0296, 1.0346, 1.0311, 1.0295, 1.0292, 1.0334, 1.0308, 1.0375,\n",
       "                      1.0328, 1.0306, 1.0401, 1.0321, 1.0310, 1.0304, 1.0271, 1.0307, 1.0345,\n",
       "                      1.0313, 1.0297, 1.0290, 1.0308, 1.0278, 1.0287, 1.0296, 1.0294, 1.0334,\n",
       "                      1.0328, 1.0328, 1.0293, 1.0284, 1.0318, 1.0293, 1.0327, 1.0292, 1.0284,\n",
       "                      1.0276, 1.0312, 1.0304, 1.0299, 1.0315, 1.0293, 1.0306, 1.0328, 1.0279,\n",
       "                      1.0304, 1.0324, 1.0296, 1.0297, 1.0277, 1.0327, 1.0301, 1.0299, 1.0293,\n",
       "                      1.0288, 1.0263, 1.0310, 1.0290, 1.0309, 1.0320, 1.0298, 1.0318, 1.0287,\n",
       "                      1.0308, 1.0287, 1.0367, 1.0305, 1.0347, 1.0306, 1.0264, 1.0293, 1.0323,\n",
       "                      1.0297, 1.0273, 1.0296, 1.0310, 1.0278, 1.0292, 1.0309, 1.0329, 1.0305,\n",
       "                      1.0280, 1.0288, 1.0270, 1.0351, 1.0289, 1.0312, 1.0298, 1.0348, 1.0361,\n",
       "                      1.0297, 1.0323, 1.0307, 1.0274, 1.0267, 1.0304, 1.0287, 1.0386, 1.0295,\n",
       "                      1.0327, 1.0307, 1.0313, 1.0303, 1.0301, 1.0314, 1.0308, 1.0285, 1.0310,\n",
       "                      1.0290, 1.0359, 1.0318, 1.0332, 1.0289, 1.0292, 1.0296, 1.0313, 1.0285,\n",
       "                      1.0300, 1.0305, 1.0298, 1.0311, 1.0303, 1.0307, 1.0302, 1.0360, 1.0362,\n",
       "                      1.0334, 1.0303, 1.0303, 1.0317, 1.0301, 1.0357, 1.0319, 1.0337, 1.0260,\n",
       "                      1.0335, 1.0355, 1.0289, 1.0308, 1.0315, 1.0325, 1.0311, 1.0284, 1.0334,\n",
       "                      1.0322, 1.0300, 1.0297, 1.0278, 1.0303, 1.0298, 1.0310, 1.0342, 1.0311,\n",
       "                      1.0290, 1.0321, 1.0299, 1.0299, 1.0290, 1.0354, 1.0396, 1.0309, 1.0297,\n",
       "                      1.0274, 1.0308, 1.0304, 1.0279, 1.0327, 1.0310, 1.0295, 1.0339, 1.0362,\n",
       "                      1.0283, 1.0309, 1.0341, 1.0304, 1.0312, 1.0280, 1.0325, 1.0263, 1.0330,\n",
       "                      1.0301, 1.0266, 1.0307, 1.0353, 1.0360, 1.0316, 1.0281, 1.0313, 1.0288,\n",
       "                      1.0313, 1.0337, 1.0287, 1.0296, 1.0293, 1.0281, 1.0297, 1.0318, 1.0273,\n",
       "                      1.0293, 1.0231, 1.0303, 1.0309, 1.0301, 1.0293, 1.0298, 1.0297, 1.0310,\n",
       "                      1.0310, 1.0282, 1.0304, 1.0290, 1.0313, 1.0312, 1.0308, 1.0298, 1.0326,\n",
       "                      1.0289, 1.0336, 1.0302, 1.0269, 1.0313, 1.0290, 1.0290, 1.0330, 1.0314,\n",
       "                      1.0315, 1.0333, 1.0359, 1.0282, 1.0287, 1.0387, 1.0276, 1.0267, 1.0260,\n",
       "                      1.0310, 1.0369, 1.0288, 1.0282, 1.0306, 1.0378, 1.0288, 1.0306, 1.0288,\n",
       "                      1.0268, 1.0293, 1.0310, 1.0343, 1.0325, 1.0324, 1.0304, 1.0323, 1.0333,\n",
       "                      1.0323, 1.0297, 1.0309, 1.0287, 1.0303, 1.0307, 1.0313, 1.0283, 1.0291,\n",
       "                      1.0320, 1.0329, 1.0301, 1.0301, 1.0270, 1.0306, 1.0255, 1.0309, 1.0349,\n",
       "                      1.0286, 1.0277, 1.0301, 1.0325, 1.0281, 1.0309, 1.0290, 1.0321, 1.0386,\n",
       "                      1.0322, 1.0291, 1.0304, 1.0389, 1.0282, 1.0302, 1.0320, 1.0307, 1.0363,\n",
       "                      1.0248, 1.0340, 1.0245, 1.0304, 1.0297, 1.0305, 1.0305, 1.0339, 1.0315,\n",
       "                      1.0320, 1.0322, 1.0325, 1.0311, 1.0304, 1.0301, 1.0289, 1.0303, 1.0299,\n",
       "                      1.0284, 1.0315, 1.0288, 1.0304, 1.0277, 1.0394, 1.0284, 1.0290, 1.0306,\n",
       "                      1.0338, 1.0341, 1.0293, 1.0318, 1.0311, 1.0334, 1.0380, 1.0327, 1.0296,\n",
       "                      1.0372, 1.0341, 1.0344, 1.0344, 1.0299, 1.0309, 1.0294, 1.0311, 1.0289,\n",
       "                      1.0304, 1.0297, 1.0281, 1.0281, 1.0348, 1.0307, 1.0282, 1.0289, 1.0316,\n",
       "                      1.0289, 1.0308, 1.0297, 1.0360, 1.0367, 1.0340, 1.0349, 1.0293, 1.0299,\n",
       "                      1.0288, 1.0335, 1.0295, 1.0304, 1.0308, 1.0317, 1.0319, 1.0325])),\n",
       "             ('decoders.5.bn4.bias',\n",
       "              tensor([0.0344, 0.0388, 0.0375, 0.0340, 0.0369, 0.0352, 0.0389, 0.0352, 0.0380,\n",
       "                      0.0387, 0.0371, 0.0367, 0.0377, 0.0383, 0.0343, 0.0396, 0.0371, 0.0340,\n",
       "                      0.0334, 0.0383, 0.0386, 0.0367, 0.0385, 0.0370, 0.0379, 0.0363, 0.0383,\n",
       "                      0.0362, 0.0362, 0.0358, 0.0394, 0.0382, 0.0383, 0.0370, 0.0361, 0.0374,\n",
       "                      0.0357, 0.0389, 0.0359, 0.0381, 0.0388, 0.0386, 0.0372, 0.0375, 0.0337,\n",
       "                      0.0372, 0.0379, 0.0379, 0.0352, 0.0383, 0.0360, 0.0369, 0.0380, 0.0387,\n",
       "                      0.0373, 0.0352, 0.0393, 0.0389, 0.0365, 0.0380, 0.0385, 0.0368, 0.0373,\n",
       "                      0.0357, 0.0353, 0.0365, 0.0352, 0.0372, 0.0366, 0.0377, 0.0382, 0.0383,\n",
       "                      0.0376, 0.0378, 0.0364, 0.0374, 0.0370, 0.0383, 0.0376, 0.0379, 0.0387,\n",
       "                      0.0394, 0.0379, 0.0368, 0.0409, 0.0383, 0.0378, 0.0395, 0.0352, 0.0384,\n",
       "                      0.0332, 0.0381, 0.0360, 0.0352, 0.0380, 0.0376, 0.0392, 0.0375, 0.0359,\n",
       "                      0.0380, 0.0388, 0.0366, 0.0370, 0.0380, 0.0386, 0.0347, 0.0368, 0.0341,\n",
       "                      0.0408, 0.0398, 0.0388, 0.0337, 0.0364, 0.0369, 0.0380, 0.0372, 0.0395,\n",
       "                      0.0369, 0.0361, 0.0398, 0.0372, 0.0365, 0.0372, 0.0363, 0.0355, 0.0347,\n",
       "                      0.0382, 0.0351, 0.0382, 0.0354, 0.0381, 0.0367, 0.0356, 0.0367, 0.0373,\n",
       "                      0.0388, 0.0385, 0.0349, 0.0371, 0.0335, 0.0330, 0.0383, 0.0327, 0.0363,\n",
       "                      0.0344, 0.0351, 0.0381, 0.0380, 0.0390, 0.0359, 0.0360, 0.0358, 0.0399,\n",
       "                      0.0393, 0.0390, 0.0340, 0.0382, 0.0343, 0.0364, 0.0401, 0.0375, 0.0359,\n",
       "                      0.0377, 0.0374, 0.0364, 0.0374, 0.0404, 0.0385, 0.0372, 0.0374, 0.0326,\n",
       "                      0.0364, 0.0379, 0.0372, 0.0369, 0.0368, 0.0372, 0.0379, 0.0367, 0.0338,\n",
       "                      0.0408, 0.0390, 0.0362, 0.0373, 0.0370, 0.0365, 0.0362, 0.0391, 0.0389,\n",
       "                      0.0359, 0.0368, 0.0390, 0.0399, 0.0398, 0.0386, 0.0394, 0.0349, 0.0362,\n",
       "                      0.0394, 0.0341, 0.0385, 0.0376, 0.0378, 0.0375, 0.0365, 0.0374, 0.0360,\n",
       "                      0.0372, 0.0366, 0.0382, 0.0384, 0.0378, 0.0382, 0.0388, 0.0379, 0.0388,\n",
       "                      0.0384, 0.0367, 0.0354, 0.0395, 0.0379, 0.0369, 0.0383, 0.0369, 0.0382,\n",
       "                      0.0369, 0.0349, 0.0378, 0.0387, 0.0363, 0.0378, 0.0383, 0.0396, 0.0361,\n",
       "                      0.0383, 0.0361, 0.0370, 0.0343, 0.0383, 0.0384, 0.0392, 0.0335, 0.0346,\n",
       "                      0.0384, 0.0330, 0.0386, 0.0352, 0.0355, 0.0393, 0.0371, 0.0360, 0.0376,\n",
       "                      0.0348, 0.0387, 0.0364, 0.0370, 0.0392, 0.0382, 0.0383, 0.0379, 0.0360,\n",
       "                      0.0362, 0.0353, 0.0387, 0.0382, 0.0362, 0.0372, 0.0378, 0.0389, 0.0364,\n",
       "                      0.0375, 0.0369, 0.0381, 0.0330, 0.0383, 0.0394, 0.0387, 0.0355, 0.0363,\n",
       "                      0.0338, 0.0387, 0.0388, 0.0401, 0.0379, 0.0363, 0.0353, 0.0345, 0.0295,\n",
       "                      0.0365, 0.0348, 0.0378, 0.0398, 0.0346, 0.0385, 0.0389, 0.0386, 0.0331,\n",
       "                      0.0366, 0.0363, 0.0375, 0.0367, 0.0378, 0.0363, 0.0383, 0.0359, 0.0394,\n",
       "                      0.0374, 0.0388, 0.0379, 0.0375, 0.0387, 0.0344, 0.0371, 0.0381, 0.0382,\n",
       "                      0.0361, 0.0385, 0.0388, 0.0368, 0.0384, 0.0373, 0.0392, 0.0349, 0.0350,\n",
       "                      0.0370, 0.0404, 0.0337, 0.0392, 0.0380, 0.0386, 0.0385, 0.0386, 0.0327,\n",
       "                      0.0363, 0.0328, 0.0377, 0.0322, 0.0347, 0.0383, 0.0373, 0.0370, 0.0374,\n",
       "                      0.0401, 0.0344, 0.0356, 0.0379, 0.0356, 0.0372, 0.0379, 0.0382, 0.0361,\n",
       "                      0.0379, 0.0377, 0.0380, 0.0368, 0.0364, 0.0390, 0.0374, 0.0367, 0.0384,\n",
       "                      0.0369, 0.0359, 0.0375, 0.0386, 0.0385, 0.0371, 0.0390, 0.0370, 0.0346,\n",
       "                      0.0369, 0.0353, 0.0381, 0.0365, 0.0384, 0.0386, 0.0389, 0.0316, 0.0366,\n",
       "                      0.0381, 0.0361, 0.0356, 0.0361, 0.0372, 0.0355, 0.0391, 0.0382, 0.0349,\n",
       "                      0.0372, 0.0357, 0.0372, 0.0392, 0.0366, 0.0341, 0.0361, 0.0379, 0.0367,\n",
       "                      0.0369, 0.0365, 0.0383, 0.0353, 0.0374, 0.0384, 0.0397, 0.0383, 0.0381,\n",
       "                      0.0383, 0.0377, 0.0379, 0.0369, 0.0383, 0.0382, 0.0369, 0.0364, 0.0375,\n",
       "                      0.0386, 0.0384, 0.0352, 0.0368, 0.0351, 0.0377, 0.0382, 0.0374, 0.0357,\n",
       "                      0.0363, 0.0368, 0.0383, 0.0354, 0.0387, 0.0381, 0.0365, 0.0381, 0.0358,\n",
       "                      0.0383, 0.0376, 0.0369, 0.0356, 0.0359, 0.0383, 0.0392, 0.0373, 0.0355,\n",
       "                      0.0383, 0.0336, 0.0392, 0.0369, 0.0367, 0.0386, 0.0375, 0.0380, 0.0351,\n",
       "                      0.0394, 0.0400, 0.0390, 0.0388, 0.0381, 0.0377, 0.0376, 0.0383, 0.0379,\n",
       "                      0.0363, 0.0364, 0.0360, 0.0382, 0.0372, 0.0354, 0.0382, 0.0381, 0.0373,\n",
       "                      0.0347, 0.0336, 0.0383, 0.0388, 0.0378, 0.0339, 0.0370, 0.0371, 0.0361,\n",
       "                      0.0357, 0.0341, 0.0339, 0.0352, 0.0372, 0.0362, 0.0381, 0.0401, 0.0374,\n",
       "                      0.0388, 0.0378, 0.0381, 0.0391, 0.0346, 0.0385, 0.0382, 0.0379, 0.0331,\n",
       "                      0.0390, 0.0379, 0.0366, 0.0355, 0.0366, 0.0338, 0.0342, 0.0363, 0.0383,\n",
       "                      0.0365, 0.0351, 0.0381, 0.0392, 0.0387, 0.0343, 0.0384, 0.0391])),\n",
       "             ('decoders.5.bn4.running_mean',\n",
       "              tensor([-0.3589, -0.8901, -0.8564, -0.5864, -0.4774, -0.1724, -0.5647, -0.2068,\n",
       "                      -0.7091, -0.7700, -0.9355, -0.7483, -0.8705, -0.4551, -0.6271, -0.8184,\n",
       "                      -0.8599, -0.7056, -0.3869, -0.6870, -0.7777, -0.5655, -0.5825, -0.4781,\n",
       "                      -0.6157, -0.8507, -0.6960, -0.6259, -0.9021, -0.6727, -0.6362, -0.6629,\n",
       "                      -0.6364, -0.4460, -0.4741, -0.7921, -1.1436, -0.5964, -0.6392, -0.5025,\n",
       "                      -0.8581, -0.7569, -1.1076, -0.4227, -0.5165, -0.7026, -0.6755, -0.9211,\n",
       "                      -0.6265, -0.4167, -0.5330, -0.6612, -0.8942, -0.7862, -0.5216, -0.6820,\n",
       "                      -0.7324, -0.8461, -0.7141, -0.5723, -0.7662, -0.8508, -0.7305, -0.7074,\n",
       "                      -0.3993, -0.5105, -0.5081, -0.6325, -0.6821, -0.6815, -0.6516, -0.6982,\n",
       "                      -0.8322, -0.7974, -0.5394, -0.5408, -0.4407, -0.5967, -0.6617, -0.6683,\n",
       "                      -0.7060, -0.5412, -0.7046, -0.8903, -0.5944, -0.8679, -0.7528, -0.5345,\n",
       "                      -0.3502, -0.7129, -0.4840, -0.7348, -0.5550, -0.4987, -0.7876, -0.8025,\n",
       "                      -0.8502, -0.9317, -0.4288, -0.8220, -0.8073, -0.5826, -0.6608, -0.7157,\n",
       "                      -0.5179, -0.5788, -0.6783, -0.4854, -0.6991, -0.7543, -0.6025, -0.6560,\n",
       "                      -0.3996, -0.6195, -0.6755, -0.4941, -0.5730, -0.4678, -1.1073, -1.0607,\n",
       "                      -0.2435, -0.8291, -0.7708, -0.4694, -0.5078, -1.0131, -0.7563, -0.6093,\n",
       "                      -0.4620, -0.5963, -0.8746, -0.9127, -0.3544, -0.5164, -0.8246, -0.5506,\n",
       "                      -0.5668, -0.3756, -0.8071, -0.5621, -0.6156, -0.3553, -0.4235, -0.4116,\n",
       "                      -0.4507, -0.4374, -0.6574, -0.7230, -0.6116, -0.3137, -0.6041, -0.8776,\n",
       "                      -0.7677, -0.8313, -0.7605, -0.4704, -0.9412, -0.4427, -0.6343, -0.8040,\n",
       "                      -0.4499, -0.5619, -0.8008, -0.6685, -0.3937, -0.2928, -0.7227, -0.7366,\n",
       "                      -0.7153, -0.6085, -0.7331, -0.7449, -0.5003, -0.6894, -0.7157, -0.4674,\n",
       "                      -0.6883, -0.5602, -0.6860, -0.5161, -0.6139, -0.7060, -0.9900, -0.8143,\n",
       "                      -0.4373, -0.8801, -0.5472, -0.5359, -0.8710, -0.7202, -0.6110, -1.0272,\n",
       "                      -0.7662, -0.8417, -0.8875, -0.4769, -0.4183, -0.8268, -0.7677, -0.3437,\n",
       "                      -0.7859, -0.6742, -0.5891, -0.2513, -0.9076, -0.6238, -0.6794, -0.9053,\n",
       "                      -0.5505, -0.4975, -1.0954, -0.8641, -0.8882, -0.6911, -0.4899, -0.7674,\n",
       "                      -0.5096, -0.9973, -0.5580, -0.7316, -0.3440, -0.7009, -0.8232, -0.5374,\n",
       "                      -0.7321, -0.9674, -0.5038, -0.2610, -0.5833, -0.8396, -0.6519, -0.7729,\n",
       "                      -0.8611, -0.4684, -0.4612, -0.4612, -0.5355, -0.4370, -0.7869, -0.5285,\n",
       "                      -0.4878, -0.2721, -0.4253, -0.5840, -0.3901, -0.7003, -0.4924, -0.8478,\n",
       "                      -0.8285, -0.7002, -0.7157, -0.8112, -0.2286, -0.6644, -0.8133, -0.6558,\n",
       "                      -0.5569, -0.5718, -0.7058, -0.6765, -0.8853, -0.4882, -0.4946, -0.6613,\n",
       "                      -0.7417, -0.6360, -0.8325, -0.7150, -0.6463, -0.7277, -0.6512, -0.5690,\n",
       "                      -1.0080, -0.4765, -0.6224, -0.7715, -0.9157, -0.3585, -0.5946, -0.2747,\n",
       "                      -0.7408, -0.7767, -0.6793, -0.5760, -0.2939, -0.4739, -0.4935, -0.6512,\n",
       "                      -0.3296, -0.5768, -0.8486, -0.6768, -0.7109, -0.6034, -0.8787, -0.7142,\n",
       "                      -0.3898, -0.6916, -0.9448, -1.0089, -0.7509, -0.6857, -0.8315, -0.6842,\n",
       "                      -0.4758, -0.6794, -1.0179, -0.4065, -0.9667, -0.6128, -0.8903, -0.8383,\n",
       "                      -0.5076, -0.5813, -0.7974, -0.8394, -0.6276, -0.5960, -0.6309, -0.7198,\n",
       "                      -0.6153, -1.2149, -0.4930, -0.3058, -0.6152, -0.7222, -0.6705, -0.4984,\n",
       "                      -0.5509, -0.8857, -0.6488, -0.7750, -0.4366, -1.0158, -0.3729, -0.7740,\n",
       "                      -0.7921, -0.1731, -0.8049, -0.8200, -0.5155, -0.5527, -0.6515, -0.5817,\n",
       "                      -0.6108, -0.6447, -0.5651, -0.8802, -1.0445, -0.6061, -0.5352, -0.3899,\n",
       "                      -0.5604, -0.5727, -0.3755, -1.1939, -0.5466, -0.7076, -0.5433, -0.7253,\n",
       "                      -0.9458, -0.9872, -0.7535, -0.8830, -0.7378, -0.7084, -0.4359, -0.8019,\n",
       "                      -0.4404, -0.4216, -0.3164, -0.9462, -0.8236, -0.5052, -0.9766, -0.8764,\n",
       "                      -0.5099, -0.3990, -0.5613, -0.4982, -0.5692, -0.7238, -0.9163, -0.5741,\n",
       "                      -0.4463, -0.8259, -0.5734, -0.6852, -0.3807, -0.7150, -0.6352, -0.7563,\n",
       "                      -0.4137, -0.5400, -0.5229, -0.6472, -1.0314, -0.6378, -0.5491, -0.2043,\n",
       "                      -0.5140, -0.3405, -0.8003, -0.5476, -0.5760, -0.9746, -0.3251, -0.7749,\n",
       "                      -0.5615, -0.7022, -0.5113, -0.4088, -0.9021, -0.7385, -0.5220, -0.5446,\n",
       "                      -0.4880, -0.9204, -0.7335, -0.9280, -0.7546, -0.6249, -0.5669, -0.8092,\n",
       "                      -1.0474, -0.6656, -0.6299, -0.8301, -0.6216, -1.0572, -0.7106, -0.5950,\n",
       "                      -0.6019, -0.7060, -0.6160, -0.2013, -0.4544, -0.8138, -0.5426, -0.4918,\n",
       "                      -0.4993, -0.7044, -0.4620, -0.8942, -1.0090, -0.6880, -0.8214, -0.5712,\n",
       "                      -0.8590, -0.5220, -0.6134, -0.7021, -0.5671, -0.5841, -0.7919, -0.6996,\n",
       "                      -0.7253, -0.5723, -0.6411, -0.8353, -0.7202, -0.7799, -0.7747, -0.7798,\n",
       "                      -0.4570, -0.9313, -0.7524, -0.7567, -0.5002, -0.6094, -0.9644, -0.7161,\n",
       "                      -0.3876, -0.6786, -0.7167, -0.6024, -0.3766, -0.4423, -0.6644, -0.5602,\n",
       "                      -0.4869, -0.6441, -0.6014, -0.5389, -0.8163, -0.6163, -0.7154, -0.5047,\n",
       "                      -0.6425, -0.7289, -0.3686, -0.4188, -0.7615, -0.8639, -0.5402, -0.8646,\n",
       "                      -0.5367, -0.6766, -0.4281, -0.5703, -0.4355, -0.5522, -0.7950, -0.4877,\n",
       "                      -0.0423, -0.4112, -0.7248, -0.6064, -0.4034, -0.3439, -0.5136, -0.8200])),\n",
       "             ('decoders.5.bn4.running_var',\n",
       "              tensor([1.1960, 1.6984, 4.4708, 1.0655, 4.4339, 1.2233, 3.0384, 0.8191, 5.5360,\n",
       "                      1.8979, 4.8537, 4.3891, 7.5396, 5.2799, 0.5850, 4.4084, 5.5642, 0.5024,\n",
       "                      2.3392, 5.3365, 2.4555, 5.2503, 2.6006, 0.8601, 5.0256, 0.3502, 2.6843,\n",
       "                      4.9709, 6.3210, 6.0961, 3.9522, 2.8118, 4.0175, 0.9089, 5.7490, 3.9773,\n",
       "                      6.8955, 6.6602, 8.6274, 3.0597, 3.1188, 3.6531, 2.1462, 4.3243, 0.9111,\n",
       "                      5.2492, 2.4034, 2.5313, 0.4230, 4.0744, 4.9532, 5.1879, 0.5270, 3.5708,\n",
       "                      2.7514, 0.4954, 3.2416, 3.3325, 0.4480, 1.4690, 3.6609, 7.1247, 4.7273,\n",
       "                      0.8886, 1.1296, 6.3126, 0.5887, 4.1402, 4.0278, 4.8901, 4.3882, 6.0107,\n",
       "                      6.7940, 4.5454, 3.7912, 3.6676, 4.3320, 5.1795, 3.4175, 4.3535, 4.8607,\n",
       "                      4.1199, 3.9615, 3.8716, 2.8429, 4.2416, 2.5790, 2.4960, 0.6217, 4.8632,\n",
       "                      0.8164, 2.9367, 6.0903, 1.0940, 4.7862, 2.9515, 3.8159, 2.1554, 0.8113,\n",
       "                      4.0510, 5.5488, 5.6063, 3.6546, 3.0672, 5.9524, 0.8438, 4.8970, 0.7697,\n",
       "                      2.2245, 2.5408, 2.6080, 0.8044, 5.1333, 6.2080, 2.7765, 3.4724, 3.0609,\n",
       "                      5.3864, 6.3151, 4.0708, 5.2236, 4.2837, 4.4197, 4.6191, 0.7009, 0.2037,\n",
       "                      2.4675, 1.0264, 4.1726, 0.8912, 3.0386, 4.9272, 0.6741, 0.8479, 5.9151,\n",
       "                      4.2794, 3.5809, 0.7629, 2.1947, 1.4841, 2.1447, 3.9314, 0.7487, 6.2072,\n",
       "                      0.6586, 0.9377, 2.3488, 4.0827, 4.1974, 0.7960, 0.5311, 5.3123, 2.0091,\n",
       "                      4.0379, 2.5647, 0.8019, 2.9363, 0.8632, 4.4055, 2.5764, 5.2766, 0.6404,\n",
       "                      5.0547, 4.3547, 0.9847, 3.4558, 1.8742, 2.1936, 2.4502, 4.5295, 0.3409,\n",
       "                      5.7891, 2.9654, 2.9462, 5.4339, 5.3487, 2.4860, 3.4682, 4.5500, 1.2254,\n",
       "                      2.9868, 3.6947, 6.8575, 3.3021, 5.5914, 5.0258, 1.0541, 2.3228, 3.2844,\n",
       "                      3.5611, 6.2324, 2.4411, 3.2020, 5.2065, 3.6597, 3.6593, 0.8556, 3.0199,\n",
       "                      2.9251, 0.7918, 4.0303, 4.7447, 3.6711, 5.1412, 5.9573, 3.3807, 6.5068,\n",
       "                      3.1461, 2.8277, 4.6586, 3.7576, 3.7566, 3.5211, 3.9155, 4.0175, 4.3345,\n",
       "                      3.3934, 3.6961, 0.6994, 3.7737, 5.2622, 5.6584, 2.1327, 3.1611, 3.9014,\n",
       "                      4.0449, 8.0276, 6.6689, 3.5515, 2.7110, 4.6713, 2.8876, 2.8079, 5.3982,\n",
       "                      2.2089, 4.5165, 2.7526, 0.5100, 2.3671, 4.4403, 1.8459, 0.7004, 1.4745,\n",
       "                      2.3822, 0.7798, 4.8082, 6.3643, 2.4335, 2.4430, 5.5905, 0.7810, 2.7541,\n",
       "                      0.8764, 4.5139, 5.7757, 4.4751, 3.9548, 3.8738, 2.2813, 5.2267, 0.3991,\n",
       "                      5.6429, 0.5910, 4.0491, 3.9821, 3.9834, 2.5056, 6.0568, 4.0835, 4.8153,\n",
       "                      4.2546, 3.8952, 4.8781, 0.8181, 2.9391, 3.6116, 3.0726, 0.7363, 0.7403,\n",
       "                      0.8207, 2.4504, 4.3180, 2.2729, 3.1390, 1.4182, 0.9331, 1.3273, 1.1256,\n",
       "                      0.9257, 1.0201, 7.2335, 3.9815, 0.8775, 3.5897, 2.7030, 2.2929, 0.8402,\n",
       "                      0.6092, 3.9943, 3.9289, 3.3047, 8.7387, 5.3204, 5.2857, 0.7677, 3.2104,\n",
       "                      5.5302, 3.2605, 5.0883, 3.4190, 2.7373, 0.6944, 0.4526, 3.0511, 7.6620,\n",
       "                      2.8229, 3.7704, 5.1452, 2.6494, 5.5683, 5.9700, 4.3724, 0.7771, 1.0088,\n",
       "                      2.7169, 2.6010, 0.6350, 4.0980, 3.3707, 3.1305, 4.5478, 1.4810, 0.7027,\n",
       "                      6.8888, 0.5345, 3.5754, 0.8299, 1.0107, 5.2409, 4.6972, 4.5758, 4.1971,\n",
       "                      2.9297, 0.6658, 6.1454, 6.5804, 5.7480, 2.4814, 2.4535, 3.3732, 3.0916,\n",
       "                      3.0402, 1.2643, 5.3823, 4.2610, 4.6944, 1.6836, 4.7793, 4.5889, 3.2163,\n",
       "                      5.9111, 4.3782, 3.0544, 2.2235, 5.0257, 0.4344, 4.5260, 4.8764, 0.7696,\n",
       "                      2.5719, 0.8296, 6.7985, 4.4736, 2.6528, 2.0259, 4.5110, 2.2372, 6.3865,\n",
       "                      3.6830, 0.9951, 0.6921, 3.6517, 2.9854, 0.7748, 0.7202, 2.4355, 3.0245,\n",
       "                      6.6270, 0.5573, 3.4927, 2.9045, 5.1168, 1.2338, 4.3918, 4.2739, 2.7422,\n",
       "                      3.0130, 3.4315, 6.2001, 3.2559, 4.6436, 3.3810, 2.8618, 3.7482, 4.3051,\n",
       "                      3.1087, 6.4667, 3.2011, 2.6114, 2.9194, 3.2596, 4.7183, 3.9766, 3.6340,\n",
       "                      4.9268, 3.6481, 0.9178, 4.5390, 5.1362, 3.6405, 1.3083, 5.4120, 1.8954,\n",
       "                      4.3444, 2.8350, 4.9727, 0.9085, 1.9665, 3.0286, 4.6239, 6.1183, 0.7915,\n",
       "                      3.4410, 5.3791, 4.3924, 2.5143, 4.7957, 4.7850, 4.8526, 2.8123, 1.3996,\n",
       "                      1.1142, 0.7962, 2.1469, 4.4194, 3.9571, 4.3546, 7.2785, 5.6683, 0.8541,\n",
       "                      3.9453, 3.2235, 2.9107, 4.2097, 5.3499, 4.4759, 4.8848, 1.9272, 4.0195,\n",
       "                      3.3608, 6.0279, 5.1094, 4.7809, 4.7329, 0.9170, 3.6492, 3.0386, 5.2397,\n",
       "                      0.9346, 0.7643, 4.1181, 4.6479, 3.2787, 1.1804, 0.6366, 6.9365, 4.4146,\n",
       "                      0.6639, 0.9365, 0.8660, 0.5255, 3.7680, 5.5705, 4.0717, 2.6497, 3.5197,\n",
       "                      5.0149, 3.4625, 1.9626, 2.4749, 2.0936, 4.8350, 2.4205, 2.0797, 0.7988,\n",
       "                      3.6405, 2.9889, 5.6436, 0.8913, 0.9387, 0.7825, 1.0790, 5.0647, 2.3339,\n",
       "                      3.3377, 0.9374, 4.4883, 5.1793, 4.6754, 0.7185, 3.6568, 5.6126])),\n",
       "             ('decoders.5.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.5.dense5.weight',\n",
       "              tensor([[-0.0337,  0.0168, -0.0241,  ..., -0.0072, -0.0071, -0.0253],\n",
       "                      [-0.0605,  0.0075, -0.0644,  ...,  0.0023,  0.0127, -0.0262],\n",
       "                      [-0.0027,  0.0108, -0.0709,  ..., -0.0012,  0.0029, -0.0171],\n",
       "                      ...,\n",
       "                      [-0.0298, -0.0623,  0.0125,  ..., -0.0022, -0.0256,  0.0085],\n",
       "                      [-0.0147, -0.0490, -0.0108,  ..., -0.0206, -0.0130,  0.0115],\n",
       "                      [-0.0608, -0.0264,  0.0093,  ..., -0.0258, -0.0175,  0.0169]])),\n",
       "             ('decoders.5.dense5.bias',\n",
       "              tensor([ 0.0203, -0.0353,  0.0180,  ..., -0.0606, -0.0160, -0.0544])),\n",
       "             ('decoders.6.dense1.weight',\n",
       "              tensor([[-0.0896, -0.0476, -0.0867,  ..., -0.0551, -0.0217,  0.1698],\n",
       "                      [-0.0963,  0.0602, -0.1232,  ..., -0.0127,  0.0415, -0.0727],\n",
       "                      [ 0.0062,  0.0664,  0.1529,  ...,  0.0652, -0.0324, -0.0809],\n",
       "                      ...,\n",
       "                      [-0.0203,  0.0691,  0.0448,  ...,  0.0861, -0.1506, -0.1250],\n",
       "                      [-0.0372,  0.0070,  0.0927,  ...,  0.0660, -0.0326,  0.0605],\n",
       "                      [-0.0424,  0.1506,  0.0778,  ..., -0.1601, -0.0584,  0.1519]])),\n",
       "             ('decoders.6.bn1.weight',\n",
       "              tensor([0.9922, 0.9802, 1.0253, 1.0171, 0.9937, 1.0016, 0.9957, 0.9988, 0.9930,\n",
       "                      0.9861, 0.9922, 1.0144, 0.9806, 1.0039, 1.0085, 1.0048, 0.9936, 1.0126,\n",
       "                      1.0077, 1.0063, 0.9996, 0.9905, 1.0010, 0.9870, 0.9814, 0.9975, 0.9945,\n",
       "                      1.0031, 1.0160, 0.9973, 0.9936, 1.0106, 1.0178, 1.0071, 0.9997, 0.9842,\n",
       "                      1.0043, 0.9999, 0.9964, 1.0180, 1.0014, 0.9924, 1.0010, 0.9976, 1.0142,\n",
       "                      1.0087, 0.9861, 0.9891, 1.0111, 1.0014, 1.0259, 0.9977, 0.9852, 1.0074,\n",
       "                      0.9888, 1.0067, 1.0034, 1.0107, 1.0052, 1.0003, 1.0224, 0.9848, 0.9948,\n",
       "                      0.9979, 0.9914, 0.9943, 0.9980, 0.9923, 0.9976, 0.9981, 0.9924, 0.9959,\n",
       "                      0.9942, 0.9816, 0.9946, 1.0013, 1.0125, 1.0185, 1.0090, 0.9857, 0.9885,\n",
       "                      0.9857, 1.0101, 0.9885, 0.9947, 0.9908, 0.9952, 0.9994, 1.0009, 0.9823,\n",
       "                      0.9924, 0.9813, 1.0044, 0.9791, 0.9949, 1.0003, 0.9898, 1.0173, 1.0163,\n",
       "                      1.0019, 0.9996, 1.0024, 0.9784, 0.9945, 0.9940, 1.0200, 0.9945, 0.9905,\n",
       "                      0.9942, 1.0179, 0.9974, 1.0106, 1.0007, 0.9849, 1.0068, 1.0104, 0.9800,\n",
       "                      0.9916, 1.0158, 0.9907, 1.0036, 1.0051, 1.0034, 1.0087, 0.9900, 0.9876,\n",
       "                      0.9875, 1.0033])),\n",
       "             ('decoders.6.bn1.bias',\n",
       "              tensor([-6.9972e-03, -1.2460e-02,  1.2619e-02,  1.2896e-02,  1.1401e-02,\n",
       "                       1.0749e-02,  6.5013e-03, -1.8387e-03,  2.0223e-03, -1.0019e-02,\n",
       "                      -9.5583e-04,  1.4859e-02, -1.6463e-02,  9.6902e-03,  1.5387e-02,\n",
       "                       1.8527e-02, -3.4248e-03,  2.5857e-02,  3.4369e-02,  2.5799e-02,\n",
       "                       4.0477e-03, -9.8343e-04,  8.7197e-03, -8.4082e-03, -1.2294e-02,\n",
       "                       4.0495e-03,  1.8619e-02, -9.4744e-03,  4.2683e-02,  1.2637e-02,\n",
       "                      -3.4202e-03,  4.3439e-02,  3.0532e-02, -4.9818e-03, -9.5131e-03,\n",
       "                      -6.8471e-03,  8.4685e-03,  2.5733e-02,  2.8000e-03,  8.0694e-03,\n",
       "                       6.0689e-03, -3.8411e-04,  4.4817e-03, -1.6896e-03,  3.8348e-02,\n",
       "                       2.4010e-02, -4.2488e-03, -7.8640e-03,  9.0023e-03,  4.3928e-03,\n",
       "                       1.4231e-02,  5.6409e-04, -2.3144e-03,  2.6281e-02, -1.5287e-02,\n",
       "                       8.9641e-03,  7.2260e-03,  3.4323e-02,  1.0499e-02,  1.8024e-03,\n",
       "                       4.0056e-02, -8.0095e-03,  7.9997e-03, -1.0922e-03, -5.4340e-04,\n",
       "                      -9.1518e-03,  4.9645e-03,  3.3363e-03,  1.1901e-02, -7.9100e-05,\n",
       "                       9.8547e-03,  5.7732e-03, -2.7155e-03, -2.2770e-02, -1.3506e-02,\n",
       "                       8.2005e-03,  1.3547e-02,  2.6020e-02,  4.1578e-02, -7.0411e-03,\n",
       "                      -1.1274e-02, -1.4338e-02,  1.8237e-02, -3.9569e-03, -4.3512e-03,\n",
       "                      -6.7722e-03,  1.3661e-02,  1.0101e-02,  1.8528e-02, -9.0878e-03,\n",
       "                      -4.0110e-03, -1.7230e-02,  2.1506e-04, -1.2310e-02,  4.5894e-03,\n",
       "                       1.7454e-04,  4.1036e-03,  9.6217e-03,  3.2867e-02, -6.3338e-03,\n",
       "                       3.1361e-03,  1.9017e-02, -1.3410e-02,  6.3816e-03, -1.9469e-03,\n",
       "                       9.0224e-03, -3.9248e-03, -2.4466e-05,  1.0938e-03,  1.0625e-02,\n",
       "                      -1.0275e-02,  2.0226e-02,  1.7912e-02, -1.4481e-02,  1.6139e-02,\n",
       "                      -2.6075e-03,  9.1757e-04, -8.5159e-03,  2.4548e-02, -1.0259e-02,\n",
       "                       2.1811e-02,  1.9329e-02,  2.0462e-02,  1.6562e-03,  3.1635e-03,\n",
       "                      -1.4109e-02, -1.1745e-02,  1.4368e-02])),\n",
       "             ('decoders.6.bn1.running_mean',\n",
       "              tensor([ 0.0564, -0.0108,  0.5532,  0.6953, -0.3203, -0.6656, -0.2709,  0.3795,\n",
       "                      -0.0591,  0.1943, -0.3390,  0.4222,  0.0768,  0.1551,  0.3565, -0.3464,\n",
       "                       0.2480, -0.3099, -0.5419,  0.4232, -0.0498, -0.1033, -0.3858,  0.5614,\n",
       "                      -0.0786,  0.0534, -0.3234,  0.3826, -0.6419, -0.2666,  0.2315, -0.5871,\n",
       "                      -0.4952,  0.4176, -0.1734, -0.0815,  0.2917, -0.5276, -0.1314,  0.8093,\n",
       "                       0.2410,  0.4810,  0.2240,  0.1327, -0.3334,  0.4027, -0.1438,  0.2831,\n",
       "                       0.3190,  0.3030,  0.8383, -0.3494, -0.0733,  0.4454,  0.3178,  0.4678,\n",
       "                      -0.1281, -0.3839,  0.3802,  0.2750, -0.4265,  0.0498, -0.3331,  0.3593,\n",
       "                       0.2668, -0.0515,  0.0058, -0.2894, -0.2361,  0.1891, -0.3406, -0.3424,\n",
       "                      -0.4990, -0.1429,  0.3056,  0.2495,  0.5010, -0.5666, -0.4793,  0.3064,\n",
       "                       0.0472,  0.1816,  0.4132,  0.0597,  0.2813,  0.3288, -0.3894, -0.1399,\n",
       "                      -0.3546, -0.0507,  0.1644,  0.0595,  0.4825, -0.3693, -0.0140,  0.6326,\n",
       "                       0.2526,  0.6315, -0.4412,  0.3486,  0.3835, -0.3120, -0.2831, -0.2826,\n",
       "                       0.1341,  0.6434,  0.3576, -0.2845,  0.1642,  0.3097,  0.3550, -0.5823,\n",
       "                      -0.2403,  0.3796, -0.6098,  0.5252, -0.1608,  0.0155, -0.2010, -0.1258,\n",
       "                      -0.3024,  0.5303, -0.2525,  0.5107,  0.3733,  0.3091,  0.0980, -0.3812])),\n",
       "             ('decoders.6.bn1.running_var',\n",
       "              tensor([0.0943, 0.1208, 0.8761, 1.1189, 0.3093, 0.8541, 0.2123, 0.2349, 0.1222,\n",
       "                      0.1937, 0.2877, 0.3407, 0.1353, 0.1632, 0.5467, 0.6225, 0.2746, 0.3587,\n",
       "                      0.6778, 0.4500, 0.1571, 0.1453, 0.3196, 0.7020, 0.2019, 0.1542, 0.2564,\n",
       "                      0.3179, 0.9547, 0.3171, 0.2301, 0.6332, 0.6261, 0.7184, 0.1434, 0.0950,\n",
       "                      0.3217, 0.4499, 0.1099, 1.4151, 0.2149, 0.3780, 0.1060, 0.1691, 0.4842,\n",
       "                      0.4118, 0.1212, 0.2207, 0.2759, 0.2808, 1.2907, 0.3539, 0.1426, 0.5239,\n",
       "                      0.2570, 0.4923, 0.2030, 0.3216, 0.3385, 0.2449, 0.4901, 0.1429, 0.4598,\n",
       "                      0.3860, 0.3961, 0.1438, 0.1359, 0.2549, 0.1679, 0.1100, 0.3537, 0.2506,\n",
       "                      0.3353, 0.1233, 0.3999, 0.3041, 0.4348, 0.5562, 0.6094, 0.3827, 0.1587,\n",
       "                      0.1059, 0.4251, 0.1479, 0.1625, 0.1792, 0.4699, 0.1399, 0.3607, 0.1005,\n",
       "                      0.2523, 0.1619, 0.8073, 0.2323, 0.1113, 0.8593, 0.1938, 0.9650, 0.4407,\n",
       "                      0.4680, 0.3330, 0.3209, 0.2464, 0.4799, 0.1111, 0.7294, 0.2369, 0.3068,\n",
       "                      0.1315, 0.3982, 0.4250, 0.4189, 0.2881, 0.2648, 0.9051, 0.9457, 0.1487,\n",
       "                      0.1255, 0.3410, 0.1094, 0.3596, 0.5931, 0.2541, 0.6299, 0.3722, 0.3068,\n",
       "                      0.1152, 0.4397])),\n",
       "             ('decoders.6.bn1.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense2.weight',\n",
       "              tensor([[ 0.0547,  0.0526, -0.0547,  ...,  0.0298,  0.0100, -0.0508],\n",
       "                      [ 0.0641,  0.0639,  0.0574,  ..., -0.0043,  0.0318, -0.0712],\n",
       "                      [-0.0824, -0.0373,  0.0756,  ...,  0.0167, -0.0638, -0.0284],\n",
       "                      ...,\n",
       "                      [-0.0337, -0.0759,  0.0848,  ...,  0.0904,  0.0263,  0.0142],\n",
       "                      [-0.0274,  0.0493, -0.0347,  ..., -0.0441, -0.0533, -0.0287],\n",
       "                      [-0.0288,  0.0676, -0.0647,  ..., -0.0804,  0.0754,  0.0822]])),\n",
       "             ('decoders.6.bn2.weight',\n",
       "              tensor([1.0038, 0.9891, 1.0125, 0.9986, 0.9970, 1.0193, 0.9913, 0.9976, 0.9932,\n",
       "                      0.9931, 0.9999, 0.9939, 0.9996, 1.0060, 1.0143, 0.9992, 0.9912, 0.9896,\n",
       "                      1.0115, 0.9903, 1.0030, 0.9843, 0.9983, 0.9862, 1.0126, 0.9817, 1.0091,\n",
       "                      0.9995, 1.0185, 1.0068, 0.9985, 1.0192, 1.0155, 1.0083, 1.0015, 0.9885,\n",
       "                      0.9960, 1.0162, 0.9883, 1.0018, 1.0069, 1.0043, 1.0114, 1.0234, 0.9970,\n",
       "                      0.9886, 0.9973, 0.9935, 1.0021, 1.0057, 1.0046, 0.9962, 0.9895, 0.9954,\n",
       "                      0.9886, 0.9988, 1.0005, 0.9935, 1.0092, 0.9916, 0.9987, 0.9991, 0.9987,\n",
       "                      1.0072, 0.9999, 1.0036, 1.0061, 1.0174, 0.9923, 1.0176, 1.0042, 0.9913,\n",
       "                      1.0146, 1.0099, 0.9922, 0.9902, 0.9899, 0.9868, 0.9987, 1.0114, 1.0016,\n",
       "                      0.9926, 0.9960, 1.0054, 0.9940, 0.9760, 1.0126, 0.9924, 1.0114, 0.9920,\n",
       "                      0.9957, 1.0087, 1.0200, 1.0170, 0.9923, 1.0051, 1.0029, 1.0023, 1.0119,\n",
       "                      1.0083, 0.9860, 1.0011, 1.0106, 1.0071, 0.9941, 0.9965, 1.0124, 0.9934,\n",
       "                      1.0063, 1.0046, 1.0104, 0.9910, 0.9817, 1.0010, 0.9906, 0.9879, 0.9799,\n",
       "                      0.9989, 0.9990, 1.0013, 0.9951, 0.9999, 1.0013, 0.9982, 1.0080, 1.0069,\n",
       "                      0.9908, 1.0079, 0.9847, 0.9968, 0.9912, 0.9867, 1.0085, 1.0127, 0.9852,\n",
       "                      0.9843, 1.0234, 1.0060, 0.9929, 1.0012, 0.9956, 1.0067, 0.9878, 0.9876,\n",
       "                      0.9898, 1.0037, 1.0103, 1.0045, 1.0067, 0.9950, 0.9913, 0.9958, 1.0013,\n",
       "                      1.0015, 0.9917, 0.9820, 1.0022, 0.9868, 1.0016, 1.0041, 0.9915, 0.9892,\n",
       "                      1.0049, 1.0186, 0.9973, 0.9957, 0.9924, 1.0013, 1.0097, 0.9955, 1.0148,\n",
       "                      0.9907, 1.0128, 0.9847, 0.9965, 0.9864, 0.9972, 0.9955, 0.9992, 1.0064,\n",
       "                      1.0050, 1.0076, 1.0261, 0.9906, 0.9937, 1.0036, 0.9920, 0.9817, 1.0016,\n",
       "                      0.9977, 1.0125, 1.0060, 0.9940, 0.9839, 0.9968, 1.0124, 0.9988, 0.9822,\n",
       "                      1.0112, 1.0148, 1.0037, 0.9847, 0.9926, 1.0041, 0.9985, 0.9874, 0.9931,\n",
       "                      0.9799, 0.9957, 1.0148, 0.9801, 1.0054, 1.0136, 1.0114, 1.0009, 1.0251,\n",
       "                      0.9927, 1.0080, 1.0069, 0.9912, 1.0202, 0.9915, 1.0066, 0.9962, 1.0204,\n",
       "                      0.9906, 0.9928, 1.0164, 1.0087, 1.0113, 0.9983, 1.0190, 0.9859, 0.9976,\n",
       "                      0.9963, 0.9902, 0.9991, 1.0060, 1.0034, 1.0109, 0.9990, 1.0059, 1.0161,\n",
       "                      0.9970, 0.9980, 0.9817, 0.9905, 1.0010, 0.9918, 1.0123, 0.9957, 0.9806,\n",
       "                      0.9953, 1.0071, 0.9949, 1.0006])),\n",
       "             ('decoders.6.bn2.bias',\n",
       "              tensor([-5.8641e-03,  3.3090e-03,  4.7800e-02,  2.6945e-02,  2.9807e-03,\n",
       "                       9.5617e-03,  1.8479e-03, -6.6461e-03, -8.9970e-03,  1.7983e-02,\n",
       "                       1.1743e-02, -1.0491e-02,  5.1348e-03,  6.5420e-03,  1.8193e-02,\n",
       "                       7.0628e-03, -7.1738e-03, -6.1123e-03,  2.5412e-02, -4.7322e-03,\n",
       "                      -1.3640e-02, -7.9166e-03,  4.7239e-03, -6.6805e-05,  9.4390e-03,\n",
       "                      -6.6271e-03,  4.1035e-02,  1.1783e-02,  9.8556e-03,  7.7483e-03,\n",
       "                       8.5267e-03,  5.8312e-02,  4.7761e-02,  3.7987e-02,  2.2549e-02,\n",
       "                      -2.4928e-04, -1.0945e-02, -2.0935e-03, -3.2148e-03,  1.2059e-02,\n",
       "                       2.9258e-02,  7.7145e-03,  1.7263e-02,  4.7465e-02,  9.5437e-03,\n",
       "                      -4.0651e-04,  4.2154e-04,  1.9324e-02,  2.1147e-03,  1.0153e-02,\n",
       "                       4.3343e-03,  1.3351e-02, -7.0149e-03,  1.9847e-02,  1.6547e-03,\n",
       "                       1.7264e-02,  9.4775e-03,  1.0479e-02,  9.2263e-03, -4.6694e-04,\n",
       "                       3.0017e-02,  1.4990e-02,  2.6100e-02,  1.3780e-02, -1.0332e-03,\n",
       "                       9.2831e-03,  3.2152e-02,  3.8481e-02, -9.1967e-04,  2.7309e-02,\n",
       "                       3.1329e-02,  6.0593e-03,  1.4275e-02,  1.4730e-02,  1.7524e-02,\n",
       "                      -1.0107e-02, -1.5921e-02, -1.6085e-02,  1.3666e-02,  6.4490e-03,\n",
       "                      -4.4776e-03, -9.3687e-04, -8.2482e-03,  1.3206e-02,  1.9260e-02,\n",
       "                       5.7666e-04,  1.4560e-02,  8.7541e-03,  4.8856e-03, -1.0306e-02,\n",
       "                      -2.3143e-03,  1.0211e-02,  3.7987e-02,  3.3994e-02,  5.0202e-03,\n",
       "                       8.7524e-03,  6.7773e-03, -6.1439e-03,  2.8842e-02,  2.1397e-02,\n",
       "                       2.0345e-03,  3.2876e-03,  1.8190e-03, -3.1645e-03, -4.3482e-03,\n",
       "                       6.4592e-04,  4.9475e-02,  3.1002e-03,  1.4097e-02,  1.0555e-02,\n",
       "                       2.7932e-03, -6.6506e-03, -6.2422e-03,  2.2189e-03, -6.0068e-03,\n",
       "                      -4.6228e-03, -1.5638e-02,  1.6381e-02,  1.1043e-02,  2.4103e-03,\n",
       "                      -6.7255e-03, -6.2148e-03, -1.3803e-03,  1.5134e-02,  3.5630e-02,\n",
       "                       1.4268e-02, -5.2185e-03,  3.3266e-02, -1.1691e-03,  8.4996e-03,\n",
       "                       1.9098e-02, -2.1746e-03, -4.9355e-03,  1.1477e-02, -1.0119e-03,\n",
       "                      -4.9528e-03,  2.2283e-02,  1.3622e-02,  7.6015e-03,  1.3179e-02,\n",
       "                       2.5247e-02,  4.1472e-04,  4.5289e-03,  1.0429e-02,  9.8865e-04,\n",
       "                       3.1905e-02,  3.6258e-02,  2.5389e-02,  2.5949e-02, -2.3238e-03,\n",
       "                       3.0071e-02,  3.5987e-03,  6.7134e-03, -7.7167e-04,  2.4301e-02,\n",
       "                      -3.6124e-03,  2.8536e-03, -1.1201e-02,  1.5746e-02,  4.5347e-02,\n",
       "                       9.6194e-03,  2.0577e-02,  4.4640e-03,  1.2508e-02,  5.7593e-03,\n",
       "                      -1.3098e-03, -1.0520e-02,  1.4309e-02, -4.4707e-03, -2.8652e-03,\n",
       "                       2.6279e-02,  3.3302e-03,  9.4506e-03, -1.3057e-02, -1.0026e-02,\n",
       "                       8.6777e-03, -2.4836e-03,  1.0557e-02, -9.2480e-04,  1.7341e-02,\n",
       "                      -1.4135e-03,  1.9755e-02,  4.5010e-02, -5.5194e-03, -7.6132e-03,\n",
       "                      -4.2782e-03, -8.5192e-03, -1.2298e-02,  8.1296e-03, -1.9381e-03,\n",
       "                       3.3745e-02,  3.6336e-03,  1.5054e-02,  8.0382e-04,  8.4595e-03,\n",
       "                       4.2455e-02,  5.7673e-03, -5.0771e-03, -2.9527e-03,  6.0388e-03,\n",
       "                      -9.9429e-03, -1.6106e-02, -9.1915e-04,  1.6084e-02,  7.0224e-03,\n",
       "                      -1.2263e-02, -5.0987e-03, -1.3316e-02, -4.4709e-03,  2.6701e-02,\n",
       "                      -1.5128e-02, -2.6305e-03,  1.0665e-02, -7.7519e-04, -6.7848e-03,\n",
       "                       3.4332e-02, -4.6206e-03, -7.2670e-03,  1.5096e-02,  1.2672e-02,\n",
       "                       2.0616e-02,  1.1299e-02,  1.5615e-02, -6.0911e-03,  3.7678e-02,\n",
       "                       9.8605e-03, -9.0034e-03,  1.6748e-02,  6.0975e-04, -3.4674e-04,\n",
       "                       4.5569e-03,  7.7495e-03, -1.1187e-02,  1.8155e-03,  1.1098e-03,\n",
       "                      -4.0981e-03, -7.6153e-03,  1.2213e-02,  4.2720e-02,  2.3135e-03,\n",
       "                      -9.3240e-03,  4.8775e-04, -1.4795e-04, -9.2004e-04, -3.2848e-03,\n",
       "                      -1.6164e-02,  1.1491e-04, -2.6339e-03, -9.3347e-03,  1.0011e-02,\n",
       "                       3.9520e-03, -6.7999e-03,  3.1553e-03,  1.0447e-02,  1.9001e-02,\n",
       "                       8.3472e-03])),\n",
       "             ('decoders.6.bn2.running_mean',\n",
       "              tensor([ 0.3520, -0.1259, -0.0092, -0.0398,  0.2320,  0.3131,  0.2526,  0.4282,\n",
       "                       0.1214, -0.1597, -0.0080,  0.1438,  0.0534,  0.0391,  0.1794,  0.0319,\n",
       "                      -0.0780, -0.1221,  0.0297, -0.0936,  0.1041, -0.0792, -0.2186,  0.1605,\n",
       "                       0.0177, -0.3066, -0.1248, -0.3061,  0.0225, -0.1310, -0.0048,  0.1791,\n",
       "                       0.0253, -0.1288, -0.1171, -0.1668,  0.0865,  0.1429,  0.1319,  0.0138,\n",
       "                       0.2223,  0.1844, -0.2883, -0.1281,  0.2058, -0.2402, -0.2284, -0.1506,\n",
       "                       0.0436,  0.1631,  0.0314,  0.0673, -0.0721,  0.3066, -0.0891, -0.2245,\n",
       "                      -0.1869,  0.1438,  0.0361,  0.2293,  0.0420,  0.0987, -0.3723,  0.2202,\n",
       "                       0.2403,  0.0396, -0.1199, -0.2611, -0.0230,  0.1449, -0.1102, -0.2761,\n",
       "                      -0.2809,  0.0456, -0.3346,  0.2731, -0.1621, -0.0634, -0.0827, -0.0128,\n",
       "                       0.4068,  0.1838,  0.1793, -0.4898, -0.0164, -0.1705, -0.3660,  0.0922,\n",
       "                       0.1679,  0.0736, -0.0276, -0.0838, -0.2547, -0.0488,  0.0292,  0.0783,\n",
       "                       0.2561,  0.2384, -0.3462, -0.1226, -0.0293, -0.0023,  0.1646,  0.0862,\n",
       "                       0.2375, -0.1335,  0.4066, -0.2639,  0.2504,  0.0844,  0.2540,  0.0428,\n",
       "                      -0.2426, -0.1731,  0.1554, -0.2720, -0.0646,  0.1306, -0.2064,  0.0097,\n",
       "                      -0.2804, -0.0655,  0.2567,  0.1189, -0.1314,  0.1062,  0.1195,  0.2717,\n",
       "                       0.3503, -0.1790,  0.1904,  0.0073,  0.3501, -0.1181, -0.0425, -0.1451,\n",
       "                      -0.2113,  0.0711,  0.1297, -0.3485, -0.0179,  0.0816,  0.0890, -0.2169,\n",
       "                      -0.0631, -0.2073, -0.1027, -0.2577, -0.4091, -0.0166,  0.0161,  0.0924,\n",
       "                      -0.1269, -0.4430, -0.1151, -0.2168, -0.0199,  0.3784,  0.0942, -0.0487,\n",
       "                      -0.1823, -0.1079,  0.1485, -0.0150, -0.4060, -0.3489,  0.3339, -0.4942,\n",
       "                       0.4473,  0.0051, -0.3062, -0.0935,  0.3666, -0.1141, -0.1109, -0.4804,\n",
       "                      -0.1348,  0.2315, -0.0799, -0.0268, -0.1439, -0.0245, -0.3343,  0.0113,\n",
       "                      -0.0415,  0.3302,  0.1194, -0.0103, -0.0606,  0.3270, -0.1932,  0.0905,\n",
       "                      -0.0509, -0.0458,  0.1419, -0.0913, -0.1233, -0.1113,  0.0975, -0.5957,\n",
       "                       0.0578,  0.0880, -0.0448, -0.5009,  0.3016, -0.1141,  0.1543, -0.2219,\n",
       "                       0.0484, -0.4522,  0.1523, -0.0310, -0.1504,  0.0589,  0.0698, -0.5967,\n",
       "                      -0.3972,  0.2216, -0.0961, -0.1254,  0.2037,  0.0303,  0.0254, -0.1697,\n",
       "                      -0.4283, -0.1914,  0.4120,  0.3001, -0.0821,  0.3544, -0.2538,  0.2990,\n",
       "                      -0.1349,  0.0691,  0.1318,  0.1955,  0.1976,  0.2068, -0.1133,  0.1951,\n",
       "                       0.5811,  0.1218,  0.1209, -0.0443,  0.1532,  0.2039,  0.0128,  0.0684,\n",
       "                      -0.2083,  0.2643,  0.0596,  0.0626, -0.0574, -0.0398, -0.0501, -0.2694])),\n",
       "             ('decoders.6.bn2.running_var',\n",
       "              tensor([0.5355, 0.2712, 0.4344, 0.5249, 0.1970, 1.0458, 0.4722, 0.1679, 0.3022,\n",
       "                      0.2638, 0.1749, 0.2325, 0.3478, 0.4224, 0.7445, 0.2166, 0.5561, 0.2091,\n",
       "                      0.4583, 0.3218, 0.3263, 0.2367, 0.1685, 0.3455, 0.2086, 0.0974, 0.5783,\n",
       "                      0.4816, 0.6996, 0.4531, 0.1656, 0.6893, 0.3316, 1.2324, 0.3922, 0.3892,\n",
       "                      0.0954, 0.8077, 0.1966, 0.1719, 0.8797, 0.3860, 0.1552, 0.6604, 0.3762,\n",
       "                      0.2356, 0.2321, 0.8571, 0.2454, 0.3075, 0.5703, 0.2079, 0.1130, 0.5135,\n",
       "                      0.3201, 0.2979, 0.1048, 0.5026, 0.6387, 0.5042, 0.4055, 0.4775, 0.3341,\n",
       "                      0.6012, 0.2557, 0.1046, 0.3447, 0.6036, 0.1375, 0.2661, 0.5379, 0.1488,\n",
       "                      0.1790, 0.4567, 0.4044, 0.1070, 0.1350, 0.2555, 0.3450, 0.5032, 0.1331,\n",
       "                      0.2091, 0.1116, 0.2384, 0.3090, 0.2933, 0.3495, 0.1996, 0.6255, 0.3823,\n",
       "                      0.1464, 0.8389, 0.5484, 0.5942, 0.4686, 0.2801, 0.2056, 0.2539, 0.4272,\n",
       "                      0.2015, 0.3096, 0.3268, 1.1502, 0.8129, 0.2309, 0.3019, 0.4903, 0.1137,\n",
       "                      0.2905, 0.3853, 0.2510, 0.2782, 0.5963, 0.1187, 0.1855, 0.1424, 0.0949,\n",
       "                      0.4881, 0.0998, 0.3057, 0.1182, 0.2320, 0.1348, 0.3119, 0.4058, 0.5278,\n",
       "                      0.2902, 0.3699, 0.1643, 0.2865, 0.4882, 0.3125, 1.0010, 0.7074, 0.4987,\n",
       "                      0.1689, 1.0335, 0.2765, 0.2999, 0.2475, 0.3180, 1.0229, 0.2503, 0.3149,\n",
       "                      0.2511, 0.6387, 0.5462, 0.3838, 0.3385, 0.4382, 0.7988, 0.3138, 0.8947,\n",
       "                      0.1094, 0.3908, 0.2440, 0.2572, 0.1346, 0.3835, 0.4468, 0.4041, 0.4586,\n",
       "                      0.3380, 0.9876, 0.2163, 0.1239, 0.2153, 0.2800, 1.6250, 0.1405, 0.7765,\n",
       "                      0.3109, 0.0899, 0.0976, 0.1190, 0.4040, 0.0852, 0.3765, 0.7657, 0.4094,\n",
       "                      0.0774, 0.1742, 0.5888, 0.4111, 0.2480, 0.2120, 0.2503, 0.0956, 0.2606,\n",
       "                      0.1426, 0.4608, 1.0246, 0.3714, 0.3616, 0.4811, 0.6133, 0.1916, 0.2535,\n",
       "                      0.5565, 0.1683, 0.1640, 0.1374, 0.3156, 0.8755, 0.1978, 0.1259, 0.2067,\n",
       "                      0.3021, 0.4198, 0.5825, 0.2799, 0.6344, 0.4823, 1.1014, 0.2205, 0.3212,\n",
       "                      0.2280, 0.6856, 0.2782, 0.5016, 0.5068, 0.2151, 0.9461, 0.1197, 0.1516,\n",
       "                      0.4360, 0.1697, 0.5326, 0.9169, 0.5131, 0.1373, 0.5680, 0.1899, 0.1963,\n",
       "                      0.3791, 0.1774, 0.1806, 0.7533, 0.9411, 0.7036, 0.1305, 0.1322, 0.7400,\n",
       "                      0.3803, 0.1400, 0.1719, 0.1387, 0.2175, 0.2308, 0.3297, 0.3587, 0.3405,\n",
       "                      0.2994, 0.3547, 0.6991, 0.2913])),\n",
       "             ('decoders.6.bn2.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense3.weight',\n",
       "              tensor([[ 0.0187, -0.0086, -0.0351,  ..., -0.0178, -0.0142,  0.0205],\n",
       "                      [ 0.0237, -0.0108,  0.0729,  ..., -0.0141,  0.0573, -0.0040],\n",
       "                      [ 0.0062, -0.0358, -0.0473,  ...,  0.0236, -0.0368, -0.0309],\n",
       "                      ...,\n",
       "                      [ 0.0461,  0.0483,  0.0225,  ...,  0.0364, -0.0388, -0.0340],\n",
       "                      [ 0.0752,  0.0671, -0.0273,  ...,  0.0498, -0.0337,  0.0009],\n",
       "                      [-0.0218,  0.0511, -0.0123,  ..., -0.0120,  0.0380,  0.0535]])),\n",
       "             ('decoders.6.bn3.weight',\n",
       "              tensor([0.9937, 0.9928, 1.0146, 1.0063, 0.9976, 0.9992, 1.0171, 1.0011, 1.0084,\n",
       "                      1.0000, 1.0116, 1.0198, 0.9974, 0.9957, 0.9991, 0.9934, 1.0050, 1.0035,\n",
       "                      0.9898, 0.9871, 1.0070, 1.0009, 1.0161, 0.9951, 0.9963, 1.0017, 1.0086,\n",
       "                      0.9950, 0.9951, 0.9920, 0.9929, 0.9955, 1.0068, 1.0032, 0.9946, 0.9889,\n",
       "                      1.0004, 1.0119, 1.0066, 0.9932, 1.0116, 1.0054, 1.0006, 1.0050, 0.9894,\n",
       "                      0.9973, 0.9994, 1.0004, 1.0065, 0.9984, 0.9950, 1.0097, 1.0093, 0.9886,\n",
       "                      1.0006, 1.0042, 0.9963, 0.9978, 0.9851, 0.9957, 1.0094, 0.9899, 0.9846,\n",
       "                      1.0023, 0.9991, 0.9792, 1.0159, 1.0053, 1.0038, 1.0016, 0.9995, 1.0107,\n",
       "                      0.9996, 1.0146, 0.9910, 0.9938, 0.9927, 0.9840, 1.0042, 0.9954, 0.9938,\n",
       "                      0.9941, 1.0092, 1.0098, 0.9907, 0.9789, 1.0003, 0.9913, 1.0025, 1.0107,\n",
       "                      1.0169, 1.0154, 0.9892, 1.0061, 1.0033, 1.0109, 0.9885, 0.9954, 0.9952,\n",
       "                      1.0081, 1.0110, 0.9908, 1.0201, 1.0056, 0.9977, 0.9985, 1.0155, 1.0111,\n",
       "                      1.0017, 1.0000, 1.0019, 0.9914, 1.0131, 1.0074, 0.9866, 0.9921, 1.0050,\n",
       "                      1.0035, 1.0086, 0.9892, 1.0174, 1.0070, 1.0042, 1.0055, 0.9951, 1.0177,\n",
       "                      1.0056, 1.0012, 1.0077, 1.0182, 1.0012, 0.9868, 1.0019, 0.9919, 1.0166,\n",
       "                      0.9881, 1.0090, 0.9932, 0.9970, 1.0052, 1.0019, 0.9955, 0.9847, 0.9989,\n",
       "                      1.0008, 0.9923, 0.9929, 1.0043, 0.9961, 1.0009, 0.9810, 1.0059, 0.9920,\n",
       "                      1.0008, 1.0024, 1.0110, 0.9901, 0.9931, 1.0015, 1.0124, 0.9944, 1.0069,\n",
       "                      0.9946, 1.0050, 1.0034, 1.0015, 0.9986, 0.9985, 1.0111, 0.9958, 1.0061,\n",
       "                      0.9953, 1.0077, 0.9897, 0.9943, 0.9842, 0.9955, 0.9925, 0.9930, 1.0058,\n",
       "                      0.9925, 0.9998, 0.9997, 0.9887, 1.0029, 1.0001, 1.0124, 1.0062, 1.0176,\n",
       "                      0.9892, 0.9991, 0.9853, 0.9914, 0.9943, 0.9931, 1.0187, 0.9765, 0.9984,\n",
       "                      0.9917, 0.9995, 0.9791, 1.0035, 1.0044, 0.9902, 0.9990, 1.0133, 1.0013,\n",
       "                      0.9773, 1.0113, 1.0219, 1.0027, 1.0012, 1.0074, 1.0050, 1.0045, 0.9825,\n",
       "                      0.9953, 0.9915, 1.0052, 1.0178, 0.9921, 0.9851, 0.9802, 0.9975, 1.0026,\n",
       "                      1.0056, 1.0208, 0.9966, 1.0040, 0.9913, 0.9924, 0.9994, 1.0057, 1.0041,\n",
       "                      0.9956, 0.9936, 0.9857, 0.9834, 0.9982, 1.0030, 0.9962, 1.0012, 1.0092,\n",
       "                      1.0087, 0.9893, 0.9990, 0.9837, 1.0011, 1.0155, 0.9971, 1.0092, 1.0003,\n",
       "                      0.9949, 1.0092, 1.0257, 1.0057, 0.9917, 1.0131, 0.9984, 0.9981, 0.9848,\n",
       "                      0.9913, 1.0212, 1.0059, 0.9908, 0.9971, 0.9938, 1.0002, 1.0080, 0.9996,\n",
       "                      0.9860, 0.9914, 0.9972, 0.9953, 0.9935, 0.9944, 0.9903, 0.9958, 0.9965,\n",
       "                      0.9948, 0.9979, 1.0111, 0.9955, 1.0030, 1.0080, 0.9929, 0.9938, 1.0134,\n",
       "                      1.0115, 1.0017, 0.9838, 1.0176, 0.9899, 1.0019, 1.0021, 1.0090, 1.0034,\n",
       "                      1.0027, 1.0079, 1.0102, 0.9905, 1.0025, 0.9885, 1.0031, 1.0038, 0.9930,\n",
       "                      1.0009, 1.0025, 1.0043, 0.9909, 0.9988, 0.9956, 1.0171, 0.9913, 0.9983,\n",
       "                      1.0192, 0.9918, 0.9949, 0.9961, 0.9903, 0.9940, 1.0136, 0.9989, 0.9987,\n",
       "                      0.9774, 0.9946, 0.9796, 1.0186, 0.9920, 1.0092, 0.9969, 1.0055, 0.9916,\n",
       "                      1.0097, 0.9862, 0.9991, 1.0128, 0.9835, 0.9971, 1.0053, 1.0190, 0.9979,\n",
       "                      0.9955, 1.0150, 0.9906, 0.9899, 0.9935, 0.9978, 1.0132, 1.0112, 1.0128,\n",
       "                      0.9938, 1.0058, 0.9965, 0.9947, 0.9959, 0.9950, 1.0028, 0.9960, 0.9887,\n",
       "                      1.0163, 0.9944, 0.9960, 1.0028, 0.9952, 0.9933, 0.9960, 0.9820, 1.0046,\n",
       "                      0.9954, 0.9885, 1.0100, 0.9907, 0.9741, 0.9930, 0.9915, 1.0051, 0.9929,\n",
       "                      0.9914, 1.0147, 0.9910, 1.0038, 1.0000, 1.0207, 1.0010, 1.0036, 0.9904,\n",
       "                      1.0021, 0.9988, 0.9958, 1.0144, 1.0049, 0.9976, 1.0019, 1.0209, 1.0067,\n",
       "                      0.9977, 1.0132, 0.9832, 0.9991, 0.9899, 1.0235, 1.0065, 1.0109, 1.0019,\n",
       "                      1.0064, 0.9875, 1.0155, 0.9966, 1.0202, 1.0043, 1.0095, 0.9967, 0.9992,\n",
       "                      0.9916, 1.0117, 1.0022, 1.0118, 0.9974, 1.0023, 0.9983, 1.0109, 1.0074,\n",
       "                      1.0082, 0.9942, 0.9992, 1.0063, 0.9994, 0.9849, 0.9966, 0.9846, 0.9937,\n",
       "                      0.9992, 0.9962, 0.9935, 0.9871, 0.9982, 1.0058, 1.0023, 0.9930, 1.0048,\n",
       "                      1.0128, 1.0125, 0.9840, 0.9913, 0.9976, 0.9934, 1.0104, 1.0044, 0.9914,\n",
       "                      1.0071, 1.0183, 1.0014, 0.9980, 0.9963, 1.0090, 1.0012, 0.9999, 1.0210,\n",
       "                      1.0041, 1.0224, 1.0006, 1.0099, 0.9976, 0.9988, 1.0018, 1.0035, 0.9897,\n",
       "                      0.9919, 1.0094, 1.0151, 0.9898, 0.9926, 1.0001, 0.9979, 0.9934, 1.0311,\n",
       "                      0.9867, 1.0121, 0.9984, 1.0143, 0.9841, 0.9873, 0.9878, 0.9908, 0.9846,\n",
       "                      0.9918, 0.9971, 0.9955, 1.0048, 1.0103, 0.9944, 0.9992, 1.0006, 0.9974,\n",
       "                      0.9963, 0.9947, 0.9906, 0.9933, 1.0132, 0.9961, 0.9975, 0.9922, 1.0093,\n",
       "                      1.0055, 0.9770, 0.9948, 0.9951, 1.0019, 1.0105, 1.0112, 0.9966])),\n",
       "             ('decoders.6.bn3.bias',\n",
       "              tensor([-1.8564e-03,  1.9743e-03,  2.2357e-02,  3.8832e-02,  4.4636e-03,\n",
       "                      -1.9392e-03,  3.7587e-02,  2.3329e-02,  3.8438e-02, -1.0292e-02,\n",
       "                       1.7180e-02,  2.6180e-02,  6.8368e-04,  7.6168e-04,  3.9710e-03,\n",
       "                      -7.6368e-03, -8.6375e-04,  1.6170e-02, -9.0255e-03, -4.4142e-03,\n",
       "                       1.1207e-02,  2.1175e-02,  7.0850e-03, -2.5824e-03,  9.0101e-03,\n",
       "                       2.5826e-03,  1.4796e-02, -8.1400e-03,  1.6018e-02, -1.5098e-04,\n",
       "                       1.4366e-02, -1.9382e-03, -1.7632e-03, -1.7606e-02,  6.4841e-03,\n",
       "                      -9.8518e-03,  1.8522e-02,  2.9550e-02,  2.9669e-03,  8.0041e-03,\n",
       "                       1.8161e-02,  2.1638e-02,  6.9969e-03,  4.5363e-03, -2.1235e-02,\n",
       "                       1.7905e-02, -7.6052e-03, -2.3225e-03,  3.6133e-02,  1.4754e-02,\n",
       "                      -3.5814e-03,  1.5092e-02, -4.4426e-03, -1.7429e-02,  8.9615e-03,\n",
       "                       1.8456e-02,  2.6450e-02,  2.2844e-02,  4.8820e-03,  6.5169e-04,\n",
       "                       2.2961e-02,  1.1436e-02, -1.4796e-02, -6.8066e-03,  2.6429e-03,\n",
       "                      -1.8164e-03, -9.8054e-03,  1.6647e-02,  5.5076e-03, -6.2057e-03,\n",
       "                      -4.0550e-03,  2.6467e-02,  2.4004e-03,  1.5205e-02, -1.1180e-02,\n",
       "                       7.5743e-04, -4.8722e-03, -9.1813e-03,  1.9212e-02,  9.7352e-03,\n",
       "                      -3.2463e-03,  4.7882e-04,  1.6152e-02,  1.0884e-02, -6.7613e-03,\n",
       "                      -1.7923e-02,  1.2964e-02, -5.6897e-03,  3.9386e-03,  2.0824e-02,\n",
       "                       1.6702e-02,  9.1543e-03,  3.3391e-04,  3.6223e-02,  1.0828e-02,\n",
       "                       2.2199e-02,  8.2491e-04,  1.0872e-02, -4.4124e-03,  5.0012e-03,\n",
       "                       1.7609e-02,  6.9687e-04,  3.0188e-02,  2.9125e-02,  5.0534e-03,\n",
       "                       1.0974e-03,  2.8904e-02,  3.4059e-03,  3.7395e-03,  1.5819e-02,\n",
       "                       1.0213e-02, -2.2032e-03,  2.5898e-02,  3.6186e-03, -2.4659e-02,\n",
       "                       9.2469e-03,  2.0375e-03,  3.5782e-02,  1.9670e-02, -9.4779e-04,\n",
       "                       9.5292e-04,  2.5616e-02,  2.4097e-02,  1.0909e-02,  1.1776e-02,\n",
       "                      -1.1843e-02,  2.6531e-02,  8.0844e-03, -6.4025e-03,  1.1702e-02,\n",
       "                       8.2719e-03, -1.2647e-02,  1.3464e-03, -1.1260e-02,  1.5393e-02,\n",
       "                       5.2750e-03,  9.9131e-03,  8.1176e-03,  2.2377e-02,  6.0408e-03,\n",
       "                      -1.0230e-02, -2.9953e-04, -1.2611e-03, -9.9498e-04,  2.6595e-02,\n",
       "                       3.8160e-03,  4.4556e-03,  5.0278e-03,  4.7946e-03,  1.5273e-02,\n",
       "                      -6.6491e-03,  2.9580e-04,  2.4647e-02,  1.5075e-02, -4.4251e-03,\n",
       "                       3.1483e-02, -5.3996e-03, -2.7168e-03,  1.5242e-02, -1.1595e-02,\n",
       "                       1.5102e-03,  2.2613e-02, -9.2136e-04,  1.7914e-02,  2.2382e-03,\n",
       "                       1.2742e-02,  1.0309e-03, -1.9016e-02,  1.6181e-02, -9.8764e-03,\n",
       "                      -1.0833e-03,  1.6001e-02,  1.4494e-02,  1.1895e-02, -2.3531e-02,\n",
       "                      -6.5045e-03, -2.9041e-03,  7.4137e-03,  9.6214e-03,  1.3155e-02,\n",
       "                       1.2407e-03, -6.6690e-04,  5.8385e-03, -8.8195e-03,  5.7929e-03,\n",
       "                       1.7734e-02,  3.9557e-03, -2.4410e-03,  1.9531e-02, -4.9515e-03,\n",
       "                       1.8388e-02, -8.8241e-03, -4.2621e-03, -1.0401e-02,  4.9227e-05,\n",
       "                       1.2612e-02, -9.9660e-03,  7.9325e-03,  1.1716e-02,  2.5920e-02,\n",
       "                      -1.9695e-02, -1.3932e-02,  1.7202e-02, -1.2148e-02,  1.8972e-02,\n",
       "                       2.4894e-02,  1.0659e-02, -2.2713e-02, -1.0579e-02,  5.8878e-02,\n",
       "                      -3.2471e-03, -3.2821e-03,  1.8627e-02,  1.2228e-02, -8.7973e-03,\n",
       "                      -1.0235e-03, -1.4480e-03,  8.1713e-04,  1.0130e-02,  2.8366e-04,\n",
       "                       5.5310e-03,  2.0776e-03, -1.2576e-02,  4.8882e-03,  2.8913e-02,\n",
       "                       8.4789e-03,  2.5004e-02,  3.3807e-03,  2.5312e-03, -1.5871e-04,\n",
       "                      -5.5853e-03, -3.5318e-03,  6.3668e-03,  3.6241e-02,  3.0221e-03,\n",
       "                       2.3632e-03, -1.9356e-02, -2.3623e-02,  1.4365e-02,  1.5188e-02,\n",
       "                       8.6788e-03,  3.0302e-02,  2.6353e-02,  3.9597e-02, -3.3741e-03,\n",
       "                      -3.5609e-03, -3.1158e-03,  1.9222e-02, -1.4878e-03,  1.0913e-02,\n",
       "                       1.1270e-02,  1.0634e-02,  1.2601e-03, -3.7158e-04,  4.0588e-02,\n",
       "                       4.4991e-03, -1.2113e-02, -5.1181e-03,  2.2526e-02,  2.1291e-02,\n",
       "                      -1.1341e-02,  1.1998e-02,  3.8120e-02, -1.1588e-02,  2.5809e-03,\n",
       "                       6.9941e-03,  2.6992e-03,  6.7104e-03,  4.3001e-02,  9.8820e-03,\n",
       "                       4.3482e-03,  1.1398e-02,  4.1680e-03,  5.1320e-03, -6.5109e-03,\n",
       "                      -8.2733e-03, -1.5357e-02, -9.2143e-03,  1.2967e-02, -2.1174e-03,\n",
       "                       2.2942e-02,  3.2293e-03, -4.3516e-03, -9.4497e-03,  1.2881e-02,\n",
       "                      -5.7133e-03,  9.2759e-03,  2.9316e-02,  3.5312e-04, -6.7756e-03,\n",
       "                      -1.7288e-03,  4.4971e-02, -8.9552e-03,  2.3377e-02,  1.3796e-02,\n",
       "                       6.3744e-03,  2.2325e-02, -5.6658e-04,  2.3916e-02,  1.2429e-02,\n",
       "                      -1.1104e-03,  1.1726e-02, -2.0448e-03,  1.1320e-02,  1.3518e-02,\n",
       "                       1.1813e-02, -6.4482e-03, -3.6859e-03,  1.9147e-02,  8.0390e-03,\n",
       "                       3.3722e-03,  7.1502e-03,  3.9460e-02,  2.9278e-03, -1.3427e-02,\n",
       "                       2.1504e-02, -6.9731e-03, -1.9300e-03,  8.0487e-03, -1.9863e-04,\n",
       "                       7.8017e-03,  6.4469e-03,  8.1973e-03,  1.5608e-02, -1.4744e-02,\n",
       "                       1.2682e-02, -7.2308e-03,  5.5774e-02,  2.5427e-03,  2.2074e-02,\n",
       "                       1.2167e-02,  2.3698e-02,  6.6427e-04, -1.7042e-03, -3.6920e-03,\n",
       "                       1.8095e-02, -2.0460e-03, -1.4245e-02,  3.6472e-03,  1.2565e-03,\n",
       "                       3.4614e-02,  3.9183e-03,  3.3065e-03,  9.2733e-04,  1.0127e-02,\n",
       "                       1.4524e-03,  1.0104e-02, -1.7820e-02,  4.4444e-03,  1.8813e-02,\n",
       "                       3.4539e-02, -1.0399e-02,  1.4085e-02, -6.2442e-03,  7.6948e-03,\n",
       "                       3.1062e-03,  3.5428e-03,  1.1237e-02,  1.8382e-02,  1.2490e-02,\n",
       "                       2.7351e-02,  1.9289e-03, -2.5553e-03, -6.9955e-06, -9.5656e-03,\n",
       "                      -4.0716e-03,  6.0627e-03, -1.9725e-04, -3.5944e-03, -1.8648e-03,\n",
       "                      -1.3102e-02,  2.2435e-03,  2.0222e-03, -6.9311e-03, -2.7111e-03,\n",
       "                       6.8196e-04,  8.1443e-03,  1.0970e-02,  2.2206e-02,  3.3469e-02,\n",
       "                       4.9259e-03,  1.1384e-02,  6.6575e-03,  3.1760e-03, -3.2634e-03,\n",
       "                       1.6345e-02, -2.4327e-03,  9.3995e-03,  1.8532e-02,  1.9382e-03,\n",
       "                       3.3297e-02,  9.4778e-04,  3.2269e-03,  7.4417e-03,  3.4590e-02,\n",
       "                       3.3421e-02,  7.8727e-03, -4.0456e-03, -1.0256e-02,  1.1677e-02,\n",
       "                       8.7630e-03,  5.9042e-02,  2.4835e-03,  2.1173e-02,  1.2033e-02,\n",
       "                      -8.3309e-03,  3.7495e-03,  1.9949e-02, -1.9321e-03,  5.2502e-02,\n",
       "                       3.0604e-02,  3.8218e-03,  2.0967e-02,  1.0693e-02,  5.7044e-03,\n",
       "                       6.9045e-03, -3.7503e-03,  6.0654e-03,  9.5917e-03,  1.2673e-02,\n",
       "                       5.1414e-03,  1.7166e-03, -9.0010e-04,  1.2367e-02,  2.2059e-03,\n",
       "                       5.9326e-03,  1.2040e-02, -5.7548e-03, -1.0257e-02,  6.5790e-03,\n",
       "                      -9.8662e-03,  4.5455e-03,  2.1673e-02,  5.9898e-03,  4.7628e-04,\n",
       "                      -2.1675e-03,  4.4309e-04,  4.2737e-03, -7.4197e-05, -4.1000e-03,\n",
       "                       2.1492e-02,  3.3729e-02,  3.2929e-02, -1.4050e-02,  8.2164e-03,\n",
       "                       1.2418e-02,  6.9308e-03,  2.2042e-02, -1.2609e-02,  3.5787e-02,\n",
       "                       1.0229e-02,  2.9351e-02,  5.1591e-03,  2.0025e-02,  9.7702e-03,\n",
       "                       2.0205e-02,  3.4311e-03,  1.7277e-02,  3.6937e-02,  1.9046e-02,\n",
       "                       1.1421e-02,  2.6113e-02,  2.6819e-02,  9.4227e-03, -2.2332e-03,\n",
       "                       8.6023e-03,  8.9667e-03,  1.9067e-04,  4.1463e-03,  1.6422e-02,\n",
       "                       3.2311e-02,  2.0875e-03,  6.1099e-03,  6.2047e-03,  1.0805e-02,\n",
       "                      -7.7628e-03,  4.3342e-02,  3.2287e-03,  1.9793e-02,  1.0922e-02,\n",
       "                       9.3624e-03, -1.3339e-02,  1.5325e-02, -9.5731e-03, -9.6026e-03,\n",
       "                       2.9597e-03, -8.6482e-03,  9.8520e-03,  7.9174e-03,  4.6177e-03,\n",
       "                       2.4361e-02,  6.3278e-03,  5.6550e-03, -1.0178e-03, -8.0716e-03,\n",
       "                      -4.4177e-03,  9.7345e-05,  2.0447e-02, -1.1473e-02,  7.8229e-03,\n",
       "                       2.4818e-03, -3.5576e-03,  1.3601e-02,  2.8656e-02,  2.4519e-02,\n",
       "                      -1.2683e-02,  1.7819e-02, -8.7397e-03,  1.9315e-02,  8.4205e-03,\n",
       "                       2.1468e-02, -5.0349e-03])),\n",
       "             ('decoders.6.bn3.running_mean',\n",
       "              tensor([-0.2135, -0.0621, -0.3583, -0.0403, -0.0891,  0.0170, -0.2443, -0.1527,\n",
       "                      -0.0675,  0.0402, -0.0052, -0.3245,  0.4088,  0.1760,  0.0193,  0.1482,\n",
       "                       0.4267, -0.1056,  0.1959, -0.1073,  0.1768,  0.1107,  0.2194, -0.2687,\n",
       "                      -0.0756,  0.0956,  0.2424,  0.2565, -0.3674, -0.2848, -0.1118,  0.3999,\n",
       "                      -0.1359,  0.3692, -0.2219,  0.4892, -0.2801, -0.0402,  0.2454, -0.0554,\n",
       "                      -0.2059, -0.4235,  0.0162, -0.4181,  0.3757,  0.0067, -0.2517, -0.1101,\n",
       "                      -0.2202, -0.2727, -0.1422,  0.0376,  0.7860,  0.0256, -0.3187, -0.0353,\n",
       "                      -0.1596, -0.4564, -0.2953,  0.3447, -0.2731, -0.4389, -0.3102,  0.4476,\n",
       "                      -0.3199, -0.0691,  0.3305,  0.1164,  0.1815,  0.1358, -0.2190, -0.5657,\n",
       "                       0.2907,  0.4022, -0.2503, -0.0740,  0.1693, -0.0291,  0.0295, -0.2451,\n",
       "                       0.0363,  0.0339, -0.2297,  0.1093, -0.3490,  0.4714, -0.2889, -0.3338,\n",
       "                       0.0274, -0.0494, -0.1122,  0.3250, -0.4309, -0.0581, -0.2215, -0.1368,\n",
       "                       0.0715,  0.1212, -0.0034, -0.3716, -0.0408, -0.0548, -0.1375,  0.2561,\n",
       "                       0.0565,  0.1702, -0.4290,  0.2867, -0.1110, -0.2951, -0.2039, -0.0186,\n",
       "                      -0.4061, -0.0754,  0.2987, -0.1165,  0.4724, -0.4323,  0.3346, -0.2401,\n",
       "                       0.1780, -0.1468, -0.3408,  0.2171, -0.2120,  0.6285, -0.0329, -0.5362,\n",
       "                       0.3223, -0.5754, -0.2982, -0.4104, -0.0705,  0.3045,  0.1957, -0.2071,\n",
       "                       0.0497,  0.1785, -0.1889,  0.0742,  0.3999, -0.0414,  0.0316,  0.5989,\n",
       "                      -0.1987,  0.4385, -0.2673,  0.3324, -0.1235, -0.4943,  0.0880,  0.3459,\n",
       "                      -0.2502,  0.2014,  0.2814, -0.1984,  0.0756,  0.1069,  0.2144,  0.4227,\n",
       "                      -0.2247, -0.1792, -0.3311, -0.0859,  0.0810, -0.1259, -0.2409,  0.4782,\n",
       "                      -0.0689,  0.4562,  0.5717,  0.0271, -0.0069, -0.3036,  0.2558,  0.0802,\n",
       "                      -0.0353,  0.2375, -0.0621, -0.3009, -0.3655, -0.4106,  0.0217, -0.1221,\n",
       "                       0.2377, -0.0997,  0.6084,  0.1664,  0.0304,  0.0344, -0.1605, -0.0718,\n",
       "                       0.0319,  0.3531,  0.1038, -0.4505,  0.1167, -0.2887, -0.4854, -0.0576,\n",
       "                       0.0364,  0.2142, -0.2348, -0.2403,  0.0896, -0.2751, -0.0009,  0.2738,\n",
       "                       0.3675,  0.0092,  0.1209,  0.3314, -0.0493, -0.1938,  0.3974,  0.0669,\n",
       "                       0.3171, -0.1604, -0.2492,  0.3199, -0.0392, -0.0758,  0.0420,  0.0868,\n",
       "                      -0.3771,  0.0678, -0.2556, -0.2120, -0.2573,  0.0647,  0.3532,  0.4653,\n",
       "                      -0.2993, -0.0839, -0.3508, -0.2307, -0.0906,  0.3630, -0.1026,  0.0498,\n",
       "                       0.3113, -0.3490, -0.2213, -0.1880,  0.1801,  0.3297,  0.2616, -0.2693,\n",
       "                       0.6138, -0.3448,  0.0616, -0.2189, -0.0564,  0.3959, -0.1884,  0.0987,\n",
       "                      -0.1348,  0.1775, -0.1487, -0.2299,  0.3704, -0.4138, -0.1888,  0.5376,\n",
       "                       0.0759, -0.4488,  0.3436,  0.6407, -0.6054, -0.5523, -0.3901, -0.0069,\n",
       "                      -0.4393, -0.4192,  0.0062, -0.0888,  0.3424, -0.1906,  0.0770, -0.3325,\n",
       "                      -0.0888,  0.2303,  0.2774,  0.1380,  0.1731,  0.0669,  0.0094, -0.2477,\n",
       "                       0.3625,  0.1339, -0.3423, -0.2293,  0.2637, -0.1020, -0.1683,  0.4502,\n",
       "                       0.0448,  0.3287, -0.2589,  0.3765, -0.5362, -0.1243, -0.0316, -0.1886,\n",
       "                      -0.2707,  0.0747, -0.0170,  0.3584, -0.4306, -0.0097, -0.1791, -0.1887,\n",
       "                      -0.0734,  0.0591,  0.4622, -0.5350,  0.2724, -0.2631, -0.1321,  0.1406,\n",
       "                      -0.3568,  0.1417, -0.0342, -0.0268,  0.1955,  0.2963,  0.1165, -0.6795,\n",
       "                      -0.3424, -0.2743, -0.1004, -0.0238, -0.3331,  0.4538,  0.2078,  0.0245,\n",
       "                       0.5117,  0.0757, -0.0994,  0.5439, -0.1737, -0.3291,  0.0473,  0.4381,\n",
       "                      -0.1385, -0.2257, -0.3988,  0.6401,  0.2516, -0.1836,  0.0134,  0.3367,\n",
       "                      -0.0015,  0.1317, -0.2622, -0.0985, -0.0275, -0.1551, -0.2785, -0.3410,\n",
       "                      -0.1523, -0.3628,  0.0853,  0.1162,  0.2362, -0.0209, -0.1378, -0.1043,\n",
       "                       0.4307, -0.3720,  0.1739,  0.4378, -0.1182, -0.1616,  0.1300, -0.1565,\n",
       "                      -0.3336, -0.0584, -0.3487, -0.3920, -0.1932,  0.5890, -0.1604,  0.3743,\n",
       "                       0.1653, -0.0501, -0.1375,  0.2374, -0.2244, -0.2636, -0.4004, -0.3599,\n",
       "                      -0.3707, -0.0906, -0.2675, -0.2853, -0.0964,  0.5166, -0.1551,  0.2206,\n",
       "                      -0.1515, -0.4608,  0.4243,  0.5013, -0.2671, -0.1765, -0.0249, -0.2259,\n",
       "                       0.2141, -0.1973, -0.3282,  0.1961, -0.3888, -0.2668,  0.0158,  0.1015,\n",
       "                       0.0745,  0.0708, -0.0656, -0.1946, -0.1321, -0.0647, -0.1419, -0.2015,\n",
       "                      -0.3555, -0.1097, -0.6726, -0.0837,  0.2392, -0.1135,  0.1533, -0.0110,\n",
       "                      -0.1331, -0.3808, -0.4951, -0.0702, -0.2988, -0.4208, -0.1569,  0.1160,\n",
       "                      -0.3128, -0.4202,  0.1074, -0.3780,  0.0305,  0.2823, -0.2989, -0.0409,\n",
       "                       0.4238, -0.3491,  0.2295, -0.3014, -0.2193, -0.1316, -0.0328, -0.2481,\n",
       "                       0.0391, -0.4287, -0.3824, -0.2686,  0.2126,  0.0419, -0.1316, -0.3036,\n",
       "                       0.0828,  0.1059,  0.0355, -0.1446,  0.1463, -0.0811, -0.1606,  0.1521,\n",
       "                      -0.2935, -0.2479,  0.1139,  0.3119, -0.4564, -0.1376, -0.0675,  0.1040,\n",
       "                      -0.5038, -0.1423, -0.1209, -0.0513, -0.2439,  0.1726, -0.1267,  0.1504,\n",
       "                       0.0834, -0.5609, -0.2849, -0.2743, -0.2060, -0.0109,  0.3052, -0.1083,\n",
       "                      -0.2132, -0.2617,  0.5153,  0.1110, -0.2511, -0.2948,  0.1314, -0.3493,\n",
       "                      -0.3231, -0.1411, -0.1332,  0.3556, -0.5347,  0.2965,  0.2548,  0.2161])),\n",
       "             ('decoders.6.bn3.running_var',\n",
       "              tensor([0.9567, 0.8368, 1.5330, 1.7574, 0.3182, 1.2698, 0.6994, 0.3901, 1.0792,\n",
       "                      2.5660, 0.5069, 0.6290, 0.9446, 0.4859, 0.3792, 0.6237, 0.5515, 0.5111,\n",
       "                      0.3504, 0.3357, 1.1542, 0.9292, 1.1540, 0.2363, 0.2265, 0.6674, 1.7246,\n",
       "                      1.0200, 0.6162, 0.2376, 0.6185, 0.2248, 0.1700, 0.5526, 0.3590, 0.2685,\n",
       "                      0.8687, 1.3150, 0.4104, 0.5669, 0.4925, 1.8954, 0.4660, 0.3643, 0.3641,\n",
       "                      0.8416, 0.1451, 0.1395, 0.8827, 0.5190, 0.8462, 1.5134, 1.5085, 0.3622,\n",
       "                      0.3474, 0.8808, 0.9008, 0.9418, 0.4405, 0.6323, 0.7361, 0.6278, 0.2368,\n",
       "                      0.6724, 0.3904, 0.5852, 0.8328, 0.5790, 1.2341, 2.1560, 0.2041, 0.3543,\n",
       "                      0.3306, 0.2867, 0.2651, 0.4582, 0.6835, 0.2283, 0.6360, 1.2760, 0.1915,\n",
       "                      0.2895, 0.2306, 0.9627, 0.3418, 0.2138, 0.7379, 0.1841, 0.9634, 0.4427,\n",
       "                      0.6534, 0.5439, 0.3554, 1.1729, 0.7400, 0.5823, 0.3869, 0.3140, 0.4455,\n",
       "                      0.4054, 0.5917, 0.4643, 0.3825, 0.7663, 0.6529, 0.6233, 0.5811, 2.0823,\n",
       "                      1.5310, 0.5232, 0.2006, 0.4071, 0.6937, 0.5461, 0.2945, 0.3888, 0.2094,\n",
       "                      1.5771, 0.9426, 0.0858, 1.2532, 0.7547, 0.8964, 1.8781, 0.7845, 0.8866,\n",
       "                      1.1495, 0.2906, 1.9616, 0.2994, 0.2098, 0.1745, 1.3349, 0.3984, 1.2675,\n",
       "                      0.6307, 1.7086, 0.7335, 0.5089, 1.0776, 2.5551, 0.5409, 0.2837, 0.3264,\n",
       "                      1.1581, 0.1953, 0.1252, 0.5390, 0.4120, 0.6721, 0.3280, 2.5427, 0.8620,\n",
       "                      0.4532, 0.4673, 0.9190, 0.4165, 0.5398, 0.7214, 0.8327, 0.3838, 0.6809,\n",
       "                      1.8377, 0.7730, 0.2598, 1.0264, 0.2051, 0.2903, 0.1628, 0.7378, 0.2588,\n",
       "                      0.5413, 0.7452, 0.6965, 0.3739, 0.3968, 0.4818, 0.8081, 0.8237, 0.7630,\n",
       "                      0.5259, 0.2135, 0.7748, 0.2396, 1.5775, 0.5868, 2.0630, 1.1852, 0.6455,\n",
       "                      0.3241, 1.0134, 0.1960, 0.4551, 0.7117, 0.9804, 0.3160, 0.3824, 0.1864,\n",
       "                      0.2057, 1.1802, 0.3497, 0.6106, 1.7789, 0.1417, 1.0757, 0.6667, 0.7710,\n",
       "                      0.1566, 0.7157, 1.0566, 0.8565, 0.2762, 1.6562, 0.3146, 0.9814, 0.7743,\n",
       "                      1.4807, 0.3797, 0.4701, 1.6650, 0.8536, 0.2391, 0.4548, 0.6796, 0.3788,\n",
       "                      0.3964, 0.3263, 0.3741, 0.3275, 1.1073, 0.1764, 1.0772, 0.2739, 0.5977,\n",
       "                      0.3896, 0.1711, 0.1697, 0.3061, 0.7902, 0.7735, 0.6850, 0.4934, 0.5712,\n",
       "                      0.9385, 0.2459, 0.8893, 0.2804, 1.0194, 0.5367, 1.2866, 0.5332, 0.5447,\n",
       "                      0.3888, 2.0083, 0.8261, 0.4722, 0.2289, 1.0168, 0.4781, 1.1034, 0.2324,\n",
       "                      0.9623, 0.3943, 0.4949, 0.7674, 0.3568, 0.3019, 0.2434, 0.8986, 0.2843,\n",
       "                      0.7713, 0.5422, 0.3300, 0.3292, 0.3453, 1.9916, 0.3089, 0.2329, 0.3909,\n",
       "                      0.7568, 1.1333, 1.7776, 0.6638, 1.1290, 0.7043, 0.3956, 0.6272, 0.5091,\n",
       "                      1.1154, 1.1258, 0.2582, 0.7018, 0.5629, 0.7919, 0.6811, 0.9025, 0.7879,\n",
       "                      1.4899, 0.6840, 1.9726, 0.3077, 1.2181, 0.3781, 0.9046, 0.3831, 1.4211,\n",
       "                      1.3557, 0.6197, 1.9705, 1.3540, 0.1628, 0.3138, 1.3388, 0.3643, 0.6273,\n",
       "                      0.3615, 0.4621, 0.1112, 0.4399, 0.7345, 1.3133, 0.7991, 0.1828, 1.1269,\n",
       "                      1.1100, 1.8921, 0.5906, 0.7114, 0.4987, 1.8864, 1.0812, 0.8229, 0.3445,\n",
       "                      0.7989, 0.6434, 1.1278, 1.7123, 0.3914, 0.2385, 1.1509, 0.7207, 0.7137,\n",
       "                      0.4906, 1.1634, 0.8319, 0.3462, 0.2106, 0.2420, 1.9743, 0.7943, 1.1353,\n",
       "                      0.5647, 1.1496, 0.5580, 1.1134, 0.2419, 0.4007, 1.2066, 1.0579, 0.6006,\n",
       "                      0.7018, 0.3792, 0.9255, 1.7094, 0.8532, 0.7705, 0.6455, 0.5296, 0.8509,\n",
       "                      0.2106, 0.4469, 0.2858, 0.8260, 0.6113, 0.2381, 0.1739, 0.2161, 0.8151,\n",
       "                      0.7676, 1.4780, 0.2112, 0.3026, 0.5972, 2.1318, 0.2845, 0.6773, 0.5780,\n",
       "                      1.7742, 1.1027, 0.4886, 0.4148, 0.2429, 0.2996, 0.8368, 0.6462, 0.8969,\n",
       "                      1.6318, 1.0916, 0.3652, 0.6401, 0.5348, 0.8928, 0.5558, 0.6680, 0.1857,\n",
       "                      0.7858, 1.8359, 0.6203, 0.2999, 0.8644, 0.8280, 2.3121, 0.7684, 0.2925,\n",
       "                      0.7512, 0.9917, 0.3813, 2.0449, 0.5326, 0.8425, 0.2416, 1.9096, 1.0824,\n",
       "                      0.3163, 0.4815, 1.3979, 0.2456, 1.4936, 0.5076, 0.6384, 0.3253, 0.4728,\n",
       "                      0.8334, 0.2225, 0.2740, 0.4332, 0.4861, 0.5056, 0.2863, 0.3521, 0.3373,\n",
       "                      1.1622, 0.9374, 0.1441, 0.8785, 1.0773, 0.6379, 1.1135, 1.1811, 1.4559,\n",
       "                      2.7989, 0.6706, 0.3692, 1.1632, 0.5578, 0.3746, 0.1817, 0.6291, 0.3660,\n",
       "                      0.7437, 1.2557, 0.7284, 0.7988, 0.4284, 0.8618, 0.4266, 0.3238, 0.2960,\n",
       "                      1.2157, 0.8910, 1.1301, 0.5469, 0.2889, 0.3098, 1.0026, 0.6594, 0.5551,\n",
       "                      0.2748, 0.7557, 0.7032, 0.2627, 0.1587, 0.8463, 0.4928, 0.1369, 0.3197,\n",
       "                      0.3833, 1.5356, 0.6164, 0.3247, 0.7233, 0.6651, 0.2876, 1.1275, 0.2948,\n",
       "                      0.2657, 0.2346, 1.3681, 0.2986, 0.7177, 0.1138, 0.2591, 0.5914, 1.9492,\n",
       "                      0.7581, 0.1728, 0.7132, 0.2879, 0.5205, 0.9958, 1.3866, 0.9134])),\n",
       "             ('decoders.6.bn3.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense4.weight',\n",
       "              tensor([[-0.0088,  0.0258,  0.0159,  ..., -0.0361, -0.0518,  0.0215],\n",
       "                      [ 0.0050,  0.0045, -0.0189,  ..., -0.0268,  0.0290, -0.0245],\n",
       "                      [-0.0416, -0.0011,  0.0279,  ..., -0.0555,  0.0132, -0.0070],\n",
       "                      ...,\n",
       "                      [ 0.0072, -0.0441,  0.0035,  ..., -0.0044, -0.0230,  0.0339],\n",
       "                      [-0.0403, -0.0371, -0.0413,  ..., -0.0349, -0.0132,  0.0192],\n",
       "                      [ 0.0418, -0.0104,  0.0394,  ..., -0.0416, -0.0341, -0.0121]])),\n",
       "             ('decoders.6.bn4.weight',\n",
       "              tensor([1.0278, 1.0283, 1.0273, 1.0291, 1.0286, 1.0290, 1.0281, 1.0276, 1.0277,\n",
       "                      1.0263, 1.0286, 1.0299, 1.0323, 1.0298, 1.0315, 1.0312, 1.0285, 1.0289,\n",
       "                      1.0309, 1.0317, 1.0302, 1.0296, 1.0281, 1.0260, 1.0278, 1.0266, 1.0303,\n",
       "                      1.0292, 1.0296, 1.0289, 1.0279, 1.0281, 1.0276, 1.0290, 1.0277, 1.0271,\n",
       "                      1.0261, 1.0273, 1.0309, 1.0292, 1.0278, 1.0289, 1.0287, 1.0288, 1.0297,\n",
       "                      1.0305, 1.0304, 1.0275, 1.0253, 1.0296, 1.0293, 1.0330, 1.0298, 1.0279,\n",
       "                      1.0314, 1.0278, 1.0292, 1.0259, 1.0308, 1.0303, 1.0273, 1.0252, 1.0299,\n",
       "                      1.0302, 1.0278, 1.0312, 1.0205, 1.0280, 1.0265, 1.0287, 1.0297, 1.0294,\n",
       "                      1.0285, 1.0265, 1.0296, 1.0227, 1.0288, 1.0305, 1.0296, 1.0311, 1.0301,\n",
       "                      1.0294, 1.0274, 1.0258, 1.0281, 1.0305, 1.0254, 1.0278, 1.0294, 1.0305,\n",
       "                      1.0278, 1.0297, 1.0263, 1.0321, 1.0261, 1.0296, 1.0284, 1.0311, 1.0286,\n",
       "                      1.0304, 1.0275, 1.0328, 1.0288, 1.0287, 1.0311, 1.0271, 1.0265, 1.0268,\n",
       "                      1.0291, 1.0287, 1.0308, 1.0284, 1.0293, 1.0236, 1.0293, 1.0290, 1.0260,\n",
       "                      1.0281, 1.0284, 1.0274, 1.0284, 1.0294, 1.0285, 1.0292, 1.0331, 1.0232,\n",
       "                      1.0258, 1.0230, 1.0282, 1.0275, 1.0262, 1.0310, 1.0301, 1.0264, 1.0250,\n",
       "                      1.0306, 1.0261, 1.0287, 1.0289, 1.0273, 1.0273, 1.0272, 1.0301, 1.0229,\n",
       "                      1.0296, 1.0322, 1.0283, 1.0325, 1.0314, 1.0299, 1.0306, 1.0302, 1.0291,\n",
       "                      1.0308, 1.0304, 1.0267, 1.0304, 1.0299, 1.0298, 1.0289, 1.0282, 1.0277,\n",
       "                      1.0297, 1.0315, 1.0277, 1.0312, 1.0267, 1.0303, 1.0287, 1.0300, 1.0315,\n",
       "                      1.0295, 1.0289, 1.0335, 1.0266, 1.0292, 1.0268, 1.0302, 1.0281, 1.0310,\n",
       "                      1.0305, 1.0267, 1.0295, 1.0264, 1.0282, 1.0300, 1.0274, 1.0258, 1.0274,\n",
       "                      1.0308, 1.0267, 1.0300, 1.0291, 1.0276, 1.0237, 1.0276, 1.0302, 1.0298,\n",
       "                      1.0279, 1.0335, 1.0254, 1.0272, 1.0258, 1.0289, 1.0296, 1.0224, 1.0280,\n",
       "                      1.0294, 1.0311, 1.0265, 1.0310, 1.0298, 1.0268, 1.0274, 1.0314, 1.0296,\n",
       "                      1.0307, 1.0311, 1.0283, 1.0278, 1.0301, 1.0277, 1.0280, 1.0265, 1.0307,\n",
       "                      1.0281, 1.0258, 1.0321, 1.0326, 1.0260, 1.0307, 1.0296, 1.0275, 1.0291,\n",
       "                      1.0276, 1.0277, 1.0278, 1.0290, 1.0281, 1.0302, 1.0285, 1.0310, 1.0251,\n",
       "                      1.0283, 1.0258, 1.0296, 1.0283, 1.0284, 1.0288, 1.0292, 1.0258, 1.0281,\n",
       "                      1.0261, 1.0280, 1.0318, 1.0288, 1.0308, 1.0296, 1.0286, 1.0237, 1.0288,\n",
       "                      1.0280, 1.0249, 1.0275, 1.0293, 1.0275, 1.0242, 1.0280, 1.0291, 1.0306,\n",
       "                      1.0293, 1.0308, 1.0282, 1.0299, 1.0269, 1.0266, 1.0272, 1.0287, 1.0306,\n",
       "                      1.0297, 1.0302, 1.0271, 1.0309, 1.0311, 1.0287, 1.0318, 1.0303, 1.0301,\n",
       "                      1.0291, 1.0298, 1.0282, 1.0269, 1.0267, 1.0282, 1.0294, 1.0282, 1.0282,\n",
       "                      1.0283, 1.0277, 1.0265, 1.0307, 1.0318, 1.0228, 1.0251, 1.0306, 1.0274,\n",
       "                      1.0259, 1.0259, 1.0309, 1.0263, 1.0269, 1.0280, 1.0288, 1.0301, 1.0304,\n",
       "                      1.0318, 1.0282, 1.0280, 1.0291, 1.0291, 1.0288, 1.0242, 1.0296, 1.0286,\n",
       "                      1.0295, 1.0283, 1.0281, 1.0282, 1.0281, 1.0305, 1.0293, 1.0309, 1.0281,\n",
       "                      1.0312, 1.0275, 1.0291, 1.0286, 1.0300, 1.0294, 1.0248, 1.0281, 1.0271,\n",
       "                      1.0266, 1.0257, 1.0263, 1.0280, 1.0291, 1.0300, 1.0241, 1.0249, 1.0280,\n",
       "                      1.0295, 1.0296, 1.0296, 1.0314, 1.0299, 1.0269, 1.0317, 1.0296, 1.0264,\n",
       "                      1.0287, 1.0282, 1.0270, 1.0291, 1.0268, 1.0318, 1.0270, 1.0289, 1.0319,\n",
       "                      1.0310, 1.0286, 1.0305, 1.0300, 1.0286, 1.0312, 1.0322, 1.0303, 1.0269,\n",
       "                      1.0330, 1.0310, 1.0299, 1.0303, 1.0268, 1.0291, 1.0294, 1.0264, 1.0245,\n",
       "                      1.0286, 1.0296, 1.0281, 1.0282, 1.0331, 1.0278, 1.0269, 1.0260, 1.0267,\n",
       "                      1.0264, 1.0274, 1.0288, 1.0283, 1.0303, 1.0298, 1.0296, 1.0274, 1.0306,\n",
       "                      1.0252, 1.0298, 1.0278, 1.0299, 1.0315, 1.0296, 1.0300, 1.0261, 1.0280,\n",
       "                      1.0284, 1.0270, 1.0240, 1.0283, 1.0286, 1.0301, 1.0293, 1.0287, 1.0265,\n",
       "                      1.0301, 1.0275, 1.0313, 1.0272, 1.0289, 1.0286, 1.0269, 1.0275, 1.0259,\n",
       "                      1.0271, 1.0289, 1.0266, 1.0296, 1.0199, 1.0288, 1.0302, 1.0261, 1.0284,\n",
       "                      1.0285, 1.0320, 1.0308, 1.0276, 1.0270, 1.0275, 1.0279, 1.0220, 1.0261,\n",
       "                      1.0287, 1.0291, 1.0271, 1.0269, 1.0319, 1.0304, 1.0278, 1.0261, 1.0280,\n",
       "                      1.0298, 1.0294, 1.0313, 1.0286, 1.0256, 1.0280, 1.0222, 1.0298, 1.0227,\n",
       "                      1.0324, 1.0256, 1.0291, 1.0303, 1.0293, 1.0272, 1.0285, 1.0258, 1.0300,\n",
       "                      1.0278, 1.0292, 1.0305, 1.0260, 1.0283, 1.0264, 1.0287, 1.0305, 1.0301,\n",
       "                      1.0313, 1.0273, 1.0313, 1.0285, 1.0286, 1.0266, 1.0293, 1.0275, 1.0323,\n",
       "                      1.0328, 1.0271, 1.0292, 1.0298, 1.0314, 1.0282, 1.0253, 1.0239, 1.0278,\n",
       "                      1.0272, 1.0309, 1.0296, 1.0292, 1.0297, 1.0254, 1.0259, 1.0273])),\n",
       "             ('decoders.6.bn4.bias',\n",
       "              tensor([0.0359, 0.0363, 0.0359, 0.0362, 0.0376, 0.0363, 0.0356, 0.0351, 0.0340,\n",
       "                      0.0357, 0.0362, 0.0369, 0.0365, 0.0364, 0.0366, 0.0372, 0.0375, 0.0357,\n",
       "                      0.0382, 0.0369, 0.0366, 0.0348, 0.0357, 0.0351, 0.0356, 0.0350, 0.0343,\n",
       "                      0.0340, 0.0342, 0.0387, 0.0352, 0.0352, 0.0344, 0.0357, 0.0329, 0.0359,\n",
       "                      0.0356, 0.0344, 0.0362, 0.0373, 0.0355, 0.0366, 0.0341, 0.0332, 0.0354,\n",
       "                      0.0343, 0.0356, 0.0372, 0.0341, 0.0385, 0.0376, 0.0365, 0.0366, 0.0355,\n",
       "                      0.0369, 0.0362, 0.0347, 0.0343, 0.0364, 0.0380, 0.0366, 0.0342, 0.0371,\n",
       "                      0.0352, 0.0362, 0.0364, 0.0320, 0.0358, 0.0335, 0.0370, 0.0371, 0.0368,\n",
       "                      0.0361, 0.0345, 0.0361, 0.0331, 0.0365, 0.0380, 0.0352, 0.0376, 0.0364,\n",
       "                      0.0368, 0.0359, 0.0343, 0.0381, 0.0363, 0.0347, 0.0345, 0.0352, 0.0376,\n",
       "                      0.0354, 0.0360, 0.0342, 0.0374, 0.0356, 0.0380, 0.0372, 0.0358, 0.0369,\n",
       "                      0.0365, 0.0347, 0.0393, 0.0358, 0.0367, 0.0379, 0.0358, 0.0378, 0.0348,\n",
       "                      0.0368, 0.0372, 0.0376, 0.0343, 0.0360, 0.0337, 0.0337, 0.0357, 0.0343,\n",
       "                      0.0376, 0.0369, 0.0368, 0.0363, 0.0359, 0.0360, 0.0373, 0.0376, 0.0330,\n",
       "                      0.0346, 0.0333, 0.0339, 0.0356, 0.0364, 0.0370, 0.0340, 0.0345, 0.0346,\n",
       "                      0.0365, 0.0361, 0.0355, 0.0343, 0.0358, 0.0343, 0.0346, 0.0370, 0.0337,\n",
       "                      0.0362, 0.0374, 0.0377, 0.0367, 0.0372, 0.0363, 0.0377, 0.0365, 0.0364,\n",
       "                      0.0354, 0.0355, 0.0352, 0.0363, 0.0362, 0.0371, 0.0358, 0.0363, 0.0349,\n",
       "                      0.0382, 0.0372, 0.0351, 0.0357, 0.0345, 0.0386, 0.0341, 0.0359, 0.0385,\n",
       "                      0.0356, 0.0381, 0.0370, 0.0333, 0.0366, 0.0379, 0.0351, 0.0351, 0.0346,\n",
       "                      0.0366, 0.0355, 0.0373, 0.0360, 0.0354, 0.0382, 0.0348, 0.0356, 0.0373,\n",
       "                      0.0395, 0.0369, 0.0358, 0.0354, 0.0353, 0.0357, 0.0372, 0.0343, 0.0375,\n",
       "                      0.0346, 0.0377, 0.0346, 0.0353, 0.0354, 0.0366, 0.0378, 0.0337, 0.0356,\n",
       "                      0.0355, 0.0371, 0.0372, 0.0384, 0.0351, 0.0354, 0.0363, 0.0365, 0.0375,\n",
       "                      0.0357, 0.0374, 0.0361, 0.0356, 0.0378, 0.0365, 0.0360, 0.0331, 0.0378,\n",
       "                      0.0354, 0.0348, 0.0358, 0.0378, 0.0351, 0.0353, 0.0372, 0.0359, 0.0354,\n",
       "                      0.0314, 0.0337, 0.0364, 0.0383, 0.0363, 0.0367, 0.0356, 0.0368, 0.0344,\n",
       "                      0.0355, 0.0355, 0.0330, 0.0376, 0.0358, 0.0375, 0.0337, 0.0347, 0.0353,\n",
       "                      0.0352, 0.0349, 0.0377, 0.0334, 0.0363, 0.0370, 0.0358, 0.0334, 0.0358,\n",
       "                      0.0357, 0.0352, 0.0339, 0.0356, 0.0351, 0.0339, 0.0350, 0.0370, 0.0366,\n",
       "                      0.0374, 0.0367, 0.0343, 0.0358, 0.0351, 0.0328, 0.0346, 0.0365, 0.0381,\n",
       "                      0.0358, 0.0377, 0.0358, 0.0369, 0.0383, 0.0351, 0.0370, 0.0383, 0.0377,\n",
       "                      0.0355, 0.0381, 0.0349, 0.0359, 0.0351, 0.0354, 0.0362, 0.0375, 0.0359,\n",
       "                      0.0354, 0.0361, 0.0348, 0.0376, 0.0376, 0.0319, 0.0344, 0.0371, 0.0349,\n",
       "                      0.0343, 0.0354, 0.0343, 0.0353, 0.0344, 0.0368, 0.0360, 0.0370, 0.0367,\n",
       "                      0.0390, 0.0333, 0.0352, 0.0356, 0.0370, 0.0344, 0.0343, 0.0378, 0.0348,\n",
       "                      0.0347, 0.0376, 0.0384, 0.0350, 0.0355, 0.0358, 0.0342, 0.0374, 0.0375,\n",
       "                      0.0377, 0.0329, 0.0349, 0.0357, 0.0386, 0.0371, 0.0316, 0.0347, 0.0346,\n",
       "                      0.0355, 0.0352, 0.0354, 0.0352, 0.0364, 0.0345, 0.0349, 0.0358, 0.0335,\n",
       "                      0.0362, 0.0357, 0.0361, 0.0369, 0.0356, 0.0340, 0.0349, 0.0352, 0.0345,\n",
       "                      0.0352, 0.0352, 0.0330, 0.0374, 0.0366, 0.0388, 0.0349, 0.0355, 0.0358,\n",
       "                      0.0363, 0.0369, 0.0353, 0.0343, 0.0364, 0.0362, 0.0377, 0.0356, 0.0340,\n",
       "                      0.0363, 0.0381, 0.0367, 0.0366, 0.0325, 0.0355, 0.0360, 0.0343, 0.0336,\n",
       "                      0.0357, 0.0374, 0.0375, 0.0350, 0.0373, 0.0325, 0.0354, 0.0374, 0.0357,\n",
       "                      0.0362, 0.0351, 0.0373, 0.0342, 0.0366, 0.0377, 0.0346, 0.0362, 0.0375,\n",
       "                      0.0345, 0.0351, 0.0352, 0.0383, 0.0375, 0.0355, 0.0381, 0.0348, 0.0363,\n",
       "                      0.0369, 0.0352, 0.0347, 0.0362, 0.0376, 0.0344, 0.0361, 0.0375, 0.0374,\n",
       "                      0.0346, 0.0349, 0.0369, 0.0346, 0.0373, 0.0330, 0.0350, 0.0344, 0.0347,\n",
       "                      0.0362, 0.0334, 0.0373, 0.0375, 0.0301, 0.0352, 0.0371, 0.0358, 0.0351,\n",
       "                      0.0357, 0.0358, 0.0380, 0.0364, 0.0346, 0.0349, 0.0336, 0.0317, 0.0350,\n",
       "                      0.0351, 0.0373, 0.0370, 0.0353, 0.0372, 0.0361, 0.0354, 0.0349, 0.0353,\n",
       "                      0.0361, 0.0354, 0.0359, 0.0338, 0.0351, 0.0353, 0.0329, 0.0363, 0.0329,\n",
       "                      0.0347, 0.0344, 0.0380, 0.0375, 0.0376, 0.0356, 0.0379, 0.0346, 0.0360,\n",
       "                      0.0313, 0.0358, 0.0366, 0.0348, 0.0376, 0.0341, 0.0359, 0.0358, 0.0373,\n",
       "                      0.0379, 0.0369, 0.0387, 0.0353, 0.0347, 0.0361, 0.0355, 0.0353, 0.0361,\n",
       "                      0.0358, 0.0348, 0.0379, 0.0340, 0.0392, 0.0352, 0.0350, 0.0336, 0.0373,\n",
       "                      0.0354, 0.0364, 0.0367, 0.0387, 0.0377, 0.0332, 0.0332, 0.0341])),\n",
       "             ('decoders.6.bn4.running_mean',\n",
       "              tensor([-0.4495, -0.4252, -0.7594, -0.7199, -0.4868, -0.8940, -0.1243, -0.4332,\n",
       "                      -0.5308, -0.4981, -0.6592, -0.5402, -0.3107, -0.4670, -0.2322, -0.6932,\n",
       "                      -0.2772, -0.7176, -0.4820, -0.5335, -0.5890, -0.3711, -0.7373, -0.7947,\n",
       "                      -0.6909, -0.5949, -0.2013, -0.4308, -0.0491, -0.5958, -0.6227, -0.5523,\n",
       "                      -0.0056, -0.4047, -0.2324, -0.5219, -0.7185, -0.4594, -0.4420, -0.5419,\n",
       "                      -0.7287, -0.8445, -0.3457, -0.2119, -0.0293, -0.0133, -0.4126, -0.1599,\n",
       "                      -0.3651, -0.6950, -0.4820, -0.3274, -0.2366, -0.8343, -0.5571, -0.4633,\n",
       "                      -0.2466, -0.7725, -0.2679, -0.6833, -0.4138, -0.6225, -0.4232, -0.0849,\n",
       "                      -0.8398, -0.2188, -0.7037, -0.3951, -0.1115, -0.7155, -0.2029, -0.4872,\n",
       "                      -0.5447, -0.3327, -0.0828, -0.8560, -0.7913, -0.7647, -0.4432, -0.4485,\n",
       "                      -0.5525, -0.2628, -0.3967, -0.4566, -0.5902, -0.0671, -0.7315, -0.0472,\n",
       "                      -0.2702, -0.4293, -0.5444, -0.1316, -0.5022, -0.6081, -0.7336, -0.6890,\n",
       "                      -0.4804, -0.6743, -0.4589, -0.2153, -0.4345, -0.7968, -0.4141, -0.5696,\n",
       "                      -0.4451, -0.5873, -0.7297, -0.3896, -0.3707, -0.6434, -0.2605, -0.3017,\n",
       "                      -0.3804, -0.7629, -0.1858, -0.4083, -0.3218, -0.6217, -0.7587, -0.7713,\n",
       "                      -0.5526, -0.5460, -0.7321, -0.5284, -0.4310, -0.8577, -0.6270, -0.6695,\n",
       "                      -0.2145, -0.4851, -0.4145, -0.7341, -0.3453, -0.3579, -0.4368, -0.4916,\n",
       "                      -0.6167, -0.6340, -0.3008, -0.8236, -0.4185, -0.3945, -0.1578, -0.5179,\n",
       "                      -0.6292, -0.4588, -0.5003, -0.5183, -0.4835, -0.3808, -0.7210, -0.3528,\n",
       "                      -0.3816, -0.2615, -0.0540, -0.5543, -0.4163, -0.3931, -0.2762, -0.6139,\n",
       "                      -0.6365, -0.5521, -0.5691, -0.6235, -0.5003, -0.1721, -0.4272, -0.5205,\n",
       "                      -0.1996, -0.4721, -0.4892, -0.4578, -0.5578, -0.4015, -0.1305,  0.1154,\n",
       "                      -0.4875, -0.1772, -0.4626, -0.5530, -0.6710, -0.5407, -0.4829, -0.6392,\n",
       "                      -0.4856, -0.4716, -0.4284, -0.6506, -0.5723, -0.6000, -0.5592, -0.6120,\n",
       "                      -0.7514, -0.5466, -0.2860, -0.4218,  0.0658, -0.7584, -0.1775, -0.2398,\n",
       "                      -0.4515, -0.8042, -0.5661, -0.6694, -0.7065, -0.5471, -0.4069, -0.4070,\n",
       "                      -0.2505, -0.5686, -0.3574, -0.5421, -0.5356, -0.4587, -0.1362, -0.7384,\n",
       "                      -0.6039, -0.4101, -0.2842, -0.7238, -0.6487, -0.3857, -0.5689, -0.4516,\n",
       "                      -0.3481, -0.7978, -0.6022, -0.2723, -0.6766, -0.6053, -0.3503, -0.6211,\n",
       "                      -0.5121, -0.4237, -0.2715, -0.3575, -0.6020, -0.5127, -0.5709, -0.3694,\n",
       "                      -0.7314, -0.1059, -0.5726, -0.5982, -0.8365, -0.2954, -0.5865, -0.4439,\n",
       "                      -0.8446, -0.4710, -0.3939, -0.6647, -0.5952, -0.5784, -0.6282, -0.2765,\n",
       "                      -0.2645, -0.7688, -0.6389, -0.6281, -0.7287, -0.3604, -0.4034, -0.2729,\n",
       "                      -0.4782, -0.5889, -0.8489, -0.3367, -0.5877, -0.4543, -0.9145, -0.1540,\n",
       "                      -0.3848, -0.1940, -0.5553, -0.3901, -0.3549, -0.4231, -0.6373, -0.5054,\n",
       "                      -0.1778, -0.5303, -0.1199, -0.4833, -0.0189, -0.5342, -0.4017, -0.8031,\n",
       "                      -0.6526, -0.5746, -0.5728, -0.5078, -0.7579, -0.4152, -0.3704, -0.6337,\n",
       "                      -0.6284, -0.3997, -0.5336, -0.6608, -0.4217, -0.5639, -0.4698, -0.4114,\n",
       "                      -0.5368, -0.5688, -0.5672, -0.7968, -0.2851, -0.6673, -0.3595, -0.4566,\n",
       "                      -0.5728, -0.6788, -0.4072, -0.4948, -0.4077, -0.5339, -0.3694, -0.7018,\n",
       "                      -0.3626, -0.8015, -0.3387, -0.3922, -0.4633, -0.4861, -0.4551, -0.4154,\n",
       "                      -0.8206, -0.6536, -0.2897, -0.2649, -0.5894, -0.7993, -0.5313, -0.4198,\n",
       "                      -0.6125, -0.4725, -0.5355, -0.4406, -0.1901, -0.3997, -0.6318, -0.6276,\n",
       "                      -0.7891, -0.5022, -0.5320, -0.1936, -0.4765, -0.7623, -0.1621, -0.2121,\n",
       "                      -0.4185, -0.2151, -0.4678, -0.1981, -0.4423, -0.2157, -0.5880, -0.3664,\n",
       "                      -0.1190, -0.5111, -0.3478, -0.5342, -0.5521, -0.3910, -0.7317, -0.7504,\n",
       "                      -0.1574, -0.5240, -0.5097, -0.2670, -0.0505, -0.4099, -0.5142, -0.8681,\n",
       "                      -0.3226, -0.2355, -0.0233, -0.4887, -0.4335, -0.5113, -0.3912, -0.4642,\n",
       "                      -0.7271, -0.5077, -0.5415, -0.6181, -0.5284, -0.2852, -0.4741, -0.7098,\n",
       "                      -0.2491, -0.2622, -0.3305, -0.6729, -0.7810, -0.4650, -0.5199, -0.2255,\n",
       "                      -0.6747, -0.6184, -0.3118, -0.6612, -0.4652, -0.6085, -0.5000, -0.3726,\n",
       "                      -0.6120, -0.4938, -0.4458, -0.5540, -0.4137, -0.2888, -0.4912, -0.5918,\n",
       "                      -0.7363, -0.4958, -0.8258, -0.1379, -0.3901, -0.4478, -0.8148, -0.1301,\n",
       "                      -0.7198, -0.5108, -0.5229, -0.5659, -0.3393, -0.6863, -0.4848, -0.4801,\n",
       "                      -0.4593, -0.3774, -0.4870, -0.4600, -0.5986, -0.5122, -0.4876, -0.6240,\n",
       "                      -0.4907, -0.6759,  0.2255, -0.5237, -0.3100, -0.5098, -0.5224,  0.0381,\n",
       "                      -0.4458, -0.6295, -0.3068, -0.4959, -0.3852, -0.3938,  0.0807, -0.3010,\n",
       "                      -0.6090, -0.6383, -0.4879, -0.5346, -0.5202, -0.4001, -0.4102, -0.4487,\n",
       "                      -0.5980, -0.5008, -0.7257, -0.6016, -0.0918, -0.6217, -0.6755, -0.2450,\n",
       "                      -0.3677, -0.5827, -0.8595, -0.5727, -0.3893, -0.2975, -0.7877, -0.5586,\n",
       "                      -0.5758, -0.4682, -0.2475, -0.6170, -0.1281, -0.4578, -0.5458, -0.5934,\n",
       "                      -0.4679, -0.3179, -0.1978, -0.6258, -0.2753, -0.5080,  0.0202, -0.2493,\n",
       "                      -0.4870, -0.4148, -0.1983, -0.5773, -0.4568, -0.4956, -0.8456, -0.5761,\n",
       "                      -0.6462, -0.5805, -0.6721, -0.3226, -0.5411, -0.1823, -0.6537, -0.3677])),\n",
       "             ('decoders.6.bn4.running_var',\n",
       "              tensor([2.5693, 2.0950, 2.9007, 1.4335, 1.9501, 2.3752, 0.5789, 3.0440, 0.2988,\n",
       "                      1.3773, 3.5222, 2.1942, 2.3016, 2.6081, 2.9485, 2.4315, 1.9085, 2.2895,\n",
       "                      3.4451, 2.0326, 2.1180, 0.6217, 1.8053, 2.8199, 0.4617, 1.8779, 1.5848,\n",
       "                      0.4571, 0.7307, 2.1974, 3.1422, 1.6595, 0.5103, 3.2784, 1.3948, 2.5785,\n",
       "                      1.3512, 2.8849, 2.3137, 2.1404, 1.5249, 2.5130, 0.2948, 0.6962, 0.4574,\n",
       "                      0.9881, 2.6905, 0.4977, 2.1986, 2.0143, 1.8574, 0.4655, 3.1956, 0.8945,\n",
       "                      2.7350, 1.2713, 0.6687, 1.4795, 0.8132, 2.8123, 0.5081, 1.9311, 0.6028,\n",
       "                      0.5707, 2.1540, 0.4854, 1.2321, 1.8780, 0.7130, 2.0325, 0.7613, 2.0767,\n",
       "                      0.6273, 0.9344, 0.7179, 0.3675, 2.1843, 3.0200, 3.4101, 0.4516, 0.7142,\n",
       "                      0.5122, 2.6211, 2.1931, 1.7410, 0.6231, 1.6779, 0.7173, 0.6512, 2.6452,\n",
       "                      2.7861, 0.4609, 1.7598, 2.4834, 1.5155, 3.1374, 2.7034, 4.0759, 2.5933,\n",
       "                      1.2714, 2.0088, 0.6246, 2.2689, 1.4063, 2.6712, 2.0399, 2.5543, 0.4887,\n",
       "                      2.2510, 2.4505, 2.1335, 0.3846, 3.3097, 1.5072, 1.2191, 2.3378, 2.4535,\n",
       "                      2.7786, 2.7921, 1.0997, 1.7785, 2.5893, 1.8331, 3.1508, 1.7246, 1.2730,\n",
       "                      2.3151, 1.8307, 0.9070, 2.0024, 0.6748, 2.6192, 0.8246, 4.0712, 1.2571,\n",
       "                      2.7320, 1.7624, 0.4075, 0.5951, 3.0878, 0.2848, 2.5231, 0.6466, 1.0960,\n",
       "                      3.2441, 0.5978, 2.6417, 4.1197, 3.1870, 2.8997, 0.4052, 2.2998, 1.9881,\n",
       "                      0.9985, 0.6368, 2.2848, 1.8728, 1.9537, 2.2763, 1.8037, 2.7353, 2.8096,\n",
       "                      2.7026, 1.6453, 1.8487, 0.5712, 0.3175, 2.3974, 0.5349, 3.1171, 1.8197,\n",
       "                      2.7786, 2.5484, 2.1533, 0.6205, 0.4943, 2.2055, 0.7766, 1.8668, 0.3295,\n",
       "                      2.3480, 0.5155, 1.9137, 2.9987, 0.4470, 2.1150, 2.3833, 0.3618, 1.4818,\n",
       "                      2.5334, 1.4877, 4.1079, 2.3662, 2.4301, 0.4179, 1.9741, 1.7017, 1.9142,\n",
       "                      1.0099, 2.7514, 1.9292, 1.9927, 1.0443, 1.8591, 2.6150, 2.1610, 2.5552,\n",
       "                      3.0065, 0.6604, 2.2695, 1.9674, 0.3085, 1.5000, 1.6996, 0.7923, 0.3945,\n",
       "                      0.5158, 2.5405, 2.0618, 1.7621, 0.4178, 2.2052, 1.8669, 0.3502, 0.4436,\n",
       "                      3.2069, 0.4807, 0.6652, 1.6906, 0.6362, 0.5835, 2.5479, 1.3961, 0.4742,\n",
       "                      1.2306, 0.3288, 1.5684, 2.4899, 1.9135, 0.4274, 2.0333, 0.7175, 1.5304,\n",
       "                      3.4358, 0.8302, 1.2200, 0.9134, 0.5458, 1.4639, 0.5232, 0.3389, 3.5397,\n",
       "                      1.4959, 0.6020, 2.0129, 1.0548, 0.7255, 1.3226, 2.7379, 0.6393, 2.4480,\n",
       "                      0.6661, 2.0320, 0.4337, 2.7494, 0.4511, 1.5549, 0.4254, 2.1953, 3.3122,\n",
       "                      2.9228, 0.5499, 0.3680, 0.7963, 1.4696, 0.4045, 0.4241, 0.3323, 2.5666,\n",
       "                      1.8921, 0.5525, 2.5039, 0.9267, 2.1337, 0.6669, 2.2788, 2.5357, 3.2601,\n",
       "                      2.8024, 2.2916, 3.1771, 2.4112, 1.4301, 3.0884, 0.4412, 1.7007, 2.1105,\n",
       "                      1.5345, 1.5213, 2.7498, 1.6882, 3.0925, 0.6058, 2.3822, 2.2898, 1.6477,\n",
       "                      2.3288, 2.0650, 1.5561, 1.5465, 2.1603, 1.8004, 2.0373, 3.0373, 0.4729,\n",
       "                      2.4895, 0.5880, 2.2698, 3.0429, 2.7459, 0.3523, 1.6644, 2.7262, 0.4657,\n",
       "                      0.4977, 1.6154, 2.1087, 0.6338, 2.1737, 3.3467, 0.3346, 0.4545, 2.8311,\n",
       "                      3.9021, 0.2000, 3.0601, 2.2900, 0.7684, 0.9643, 0.2531, 2.1443, 0.6295,\n",
       "                      1.9640, 2.0303, 0.4861, 1.5928, 1.9256, 1.1523, 0.5354, 1.5655, 1.1164,\n",
       "                      0.4210, 2.2248, 0.3977, 2.1000, 2.4657, 2.6415, 0.8243, 0.5440, 1.7451,\n",
       "                      0.4968, 2.0424, 0.8456, 1.4057, 1.0945, 2.0967, 1.7675, 2.8270, 0.3416,\n",
       "                      1.9078, 0.4628, 0.9322, 0.7745, 2.2054, 1.7375, 2.6298, 0.7007, 0.4290,\n",
       "                      0.8043, 2.1192, 3.0042, 3.6825, 0.5416, 1.3912, 1.8950, 0.4325, 1.3592,\n",
       "                      0.4645, 3.1594, 0.3329, 2.5535, 2.7235, 1.4558, 1.6885, 0.5201, 2.6059,\n",
       "                      2.5254, 2.9505, 1.6871, 0.5705, 3.5347, 2.3251, 0.3894, 1.5420, 0.4241,\n",
       "                      2.3699, 0.4642, 2.6835, 3.1235, 1.6213, 0.6424, 2.0394, 0.3826, 2.2224,\n",
       "                      3.2815, 1.4817, 1.8882, 0.5025, 1.8727, 0.9894, 1.7987, 1.9079, 1.8729,\n",
       "                      1.1478, 2.6330, 3.3404, 1.6251, 2.0213, 1.0323, 0.3624, 2.2167, 2.5910,\n",
       "                      0.5569, 0.9958, 2.4507, 2.0981, 0.4379, 0.6500, 2.0726, 2.0888, 1.1676,\n",
       "                      3.3167, 0.8534, 2.5982, 1.1842, 0.3642, 2.3280, 0.9615, 0.4885, 0.3066,\n",
       "                      0.5644, 2.3389, 2.2684, 0.7680, 1.2421, 2.1090, 2.0674, 1.6657, 2.8508,\n",
       "                      2.3336, 0.5536, 0.6713, 0.5888, 2.0050, 2.1433, 2.0250, 0.3922, 1.1971,\n",
       "                      1.0720, 1.9346, 3.3053, 0.9183, 3.3513, 2.1794, 2.5269, 1.9290, 2.3538,\n",
       "                      1.1869, 2.9055, 4.3578, 2.0425, 2.0310, 0.3228, 1.5995, 0.6301, 1.7933,\n",
       "                      1.9258, 1.4802, 2.5477, 0.5004, 0.5993, 1.3532, 1.5379, 1.3045, 0.8335,\n",
       "                      0.5694, 2.6310, 2.4056, 0.5785, 2.2140, 2.3110, 1.4035, 0.3618, 0.7175,\n",
       "                      1.5624, 4.1863, 2.3966, 1.8603, 2.9091, 0.2889, 2.3672, 0.6693])),\n",
       "             ('decoders.6.bn4.num_batches_tracked', tensor(456)),\n",
       "             ('decoders.6.dense5.weight',\n",
       "              tensor([[-0.0092,  0.0440,  0.0041,  ...,  0.0245, -0.0165,  0.0379],\n",
       "                      [ 0.0099, -0.0136, -0.0076,  ..., -0.0181, -0.0358, -0.0364],\n",
       "                      [-0.0366, -0.0073, -0.0451,  ..., -0.0483, -0.0615, -0.0292],\n",
       "                      ...,\n",
       "                      [-0.0136, -0.0040,  0.0147,  ..., -0.0424, -0.0300, -0.0093],\n",
       "                      [-0.0375, -0.0320, -0.0556,  ...,  0.0013,  0.0195,  0.0061],\n",
       "                      [-0.0058, -0.0172, -0.0426,  ..., -0.0486, -0.0554,  0.0199]])),\n",
       "             ('decoders.6.dense5.bias',\n",
       "              tensor([ 0.0120, -0.0305, -0.0317,  ...,  0.0021, -0.0260, -0.0588]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(checkpoint_path+'/model_weights.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_path+'/model_weights.pt',map_location=torch.device('cpu')),strict=True)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "\n",
    "plot_tree_graph(data_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.kwargs[\"input_data\"]='varient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]/home/junyi/.conda/envs/RNA-FM/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|| 9/9 [00:00<00:00, 22.63it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do you want to look at pca embeddings or learnt representations\n",
    "use_pca = 'UMAP'\n",
    "\n",
    "# pick data loader\n",
    "data_loader = gen_test\n",
    "\n",
    "\n",
    "# each entry in node_embeddings is a dictionary with keys 'prob' and 'z_sample' for each leaf\n",
    "nb_nodes = len(data_tree)\n",
    "node_embeddings = [{'prob': [], 'z_sample': []} for _ in range(nb_nodes)]\n",
    "label_list = []\n",
    "\n",
    "# iterate over test data points\n",
    "for inputs, labels in tqdm(data_loader):\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "\n",
    "    label_list.append(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        node_info = get_node_embeddings(model, inputs_gpu)\n",
    "    node_info = move_to(node_info, 'cpu')\n",
    "\n",
    "    # for each node, append the probability and z_sample to the list\n",
    "\n",
    "    k = 0 # need this variable to skip \"no digits\" nodes\n",
    "    for i in range(nb_nodes):\n",
    "        j = i - k\n",
    "        if data_tree[i][1] == 'no digits':\n",
    "            k += 1\n",
    "            continue\n",
    "\n",
    "        node_embeddings[i]['prob'].append(node_info[j]['prob'].numpy())\n",
    "        node_embeddings[i]['z_sample'].append(node_info[j]['z_sample'].numpy())\n",
    "\n",
    "# flatten the lists\n",
    "k = 0\n",
    "for i in range(nb_nodes):\n",
    "    if data_tree[i][1] == 'no digits':\n",
    "        node_embeddings[i]['prob'] = []\n",
    "        node_embeddings[i]['z_sample'] = []\n",
    "        continue\n",
    "    \n",
    "    node_embeddings[i]['prob'] = np.concatenate(node_embeddings[i]['prob'])\n",
    "    node_embeddings[i]['z_sample'] = np.concatenate(node_embeddings[i]['z_sample'])\n",
    "\n",
    "label_list = np.concatenate(label_list)\n",
    "\n",
    "# Draw the tree graph with scatter plots as nodes and arrows for edges\n",
    "draw_tree_with_scatter_plots(data_tree, node_embeddings, label_list, pca = use_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = []\n",
    "label_list = []\n",
    "for inputs, labels in tqdm(data_loader):\n",
    "    inputs_list.append(inputs.numpy())\n",
    "    label_list.append(labels.numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_af = np.concatenate(inputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_af[:,:mat_af.shape[1]//2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(mat_af[:,:mat_af.shape[1]//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ar_name = pd.read_csv(configs['data']['varient_path']+'passed_variant_names.txt',header=None,index_col=0)\n",
    "df_obs = pd.read_csv(configs['data']['varient_path']+'cell_label.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell_names = ar_name.loc[adata.obs_names].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index = ar_name.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts'] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata)\n",
    "# Logarithmize the data\n",
    "sc.pp.log1p(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(adata, n_pcs=50, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = df_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"true_label\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"6185A>G\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[\"X_treevae_n0\"] = node_embeddings[0][\"z_sample\"]\n",
    "adata.obsm[\"X_treevae_n1\"] = node_embeddings[1][\"z_sample\"]\n",
    "adata.obsm[\"X_treevae_n2\"] = node_embeddings[2][\"z_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"node_lv1\"] = (((node_embeddings[1][\"prob\"]<0.5)*1)+1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata,use_rep=\"X_treevae_n0\",n_neighbors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=100, facecolor=\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"node_lv1\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"true_label\",\n",
    "    # Setting a smaller point size to get prevent overlap\n",
    "    size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata, 'node_lv1', method='wilcoxon',key_added='rank_genes_node_lv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degs=sc.get.rank_genes_groups_df(adata,'1',key=\"rank_genes_node_lv1\",pval_cutoff=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degs.sort_values(\"logfoldchanges\",ascending=False).to_csv(\"results/bpdcn712_Wald_degs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_degs.head() shows the degree distribution of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dgs= df_degs.sort_values(\"logfoldchanges\",ascending=False)\n",
    "df_dgs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dgs.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.heatmap(adata,  list(df_dgs.head(20).names.values) + list(df_dgs.tail(20).names.values), groupby='node_lv1',swap_axes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Train NMI\n",
    "prob_leaves = predict(gen_train_eval, model, device,'prob_leaves')\n",
    "y = np.squeeze(np.argmax(prob_leaves, axis=-1))\n",
    "print('Train NMI:',normalized_mutual_info_score(y, np.squeeze(y_train)))\n",
    "\n",
    "tot_counts = []\n",
    "print(\"                                  Leaf\", np.arange(10))\n",
    "for i in np.unique(y_test):\n",
    "    list_y_hat, counts = np.unique(y[np.squeeze(y_train)==i], return_counts=True)\n",
    "    for j in range(n_d):\n",
    "        if j not in list_y_hat:\n",
    "            list_y_hat = np.insert(list_y_hat, j, j)\n",
    "            counts = np.insert(counts, j, 0)\n",
    "    tot_counts.append(counts)\n",
    "    print(f\"Class {i:<10}\", list_y_hat, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Test NMI\n",
    "prob_leaves = predict(gen_test, model, device,'prob_leaves')\n",
    "y = np.squeeze(np.argmax(prob_leaves, axis=-1))\n",
    "print('Test NMI:', normalized_mutual_info_score(y, np.squeeze(y_test)))\n",
    "\n",
    "tot_counts = []\n",
    "print(\"                                  Leaf\", np.arange(10))\n",
    "for i in np.unique(y_test):\n",
    "    list_y_hat, counts = np.unique(y[np.squeeze(y_test)==i], return_counts=True)\n",
    "    for j in range(n_d):\n",
    "        if j not in list_y_hat:\n",
    "            list_y_hat = np.insert(list_y_hat, j, j)\n",
    "            counts = np.insert(counts, j, 0)\n",
    "    tot_counts.append(counts)\n",
    "    print(f\"Class {i:<10}\", list_y_hat, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_2\"></a> 2. Generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is concerned with unconditionally generating new samples as opposed to reconstructing existing data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterwise generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, given one unconditional random sampling from the root, we visualize the generations for each leaf. That is, each row corresponds to one sample and each column corresponds to one leaf. Above each generation, we provide the probability of falling into the respective leaf for this sample. \n",
    "\n",
    "This way of visualization can provide insights on the characteristics each leaf is associated with. Observe that the generations differ across the leaves, as each leaf decodes the sample in the style of the cluster that it learnt. It is likely that cluster-differences are observed more strongly than in the reconstructions' section, as here, we have no guiding information from the bottom-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_imgs = 15\n",
    "with torch.no_grad():\n",
    "    reconstructions, p_c_z = model.generate_images(n_imgs, device)\n",
    "reconstructions = move_to(reconstructions, 'cpu')\n",
    "for i in range(n_imgs):\n",
    "    fig, axs = plt.subplots(1, n_d, figsize=(15, 15))\n",
    "    for c in range(n_d):\n",
    "        axs[c].imshow(display_image(reconstructions[c][i]), cmap=plt.get_cmap('gray'))\n",
    "        axs[c].set_title(f\"L{c}: \" + f\"p=%.2f\" % torch.round(p_c_z[i][c],))\n",
    "        axs[c].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new images according to cluster assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, given a leaf, we store the first 100 generations, for which this leaf is their most likely cluster assignment. This allows us to gain insights on the cluster and characteristics that each leaf learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we store generations for each leaf simultaneously until\n",
    "# every leaf has n_imgs associated generations, or we iterated through max_iter batches.\n",
    "n_imgs = configs['training']['batch_size']\n",
    "max_iter = 200\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructions, p_c_z = model.generate_images(n_imgs, device)\n",
    "reconstructions = move_to(reconstructions, 'cpu')\n",
    "clusterwise_reconst = [torch.zeros_like(reconstructions[0][0:2]) for i in range(len(reconstructions))]\n",
    "n_iter=0\n",
    "while min([clusterwise_reconst[leaf_ind].shape[0] for leaf_ind in range(len(reconstructions))]) < n_imgs+2 and n_iter < max_iter:\n",
    "    for i in range(n_imgs):\n",
    "        leaf_ind = torch.argmax(p_c_z[i])\n",
    "        if clusterwise_reconst[leaf_ind].shape[0] < n_imgs+2:\n",
    "            clusterwise_reconst[leaf_ind] = torch.vstack([clusterwise_reconst[leaf_ind], reconstructions[leaf_ind][i].unsqueeze(0)])\n",
    "    with torch.no_grad():\n",
    "        reconstructions, p_c_z = model.generate_images(n_imgs, device)\n",
    "    reconstructions = move_to(reconstructions, 'cpu')\n",
    "    n_iter += 1\n",
    "    if n_iter %10 == 0:\n",
    "        print(n_iter)\n",
    "for i in range(len(reconstructions)):\n",
    "    clusterwise_reconst[i] = clusterwise_reconst[i][2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusterwise_reconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each leaf, we visualize n_grid x n_grid generations, \n",
    "# which have highest probability of being assigned to this cluster\n",
    "n_leaves = len(clusterwise_reconst)\n",
    "n_grid = min(5,int((clusterwise_reconst[leaf_ind].shape[0])**.5))\n",
    "\n",
    "k=0\n",
    "for l in range(n_leaves):\n",
    "        fig, axs = plt.subplots(n_grid, n_grid, figsize=(4,4))\n",
    "        i=0\n",
    "        for a in range(n_grid):\n",
    "            for b in range(n_grid):\n",
    "                try:\n",
    "                        axs[a,b].set_axis_off()\n",
    "                        axs[a,b].imshow(display_image(clusterwise_reconst[k][i]), cmap=plt.get_cmap('gray'))\n",
    "                        i+=1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "        fig.suptitle(f\"Leaf {k} samples\",fontsize=25)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.87)\n",
    "        k+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For closer inspection, one can select a specific leaf by leaf_ind and investigate more generations.\n",
    "leaf_ind = 0\n",
    "    \n",
    "n_grid = int((clusterwise_reconst[leaf_ind].shape[0])**.5)\n",
    "fig, axs = plt.subplots(n_grid, n_grid, figsize=(15,15))\n",
    "\n",
    "i=0\n",
    "for a in range(n_grid):\n",
    "    for b in range(n_grid):\n",
    "        axs[a,b].set_axis_off()\n",
    "        axs[a,b].imshow(display_image(clusterwise_reconst[leaf_ind][i]), cmap=plt.get_cmap('gray'))\n",
    "        i+=1\n",
    "fig.suptitle(f\"Leaf {leaf_ind} samples\",fontsize=25)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_3\"></a> 3. Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is concerned with computing reconstructions of input samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterwise reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, given one input image, we visualize the reconstructions for each leaf. That is, each row corresponds to one input image and each column corresponds to one leaf. Above each reconstruction, we provide the probability of falling into the respective leaf for this sample. \n",
    "\n",
    "This way of visualization can provide insights on the characteristics each leaf is associated with. Observe that the reconstructions differ across the leaves, as each leaf reconstructs the image in the style of the cluster that it learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Set\n",
    "gen_train_eval_iter = iter(gen_train_eval)\n",
    "inputs, labels = next(gen_train_eval_iter)\n",
    "\n",
    "\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Class:\", labels[i].item())\n",
    "    fig, axs = plt.subplots(1, n_d+1, figsize=(15, 15))\n",
    "    axs[n_d].imshow(display_image(inputs[i]), cmap=plt.get_cmap('gray'))\n",
    "    axs[n_d].set_title(\"Original\")\n",
    "    axs[n_d].axis('off')\n",
    "    for c in range(n_d):\n",
    "        axs[c].imshow(display_image(reconstructions[c][i]), cmap=plt.get_cmap('gray'))\n",
    "        axs[c].set_title(f\"L{c}: \" + f\"p=%.2f\" % torch.round(node_leaves[c]['prob'][i]))\n",
    "        axs[c].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test Set\n",
    "gen_test_iter = iter(gen_test)\n",
    "inputs, labels = next(gen_test_iter)\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Class:\", labels[i].item())\n",
    "    fig, axs = plt.subplots(1, n_d+1, figsize=(15, 15))\n",
    "    axs[n_d].imshow(display_image(inputs[i]), cmap=plt.get_cmap('gray'))\n",
    "    axs[n_d].set_title(\"Original\")\n",
    "    axs[n_d].axis('off')\n",
    "    for c in range(n_d):\n",
    "        axs[c].imshow(display_image(reconstructions[c][i]), cmap=plt.get_cmap('gray'))\n",
    "        axs[c].set_title(f\"L{c}: \" + f\"p=%.2f\" % torch.round(node_leaves[c]['prob'][i]))\n",
    "        axs[c].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group reconstructions according to cluster assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, given a leaf, we store the reconstructions of the first 100 samples, for which this leaf is their most likely cluster assignment. This allows us to visualize for each leaf, which samples fall into it, in order to gain insights on the cluster that each leaf learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "# Here, we store samples for each leaf simultaneously by iterating through the training set until\n",
    "# every leaf has n_imgs associated samples, or we iterated through max_iter batches.\n",
    "max_iter = 100\n",
    "n_imgs = configs['training']['batch_size']\n",
    "\n",
    "n_iter=0\n",
    "gen_test_iter = iter(gen_test)\n",
    "inputs, labels = next(gen_test_iter)\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "p_c_z = torch.stack([node_leaves[i]['prob'] for i in range(len(node_leaves))],1)\n",
    "clusterwise_reconst = [torch.zeros_like(reconstructions[0][0:2]) for i in range(len(reconstructions))]\n",
    "while min([clusterwise_reconst[leaf_ind].shape[0] for leaf_ind in range(len(reconstructions))]) < n_imgs+2 and n_iter < max_iter:\n",
    "    n_iter += 1\n",
    "    if n_iter %10 == 0:\n",
    "        print(n_iter)\n",
    "    for i in range(n_imgs):\n",
    "        leaf_ind = p_c_z[i].numpy().argmax()\n",
    "        if clusterwise_reconst[leaf_ind].shape[0] < n_imgs+2:\n",
    "            clusterwise_reconst[leaf_ind] = torch.vstack([clusterwise_reconst[leaf_ind], reconstructions[leaf_ind][i].unsqueeze(0)])\n",
    "    inputs, labels = next(gen_test_iter)\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "    reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "    node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "    p_c_z = torch.stack([node_leaves[i]['prob'] for i in range(len(node_leaves))],1)\n",
    "for i in range(len(reconstructions)):\n",
    "    clusterwise_reconst[i] = clusterwise_reconst[i][2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each leaf, we visualize n_grid x n_grid reconstructions of samples, \n",
    "# which have highest probability of being assigned to this cluster\n",
    "n_leaves = len(clusterwise_reconst)\n",
    "n_grid = min(5,int((clusterwise_reconst[leaf_ind].shape[0])**.5))\n",
    "\n",
    "k=0\n",
    "for l in range(n_leaves):\n",
    "        fig, axs = plt.subplots(n_grid, n_grid, figsize=(4,4))\n",
    "        i=0\n",
    "        for a in range(n_grid):\n",
    "            for b in range(n_grid):\n",
    "                axs[a,b].set_axis_off()\n",
    "                axs[a,b].imshow(display_image(clusterwise_reconst[k][i]), cmap=plt.get_cmap('gray'))\n",
    "                i+=1\n",
    "        fig.suptitle(f\"Leaf {k} samples\",fontsize=25)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.87)\n",
    "        k+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For closer inspection, one can select a specific leaf by leaf_ind and investigate more reconstructions.\n",
    "leaf_ind = 0\n",
    "    \n",
    "n_grid = int((clusterwise_reconst[leaf_ind].shape[0])**.5)\n",
    "fig, axs = plt.subplots(n_grid, n_grid, figsize=(15,15))\n",
    "\n",
    "i=0\n",
    "for a in range(n_grid):\n",
    "    for b in range(n_grid):\n",
    "        axs[a,b].set_axis_off()\n",
    "        axs[a,b].imshow(display_image(clusterwise_reconst[leaf_ind][i]), cmap=plt.get_cmap('gray'))\n",
    "        i+=1\n",
    "fig.suptitle(f\"Leaf {leaf_ind} samples\",fontsize=25)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_4\"></a> 4. Tree and Representation Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we explore the structure of the learnt tree as well as the representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we visualize the learnt embeddings by performing PCA on each node. Set use_pca to False if you want to directly see the first two dimensions without dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want to look at pca embeddings or learnt representations\n",
    "use_pca = True\n",
    "\n",
    "# pick data loader\n",
    "data_loader = gen_test\n",
    "\n",
    "\n",
    "# each entry in node_embeddings is a dictionary with keys 'prob' and 'z_sample' for each leaf\n",
    "nb_nodes = len(data_tree)\n",
    "node_embeddings = [{'prob': [], 'z_sample': []} for _ in range(nb_nodes)]\n",
    "label_list = []\n",
    "\n",
    "# iterate over test data points\n",
    "for inputs, labels in tqdm(data_loader):\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "\n",
    "    label_list.append(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        node_info = get_node_embeddings(model, inputs_gpu)\n",
    "    node_info = move_to(node_info, 'cpu')\n",
    "\n",
    "    # for each node, append the probability and z_sample to the list\n",
    "\n",
    "    k = 0 # need this variable to skip \"no digits\" nodes\n",
    "    for i in range(nb_nodes):\n",
    "        j = i - k\n",
    "        if data_tree[i][1] == 'no digits':\n",
    "            k += 1\n",
    "            continue\n",
    "\n",
    "        node_embeddings[i]['prob'].append(node_info[j]['prob'].numpy())\n",
    "        node_embeddings[i]['z_sample'].append(node_info[j]['z_sample'].numpy())\n",
    "\n",
    "# flatten the lists\n",
    "k = 0\n",
    "for i in range(nb_nodes):\n",
    "    if data_tree[i][1] == 'no digits':\n",
    "        node_embeddings[i]['prob'] = []\n",
    "        node_embeddings[i]['z_sample'] = []\n",
    "        continue\n",
    "    \n",
    "    node_embeddings[i]['prob'] = np.concatenate(node_embeddings[i]['prob'])\n",
    "    node_embeddings[i]['z_sample'] = np.concatenate(node_embeddings[i]['z_sample'])\n",
    "\n",
    "label_list = np.concatenate(label_list)\n",
    "\n",
    "# Draw the tree graph with scatter plots as nodes and arrows for edges\n",
    "draw_tree_with_scatter_plots(data_tree, node_embeddings, label_list, pca = use_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaf embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we visualize the learnt leaf embeddings after performing PCA. This allows for a closer inspection of the leaf embeddings, which are also visualized in the tree above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get leaf embeddings for each test data point\n",
    "gen_test_iter = iter(gen_test)\n",
    "inputs, labels = next(gen_test_iter)\n",
    "inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructions_gpu, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "reconstructions = move_to(reconstructions_gpu, 'cpu')\n",
    "node_leaves = move_to(node_leaves_gpu, 'cpu')\n",
    "\n",
    "# each entry in node_leaves is a dictionary with keys 'prob' and 'z_sample' for each leaf\n",
    "node_leaves = [{'prob': [], 'z_sample': []} for _ in range(n_d)]\n",
    "label_list = []\n",
    "\n",
    "for inputs, labels in tqdm(gen_test):\n",
    "    inputs_gpu, labels_gpu = inputs.to(device), labels.to(device)\n",
    "\n",
    "    label_list.append(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, node_leaves_gpu = model.compute_reconstruction(inputs_gpu)\n",
    "        node_leaves_cpu = move_to(node_leaves_gpu, 'cpu')\n",
    "        \n",
    "    # for each leaf, append the probability and z_sample to the list\n",
    "    for i in range(n_d):\n",
    "        node_leaves[i]['prob'].append(node_leaves_cpu[i]['prob'].numpy())\n",
    "        node_leaves[i]['z_sample'].append(node_leaves_cpu[i]['z_sample'].numpy())\n",
    "\n",
    "# flatten the lists\n",
    "for i in range(n_d):\n",
    "    node_leaves[i]['prob'] = np.concatenate(node_leaves[i]['prob'])\n",
    "    node_leaves[i]['z_sample'] = np.concatenate(node_leaves[i]['z_sample'])\n",
    "\n",
    "label_list = np.concatenate(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize z_sample for each leaf, do PCA and plot in 2D\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA on node_leaves['z_sample']\n",
    "colors = label_list\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(n_d):\n",
    "    z_sample = node_leaves[i]['z_sample']\n",
    "    weights = node_leaves[i]['prob']\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    z_sample_pca = pca.fit_transform(z_sample)\n",
    "\n",
    "    plt.subplot(2, -(-len(node_leaves)//2), i+1)\n",
    "    plt.scatter(z_sample_pca[:, 0], z_sample_pca[:, 1], c=colors, cmap='tab10', alpha=weights)\n",
    "    plt.title(f\"Leaf {i}\")\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"section_5\"></a> 5. CelebA attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is designated for analyzing the learnt splits and clusters of datasets without ground truth cluster labels, but various attributes. It is designed with a focus on CelebA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert configs['data']['data_name'] == 'celeba'\n",
    "import pandas as pd\n",
    "data_dir = './data/celeba/'\n",
    "attr = pd.read_csv(data_dir+'/list_attr_celeba.txt', sep=\"\\s+\", skiprows=1)\n",
    "y_test = attr[182637:]\n",
    "y_train = attr[:162770]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cluster-matching attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing step where we store for every node, the indeces of the test samples, whose most likely path went through said node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to leafwise view of samples\n",
    "prob_leaves = predict(gen_test, model, device,'prob_leaves')\n",
    "y = np.squeeze(np.argmax(prob_leaves, axis=-1))\n",
    "sample_ind = []\n",
    "for i in range(len(np.unique(y))):\n",
    "    sample_ind.append([])\n",
    "for i in np.unique(y):\n",
    "    sample_ind[i] = np.where(y==i)[0]\n",
    "    \n",
    "# Fill all internal nodes and create datatree with corresponding samples\n",
    "data_tree_ids = []\n",
    "for i in range(len(data_tree)):\n",
    "    data_tree_ids.append([i,[]])\n",
    "for listnode in reversed(data_tree_ids):\n",
    "    i = listnode[0]\n",
    "    if data_tree[i][3] == 1:\n",
    "        # If leaf, just copy samples from above\n",
    "        data_tree_ids[i][1] = sample_ind[i-(len(data_tree_ids)-len(sample_ind))]\n",
    "    else:\n",
    "        # If internal node, take samples from children\n",
    "        children = []\n",
    "        for j in range(len(data_tree)):\n",
    "            if data_tree[j][2] == i:\n",
    "                children.append(j)\n",
    "        assert len(children)==2\n",
    "        data_tree_ids[i][1] = np.sort(np.concatenate((data_tree_ids[children[0]][1],data_tree_ids[children[1]][1])))\n",
    "        \n",
    "        \n",
    "        \n",
    "# Final ID-tree, where for each node, we store which test sample went through it\n",
    "data_tree_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each split, we additionally store the five attribute that correlate most highly with the the split. This gives an intuition on what attributes the split is based on, i.e. which characteristics the split differentiates between.\n",
    "\n",
    "Note that for CelebA, the \"ground truth\" attributes are in our opinion not the most descriptive ones regarding overall image&cluster impression and focus sometimes on details, on which we don't pick up on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Highest correlated features per split\n",
    "data_tree_new = data_tree.copy()\n",
    "for i in range(len(data_tree_ids)):\n",
    "    in_leaf = False\n",
    "    node_ind = data_tree_ids[i][1]\n",
    "    # Samples in node before split\n",
    "    node_samples = y_test.iloc[node_ind]\n",
    "    # Split of samples\n",
    "    node_split = np.zeros(len(y_test))\n",
    "    children = []\n",
    "    for j in range(len(data_tree)):\n",
    "        if data_tree[j][2] == i:\n",
    "            children.append(j)\n",
    "        if children == []:\n",
    "            in_leaf = True\n",
    "        else:\n",
    "            in_leaf = False\n",
    "    if not in_leaf: \n",
    "        child_left = children[0]\n",
    "        node_split[data_tree_ids[child_left][1]] = 1\n",
    "        node_split = node_split[node_ind]\n",
    "        # Store corr coefficients\n",
    "        corr = np.corrcoef(np.concatenate((np.array(node_samples),np.expand_dims(node_split,1)),1).T)[len(y_test.columns),0:len(y_test.columns)]\n",
    "        data_tree_ids[i].append(corr)\n",
    "        \n",
    "        # Store 5 strongest correlations\n",
    "        ind = np.abs(corr).argsort()[-5:][::-1]\n",
    "        features = y_test.columns[ind].tolist()\n",
    "        for k in range(len(ind)):\n",
    "            if corr[ind[k]] < 0:\n",
    "                features[k] = 'not ' + features[k]\n",
    "            features[k] = features[k] + ' ({})'.format(round(corr[ind[k]], 2))\n",
    "        data_tree_ids[i].append(features)\n",
    "        \n",
    "data_tree_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a summary, for each attribute, we print the split that has the highest correlation with it. This gives an intuition on what internal node differentiates the most according to a given attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributewise node with highest correlation (i.e. internal node that was splitting attribute the most)\n",
    "attr_maxnode = y_test.columns.tolist()\n",
    "for i in range(len(y_test.columns)):\n",
    "    attrcorr = []\n",
    "    for node in range(len(data_tree_ids)):\n",
    "        if len(data_tree_ids[node])==len(data_tree_ids[0]):\n",
    "            attrcorr.append(data_tree_ids[node][2][i])\n",
    "    attrcorr = np.array(attrcorr)\n",
    "    if len(np.argwhere(np.isnan(attrcorr)).squeeze(1))>0:\n",
    "        attrcorr[np.argwhere(np.isnan(attrcorr)).squeeze(1)] = 0\n",
    "    ind = np.argmax(np.abs(attrcorr))\n",
    "    attr_maxnode[i] = attr_maxnode[i] + \": \" + f'{ind}' ' ({})'.format(round(attrcorr[ind], 2))\n",
    "attr_maxnode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the clustering quality according to certain attributes. To do this, in the second cell, pick the indeces of the attributes, whose intersections you want to determine as ground truth clusterings. Then, the NMI is calculated for treating the selected attributes' intersections as ground-truth clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick labels here\n",
    "label_ind = [2,20,39]\n",
    "print([attr_maxnode[i] for i in label_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(label_ind)==2:\n",
    "    label_dict = {\n",
    "        (-1, -1): 0,\n",
    "        (-1, 1): 1,\n",
    "        (1, -1): 2,\n",
    "        (1, 1): 3\n",
    "    }\n",
    "else:\n",
    "    label_dict = {\n",
    "        (-1, -1, -1): 0,\n",
    "        (-1, -1, 1): 1,\n",
    "        (-1, 1, -1): 2,\n",
    "        (-1, 1, 1): 3,\n",
    "        (1, -1, -1): 4,\n",
    "        (1, -1, 1): 5,\n",
    "        (1, 1, -1): 6,\n",
    "        (1, 1, 1): 7\n",
    "    }\n",
    "selected_classes = np.array(y_test.iloc[:, label_ind])\n",
    "selected_classes = [tuple([x for x in a]) for a in selected_classes]\n",
    "label_true = [label_dict[sample_labels] for sample_labels in selected_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NMI:')\n",
    "normalized_mutual_info_score(y, label_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create attribute-wise percentage table for leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subsection presents the frequency of the attributes for each leaf. The numbers indicate the percentage of samples assigned to a given leaf, that contain a certain attribute. For example: 67% of all people assigned to leaf 3 are blonde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_attr = []\n",
    "n_leaves = len(np.unique(y))\n",
    "for i in range(1,1+n_leaves):\n",
    "    data_tree_ids[-i].append((y_test.iloc[data_tree_ids[-i][1]] == 1).mean())\n",
    "    leaf_attr.append((y_test.iloc[data_tree_ids[-i][1]] == 1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_attr_table = pd.DataFrame(np.stack(leaf_attr)[::-1])\n",
    "leaf_attr_table.columns = y_test.columns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "leaf_attr_table.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, one can create new attributes by combining previous attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vars =[]\n",
    "for i in range(1,1+n_leaves):\n",
    "    temp = y_test.iloc[data_tree_ids[-i][1]] == 1\n",
    "    temp['Hair_Loss'] = np.clip(temp['Bald'] + temp['Receding_Hairline'],0,1)\n",
    "    temp['Dark_Hair'] = np.clip(temp['Brown_Hair'] + temp['Black_Hair'],0,1)\n",
    "    temp['Happy'] = np.clip(temp['Smiling'] + temp['Mouth_Slightly_Open'],0,1)\n",
    "    temp['Light_Hair'] = np.clip(temp['Blond_Hair'] + temp['Gray_Hair'],0,1)\n",
    "    temp['Beard'] = np.clip(temp['5_o_Clock_Shadow'] + 1-temp['No_Beard'],0,1)\n",
    "\n",
    "    new_vars.append([temp['Hair_Loss'].mean(),temp['Dark_Hair'].mean(),temp['Happy'].mean(),temp['Light_Hair'].mean(),temp['Beard'].mean()])\n",
    "    \n",
    "new_vars_table = pd.DataFrame(np.stack(new_vars)[::-1])\n",
    "new_vars_table.columns = ['Hair_Loss','Dark_Hair','Happy','Light_Hair','Beard']\n",
    "new_vars_table.round(3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA-FM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
